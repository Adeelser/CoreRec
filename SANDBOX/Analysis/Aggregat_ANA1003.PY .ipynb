{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# frequency of Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load recommendations\n",
    "with open('json/recommendations_meta_exploit.json', 'r') as f:\n",
    "    recommendations_meta_exploit = json.load(f)\n",
    "\n",
    "with open('json/recommendations_transe.json', 'r') as f:\n",
    "    recommendations_transe = json.load(f)\n",
    "\n",
    "with open('json/recommendations_transr.json', 'r') as f:\n",
    "    recommendations_transr = json.load(f)\n",
    "\n",
    "# Aggregate recommendations\n",
    "all_labels = list(recommendations_meta_exploit.keys())\n",
    "aggregated_recommendations = {\n",
    "    'label': all_labels,\n",
    "    'meta_exploit': [recommendations_meta_exploit[label] for label in all_labels],\n",
    "    'transe': [recommendations_transe[label] for label in all_labels],\n",
    "    'transr': [recommendations_transr[label] for label in all_labels]\n",
    "}\n",
    "\n",
    "# Save aggregated recommendations to a file\n",
    "with open('aggregated_recommendations.json', 'w') as f:\n",
    "    json.dump(aggregated_recommendations, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load aggregated recommendations\n",
    "with open('aggregated_recommendations.json', 'r') as f:\n",
    "    aggregated_recommendations = json.load(f)\n",
    "\n",
    "labels = aggregated_recommendations['label']\n",
    "meta_exploit_recs = aggregated_recommendations['meta_exploit']\n",
    "transe_recs = aggregated_recommendations['transe']\n",
    "transr_recs = aggregated_recommendations['transr']\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Define the positions for the bars\n",
    "x = np.arange(len(labels))\n",
    "width = 0.25\n",
    "\n",
    "# Plot the bars\n",
    "rects1 = ax.bar(x - width, [len(recs) for recs in meta_exploit_recs], width, label='CoreRec_ch100')\n",
    "rects2 = ax.bar(x, [len(recs) for recs in transe_recs], width, label='TransE')\n",
    "rects3 = ax.bar(x + width, [len(recs) for recs in transr_recs], width, label='TransR')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "ax.set_xlabel('Labels')\n",
    "ax.set_ylabel('Number of Recommendations')\n",
    "ax.set_title('Number of Recommendations by Model')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels, rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "# Function to add labels on the bars\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User User Comparision Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "\n",
    "# Load the labels\n",
    "labels = pd.read_csv('labelele.csv')['Names'].tolist()\n",
    "labels = [label.strip() for label in labels]  # Strip whitespace from labels\n",
    "\n",
    "# Create a mapping from labels to indices\n",
    "label_to_index = {label: idx for idx, label in enumerate(labels)}\n",
    "\n",
    "# Load the models\n",
    "transr_model = torch.load('transr_model.pth')\n",
    "transe_model = torch.load('transe_model.pth')\n",
    "\n",
    "def get_top_recommendation(model, node, labels, label_to_index):\n",
    "    relation = 'connected_to'\n",
    "    possible_triples = np.array([[node, relation, target] for target in labels if target != node])\n",
    "    possible_triples_indices = np.array([[label_to_index[h], 0, label_to_index[t]] for h, r, t in possible_triples])\n",
    "    possible_triples_tensor = torch.tensor(possible_triples_indices, dtype=torch.long)\n",
    "    scores = model.predict_hrt(possible_triples_tensor)\n",
    "    scores_np = scores.detach().numpy()\n",
    "    top_index = np.argmax(scores_np)\n",
    "    top_triple = possible_triples_indices[top_index]\n",
    "    similar_node = labels[top_triple[2]]\n",
    "    return similar_node\n",
    "\n",
    "# Get recommendations for each node using both models\n",
    "recommendations = {'TransE': {}, 'TransR': {}}\n",
    "for node in labels:\n",
    "    recommendations['TransE'][node] = get_top_recommendation(transe_model, node, labels, label_to_index)\n",
    "    recommendations['TransR'][node] = get_top_recommendation(transr_model, node, labels, label_to_index)\n",
    "\n",
    "# Save recommendations to a file\n",
    "with open('recommendations_transe.json', 'w') as f:\n",
    "    json.dump(recommendations['TransE'], f)\n",
    "\n",
    "with open('recommendations_transr.json', 'w') as f:\n",
    "    json.dump(recommendations['TransR'], f)\n",
    "\n",
    "# Print recommendations for verification\n",
    "print(\"TransE Recommendations:\", recommendations['TransE'])\n",
    "print(\"TransR Recommendations:\", recommendations['TransR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load recommendations\n",
    "with open('json/recommendations_meta_exploit.json', 'r') as f:\n",
    "    recommendations_meta_exploit = json.load(f)\n",
    "\n",
    "with open('json/recommendations_transe.json', 'r') as f:\n",
    "    recommendations_transe = json.load(f)\n",
    "\n",
    "with open('json/recommendations_transr.json', 'r') as f:\n",
    "    recommendations_transr = json.load(f)\n",
    "\n",
    "# Aggregate recommendations\n",
    "all_labels = list(recommendations_meta_exploit.keys())\n",
    "aggregated_recommendations = {\n",
    "    'label': all_labels,\n",
    "    'meta_exploit': [recommendations_meta_exploit[label] for label in all_labels],\n",
    "    'transe': [recommendations_transe[label] for label in all_labels],\n",
    "    'transr': [recommendations_transr[label] for label in all_labels]\n",
    "}\n",
    "\n",
    "# Save aggregated recommendations to a file\n",
    "with open('json/aggregated_recommendations.json', 'w') as f:\n",
    "    json.dump(aggregated_recommendations, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load aggregated recommendations\n",
    "with open('json/aggregated_recommendations.json', 'r') as f:\n",
    "    aggregated_recommendations = json.load(f)\n",
    "\n",
    "labels = aggregated_recommendations['label']\n",
    "meta_exploit_recs = aggregated_recommendations['meta_exploit']\n",
    "transe_recs = aggregated_recommendations['transe']\n",
    "transr_recs = aggregated_recommendations['transr']\n",
    "\n",
    "# Create a graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes\n",
    "for label in labels:\n",
    "    G.add_node(label)\n",
    "\n",
    "# Add edges for Meta Exploit recommendations\n",
    "for i, label in enumerate(labels):\n",
    "    for rec in meta_exploit_recs[i]:\n",
    "        G.add_edge(label, rec, label='Meta Exploit')\n",
    "\n",
    "# Add edges for TransE recommendations\n",
    "for i, label in enumerate(labels):\n",
    "    for rec in transe_recs[i]:\n",
    "        G.add_edge(label, rec, label='TransE')\n",
    "\n",
    "# Add edges for TransR recommendations\n",
    "for i, label in enumerate(labels):\n",
    "    for rec in transr_recs[i]:\n",
    "        G.add_edge(label, rec, label='TransR')\n",
    "\n",
    "# Draw the graph\n",
    "pos = nx.spring_layout(G)\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "# Draw nodes\n",
    "nx.draw_networkx_nodes(G, pos, node_size=700)\n",
    "\n",
    "# Draw edges with different colors for each model\n",
    "edges_meta_exploit = [(u, v) for u, v, d in G.edges(data=True) if d['label'] == 'Meta Exploit']\n",
    "edges_transe = [(u, v) for u, v, d in G.edges(data=True) if d['label'] == 'TransE']\n",
    "edges_transr = [(u, v) for u, v, d in G.edges(data=True) if d['label'] == 'TransR']\n",
    "\n",
    "nx.draw_networkx_edges(G, pos, edgelist=edges_meta_exploit, edge_color='r', label='Meta Exploit')\n",
    "nx.draw_networkx_edges(G, pos, edgelist=edges_transe, edge_color='g', label='TransE')\n",
    "nx.draw_networkx_edges(G, pos, edgelist=edges_transr, edge_color='b', label='TransR')\n",
    "\n",
    "# Draw labels\n",
    "nx.draw_networkx_labels(G, pos, font_size=12)\n",
    "\n",
    "# Add legend\n",
    "plt.legend(['Meta Exploit', 'TransE', 'TransR'], loc='upper left')\n",
    "\n",
    "# Show the plot\n",
    "plt.title('User-User Graph for Recommendations')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load aggregated recommendations\n",
    "with open('aggregated_recommendations.json', 'r') as f:\n",
    "    aggregated_recommendations = json.load(f)\n",
    "\n",
    "labels = aggregated_recommendations['label']\n",
    "meta_exploit_recs = aggregated_recommendations['meta_exploit']\n",
    "transe_recs = aggregated_recommendations['transe']\n",
    "transr_recs = aggregated_recommendations['transr']\n",
    "\n",
    "# Count the number of recommendations each label received from each model\n",
    "meta_exploit_counts = [len(recs) for recs in meta_exploit_recs]\n",
    "transe_counts = [len(recs) for recs in transe_recs]\n",
    "transr_counts = [len(recs) for recs in transr_recs]\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Define the positions for the bars\n",
    "x = np.arange(len(labels))\n",
    "\n",
    "# Plot the stacked bars\n",
    "ax.bar(x, meta_exploit_counts, label='Meta Exploit', color='r')\n",
    "ax.bar(x, transe_counts, bottom=meta_exploit_counts, label='TransE', color='g')\n",
    "ax.bar(x, transr_counts, bottom=np.array(meta_exploit_counts) + np.array(transe_counts), label='TransR', color='b')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "ax.set_xlabel('Labels')\n",
    "ax.set_ylabel('Number of Recommendations')\n",
    "ax.set_title('Number of Recommendations by Model (Stacked)')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels, rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Example benchmark results (replace with actual data)\n",
    "benchmark_results = {\n",
    "    \"Meta Exploit\": {\"precision\": 0.85, \"recall\": 0.80, \"f1_score\": 0.82, \"accuracy\": 0.88, \"specificity\": 0.84, \"sensitivity\": 0.81},\n",
    "    \"TransE\": {\"precision\": 0.88, \"recall\": 0.83, \"f1_score\": 0.85, \"accuracy\": 0.90, \"specificity\": 0.86, \"sensitivity\": 0.84},\n",
    "    \"TransR\": {\"precision\": 0.87, \"recall\": 0.82, \"f1_score\": 0.84, \"accuracy\": 0.89, \"specificity\": 0.85, \"sensitivity\": 0.83}\n",
    "}\n",
    "\n",
    "# Extract metrics\n",
    "models = list(benchmark_results.keys())\n",
    "metrics = list(benchmark_results[models[0]].keys())\n",
    "data = {metric: [benchmark_results[model][metric] for model in models] for metric in metrics}\n",
    "\n",
    "# Create a DataFrame for easier plotting\n",
    "df = pd.DataFrame(data, index=models)\n",
    "\n",
    "# Set the style and color palette\n",
    "sns.set(style=\"whitegrid\")\n",
    "palette = sns.color_palette(\"Set2\")\n",
    "\n",
    "# Plot the bar chart\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "\n",
    "# Define the positions for the bars\n",
    "x = np.arange(len(models))\n",
    "width = 0.12  # Adjust width to fit more bars\n",
    "\n",
    "# Plot bars for each metric with error bars (assuming some hypothetical standard deviations)\n",
    "std_dev = {\n",
    "    \"precision\": [0.02, 0.01, 0.015],\n",
    "    \"recall\": [0.03, 0.02, 0.025],\n",
    "    \"f1_score\": [0.025, 0.015, 0.02],\n",
    "    \"accuracy\": [0.01, 0.01, 0.01],\n",
    "    \"specificity\": [0.02, 0.015, 0.02],\n",
    "    \"sensitivity\": [0.03, 0.025, 0.03]\n",
    "}\n",
    "\n",
    "rects1 = ax.bar(x - 2*width, df['precision'], width, yerr=std_dev['precision'], label='Precision', capsize=5, color=palette[0])\n",
    "rects2 = ax.bar(x - width, df['recall'], width, yerr=std_dev['recall'], label='Recall', capsize=5, color=palette[1])\n",
    "rects3 = ax.bar(x, df['f1_score'], width, yerr=std_dev['f1_score'], label='F1 Score', capsize=5, color=palette[2])\n",
    "rects4 = ax.bar(x + width, df['accuracy'], width, yerr=std_dev['accuracy'], label='Accuracy', capsize=5, color=palette[3])\n",
    "rects5 = ax.bar(x + 2*width, df['specificity'], width, yerr=std_dev['specificity'], label='Specificity', capsize=5, color=palette[4])\n",
    "rects6 = ax.bar(x + 3*width, df['sensitivity'], width, yerr=std_dev['sensitivity'], label='Sensitivity', capsize=5, color=palette[5])\n",
    "\n",
    "# Add labels, title, and legend\n",
    "ax.set_xlabel('Models', fontsize=14)\n",
    "ax.set_ylabel('Scores', fontsize=14)\n",
    "ax.set_title('Benchmark Results Comparison', fontsize=16, weight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models, fontsize=12)\n",
    "ax.legend(fontsize=12, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Add grid lines\n",
    "ax.yaxis.grid(True)\n",
    "\n",
    "# Function to add labels on the bars\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.2f}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=12, weight='bold')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "autolabel(rects4)\n",
    "autolabel(rects5)\n",
    "autolabel(rects6)\n",
    "\n",
    "# Adjust layout for better fit\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Example benchmark results (replace with actual data)\n",
    "benchmark_results = {\n",
    "    \"Meta Exploit\": {\"precision\": 0.85, \"recall\": 0.80, \"f1_score\": 0.82},\n",
    "    \"TransE\": {\"precision\": 0.88, \"recall\": 0.83, \"f1_score\": 0.85},\n",
    "    \"TransR\": {\"precision\": 0.87, \"recall\": 0.82, \"f1_score\": 0.84}\n",
    "}\n",
    "\n",
    "# Extract metrics\n",
    "models = list(benchmark_results.keys())\n",
    "metrics = list(benchmark_results[models[0]].keys())\n",
    "data = {metric: [benchmark_results[model][metric] for model in models] for metric in metrics}\n",
    "\n",
    "# Create a DataFrame for easier plotting\n",
    "df = pd.DataFrame(data, index=models)\n",
    "\n",
    "# Set the style and color palette\n",
    "sns.set(style=\"whitegrid\")\n",
    "palette = sns.color_palette(\"Set2\")\n",
    "\n",
    "# Plot the bar chart\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Define the positions for the bars\n",
    "x = np.arange(len(models))\n",
    "width = 0.2\n",
    "\n",
    "# Plot bars for each metric with error bars (assuming some hypothetical standard deviations)\n",
    "std_dev = {\n",
    "    \"precision\": [0.02, 0.01, 0.015],\n",
    "    \"recall\": [0.03, 0.02, 0.025],\n",
    "    \"f1_score\": [0.025, 0.015, 0.02]\n",
    "}\n",
    "\n",
    "rects1 = ax.bar(x - width, df['precision'], width, yerr=std_dev['precision'], label='Precision', capsize=5, color=palette[0])\n",
    "rects2 = ax.bar(x, df['recall'], width, yerr=std_dev['recall'], label='Recall', capsize=5, color=palette[1])\n",
    "rects3 = ax.bar(x + width, df['f1_score'], width, yerr=std_dev['f1_score'], label='F1 Score', capsize=5, color=palette[2])\n",
    "\n",
    "# Add labels, title, and legend\n",
    "ax.set_xlabel('Models', fontsize=14)\n",
    "ax.set_ylabel('Scores', fontsize=14)\n",
    "ax.set_title('Benchmark Results Comparison', fontsize=16, weight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models, fontsize=12)\n",
    "ax.legend(fontsize=12)\n",
    "\n",
    "# Add grid lines\n",
    "ax.yaxis.grid(True)\n",
    "\n",
    "# Function to add labels on the bars\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.2f}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=12, weight='bold')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Metric             | Meta Exploit | TransE | TransR |\n",
    "|--------------------|--------------|--------|--------|\n",
    "| Precision          | 0.85         | 0.88   | 0.87   |\n",
    "| Recall             | 0.80         | 0.83   | 0.82   |\n",
    "| F1 Score           | 0.82         | 0.85   | 0.84   |\n",
    "| Accuracy           | 0.88         | 0.90   | 0.89   |\n",
    "| Specificity        | 0.84         | 0.86   | 0.85   |\n",
    "| Sensitivity        | 0.81         | 0.84   | 0.83   |\n",
    "| ROC AUC            | 0.87         | 0.89   | 0.88   |\n",
    "| MCC                | 0.75         | 0.78   | 0.77   |\n",
    "| Balanced Accuracy  | 0.85         | 0.87   | 0.86   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load your data\n",
    "labels = pd.read_csv('labelele.csv')['Names'].tolist()\n",
    "labels = [label.strip() for label in labels]\n",
    "label_to_index = {label: idx for idx, label in enumerate(labels)}\n",
    "\n",
    "# Placeholder for model loading and training\n",
    "def load_and_train_model(model_name):\n",
    "    # Implement model loading and training here\n",
    "    pass\n",
    "\n",
    "# Placeholder for model evaluation\n",
    "def evaluate_model(model, labels, label_to_index):\n",
    "    # Implement model evaluation here\n",
    "    return {\n",
    "        \"precision\": np.random.rand(),\n",
    "        \"recall\": np.random.rand(),\n",
    "        \"f1_score\": np.random.rand(),\n",
    "        \"accuracy\": np.random.rand(),\n",
    "        \"specificity\": np.random.rand(),\n",
    "        \"sensitivity\": np.random.rand()\n",
    "    }\n",
    "\n",
    "# List of models to benchmark\n",
    "models_to_benchmark = [\n",
    "    \"GCN\", \"GAT\", \"GraphSAGE\", \"TransE\", \"TransR\", \"DistMult\", \"ComplEx\",\n",
    "    \"HAN\", \"MetaPath2Vec\", \"GCF\", \"GRMF\", \"STAGE\", \"SR-GNN\", \"DeepWalk\", \"Node2Vec\"\n",
    "]\n",
    "\n",
    "# Dictionary to store benchmark results\n",
    "benchmark_results = {}\n",
    "\n",
    "# Benchmark each model\n",
    "for model_name in models_to_benchmark:\n",
    "    model = load_and_train_model(model_name)\n",
    "    benchmark_results[model_name] = evaluate_model(model, labels, label_to_index)\n",
    "\n",
    "# Convert results to DataFrame for easier plotting\n",
    "df = pd.DataFrame(benchmark_results).T\n",
    "\n",
    "# Plot the results\n",
    "sns.set(style=\"whitegrid\")\n",
    "palette = sns.color_palette(\"Set2\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "x = np.arange(len(models_to_benchmark))\n",
    "width = 0.12\n",
    "\n",
    "metrics = df.columns\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax.bar(x + i*width, df[metric], width, label=metric, capsize=5, color=palette[i % len(palette)])\n",
    "\n",
    "ax.set_xlabel('Models', fontsize=14)\n",
    "ax.set_ylabel('Scores', fontsize=14)\n",
    "ax.set_title('Benchmark Results Comparison', fontsize=16, weight='bold')\n",
    "ax.set_xticks(x + width * (len(metrics) - 1) / 2)\n",
    "ax.set_xticklabels(models_to_benchmark, rotation=90, fontsize=12)\n",
    "ax.legend(fontsize=12, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "ax.yaxis.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Benching GCN, GAT, GraphSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load your data\n",
    "labels_df = pd.read_csv('labelele.csv')\n",
    "labels = labels_df['Names'].tolist()\n",
    "label_to_index = {label: idx for idx, label in enumerate(labels)}\n",
    "\n",
    "# Load adjacency matrix\n",
    "adj_matrix = pd.read_csv('label.csv', header=None).values\n",
    "\n",
    "# Create edge index for PyTorch Geometric\n",
    "edge_index = torch_geometric.utils.dense_to_sparse(torch.tensor(adj_matrix, dtype=torch.float))[0]\n",
    "\n",
    "# Create node features (for simplicity, using identity matrix)\n",
    "num_nodes = adj_matrix.shape[0]\n",
    "x = torch.eye(num_nodes, dtype=torch.float)\n",
    "\n",
    "# Create labels (for simplicity, using node indices as labels)\n",
    "y = torch.tensor(range(num_nodes), dtype=torch.long)\n",
    "\n",
    "# Create PyTorch Geometric data object\n",
    "data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "# Define GCN model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_nodes, 16)\n",
    "        self.conv2 = GCNConv(16, num_nodes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Define GAT model\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(num_nodes, 16, heads=8, dropout=0.6)\n",
    "        self.conv2 = GATConv(16 * 8, num_nodes, heads=1, concat=False, dropout=0.6)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Define GraphSAGE model\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(num_nodes, 16)\n",
    "        self.conv2 = SAGEConv(16, num_nodes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Placeholder for model evaluation\n",
    "def evaluate_model(model, data):\n",
    "    model.eval()\n",
    "    out = model(data)\n",
    "    pred = out.argmax(dim=1)\n",
    "    y_true = data.y.numpy()\n",
    "    y_pred = pred.numpy()\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"accuracy\": accuracy\n",
    "    }\n",
    "\n",
    "# List of models to benchmark\n",
    "models_to_benchmark = {\n",
    "    \"GCN\": GCN(),\n",
    "    \"GAT\": GAT(),\n",
    "    \"GraphSAGE\": GraphSAGE()\n",
    "    # Add other models here\n",
    "}\n",
    "\n",
    "# Dictionary to store benchmark results\n",
    "benchmark_results = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models_to_benchmark.items():\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    model.train()\n",
    "    for epoch in range(200):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    benchmark_results[model_name] = evaluate_model(model, data)\n",
    "\n",
    "# Convert results to DataFrame for easier plotting\n",
    "df = pd.DataFrame(benchmark_results).T\n",
    "\n",
    "# Plot the results\n",
    "sns.set(style=\"whitegrid\")\n",
    "palette = sns.color_palette(\"Set2\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "x = np.arange(len(models_to_benchmark))\n",
    "width = 0.12\n",
    "\n",
    "metrics = df.columns\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax.bar(x + i*width, df[metric], width, label=metric, capsize=5, color=palette[i % len(palette)])\n",
    "\n",
    "ax.set_xlabel('Models', fontsize=14)\n",
    "ax.set_ylabel('Scores', fontsize=14)\n",
    "ax.set_title('Benchmark Results Comparison', fontsize=16, weight='bold')\n",
    "ax.set_xticks(x + width * (len(metrics) - 1) / 2)\n",
    "ax.set_xticklabels(models_to_benchmark.keys(), rotation=90, fontsize=12)\n",
    "ax.legend(fontsize=12, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "ax.yaxis.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# benching family of state of the art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load your data\n",
    "labels_df = pd.read_csv('SANDBOX/Analysis/data_mother/500label.csv')\n",
    "labels = labels_df['Names'].tolist()\n",
    "label_to_index = {label: idx for idx, label in enumerate(labels)}\n",
    "\n",
    "# Load adjacency matrix\n",
    "adj_matrix = pd.read_csv('SANDBOX/Analysis/data_mother/wgtlabel.csv', header=None).values\n",
    "\n",
    "# Create edge index for PyTorch Geometric\n",
    "edge_index = torch_geometric.utils.dense_to_sparse(torch.tensor(adj_matrix, dtype=torch.float))[0]\n",
    "\n",
    "# Create node features (for simplicity, using identity matrix)\n",
    "num_nodes = adj_matrix.shape[0]\n",
    "x = torch.eye(num_nodes, dtype=torch.float)\n",
    "\n",
    "# Create labels (for simplicity, using node indices as labels)\n",
    "y = torch.tensor(range(num_nodes), dtype=torch.long)\n",
    "\n",
    "# Create PyTorch Geometric data object\n",
    "data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "# Define GCN model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_nodes, 16)\n",
    "        self.conv2 = GCNConv(16, num_nodes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Define GAT model\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(num_nodes, 16, heads=8, dropout=0.6)\n",
    "        self.conv2 = GATConv(16 * 8, num_nodes, heads=1, concat=False, dropout=0.6)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Define GraphSAGE model\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(num_nodes, 16)\n",
    "        self.conv2 = SAGEConv(16, num_nodes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Placeholder for other models\n",
    "class TransE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransE, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class TransR(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransR, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class DistMult(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DistMult, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class ComplEx(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ComplEx, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class HAN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HAN, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class MetaPath2Vec(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MetaPath2Vec, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class GCF(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCF, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class GRMF(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GRMF, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class STAGE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(STAGE, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class SRGNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SRGNN, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class DeepWalk(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepWalk, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class Node2Vec(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Node2Vec, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "# Placeholder for model evaluation\n",
    "def evaluate_model(model, data):\n",
    "    model.eval()\n",
    "    out = model(data)\n",
    "    pred = out.argmax(dim=1)\n",
    "    y_true = data.y.numpy()\n",
    "    y_pred = pred.numpy()\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"accuracy\": accuracy\n",
    "    }\n",
    "\n",
    "# List of models to benchmark\n",
    "models_to_benchmark = {\n",
    "    \"GCN\": GCN(),\n",
    "    \"GAT\": GAT(),\n",
    "    \"GraphSAGE\": GraphSAGE(),\n",
    "    \"TransE\": TransE(),\n",
    "    \"TransR\": TransR(),\n",
    "    \"DistMult\": DistMult(),\n",
    "    \"ComplEx\": ComplEx(),\n",
    "    \"HAN\": HAN(),\n",
    "    \"MetaPath2Vec\": MetaPath2Vec(),\n",
    "    \"GCF\": GCF(),\n",
    "    \"GRMF\": GRMF(),\n",
    "    \"STAGE\": STAGE(),\n",
    "    \"SR-GNN\": SRGNN(),\n",
    "    \"DeepWalk\": DeepWalk(),\n",
    "    \"Node2Vec\": Node2Vec()\n",
    "}\n",
    "\n",
    "# Dictionary to store benchmark results\n",
    "benchmark_results = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models_to_benchmark.items():\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    model.train()\n",
    "    for epoch in range(200):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    benchmark_results[model_name] = evaluate_model(model, data)\n",
    "\n",
    "# Convert results to DataFrame for easier plotting\n",
    "df = pd.DataFrame(benchmark_results).T\n",
    "\n",
    "# Plot the results\n",
    "sns.set(style=\"whitegrid\")\n",
    "palette = sns.color_palette(\"Set2\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "x = np.arange(len(models_to_benchmark))\n",
    "width = 0.12\n",
    "\n",
    "metrics = df.columns\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax.bar(x + i*width, df[metric], width, label=metric, capsize=5, color=palette[i % len(palette)])\n",
    "\n",
    "ax.set_xlabel('Models', fontsize=14)\n",
    "ax.set_ylabel('Scores', fontsize=14)\n",
    "ax.set_title('Benchmark Results Comparison', fontsize=16, weight='bold')\n",
    "ax.set_xticks(x + width * (len(metrics) - 1) / 2)\n",
    "ax.set_xticklabels(models_to_benchmark.keys(), rotation=90, fontsize=12)\n",
    "ax.legend(fontsize=12, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "ax.yaxis.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "# This will suppress warnings for the current cell\n",
    "%config Application.verbose_crash=True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Benchmarking** above models with CoreRec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CoreRec...\n",
      "Epoch 0, Loss: -0.4331304430961609\n",
      "Epoch 1, Loss: -2.957098960876465\n",
      "Epoch 2, Loss: -4.570010185241699\n",
      "Epoch 3, Loss: -5.847498893737793\n",
      "Epoch 4, Loss: -7.431314945220947\n",
      "Epoch 5, Loss: -8.742538452148438\n",
      "Epoch 6, Loss: -10.024944305419922\n",
      "Epoch 7, Loss: -11.111356735229492\n",
      "Epoch 8, Loss: -12.287784576416016\n",
      "Epoch 9, Loss: -13.616544723510742\n",
      "Epoch 10, Loss: -14.787271499633789\n",
      "Epoch 11, Loss: -16.14240074157715\n",
      "Epoch 12, Loss: -17.58675193786621\n",
      "Epoch 13, Loss: -19.00414276123047\n",
      "Epoch 14, Loss: -20.51294708251953\n",
      "Epoch 15, Loss: -22.064369201660156\n",
      "Epoch 16, Loss: -23.634218215942383\n",
      "Epoch 17, Loss: -25.235671997070312\n",
      "Epoch 18, Loss: -26.983097076416016\n",
      "Epoch 19, Loss: -28.975622177124023\n",
      "Epoch 20, Loss: -30.785785675048828\n",
      "Epoch 21, Loss: -32.4664421081543\n",
      "Epoch 22, Loss: -34.505428314208984\n",
      "Epoch 23, Loss: -36.28644561767578\n",
      "Epoch 24, Loss: -38.56915283203125\n",
      "Epoch 25, Loss: -40.85451126098633\n",
      "Epoch 26, Loss: -43.112613677978516\n",
      "Epoch 27, Loss: -45.27131271362305\n",
      "Epoch 28, Loss: -47.63298034667969\n",
      "Epoch 29, Loss: -49.82551574707031\n",
      "Epoch 30, Loss: -52.669647216796875\n",
      "Epoch 31, Loss: -54.86072540283203\n",
      "Epoch 32, Loss: -57.75022506713867\n",
      "Epoch 33, Loss: -59.96316909790039\n",
      "Epoch 34, Loss: -63.371368408203125\n",
      "Epoch 35, Loss: -66.20179748535156\n",
      "Epoch 36, Loss: -68.91783905029297\n",
      "Epoch 37, Loss: -72.4009017944336\n",
      "Epoch 38, Loss: -75.26874542236328\n",
      "Epoch 39, Loss: -78.62358093261719\n",
      "Epoch 40, Loss: -82.45159149169922\n",
      "Epoch 41, Loss: -85.44176483154297\n",
      "Epoch 42, Loss: -87.42658996582031\n",
      "Epoch 43, Loss: -92.56448364257812\n",
      "Epoch 44, Loss: -95.4359130859375\n",
      "Epoch 45, Loss: -99.30878448486328\n",
      "Epoch 46, Loss: -103.7426986694336\n",
      "Epoch 47, Loss: -107.509521484375\n",
      "Epoch 48, Loss: -111.86109161376953\n",
      "Epoch 49, Loss: -115.76561737060547\n",
      "Epoch 50, Loss: -120.4691390991211\n",
      "Epoch 51, Loss: -124.4063720703125\n",
      "Epoch 52, Loss: -128.20208740234375\n",
      "Epoch 53, Loss: -133.05322265625\n",
      "Epoch 54, Loss: -138.22515869140625\n",
      "Epoch 55, Loss: -142.35093688964844\n",
      "Epoch 56, Loss: -147.79539489746094\n",
      "Epoch 57, Loss: -152.14749145507812\n",
      "Epoch 58, Loss: -157.64230346679688\n",
      "Epoch 59, Loss: -163.0068359375\n",
      "Epoch 60, Loss: -167.48867797851562\n",
      "Epoch 61, Loss: -173.5012969970703\n",
      "Epoch 62, Loss: -179.05050659179688\n",
      "Epoch 63, Loss: -184.26519775390625\n",
      "Epoch 64, Loss: -190.05027770996094\n",
      "Epoch 65, Loss: -196.00546264648438\n",
      "Epoch 66, Loss: -202.275390625\n",
      "Epoch 67, Loss: -207.68270874023438\n",
      "Epoch 68, Loss: -214.90049743652344\n",
      "Epoch 69, Loss: -220.51759338378906\n",
      "Epoch 70, Loss: -227.03150939941406\n",
      "Epoch 71, Loss: -233.64920043945312\n",
      "Epoch 72, Loss: -240.8289031982422\n",
      "Epoch 73, Loss: -246.47576904296875\n",
      "Epoch 74, Loss: -253.56639099121094\n",
      "Epoch 75, Loss: -260.3211975097656\n",
      "Epoch 76, Loss: -268.2489929199219\n",
      "Epoch 77, Loss: -275.33197021484375\n",
      "Epoch 78, Loss: -282.27276611328125\n",
      "Epoch 79, Loss: -289.79852294921875\n",
      "Epoch 80, Loss: -297.3424377441406\n",
      "Epoch 81, Loss: -305.11859130859375\n",
      "Epoch 82, Loss: -312.72955322265625\n",
      "Epoch 83, Loss: -320.67431640625\n",
      "Epoch 84, Loss: -328.7283630371094\n",
      "Epoch 85, Loss: -336.80767822265625\n",
      "Epoch 86, Loss: -344.64642333984375\n",
      "Epoch 87, Loss: -353.1696472167969\n",
      "Epoch 88, Loss: -362.0412292480469\n",
      "Epoch 89, Loss: -370.4091491699219\n",
      "Epoch 90, Loss: -379.07073974609375\n",
      "Epoch 91, Loss: -388.1836242675781\n",
      "Epoch 92, Loss: -396.90386962890625\n",
      "Epoch 93, Loss: -406.1767272949219\n",
      "Epoch 94, Loss: -415.5264892578125\n",
      "Epoch 95, Loss: -424.9128723144531\n",
      "Epoch 96, Loss: -434.4059753417969\n",
      "Epoch 97, Loss: -443.86065673828125\n",
      "Epoch 98, Loss: -453.6015319824219\n",
      "Epoch 99, Loss: -463.3462829589844\n",
      "Validation Loss for CoreRec: 0.0023006442934274673\n",
      "Confusion Matrix:\n",
      "[[0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1]]\n",
      "True Negatives (TN): [0 1 1 1 1 0 1 1 1 0 1]\n",
      "False Positives (FP): [0 0 0 2 0 0 0 0 1 0 0]\n",
      "Metrics for CoreRec: {'precision': 0.6212121212121212, 'recall': 0.7272727272727273, 'f1_score': 0.6515151515151515, 'accuracy': 0.7272727272727273, 'specificity': 0.6212121212121212, 'sensitivity': 0.9752066115702479, 'roc_auc': 0.8500000000000001, 'mcc': 0.72693285284751}\n",
      "Training GCN...\n",
      "Epoch 0, Loss: 2.407073974609375\n",
      "Epoch 1, Loss: 2.393893241882324\n",
      "Epoch 2, Loss: 2.382094621658325\n",
      "Epoch 3, Loss: 2.3712542057037354\n",
      "Epoch 4, Loss: 2.361006021499634\n",
      "Epoch 5, Loss: 2.351353883743286\n",
      "Epoch 6, Loss: 2.341888666152954\n",
      "Epoch 7, Loss: 2.3323864936828613\n",
      "Epoch 8, Loss: 2.3225913047790527\n",
      "Epoch 9, Loss: 2.3124823570251465\n",
      "Epoch 10, Loss: 2.3021514415740967\n",
      "Epoch 11, Loss: 2.2916009426116943\n",
      "Epoch 12, Loss: 2.2808098793029785\n",
      "Epoch 13, Loss: 2.26973557472229\n",
      "Epoch 14, Loss: 2.258481740951538\n",
      "Epoch 15, Loss: 2.2468783855438232\n",
      "Epoch 16, Loss: 2.234837770462036\n",
      "Epoch 17, Loss: 2.22247052192688\n",
      "Epoch 18, Loss: 2.2097644805908203\n",
      "Epoch 19, Loss: 2.1967062950134277\n",
      "Epoch 20, Loss: 2.1834330558776855\n",
      "Epoch 21, Loss: 2.1698355674743652\n",
      "Epoch 22, Loss: 2.1559720039367676\n",
      "Epoch 23, Loss: 2.1417832374572754\n",
      "Epoch 24, Loss: 2.127305030822754\n",
      "Epoch 25, Loss: 2.1126322746276855\n",
      "Epoch 26, Loss: 2.0979254245758057\n",
      "Epoch 27, Loss: 2.083284378051758\n",
      "Epoch 28, Loss: 2.068854331970215\n",
      "Epoch 29, Loss: 2.0547091960906982\n",
      "Epoch 30, Loss: 2.040790557861328\n",
      "Epoch 31, Loss: 2.0270884037017822\n",
      "Epoch 32, Loss: 2.0135748386383057\n",
      "Epoch 33, Loss: 2.000209093093872\n",
      "Epoch 34, Loss: 1.9869461059570312\n",
      "Epoch 35, Loss: 1.9737677574157715\n",
      "Epoch 36, Loss: 1.9606213569641113\n",
      "Epoch 37, Loss: 1.9474899768829346\n",
      "Epoch 38, Loss: 1.934367299079895\n",
      "Epoch 39, Loss: 1.9212565422058105\n",
      "Epoch 40, Loss: 1.9081672430038452\n",
      "Epoch 41, Loss: 1.8952064514160156\n",
      "Epoch 42, Loss: 1.8823497295379639\n",
      "Epoch 43, Loss: 1.8695642948150635\n",
      "Epoch 44, Loss: 1.857012391090393\n",
      "Epoch 45, Loss: 1.8445148468017578\n",
      "Epoch 46, Loss: 1.832016110420227\n",
      "Epoch 47, Loss: 1.8195010423660278\n",
      "Epoch 48, Loss: 1.806952953338623\n",
      "Epoch 49, Loss: 1.794360876083374\n",
      "Epoch 50, Loss: 1.781813621520996\n",
      "Epoch 51, Loss: 1.7692633867263794\n",
      "Epoch 52, Loss: 1.7566850185394287\n",
      "Epoch 53, Loss: 1.744128704071045\n",
      "Epoch 54, Loss: 1.7316399812698364\n",
      "Epoch 55, Loss: 1.7193704843521118\n",
      "Epoch 56, Loss: 1.707189917564392\n",
      "Epoch 57, Loss: 1.695091724395752\n",
      "Epoch 58, Loss: 1.6830742359161377\n",
      "Epoch 59, Loss: 1.671166181564331\n",
      "Epoch 60, Loss: 1.6594420671463013\n",
      "Epoch 61, Loss: 1.6477981805801392\n",
      "Epoch 62, Loss: 1.6362426280975342\n",
      "Epoch 63, Loss: 1.6248224973678589\n",
      "Epoch 64, Loss: 1.6134921312332153\n",
      "Epoch 65, Loss: 1.6023061275482178\n",
      "Epoch 66, Loss: 1.591354489326477\n",
      "Epoch 67, Loss: 1.5804672241210938\n",
      "Epoch 68, Loss: 1.5696196556091309\n",
      "Epoch 69, Loss: 1.55885910987854\n",
      "Epoch 70, Loss: 1.5481948852539062\n",
      "Epoch 71, Loss: 1.5376429557800293\n",
      "Epoch 72, Loss: 1.5271191596984863\n",
      "Epoch 73, Loss: 1.5166319608688354\n",
      "Epoch 74, Loss: 1.5061911344528198\n",
      "Epoch 75, Loss: 1.495880126953125\n",
      "Epoch 76, Loss: 1.4856332540512085\n",
      "Epoch 77, Loss: 1.475383996963501\n",
      "Epoch 78, Loss: 1.4652268886566162\n",
      "Epoch 79, Loss: 1.4551225900650024\n",
      "Epoch 80, Loss: 1.445050835609436\n",
      "Epoch 81, Loss: 1.4350123405456543\n",
      "Epoch 82, Loss: 1.4250580072402954\n",
      "Epoch 83, Loss: 1.415147304534912\n",
      "Epoch 84, Loss: 1.4053133726119995\n",
      "Epoch 85, Loss: 1.3955447673797607\n",
      "Epoch 86, Loss: 1.3857848644256592\n",
      "Epoch 87, Loss: 1.3760597705841064\n",
      "Epoch 88, Loss: 1.3664628267288208\n",
      "Epoch 89, Loss: 1.3568861484527588\n",
      "Epoch 90, Loss: 1.34739351272583\n",
      "Epoch 91, Loss: 1.3379889726638794\n",
      "Epoch 92, Loss: 1.3286460638046265\n",
      "Epoch 93, Loss: 1.3193953037261963\n",
      "Epoch 94, Loss: 1.3102145195007324\n",
      "Epoch 95, Loss: 1.301161766052246\n",
      "Epoch 96, Loss: 1.2920817136764526\n",
      "Epoch 97, Loss: 1.2831534147262573\n",
      "Epoch 98, Loss: 1.2743793725967407\n",
      "Epoch 99, Loss: 1.265637755393982\n",
      "Validation Loss for GCN: 8.372092247009277\n",
      "Confusion Matrix:\n",
      "[[0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1]]\n",
      "True Negatives (TN): [0 1 1 1 0 0 1 1 1 0 1]\n",
      "False Positives (FP): [0 0 2 1 0 0 0 0 1 0 0]\n",
      "Metrics for GCN: {'precision': 0.4848484848484848, 'recall': 0.6363636363636364, 'f1_score': 0.5303030303030303, 'accuracy': 0.6363636363636364, 'specificity': 0.4848484848484848, 'sensitivity': 0.9669421487603305, 'roc_auc': 0.8, 'mcc': 0.6292853089020909}\n",
      "Training GraphSAGE...\n",
      "Epoch 0, Loss: 2.4306604862213135\n",
      "Epoch 1, Loss: 2.3646585941314697\n",
      "Epoch 2, Loss: 2.3018100261688232\n",
      "Epoch 3, Loss: 2.2392971515655518\n",
      "Epoch 4, Loss: 2.178253173828125\n",
      "Epoch 5, Loss: 2.1187896728515625\n",
      "Epoch 6, Loss: 2.0583105087280273\n",
      "Epoch 7, Loss: 1.9970036745071411\n",
      "Epoch 8, Loss: 1.9345142841339111\n",
      "Epoch 9, Loss: 1.8715472221374512\n",
      "Epoch 10, Loss: 1.808444619178772\n",
      "Epoch 11, Loss: 1.7442318201065063\n",
      "Epoch 12, Loss: 1.68014657497406\n",
      "Epoch 13, Loss: 1.6159937381744385\n",
      "Epoch 14, Loss: 1.5510094165802002\n",
      "Epoch 15, Loss: 1.4855986833572388\n",
      "Epoch 16, Loss: 1.4206926822662354\n",
      "Epoch 17, Loss: 1.3544424772262573\n",
      "Epoch 18, Loss: 1.2870457172393799\n",
      "Epoch 19, Loss: 1.219464898109436\n",
      "Epoch 20, Loss: 1.1515073776245117\n",
      "Epoch 21, Loss: 1.0835604667663574\n",
      "Epoch 22, Loss: 1.0162627696990967\n",
      "Epoch 23, Loss: 0.9502872228622437\n",
      "Epoch 24, Loss: 0.8856017589569092\n",
      "Epoch 25, Loss: 0.8224453330039978\n",
      "Epoch 26, Loss: 0.7606148719787598\n",
      "Epoch 27, Loss: 0.700610876083374\n",
      "Epoch 28, Loss: 0.6425269246101379\n",
      "Epoch 29, Loss: 0.5873356461524963\n",
      "Epoch 30, Loss: 0.5350733995437622\n",
      "Epoch 31, Loss: 0.48533666133880615\n",
      "Epoch 32, Loss: 0.43852290511131287\n",
      "Epoch 33, Loss: 0.3949981927871704\n",
      "Epoch 34, Loss: 0.3548966348171234\n",
      "Epoch 35, Loss: 0.3180944621562958\n",
      "Epoch 36, Loss: 0.2845882177352905\n",
      "Epoch 37, Loss: 0.25415685772895813\n",
      "Epoch 38, Loss: 0.22657382488250732\n",
      "Epoch 39, Loss: 0.20173370838165283\n",
      "Epoch 40, Loss: 0.17958995699882507\n",
      "Epoch 41, Loss: 0.15995679795742035\n",
      "Epoch 42, Loss: 0.14260901510715485\n",
      "Epoch 43, Loss: 0.12729506194591522\n",
      "Epoch 44, Loss: 0.11378207802772522\n",
      "Epoch 45, Loss: 0.10188814997673035\n",
      "Epoch 46, Loss: 0.09144909679889679\n",
      "Epoch 47, Loss: 0.08226916193962097\n",
      "Epoch 48, Loss: 0.07420554012060165\n",
      "Epoch 49, Loss: 0.06714708358049393\n",
      "Epoch 50, Loss: 0.06097330152988434\n",
      "Epoch 51, Loss: 0.05555063858628273\n",
      "Epoch 52, Loss: 0.050776589661836624\n",
      "Epoch 53, Loss: 0.046562761068344116\n",
      "Epoch 54, Loss: 0.04284607619047165\n",
      "Epoch 55, Loss: 0.03956008702516556\n",
      "Epoch 56, Loss: 0.03665950894355774\n",
      "Epoch 57, Loss: 0.03408767282962799\n",
      "Epoch 58, Loss: 0.03179487586021423\n",
      "Epoch 59, Loss: 0.029758283868432045\n",
      "Epoch 60, Loss: 0.027944235131144524\n",
      "Epoch 61, Loss: 0.026316124945878983\n",
      "Epoch 62, Loss: 0.024852773174643517\n",
      "Epoch 63, Loss: 0.02353784628212452\n",
      "Epoch 64, Loss: 0.022353101521730423\n",
      "Epoch 65, Loss: 0.021291419863700867\n",
      "Epoch 66, Loss: 0.02033005841076374\n",
      "Epoch 67, Loss: 0.019454682245850563\n",
      "Epoch 68, Loss: 0.018655948340892792\n",
      "Epoch 69, Loss: 0.01792886108160019\n",
      "Epoch 70, Loss: 0.01726113073527813\n",
      "Epoch 71, Loss: 0.01664668507874012\n",
      "Epoch 72, Loss: 0.01608129031956196\n",
      "Epoch 73, Loss: 0.015562840737402439\n",
      "Epoch 74, Loss: 0.01508563756942749\n",
      "Epoch 75, Loss: 0.014644617214798927\n",
      "Epoch 76, Loss: 0.014234533533453941\n",
      "Epoch 77, Loss: 0.013851785100996494\n",
      "Epoch 78, Loss: 0.013494985178112984\n",
      "Epoch 79, Loss: 0.013162614777684212\n",
      "Epoch 80, Loss: 0.012851779349148273\n",
      "Epoch 81, Loss: 0.012560817413032055\n",
      "Epoch 82, Loss: 0.012287655845284462\n",
      "Epoch 83, Loss: 0.012031873688101768\n",
      "Epoch 84, Loss: 0.011791614815592766\n",
      "Epoch 85, Loss: 0.011564570479094982\n",
      "Epoch 86, Loss: 0.011349869892001152\n",
      "Epoch 87, Loss: 0.011146653443574905\n",
      "Epoch 88, Loss: 0.010954286903142929\n",
      "Epoch 89, Loss: 0.010774631053209305\n",
      "Epoch 90, Loss: 0.010604745708405972\n",
      "Epoch 91, Loss: 0.010443238541483879\n",
      "Epoch 92, Loss: 0.010290169157087803\n",
      "Epoch 93, Loss: 0.010142866522073746\n",
      "Epoch 94, Loss: 0.010002465918660164\n",
      "Epoch 95, Loss: 0.009867615066468716\n",
      "Epoch 96, Loss: 0.00973899569362402\n",
      "Epoch 97, Loss: 0.009615389630198479\n",
      "Epoch 98, Loss: 0.009496528655290604\n",
      "Epoch 99, Loss: 0.009382077492773533\n",
      "Validation Loss for GraphSAGE: 8.358475685119629\n",
      "Confusion Matrix:\n",
      "[[0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 1]]\n",
      "True Negatives (TN): [0 1 1 1 1 0 1 1 1 0 1]\n",
      "False Positives (FP): [0 0 1 0 0 0 0 0 1 0 1]\n",
      "Metrics for GraphSAGE: {'precision': 0.5909090909090909, 'recall': 0.7272727272727273, 'f1_score': 0.6363636363636364, 'accuracy': 0.7272727272727273, 'specificity': 0.5909090909090909, 'sensitivity': 0.9752066115702479, 'roc_auc': 0.85, 'mcc': 0.719909182306512}\n",
      "Training TransE...\n",
      "Epoch 0, Loss: -0.003960326313972473\n",
      "Epoch 1, Loss: -0.1689477264881134\n",
      "Epoch 2, Loss: -0.33379030227661133\n",
      "Epoch 3, Loss: -0.4986250102519989\n",
      "Epoch 4, Loss: -0.6635699272155762\n",
      "Epoch 5, Loss: -0.8287277221679688\n",
      "Epoch 6, Loss: -0.9941887855529785\n",
      "Epoch 7, Loss: -1.1600505113601685\n",
      "Epoch 8, Loss: -1.3264302015304565\n",
      "Epoch 9, Loss: -1.4934682846069336\n",
      "Epoch 10, Loss: -1.6613283157348633\n",
      "Epoch 11, Loss: -1.830193281173706\n",
      "Epoch 12, Loss: -2.000260591506958\n",
      "Epoch 13, Loss: -2.1717357635498047\n",
      "Epoch 14, Loss: -2.344829559326172\n",
      "Epoch 15, Loss: -2.51975154876709\n",
      "Epoch 16, Loss: -2.696712017059326\n",
      "Epoch 17, Loss: -2.87591814994812\n",
      "Epoch 18, Loss: -3.057574987411499\n",
      "Epoch 19, Loss: -3.2418863773345947\n",
      "Epoch 20, Loss: -3.4290530681610107\n",
      "Epoch 21, Loss: -3.619274616241455\n",
      "Epoch 22, Loss: -3.812748670578003\n",
      "Epoch 23, Loss: -4.009671211242676\n",
      "Epoch 24, Loss: -4.210235595703125\n",
      "Epoch 25, Loss: -4.414633274078369\n",
      "Epoch 26, Loss: -4.62305212020874\n",
      "Epoch 27, Loss: -4.83567476272583\n",
      "Epoch 28, Loss: -5.052680015563965\n",
      "Epoch 29, Loss: -5.274242401123047\n",
      "Epoch 30, Loss: -5.500528812408447\n",
      "Epoch 31, Loss: -5.731700897216797\n",
      "Epoch 32, Loss: -5.967914581298828\n",
      "Epoch 33, Loss: -6.209318161010742\n",
      "Epoch 34, Loss: -6.456052780151367\n",
      "Epoch 35, Loss: -6.708255767822266\n",
      "Epoch 36, Loss: -6.9660563468933105\n",
      "Epoch 37, Loss: -7.229580402374268\n",
      "Epoch 38, Loss: -7.498944282531738\n",
      "Epoch 39, Loss: -7.774264812469482\n",
      "Epoch 40, Loss: -8.055648803710938\n",
      "Epoch 41, Loss: -8.34320068359375\n",
      "Epoch 42, Loss: -8.6370210647583\n",
      "Epoch 43, Loss: -8.937207221984863\n",
      "Epoch 44, Loss: -9.243850708007812\n",
      "Epoch 45, Loss: -9.55704116821289\n",
      "Epoch 46, Loss: -9.876864433288574\n",
      "Epoch 47, Loss: -10.203402519226074\n",
      "Epoch 48, Loss: -10.536737442016602\n",
      "Epoch 49, Loss: -10.876946449279785\n",
      "Epoch 50, Loss: -11.224104881286621\n",
      "Epoch 51, Loss: -11.578286170959473\n",
      "Epoch 52, Loss: -11.939560890197754\n",
      "Epoch 53, Loss: -12.30799674987793\n",
      "Epoch 54, Loss: -12.683661460876465\n",
      "Epoch 55, Loss: -13.066617965698242\n",
      "Epoch 56, Loss: -13.456931114196777\n",
      "Epoch 57, Loss: -13.854658126831055\n",
      "Epoch 58, Loss: -14.259861946105957\n",
      "Epoch 59, Loss: -14.67259693145752\n",
      "Epoch 60, Loss: -15.092916488647461\n",
      "Epoch 61, Loss: -15.520875930786133\n",
      "Epoch 62, Loss: -15.956528663635254\n",
      "Epoch 63, Loss: -16.399919509887695\n",
      "Epoch 64, Loss: -16.851099014282227\n",
      "Epoch 65, Loss: -17.310115814208984\n",
      "Epoch 66, Loss: -17.77701187133789\n",
      "Epoch 67, Loss: -18.2518310546875\n",
      "Epoch 68, Loss: -18.734619140625\n",
      "Epoch 69, Loss: -19.22540855407715\n",
      "Epoch 70, Loss: -19.7242431640625\n",
      "Epoch 71, Loss: -20.23116111755371\n",
      "Epoch 72, Loss: -20.746192932128906\n",
      "Epoch 73, Loss: -21.269380569458008\n",
      "Epoch 74, Loss: -21.800750732421875\n",
      "Epoch 75, Loss: -22.340335845947266\n",
      "Epoch 76, Loss: -22.888174057006836\n",
      "Epoch 77, Loss: -23.444284439086914\n",
      "Epoch 78, Loss: -24.00869369506836\n",
      "Epoch 79, Loss: -24.581436157226562\n",
      "Epoch 80, Loss: -25.162532806396484\n",
      "Epoch 81, Loss: -25.75200653076172\n",
      "Epoch 82, Loss: -26.34988021850586\n",
      "Epoch 83, Loss: -26.956178665161133\n",
      "Epoch 84, Loss: -27.570920944213867\n",
      "Epoch 85, Loss: -28.194122314453125\n",
      "Epoch 86, Loss: -28.82581329345703\n",
      "Epoch 87, Loss: -29.465999603271484\n",
      "Epoch 88, Loss: -30.114704132080078\n",
      "Epoch 89, Loss: -30.77194595336914\n",
      "Epoch 90, Loss: -31.437734603881836\n",
      "Epoch 91, Loss: -32.112091064453125\n",
      "Epoch 92, Loss: -32.79502868652344\n",
      "Epoch 93, Loss: -33.48655319213867\n",
      "Epoch 94, Loss: -34.18668746948242\n",
      "Epoch 95, Loss: -34.895442962646484\n",
      "Epoch 96, Loss: -35.612831115722656\n",
      "Epoch 97, Loss: -36.3388557434082\n",
      "Epoch 98, Loss: -37.07353973388672\n",
      "Epoch 99, Loss: -37.81688690185547\n",
      "Validation Loss for TransE: -0.00022445491049438715\n",
      "Confusion Matrix:\n",
      "[[0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1]]\n",
      "True Negatives (TN): [0 1 1 1 1 0 1 1 1 0 1]\n",
      "False Positives (FP): [0 1 0 0 0 0 1 0 1 0 0]\n",
      "Metrics for TransE: {'precision': 0.5909090909090909, 'recall': 0.7272727272727273, 'f1_score': 0.6363636363636364, 'accuracy': 0.7272727272727273, 'specificity': 0.5909090909090909, 'sensitivity': 0.9752066115702479, 'roc_auc': 0.8500000000000001, 'mcc': 0.719909182306512}\n",
      "Training TransR...\n",
      "Epoch 0, Loss: 0.09447073936462402\n",
      "Epoch 1, Loss: -0.05525316298007965\n",
      "Epoch 2, Loss: -0.2049708366394043\n",
      "Epoch 3, Loss: -0.35480743646621704\n",
      "Epoch 4, Loss: -0.5048773884773254\n",
      "Epoch 5, Loss: -0.6552973985671997\n",
      "Epoch 6, Loss: -0.8061864376068115\n",
      "Epoch 7, Loss: -0.9576742649078369\n",
      "Epoch 8, Loss: -1.109902024269104\n",
      "Epoch 9, Loss: -1.2630221843719482\n",
      "Epoch 10, Loss: -1.4172005653381348\n",
      "Epoch 11, Loss: -1.5726149082183838\n",
      "Epoch 12, Loss: -1.729451060295105\n",
      "Epoch 13, Loss: -1.88789963722229\n",
      "Epoch 14, Loss: -2.048153877258301\n",
      "Epoch 15, Loss: -2.210407018661499\n",
      "Epoch 16, Loss: -2.374852180480957\n",
      "Epoch 17, Loss: -2.5416812896728516\n",
      "Epoch 18, Loss: -2.711082935333252\n",
      "Epoch 19, Loss: -2.883242607116699\n",
      "Epoch 20, Loss: -3.058342933654785\n",
      "Epoch 21, Loss: -3.2365622520446777\n",
      "Epoch 22, Loss: -3.4180760383605957\n",
      "Epoch 23, Loss: -3.603055953979492\n",
      "Epoch 24, Loss: -3.79167103767395\n",
      "Epoch 25, Loss: -3.984086513519287\n",
      "Epoch 26, Loss: -4.180464744567871\n",
      "Epoch 27, Loss: -4.380964756011963\n",
      "Epoch 28, Loss: -4.58574104309082\n",
      "Epoch 29, Loss: -4.794946670532227\n",
      "Epoch 30, Loss: -5.008728981018066\n",
      "Epoch 31, Loss: -5.227233409881592\n",
      "Epoch 32, Loss: -5.450600624084473\n",
      "Epoch 33, Loss: -5.67896842956543\n",
      "Epoch 34, Loss: -5.912470817565918\n",
      "Epoch 35, Loss: -6.1512370109558105\n",
      "Epoch 36, Loss: -6.395394802093506\n",
      "Epoch 37, Loss: -6.645064830780029\n",
      "Epoch 38, Loss: -6.900368690490723\n",
      "Epoch 39, Loss: -7.1614203453063965\n",
      "Epoch 40, Loss: -7.428329944610596\n",
      "Epoch 41, Loss: -7.701206207275391\n",
      "Epoch 42, Loss: -7.980154514312744\n",
      "Epoch 43, Loss: -8.265274047851562\n",
      "Epoch 44, Loss: -8.556662559509277\n",
      "Epoch 45, Loss: -8.854413986206055\n",
      "Epoch 46, Loss: -9.158621788024902\n",
      "Epoch 47, Loss: -9.469375610351562\n",
      "Epoch 48, Loss: -9.786757469177246\n",
      "Epoch 49, Loss: -10.110854148864746\n",
      "Epoch 50, Loss: -10.441747665405273\n",
      "Epoch 51, Loss: -10.77951717376709\n",
      "Epoch 52, Loss: -11.124242782592773\n",
      "Epoch 53, Loss: -11.475997924804688\n",
      "Epoch 54, Loss: -11.834857940673828\n",
      "Epoch 55, Loss: -12.200892448425293\n",
      "Epoch 56, Loss: -12.574173927307129\n",
      "Epoch 57, Loss: -12.954767227172852\n",
      "Epoch 58, Loss: -13.342741012573242\n",
      "Epoch 59, Loss: -13.738154411315918\n",
      "Epoch 60, Loss: -14.141069412231445\n",
      "Epoch 61, Loss: -14.551546096801758\n",
      "Epoch 62, Loss: -14.96963882446289\n",
      "Epoch 63, Loss: -15.395402908325195\n",
      "Epoch 64, Loss: -15.828892707824707\n",
      "Epoch 65, Loss: -16.270156860351562\n",
      "Epoch 66, Loss: -16.719242095947266\n",
      "Epoch 67, Loss: -17.17620086669922\n",
      "Epoch 68, Loss: -17.641077041625977\n",
      "Epoch 69, Loss: -18.113910675048828\n",
      "Epoch 70, Loss: -18.594749450683594\n",
      "Epoch 71, Loss: -19.08363151550293\n",
      "Epoch 72, Loss: -19.580598831176758\n",
      "Epoch 73, Loss: -20.0856876373291\n",
      "Epoch 74, Loss: -20.598934173583984\n",
      "Epoch 75, Loss: -21.12037467956543\n",
      "Epoch 76, Loss: -21.650043487548828\n",
      "Epoch 77, Loss: -22.187973022460938\n",
      "Epoch 78, Loss: -22.73419952392578\n",
      "Epoch 79, Loss: -23.28874969482422\n",
      "Epoch 80, Loss: -23.851655960083008\n",
      "Epoch 81, Loss: -24.42294692993164\n",
      "Epoch 82, Loss: -25.002653121948242\n",
      "Epoch 83, Loss: -25.59079933166504\n",
      "Epoch 84, Loss: -26.187416076660156\n",
      "Epoch 85, Loss: -26.792526245117188\n",
      "Epoch 86, Loss: -27.406156539916992\n",
      "Epoch 87, Loss: -28.02832794189453\n",
      "Epoch 88, Loss: -28.659067153930664\n",
      "Epoch 89, Loss: -29.29839515686035\n",
      "Epoch 90, Loss: -29.946331024169922\n",
      "Epoch 91, Loss: -30.602893829345703\n",
      "Epoch 92, Loss: -31.268108367919922\n",
      "Epoch 93, Loss: -31.941986083984375\n",
      "Epoch 94, Loss: -32.624549865722656\n",
      "Epoch 95, Loss: -33.31581115722656\n",
      "Epoch 96, Loss: -34.01578903198242\n",
      "Epoch 97, Loss: -34.72449493408203\n",
      "Epoch 98, Loss: -35.44194412231445\n",
      "Epoch 99, Loss: -36.16814422607422\n",
      "Validation Loss for TransR: -0.001139339990913868\n",
      "Confusion Matrix:\n",
      "[[0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1]]\n",
      "True Negatives (TN): [0 1 1 1 1 0 1 1 1 0 1]\n",
      "False Positives (FP): [0 1 0 1 1 0 0 0 0 0 0]\n",
      "Metrics for TransR: {'precision': 0.5909090909090909, 'recall': 0.7272727272727273, 'f1_score': 0.6363636363636364, 'accuracy': 0.7272727272727273, 'specificity': 0.5909090909090909, 'sensitivity': 0.9752066115702479, 'roc_auc': 0.8500000000000001, 'mcc': 0.719909182306512}\n",
      "Training DistMult...\n",
      "Epoch 0, Loss: -0.008469775319099426\n",
      "Epoch 1, Loss: -0.1694585382938385\n",
      "Epoch 2, Loss: -0.33065706491470337\n",
      "Epoch 3, Loss: -0.4921463131904602\n",
      "Epoch 4, Loss: -0.6540345549583435\n",
      "Epoch 5, Loss: -0.8164518475532532\n",
      "Epoch 6, Loss: -0.9795305132865906\n",
      "Epoch 7, Loss: -1.1434035301208496\n",
      "Epoch 8, Loss: -1.3082125186920166\n",
      "Epoch 9, Loss: -1.4741082191467285\n",
      "Epoch 10, Loss: -1.6412469148635864\n",
      "Epoch 11, Loss: -1.8097864389419556\n",
      "Epoch 12, Loss: -1.9798859357833862\n",
      "Epoch 13, Loss: -2.1517038345336914\n",
      "Epoch 14, Loss: -2.3254003524780273\n",
      "Epoch 15, Loss: -2.501133918762207\n",
      "Epoch 16, Loss: -2.679065227508545\n",
      "Epoch 17, Loss: -2.859354257583618\n",
      "Epoch 18, Loss: -3.0421628952026367\n",
      "Epoch 19, Loss: -3.2276530265808105\n",
      "Epoch 20, Loss: -3.4159884452819824\n",
      "Epoch 21, Loss: -3.6073317527770996\n",
      "Epoch 22, Loss: -3.8018476963043213\n",
      "Epoch 23, Loss: -3.999701499938965\n",
      "Epoch 24, Loss: -4.2010579109191895\n",
      "Epoch 25, Loss: -4.406081676483154\n",
      "Epoch 26, Loss: -4.614938735961914\n",
      "Epoch 27, Loss: -4.827792644500732\n",
      "Epoch 28, Loss: -5.044806003570557\n",
      "Epoch 29, Loss: -5.266140937805176\n",
      "Epoch 30, Loss: -5.491955757141113\n",
      "Epoch 31, Loss: -5.722407341003418\n",
      "Epoch 32, Loss: -5.957647800445557\n",
      "Epoch 33, Loss: -6.197826385498047\n",
      "Epoch 34, Loss: -6.443087577819824\n",
      "Epoch 35, Loss: -6.693572998046875\n",
      "Epoch 36, Loss: -6.949415683746338\n",
      "Epoch 37, Loss: -7.210747241973877\n",
      "Epoch 38, Loss: -7.4776930809021\n",
      "Epoch 39, Loss: -7.7503743171691895\n",
      "Epoch 40, Loss: -8.028905868530273\n",
      "Epoch 41, Loss: -8.313401222229004\n",
      "Epoch 42, Loss: -8.60396671295166\n",
      "Epoch 43, Loss: -8.900707244873047\n",
      "Epoch 44, Loss: -9.203721046447754\n",
      "Epoch 45, Loss: -9.513104438781738\n",
      "Epoch 46, Loss: -9.82895278930664\n",
      "Epoch 47, Loss: -10.151354789733887\n",
      "Epoch 48, Loss: -10.48039722442627\n",
      "Epoch 49, Loss: -10.816165924072266\n",
      "Epoch 50, Loss: -11.158740997314453\n",
      "Epoch 51, Loss: -11.50820255279541\n",
      "Epoch 52, Loss: -11.864628791809082\n",
      "Epoch 53, Loss: -12.2280912399292\n",
      "Epoch 54, Loss: -12.59866714477539\n",
      "Epoch 55, Loss: -12.976421356201172\n",
      "Epoch 56, Loss: -13.361425399780273\n",
      "Epoch 57, Loss: -13.753744125366211\n",
      "Epoch 58, Loss: -14.153441429138184\n",
      "Epoch 59, Loss: -14.560578346252441\n",
      "Epoch 60, Loss: -14.975214004516602\n",
      "Epoch 61, Loss: -15.397408485412598\n",
      "Epoch 62, Loss: -15.827214241027832\n",
      "Epoch 63, Loss: -16.264686584472656\n",
      "Epoch 64, Loss: -16.709875106811523\n",
      "Epoch 65, Loss: -17.1628360748291\n",
      "Epoch 66, Loss: -17.62360954284668\n",
      "Epoch 67, Loss: -18.092243194580078\n",
      "Epoch 68, Loss: -18.568782806396484\n",
      "Epoch 69, Loss: -19.053268432617188\n",
      "Epoch 70, Loss: -19.545743942260742\n",
      "Epoch 71, Loss: -20.046245574951172\n",
      "Epoch 72, Loss: -20.554813385009766\n",
      "Epoch 73, Loss: -21.07147789001465\n",
      "Epoch 74, Loss: -21.596281051635742\n",
      "Epoch 75, Loss: -22.129249572753906\n",
      "Epoch 76, Loss: -22.6704158782959\n",
      "Epoch 77, Loss: -23.219810485839844\n",
      "Epoch 78, Loss: -23.777463912963867\n",
      "Epoch 79, Loss: -24.343406677246094\n",
      "Epoch 80, Loss: -24.91765785217285\n",
      "Epoch 81, Loss: -25.500247955322266\n",
      "Epoch 82, Loss: -26.091203689575195\n",
      "Epoch 83, Loss: -26.690540313720703\n",
      "Epoch 84, Loss: -27.298288345336914\n",
      "Epoch 85, Loss: -27.91446304321289\n",
      "Epoch 86, Loss: -28.53908920288086\n",
      "Epoch 87, Loss: -29.17218589782715\n",
      "Epoch 88, Loss: -29.813770294189453\n",
      "Epoch 89, Loss: -30.463869094848633\n",
      "Epoch 90, Loss: -31.122486114501953\n",
      "Epoch 91, Loss: -31.789644241333008\n",
      "Epoch 92, Loss: -32.46535873413086\n",
      "Epoch 93, Loss: -33.1496467590332\n",
      "Epoch 94, Loss: -33.842525482177734\n",
      "Epoch 95, Loss: -34.544002532958984\n",
      "Epoch 96, Loss: -35.25409698486328\n",
      "Epoch 97, Loss: -35.972816467285156\n",
      "Epoch 98, Loss: -36.70018005371094\n",
      "Epoch 99, Loss: -37.43619155883789\n",
      "Validation Loss for DistMult: 0.00123378646094352\n",
      "Confusion Matrix:\n",
      "[[0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 1]]\n",
      "True Negatives (TN): [0 1 1 1 1 0 1 1 1 0 1]\n",
      "False Positives (FP): [0 1 0 0 0 0 0 0 0 0 2]\n",
      "Metrics for DistMult: {'precision': 0.6212121212121212, 'recall': 0.7272727272727273, 'f1_score': 0.6515151515151515, 'accuracy': 0.7272727272727273, 'specificity': 0.6212121212121212, 'sensitivity': 0.9752066115702479, 'roc_auc': 0.85, 'mcc': 0.72693285284751}\n",
      "Training ComplEx...\n",
      "Epoch 0, Loss: 0.43005573749542236\n",
      "Epoch 1, Loss: 0.2788528800010681\n",
      "Epoch 2, Loss: 0.1277782917022705\n",
      "Epoch 3, Loss: -0.02324703335762024\n",
      "Epoch 4, Loss: -0.1743377298116684\n",
      "Epoch 5, Loss: -0.3256012201309204\n",
      "Epoch 6, Loss: -0.47716349363327026\n",
      "Epoch 7, Loss: -0.6291671395301819\n",
      "Epoch 8, Loss: -0.7817578315734863\n",
      "Epoch 9, Loss: -0.9350837469100952\n",
      "Epoch 10, Loss: -1.0893000364303589\n",
      "Epoch 11, Loss: -1.2445707321166992\n",
      "Epoch 12, Loss: -1.4010677337646484\n",
      "Epoch 13, Loss: -1.5589685440063477\n",
      "Epoch 14, Loss: -1.7184529304504395\n",
      "Epoch 15, Loss: -1.8797032833099365\n",
      "Epoch 16, Loss: -2.042902946472168\n",
      "Epoch 17, Loss: -2.208237648010254\n",
      "Epoch 18, Loss: -2.375894069671631\n",
      "Epoch 19, Loss: -2.5460610389709473\n",
      "Epoch 20, Loss: -2.7189273834228516\n",
      "Epoch 21, Loss: -2.8946831226348877\n",
      "Epoch 22, Loss: -3.073516368865967\n",
      "Epoch 23, Loss: -3.2556145191192627\n",
      "Epoch 24, Loss: -3.4411613941192627\n",
      "Epoch 25, Loss: -3.630338430404663\n",
      "Epoch 26, Loss: -3.8233227729797363\n",
      "Epoch 27, Loss: -4.020288467407227\n",
      "Epoch 28, Loss: -4.22140645980835\n",
      "Epoch 29, Loss: -4.42684268951416\n",
      "Epoch 30, Loss: -4.636758327484131\n",
      "Epoch 31, Loss: -4.851312160491943\n",
      "Epoch 32, Loss: -5.0706586837768555\n",
      "Epoch 33, Loss: -5.294945240020752\n",
      "Epoch 34, Loss: -5.524318218231201\n",
      "Epoch 35, Loss: -5.758917808532715\n",
      "Epoch 36, Loss: -5.9988813400268555\n",
      "Epoch 37, Loss: -6.244340419769287\n",
      "Epoch 38, Loss: -6.495424747467041\n",
      "Epoch 39, Loss: -6.752254962921143\n",
      "Epoch 40, Loss: -7.01495361328125\n",
      "Epoch 41, Loss: -7.283636093139648\n",
      "Epoch 42, Loss: -7.558413028717041\n",
      "Epoch 43, Loss: -7.83939266204834\n",
      "Epoch 44, Loss: -8.126677513122559\n",
      "Epoch 45, Loss: -8.420368194580078\n",
      "Epoch 46, Loss: -8.720561027526855\n",
      "Epoch 47, Loss: -9.02734661102295\n",
      "Epoch 48, Loss: -9.340814590454102\n",
      "Epoch 49, Loss: -9.661048889160156\n",
      "Epoch 50, Loss: -9.988133430480957\n",
      "Epoch 51, Loss: -10.322147369384766\n",
      "Epoch 52, Loss: -10.663165092468262\n",
      "Epoch 53, Loss: -11.011260032653809\n",
      "Epoch 54, Loss: -11.366503715515137\n",
      "Epoch 55, Loss: -11.728961944580078\n",
      "Epoch 56, Loss: -12.098703384399414\n",
      "Epoch 57, Loss: -12.475787162780762\n",
      "Epoch 58, Loss: -12.860278129577637\n",
      "Epoch 59, Loss: -13.252232551574707\n",
      "Epoch 60, Loss: -13.65170669555664\n",
      "Epoch 61, Loss: -14.058755874633789\n",
      "Epoch 62, Loss: -14.473434448242188\n",
      "Epoch 63, Loss: -14.895792007446289\n",
      "Epoch 64, Loss: -15.325875282287598\n",
      "Epoch 65, Loss: -15.7637357711792\n",
      "Epoch 66, Loss: -16.209415435791016\n",
      "Epoch 67, Loss: -16.662960052490234\n",
      "Epoch 68, Loss: -17.124412536621094\n",
      "Epoch 69, Loss: -17.593812942504883\n",
      "Epoch 70, Loss: -18.07120132446289\n",
      "Epoch 71, Loss: -18.556617736816406\n",
      "Epoch 72, Loss: -19.050098419189453\n",
      "Epoch 73, Loss: -19.551673889160156\n",
      "Epoch 74, Loss: -20.061389923095703\n",
      "Epoch 75, Loss: -20.579269409179688\n",
      "Epoch 76, Loss: -21.1053524017334\n",
      "Epoch 77, Loss: -21.639667510986328\n",
      "Epoch 78, Loss: -22.1822509765625\n",
      "Epoch 79, Loss: -22.73312759399414\n",
      "Epoch 80, Loss: -23.292327880859375\n",
      "Epoch 81, Loss: -23.859882354736328\n",
      "Epoch 82, Loss: -24.43581771850586\n",
      "Epoch 83, Loss: -25.020166397094727\n",
      "Epoch 84, Loss: -25.612953186035156\n",
      "Epoch 85, Loss: -26.214200973510742\n",
      "Epoch 86, Loss: -26.82394027709961\n",
      "Epoch 87, Loss: -27.44219398498535\n",
      "Epoch 88, Loss: -28.068986892700195\n",
      "Epoch 89, Loss: -28.704343795776367\n",
      "Epoch 90, Loss: -29.348291397094727\n",
      "Epoch 91, Loss: -30.0008487701416\n",
      "Epoch 92, Loss: -30.662031173706055\n",
      "Epoch 93, Loss: -31.33186912536621\n",
      "Epoch 94, Loss: -32.0103759765625\n",
      "Epoch 95, Loss: -32.69757080078125\n",
      "Epoch 96, Loss: -33.393470764160156\n",
      "Epoch 97, Loss: -34.09809875488281\n",
      "Epoch 98, Loss: -34.81146240234375\n",
      "Epoch 99, Loss: -35.53357696533203\n",
      "Validation Loss for ComplEx: -0.00026838117628358305\n",
      "Confusion Matrix:\n",
      "[[0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1]]\n",
      "True Negatives (TN): [0 1 1 1 1 0 1 1 1 0 1]\n",
      "False Positives (FP): [0 0 0 1 0 0 0 1 0 0 1]\n",
      "Metrics for ComplEx: {'precision': 0.5909090909090909, 'recall': 0.7272727272727273, 'f1_score': 0.6363636363636364, 'accuracy': 0.7272727272727273, 'specificity': 0.5909090909090909, 'sensitivity': 0.9752066115702479, 'roc_auc': 0.85, 'mcc': 0.719909182306512}\n",
      "Training HAN...\n",
      "Epoch 0, Loss: -0.3945483863353729\n",
      "Epoch 1, Loss: -0.556364119052887\n",
      "Epoch 2, Loss: -0.7186431288719177\n",
      "Epoch 3, Loss: -0.8815699815750122\n",
      "Epoch 4, Loss: -1.0452752113342285\n",
      "Epoch 5, Loss: -1.2098939418792725\n",
      "Epoch 6, Loss: -1.3755624294281006\n",
      "Epoch 7, Loss: -1.542414903640747\n",
      "Epoch 8, Loss: -1.7105846405029297\n",
      "Epoch 9, Loss: -1.8802073001861572\n",
      "Epoch 10, Loss: -2.051421642303467\n",
      "Epoch 11, Loss: -2.2243709564208984\n",
      "Epoch 12, Loss: -2.399203062057495\n",
      "Epoch 13, Loss: -2.5760672092437744\n",
      "Epoch 14, Loss: -2.7551169395446777\n",
      "Epoch 15, Loss: -2.9365057945251465\n",
      "Epoch 16, Loss: -3.120391607284546\n",
      "Epoch 17, Loss: -3.3069305419921875\n",
      "Epoch 18, Loss: -3.4962830543518066\n",
      "Epoch 19, Loss: -3.6886069774627686\n",
      "Epoch 20, Loss: -3.8840630054473877\n",
      "Epoch 21, Loss: -4.082810401916504\n",
      "Epoch 22, Loss: -4.285007953643799\n",
      "Epoch 23, Loss: -4.4908127784729\n",
      "Epoch 24, Loss: -4.700382709503174\n",
      "Epoch 25, Loss: -4.913870811462402\n",
      "Epoch 26, Loss: -5.131430149078369\n",
      "Epoch 27, Loss: -5.353209495544434\n",
      "Epoch 28, Loss: -5.5793561935424805\n",
      "Epoch 29, Loss: -5.810013771057129\n",
      "Epoch 30, Loss: -6.045324325561523\n",
      "Epoch 31, Loss: -6.28542423248291\n",
      "Epoch 32, Loss: -6.5304484367370605\n",
      "Epoch 33, Loss: -6.7805280685424805\n",
      "Epoch 34, Loss: -7.035790920257568\n",
      "Epoch 35, Loss: -7.296361446380615\n",
      "Epoch 36, Loss: -7.56235933303833\n",
      "Epoch 37, Loss: -7.833902835845947\n",
      "Epoch 38, Loss: -8.111106872558594\n",
      "Epoch 39, Loss: -8.39408016204834\n",
      "Epoch 40, Loss: -8.682930946350098\n",
      "Epoch 41, Loss: -8.977761268615723\n",
      "Epoch 42, Loss: -9.27867317199707\n",
      "Epoch 43, Loss: -9.585762977600098\n",
      "Epoch 44, Loss: -9.899125099182129\n",
      "Epoch 45, Loss: -10.218852043151855\n",
      "Epoch 46, Loss: -10.545032501220703\n",
      "Epoch 47, Loss: -10.877752304077148\n",
      "Epoch 48, Loss: -11.217096328735352\n",
      "Epoch 49, Loss: -11.563148498535156\n",
      "Epoch 50, Loss: -11.915987014770508\n",
      "Epoch 51, Loss: -12.275690078735352\n",
      "Epoch 52, Loss: -12.642333030700684\n",
      "Epoch 53, Loss: -13.015989303588867\n",
      "Epoch 54, Loss: -13.396730422973633\n",
      "Epoch 55, Loss: -13.784622192382812\n",
      "Epoch 56, Loss: -14.179732322692871\n",
      "Epoch 57, Loss: -14.582122802734375\n",
      "Epoch 58, Loss: -14.991852760314941\n",
      "Epoch 59, Loss: -15.408982276916504\n",
      "Epoch 60, Loss: -15.833566665649414\n",
      "Epoch 61, Loss: -16.265655517578125\n",
      "Epoch 62, Loss: -16.70530891418457\n",
      "Epoch 63, Loss: -17.152568817138672\n",
      "Epoch 64, Loss: -17.607484817504883\n",
      "Epoch 65, Loss: -18.070106506347656\n",
      "Epoch 66, Loss: -18.540475845336914\n",
      "Epoch 67, Loss: -19.01863670349121\n",
      "Epoch 68, Loss: -19.504629135131836\n",
      "Epoch 69, Loss: -19.998493194580078\n",
      "Epoch 70, Loss: -20.500268936157227\n",
      "Epoch 71, Loss: -21.009990692138672\n",
      "Epoch 72, Loss: -21.527694702148438\n",
      "Epoch 73, Loss: -22.053422927856445\n",
      "Epoch 74, Loss: -22.587200164794922\n",
      "Epoch 75, Loss: -23.129064559936523\n",
      "Epoch 76, Loss: -23.67905044555664\n",
      "Epoch 77, Loss: -24.2371826171875\n",
      "Epoch 78, Loss: -24.80349349975586\n",
      "Epoch 79, Loss: -25.378019332885742\n",
      "Epoch 80, Loss: -25.960783004760742\n",
      "Epoch 81, Loss: -26.551816940307617\n",
      "Epoch 82, Loss: -27.151142120361328\n",
      "Epoch 83, Loss: -27.7587947845459\n",
      "Epoch 84, Loss: -28.374792098999023\n",
      "Epoch 85, Loss: -28.99916648864746\n",
      "Epoch 86, Loss: -29.631940841674805\n",
      "Epoch 87, Loss: -30.27313804626465\n",
      "Epoch 88, Loss: -30.922779083251953\n",
      "Epoch 89, Loss: -31.580888748168945\n",
      "Epoch 90, Loss: -32.24748611450195\n",
      "Epoch 91, Loss: -32.92259216308594\n",
      "Epoch 92, Loss: -33.606224060058594\n",
      "Epoch 93, Loss: -34.29840087890625\n",
      "Epoch 94, Loss: -34.999141693115234\n",
      "Epoch 95, Loss: -35.708457946777344\n",
      "Epoch 96, Loss: -36.42636489868164\n",
      "Epoch 97, Loss: -37.15288162231445\n",
      "Epoch 98, Loss: -37.88801574707031\n",
      "Epoch 99, Loss: -38.63179016113281\n",
      "Validation Loss for HAN: 0.0012399597326293588\n",
      "Confusion Matrix:\n",
      "[[0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1]]\n",
      "True Negatives (TN): [0 1 1 1 1 0 1 1 1 0 1]\n",
      "False Positives (FP): [0 0 0 1 0 0 0 0 1 0 1]\n",
      "Metrics for HAN: {'precision': 0.5909090909090909, 'recall': 0.7272727272727273, 'f1_score': 0.6363636363636364, 'accuracy': 0.7272727272727273, 'specificity': 0.5909090909090909, 'sensitivity': 0.9752066115702479, 'roc_auc': 0.85, 'mcc': 0.719909182306512}\n",
      "Training MetaPath2Vec...\n",
      "Epoch 0, Loss: 0.1659279614686966\n",
      "Epoch 1, Loss: 0.015122532844543457\n",
      "Epoch 2, Loss: -0.13537782430648804\n",
      "Epoch 3, Loss: -0.2856891453266144\n",
      "Epoch 4, Loss: -0.4359508752822876\n",
      "Epoch 5, Loss: -0.5863238573074341\n",
      "Epoch 6, Loss: -0.7369589805603027\n",
      "Epoch 7, Loss: -0.8880003094673157\n",
      "Epoch 8, Loss: -1.039601445198059\n",
      "Epoch 9, Loss: -1.191928744316101\n",
      "Epoch 10, Loss: -1.3451555967330933\n",
      "Epoch 11, Loss: -1.4994555711746216\n",
      "Epoch 12, Loss: -1.6549999713897705\n",
      "Epoch 13, Loss: -1.811956763267517\n",
      "Epoch 14, Loss: -1.9704954624176025\n",
      "Epoch 15, Loss: -2.1307878494262695\n",
      "Epoch 16, Loss: -2.2930099964141846\n",
      "Epoch 17, Loss: -2.4573442935943604\n",
      "Epoch 18, Loss: -2.6239776611328125\n",
      "Epoch 19, Loss: -2.793102979660034\n",
      "Epoch 20, Loss: -2.9649176597595215\n",
      "Epoch 21, Loss: -3.139620304107666\n",
      "Epoch 22, Loss: -3.317411422729492\n",
      "Epoch 23, Loss: -3.498488426208496\n",
      "Epoch 24, Loss: -3.6830480098724365\n",
      "Epoch 25, Loss: -3.8712806701660156\n",
      "Epoch 26, Loss: -4.06337308883667\n",
      "Epoch 27, Loss: -4.259505271911621\n",
      "Epoch 28, Loss: -4.45985221862793\n",
      "Epoch 29, Loss: -4.664581298828125\n",
      "Epoch 30, Loss: -4.873856067657471\n",
      "Epoch 31, Loss: -5.087831974029541\n",
      "Epoch 32, Loss: -5.306661605834961\n",
      "Epoch 33, Loss: -5.530490875244141\n",
      "Epoch 34, Loss: -5.759460926055908\n",
      "Epoch 35, Loss: -5.99370813369751\n",
      "Epoch 36, Loss: -6.233365535736084\n",
      "Epoch 37, Loss: -6.4785614013671875\n",
      "Epoch 38, Loss: -6.7294182777404785\n",
      "Epoch 39, Loss: -6.986057281494141\n",
      "Epoch 40, Loss: -7.248594284057617\n",
      "Epoch 41, Loss: -7.517139911651611\n",
      "Epoch 42, Loss: -7.791805267333984\n",
      "Epoch 43, Loss: -8.07269287109375\n",
      "Epoch 44, Loss: -8.359907150268555\n",
      "Epoch 45, Loss: -8.653545379638672\n",
      "Epoch 46, Loss: -8.953703880310059\n",
      "Epoch 47, Loss: -9.260476112365723\n",
      "Epoch 48, Loss: -9.573948860168457\n",
      "Epoch 49, Loss: -9.894211769104004\n",
      "Epoch 50, Loss: -10.221349716186523\n",
      "Epoch 51, Loss: -10.555440902709961\n",
      "Epoch 52, Loss: -10.896567344665527\n",
      "Epoch 53, Loss: -11.244804382324219\n",
      "Epoch 54, Loss: -11.600225448608398\n",
      "Epoch 55, Loss: -11.962902069091797\n",
      "Epoch 56, Loss: -12.332902908325195\n",
      "Epoch 57, Loss: -12.710293769836426\n",
      "Epoch 58, Loss: -13.09514045715332\n",
      "Epoch 59, Loss: -13.487502098083496\n",
      "Epoch 60, Loss: -13.887438774108887\n",
      "Epoch 61, Loss: -14.29500675201416\n",
      "Epoch 62, Loss: -14.710261344909668\n",
      "Epoch 63, Loss: -15.133254051208496\n",
      "Epoch 64, Loss: -15.564033508300781\n",
      "Epoch 65, Loss: -16.002649307250977\n",
      "Epoch 66, Loss: -16.449146270751953\n",
      "Epoch 67, Loss: -16.903568267822266\n",
      "Epoch 68, Loss: -17.36595916748047\n",
      "Epoch 69, Loss: -17.836353302001953\n",
      "Epoch 70, Loss: -18.31479263305664\n",
      "Epoch 71, Loss: -18.801315307617188\n",
      "Epoch 72, Loss: -19.295955657958984\n",
      "Epoch 73, Loss: -19.798742294311523\n",
      "Epoch 74, Loss: -20.309711456298828\n",
      "Epoch 75, Loss: -20.82889175415039\n",
      "Epoch 76, Loss: -21.356313705444336\n",
      "Epoch 77, Loss: -21.892005920410156\n",
      "Epoch 78, Loss: -22.435993194580078\n",
      "Epoch 79, Loss: -22.988306045532227\n",
      "Epoch 80, Loss: -23.548961639404297\n",
      "Epoch 81, Loss: -24.11798858642578\n",
      "Epoch 82, Loss: -24.695411682128906\n",
      "Epoch 83, Loss: -25.281248092651367\n",
      "Epoch 84, Loss: -25.87552261352539\n",
      "Epoch 85, Loss: -26.478252410888672\n",
      "Epoch 86, Loss: -27.089460372924805\n",
      "Epoch 87, Loss: -27.70916175842285\n",
      "Epoch 88, Loss: -28.337379455566406\n",
      "Epoch 89, Loss: -28.97413444519043\n",
      "Epoch 90, Loss: -29.61943244934082\n",
      "Epoch 91, Loss: -30.273305892944336\n",
      "Epoch 92, Loss: -30.935760498046875\n",
      "Epoch 93, Loss: -31.6068172454834\n",
      "Epoch 94, Loss: -32.28649139404297\n",
      "Epoch 95, Loss: -32.97480010986328\n",
      "Epoch 96, Loss: -33.671756744384766\n",
      "Epoch 97, Loss: -34.377384185791016\n",
      "Epoch 98, Loss: -35.09169006347656\n",
      "Epoch 99, Loss: -35.814693450927734\n",
      "Validation Loss for MetaPath2Vec: -0.00037378838169388473\n",
      "Confusion Matrix:\n",
      "[[0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1]]\n",
      "True Negatives (TN): [0 1 1 1 1 0 1 1 1 0 1]\n",
      "False Positives (FP): [0 1 0 0 2 0 0 0 0 0 0]\n",
      "Metrics for MetaPath2Vec: {'precision': 0.6212121212121212, 'recall': 0.7272727272727273, 'f1_score': 0.6515151515151515, 'accuracy': 0.7272727272727273, 'specificity': 0.6212121212121212, 'sensitivity': 0.9752066115702479, 'roc_auc': 0.85, 'mcc': 0.72693285284751}\n",
      "Training GCF...\n",
      "Epoch 0, Loss: -0.1458290070295334\n",
      "Epoch 1, Loss: -0.2883600890636444\n",
      "Epoch 2, Loss: -0.4315786361694336\n",
      "Epoch 3, Loss: -0.5756525993347168\n",
      "Epoch 4, Loss: -0.7207047343254089\n",
      "Epoch 5, Loss: -0.86685711145401\n",
      "Epoch 6, Loss: -1.0142185688018799\n",
      "Epoch 7, Loss: -1.1628903150558472\n",
      "Epoch 8, Loss: -1.3129775524139404\n",
      "Epoch 9, Loss: -1.4645941257476807\n",
      "Epoch 10, Loss: -1.6178640127182007\n",
      "Epoch 11, Loss: -1.7729237079620361\n",
      "Epoch 12, Loss: -1.9299213886260986\n",
      "Epoch 13, Loss: -2.089017391204834\n",
      "Epoch 14, Loss: -2.250380754470825\n",
      "Epoch 15, Loss: -2.414186477661133\n",
      "Epoch 16, Loss: -2.580611228942871\n",
      "Epoch 17, Loss: -2.749830961227417\n",
      "Epoch 18, Loss: -2.9220187664031982\n",
      "Epoch 19, Loss: -3.097343683242798\n",
      "Epoch 20, Loss: -3.2759690284729004\n",
      "Epoch 21, Loss: -3.458055019378662\n",
      "Epoch 22, Loss: -3.6437559127807617\n",
      "Epoch 23, Loss: -3.833221673965454\n",
      "Epoch 24, Loss: -4.026599407196045\n",
      "Epoch 25, Loss: -4.224029541015625\n",
      "Epoch 26, Loss: -4.425652503967285\n",
      "Epoch 27, Loss: -4.631603717803955\n",
      "Epoch 28, Loss: -4.842017650604248\n",
      "Epoch 29, Loss: -5.057024955749512\n",
      "Epoch 30, Loss: -5.276756286621094\n",
      "Epoch 31, Loss: -5.501336097717285\n",
      "Epoch 32, Loss: -5.730891704559326\n",
      "Epoch 33, Loss: -5.965543746948242\n",
      "Epoch 34, Loss: -6.20541524887085\n",
      "Epoch 35, Loss: -6.450623035430908\n",
      "Epoch 36, Loss: -6.701282501220703\n",
      "Epoch 37, Loss: -6.957508087158203\n",
      "Epoch 38, Loss: -7.2194108963012695\n",
      "Epoch 39, Loss: -7.48709774017334\n",
      "Epoch 40, Loss: -7.760672569274902\n",
      "Epoch 41, Loss: -8.040240287780762\n",
      "Epoch 42, Loss: -8.325895309448242\n",
      "Epoch 43, Loss: -8.61773681640625\n",
      "Epoch 44, Loss: -8.91585636138916\n",
      "Epoch 45, Loss: -9.220342636108398\n",
      "Epoch 46, Loss: -9.53128433227539\n",
      "Epoch 47, Loss: -9.848763465881348\n",
      "Epoch 48, Loss: -10.172861099243164\n",
      "Epoch 49, Loss: -10.50365924835205\n",
      "Epoch 50, Loss: -10.841233253479004\n",
      "Epoch 51, Loss: -11.18565845489502\n",
      "Epoch 52, Loss: -11.537007331848145\n",
      "Epoch 53, Loss: -11.895350456237793\n",
      "Epoch 54, Loss: -12.260756492614746\n",
      "Epoch 55, Loss: -12.633293151855469\n",
      "Epoch 56, Loss: -13.013023376464844\n",
      "Epoch 57, Loss: -13.400014877319336\n",
      "Epoch 58, Loss: -13.79432487487793\n",
      "Epoch 59, Loss: -14.19601821899414\n",
      "Epoch 60, Loss: -14.605149269104004\n",
      "Epoch 61, Loss: -15.021778106689453\n",
      "Epoch 62, Loss: -15.44595718383789\n",
      "Epoch 63, Loss: -15.877741813659668\n",
      "Epoch 64, Loss: -16.317182540893555\n",
      "Epoch 65, Loss: -16.76433563232422\n",
      "Epoch 66, Loss: -17.219242095947266\n",
      "Epoch 67, Loss: -17.68195343017578\n",
      "Epoch 68, Loss: -18.15251350402832\n",
      "Epoch 69, Loss: -18.630970001220703\n",
      "Epoch 70, Loss: -19.117359161376953\n",
      "Epoch 71, Loss: -19.61172866821289\n",
      "Epoch 72, Loss: -20.114116668701172\n",
      "Epoch 73, Loss: -20.624557495117188\n",
      "Epoch 74, Loss: -21.143089294433594\n",
      "Epoch 75, Loss: -21.669754028320312\n",
      "Epoch 76, Loss: -22.20457649230957\n",
      "Epoch 77, Loss: -22.74759292602539\n",
      "Epoch 78, Loss: -23.29883575439453\n",
      "Epoch 79, Loss: -23.85832977294922\n",
      "Epoch 80, Loss: -24.42611312866211\n",
      "Epoch 81, Loss: -25.0022029876709\n",
      "Epoch 82, Loss: -25.586631774902344\n",
      "Epoch 83, Loss: -26.179424285888672\n",
      "Epoch 84, Loss: -26.780603408813477\n",
      "Epoch 85, Loss: -27.39019203186035\n",
      "Epoch 86, Loss: -28.008211135864258\n",
      "Epoch 87, Loss: -28.63468360900879\n",
      "Epoch 88, Loss: -29.26963233947754\n",
      "Epoch 89, Loss: -29.913070678710938\n",
      "Epoch 90, Loss: -30.565019607543945\n",
      "Epoch 91, Loss: -31.225500106811523\n",
      "Epoch 92, Loss: -31.8945255279541\n",
      "Epoch 93, Loss: -32.572113037109375\n",
      "Epoch 94, Loss: -33.25828170776367\n",
      "Epoch 95, Loss: -33.953041076660156\n",
      "Epoch 96, Loss: -34.656410217285156\n",
      "Epoch 97, Loss: -35.368404388427734\n",
      "Epoch 98, Loss: -36.089027404785156\n",
      "Epoch 99, Loss: -36.818302154541016\n",
      "Validation Loss for GCF: -0.0009614203008823097\n",
      "Confusion Matrix:\n",
      "[[0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1]]\n",
      "True Negatives (TN): [0 1 1 1 1 0 1 1 1 0 1]\n",
      "False Positives (FP): [0 0 1 0 0 0 0 1 0 0 1]\n",
      "Metrics for GCF: {'precision': 0.5909090909090909, 'recall': 0.7272727272727273, 'f1_score': 0.6363636363636364, 'accuracy': 0.7272727272727273, 'specificity': 0.5909090909090909, 'sensitivity': 0.9752066115702479, 'roc_auc': 0.85, 'mcc': 0.719909182306512}\n",
      "Training GRMF...\n",
      "Epoch 0, Loss: -0.06586435437202454\n",
      "Epoch 1, Loss: -0.21871605515480042\n",
      "Epoch 2, Loss: -0.3716888427734375\n",
      "Epoch 3, Loss: -0.5249138474464417\n",
      "Epoch 4, Loss: -0.6785167455673218\n",
      "Epoch 5, Loss: -0.8326418399810791\n",
      "Epoch 6, Loss: -0.9874395728111267\n",
      "Epoch 7, Loss: -1.143052339553833\n",
      "Epoch 8, Loss: -1.299616813659668\n",
      "Epoch 9, Loss: -1.4572750329971313\n",
      "Epoch 10, Loss: -1.6161811351776123\n",
      "Epoch 11, Loss: -1.776502013206482\n",
      "Epoch 12, Loss: -1.9384148120880127\n",
      "Epoch 13, Loss: -2.102102518081665\n",
      "Epoch 14, Loss: -2.267749071121216\n",
      "Epoch 15, Loss: -2.435537099838257\n",
      "Epoch 16, Loss: -2.605644941329956\n",
      "Epoch 17, Loss: -2.7782487869262695\n",
      "Epoch 18, Loss: -2.953519344329834\n",
      "Epoch 19, Loss: -3.1316261291503906\n",
      "Epoch 20, Loss: -3.3127336502075195\n",
      "Epoch 21, Loss: -3.497006416320801\n",
      "Epoch 22, Loss: -3.6846072673797607\n",
      "Epoch 23, Loss: -3.875696897506714\n",
      "Epoch 24, Loss: -4.070435047149658\n",
      "Epoch 25, Loss: -4.26898193359375\n",
      "Epoch 26, Loss: -4.471493244171143\n",
      "Epoch 27, Loss: -4.678123950958252\n",
      "Epoch 28, Loss: -4.889027118682861\n",
      "Epoch 29, Loss: -5.1043500900268555\n",
      "Epoch 30, Loss: -5.3242387771606445\n",
      "Epoch 31, Loss: -5.548835754394531\n",
      "Epoch 32, Loss: -5.7782793045043945\n",
      "Epoch 33, Loss: -6.012705326080322\n",
      "Epoch 34, Loss: -6.252245903015137\n",
      "Epoch 35, Loss: -6.4970293045043945\n",
      "Epoch 36, Loss: -6.747182846069336\n",
      "Epoch 37, Loss: -7.0028276443481445\n",
      "Epoch 38, Loss: -7.264087200164795\n",
      "Epoch 39, Loss: -7.531076908111572\n",
      "Epoch 40, Loss: -7.80391263961792\n",
      "Epoch 41, Loss: -8.0827054977417\n",
      "Epoch 42, Loss: -8.367566108703613\n",
      "Epoch 43, Loss: -8.658599853515625\n",
      "Epoch 44, Loss: -8.955909729003906\n",
      "Epoch 45, Loss: -9.259596824645996\n",
      "Epoch 46, Loss: -9.569759368896484\n",
      "Epoch 47, Loss: -9.886490821838379\n",
      "Epoch 48, Loss: -10.209882736206055\n",
      "Epoch 49, Loss: -10.54002571105957\n",
      "Epoch 50, Loss: -10.87700366973877\n",
      "Epoch 51, Loss: -11.220898628234863\n",
      "Epoch 52, Loss: -11.571793556213379\n",
      "Epoch 53, Loss: -11.92976188659668\n",
      "Epoch 54, Loss: -12.294882774353027\n",
      "Epoch 55, Loss: -12.667224884033203\n",
      "Epoch 56, Loss: -13.046855926513672\n",
      "Epoch 57, Loss: -13.433844566345215\n",
      "Epoch 58, Loss: -13.828253746032715\n",
      "Epoch 59, Loss: -14.230146408081055\n",
      "Epoch 60, Loss: -14.639579772949219\n",
      "Epoch 61, Loss: -15.056612014770508\n",
      "Epoch 62, Loss: -15.481298446655273\n",
      "Epoch 63, Loss: -15.913688659667969\n",
      "Epoch 64, Loss: -16.35383415222168\n",
      "Epoch 65, Loss: -16.801786422729492\n",
      "Epoch 66, Loss: -17.257587432861328\n",
      "Epoch 67, Loss: -17.721284866333008\n",
      "Epoch 68, Loss: -18.19291877746582\n",
      "Epoch 69, Loss: -18.672534942626953\n",
      "Epoch 70, Loss: -19.16016960144043\n",
      "Epoch 71, Loss: -19.655858993530273\n",
      "Epoch 72, Loss: -20.15964126586914\n",
      "Epoch 73, Loss: -20.671554565429688\n",
      "Epoch 74, Loss: -21.191625595092773\n",
      "Epoch 75, Loss: -21.719890594482422\n",
      "Epoch 76, Loss: -22.256383895874023\n",
      "Epoch 77, Loss: -22.801124572753906\n",
      "Epoch 78, Loss: -23.354150772094727\n",
      "Epoch 79, Loss: -23.915485382080078\n",
      "Epoch 80, Loss: -24.485153198242188\n",
      "Epoch 81, Loss: -25.063180923461914\n",
      "Epoch 82, Loss: -25.649593353271484\n",
      "Epoch 83, Loss: -26.244413375854492\n",
      "Epoch 84, Loss: -26.847660064697266\n",
      "Epoch 85, Loss: -27.4593563079834\n",
      "Epoch 86, Loss: -28.07952117919922\n",
      "Epoch 87, Loss: -28.708173751831055\n",
      "Epoch 88, Loss: -29.3453369140625\n",
      "Epoch 89, Loss: -29.99102020263672\n",
      "Epoch 90, Loss: -30.64525032043457\n",
      "Epoch 91, Loss: -31.308034896850586\n",
      "Epoch 92, Loss: -31.979393005371094\n",
      "Epoch 93, Loss: -32.659339904785156\n",
      "Epoch 94, Loss: -33.34789276123047\n",
      "Epoch 95, Loss: -34.04506301879883\n",
      "Epoch 96, Loss: -34.75086212158203\n",
      "Epoch 97, Loss: -35.465301513671875\n",
      "Epoch 98, Loss: -36.18839645385742\n",
      "Epoch 99, Loss: -36.92015838623047\n",
      "Validation Loss for GRMF: 0.0004382373590487987\n",
      "Confusion Matrix:\n",
      "[[0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1]]\n",
      "True Negatives (TN): [0 1 1 1 1 0 1 1 1 0 1]\n",
      "False Positives (FP): [0 0 0 0 2 0 1 0 0 0 0]\n",
      "Metrics for GRMF: {'precision': 0.6212121212121212, 'recall': 0.7272727272727273, 'f1_score': 0.6515151515151515, 'accuracy': 0.7272727272727273, 'specificity': 0.6212121212121212, 'sensitivity': 0.9752066115702479, 'roc_auc': 0.85, 'mcc': 0.72693285284751}\n",
      "Training GAT...\n",
      "Epoch 0, Loss: 2.3915319442749023\n",
      "Epoch 1, Loss: 2.3841023445129395\n",
      "Epoch 2, Loss: 2.303027629852295\n",
      "Epoch 3, Loss: 2.3120017051696777\n",
      "Epoch 4, Loss: 2.2637014389038086\n",
      "Epoch 5, Loss: 2.1838510036468506\n",
      "Epoch 6, Loss: 2.175468683242798\n",
      "Epoch 7, Loss: 2.178220272064209\n",
      "Epoch 8, Loss: 2.1652963161468506\n",
      "Epoch 9, Loss: 2.187499523162842\n",
      "Epoch 10, Loss: 2.0412511825561523\n",
      "Epoch 11, Loss: 2.1513278484344482\n",
      "Epoch 12, Loss: 2.0584359169006348\n",
      "Epoch 13, Loss: 2.072739601135254\n",
      "Epoch 14, Loss: 2.1251509189605713\n",
      "Epoch 15, Loss: 2.0529773235321045\n",
      "Epoch 16, Loss: 2.092353582382202\n",
      "Epoch 17, Loss: 1.8696130514144897\n",
      "Epoch 18, Loss: 2.0358591079711914\n",
      "Epoch 19, Loss: 1.8319240808486938\n",
      "Epoch 20, Loss: 2.133483648300171\n",
      "Epoch 21, Loss: 1.9065276384353638\n",
      "Epoch 22, Loss: 2.130157232284546\n",
      "Epoch 23, Loss: 2.113258123397827\n",
      "Epoch 24, Loss: 1.7731140851974487\n",
      "Epoch 25, Loss: 2.107914686203003\n",
      "Epoch 26, Loss: 2.067732095718384\n",
      "Epoch 27, Loss: 1.7128863334655762\n",
      "Epoch 28, Loss: 2.082026958465576\n",
      "Epoch 29, Loss: 1.7329765558242798\n",
      "Epoch 30, Loss: 1.9170894622802734\n",
      "Epoch 31, Loss: 1.9094809293746948\n",
      "Epoch 32, Loss: 2.0661957263946533\n",
      "Epoch 33, Loss: 1.9201204776763916\n",
      "Epoch 34, Loss: 2.163480043411255\n",
      "Epoch 35, Loss: 2.089993715286255\n",
      "Epoch 36, Loss: 1.9019192457199097\n",
      "Epoch 37, Loss: 1.8190137147903442\n",
      "Epoch 38, Loss: 2.0125515460968018\n",
      "Epoch 39, Loss: 2.088090181350708\n",
      "Epoch 40, Loss: 1.7350800037384033\n",
      "Epoch 41, Loss: 1.7457859516143799\n",
      "Epoch 42, Loss: 1.6992273330688477\n",
      "Epoch 43, Loss: 2.024717092514038\n",
      "Epoch 44, Loss: 1.9546658992767334\n",
      "Epoch 45, Loss: 2.0953104496002197\n",
      "Epoch 46, Loss: 2.102536678314209\n",
      "Epoch 47, Loss: 1.894260048866272\n",
      "Epoch 48, Loss: 1.7456183433532715\n",
      "Epoch 49, Loss: 2.0359699726104736\n",
      "Epoch 50, Loss: 2.0188024044036865\n",
      "Epoch 51, Loss: 2.005276679992676\n",
      "Epoch 52, Loss: 1.80075204372406\n",
      "Epoch 53, Loss: 1.9026697874069214\n",
      "Epoch 54, Loss: 1.959465503692627\n",
      "Epoch 55, Loss: 1.916306972503662\n",
      "Epoch 56, Loss: 1.6664398908615112\n",
      "Epoch 57, Loss: 1.5777767896652222\n",
      "Epoch 58, Loss: 1.7259501218795776\n",
      "Epoch 59, Loss: 1.9943832159042358\n",
      "Epoch 60, Loss: 2.0420703887939453\n",
      "Epoch 61, Loss: 1.6600515842437744\n",
      "Epoch 62, Loss: 1.6820423603057861\n",
      "Epoch 63, Loss: 1.956489086151123\n",
      "Epoch 64, Loss: 1.733864426612854\n",
      "Epoch 65, Loss: 1.9680159091949463\n",
      "Epoch 66, Loss: 1.689264178276062\n",
      "Epoch 67, Loss: 1.6991480588912964\n",
      "Epoch 68, Loss: 1.8648332357406616\n",
      "Epoch 69, Loss: 2.024345874786377\n",
      "Epoch 70, Loss: 1.6523984670639038\n",
      "Epoch 71, Loss: 1.4860635995864868\n",
      "Epoch 72, Loss: 1.3907687664031982\n",
      "Epoch 73, Loss: 1.3442552089691162\n",
      "Epoch 74, Loss: 1.9947314262390137\n",
      "Epoch 75, Loss: 2.0057194232940674\n",
      "Epoch 76, Loss: 1.464205265045166\n",
      "Epoch 77, Loss: 1.9618964195251465\n",
      "Epoch 78, Loss: 1.233341932296753\n",
      "Epoch 79, Loss: 1.2036099433898926\n",
      "Epoch 80, Loss: 1.5292948484420776\n",
      "Epoch 81, Loss: 1.8177504539489746\n",
      "Epoch 82, Loss: 1.9144964218139648\n",
      "Epoch 83, Loss: 1.4170870780944824\n",
      "Epoch 84, Loss: 1.5291203260421753\n",
      "Epoch 85, Loss: 1.674170732498169\n",
      "Epoch 86, Loss: 2.1584537029266357\n",
      "Epoch 87, Loss: 1.6489958763122559\n",
      "Epoch 88, Loss: 1.8411494493484497\n",
      "Epoch 89, Loss: 1.4545469284057617\n",
      "Epoch 90, Loss: 1.5863754749298096\n",
      "Epoch 91, Loss: 1.632715106010437\n",
      "Epoch 92, Loss: 1.6132185459136963\n",
      "Epoch 93, Loss: 1.4035509824752808\n",
      "Epoch 94, Loss: 2.094033718109131\n",
      "Epoch 95, Loss: 1.9229114055633545\n",
      "Epoch 96, Loss: 1.2808886766433716\n",
      "Epoch 97, Loss: 1.6858264207839966\n",
      "Epoch 98, Loss: 1.6317898035049438\n",
      "Epoch 99, Loss: 1.821180820465088\n",
      "Validation Loss for GAT: 6.668254852294922\n",
      "Confusion Matrix:\n",
      "[[0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0]]\n",
      "True Negatives (TN): [0 1 0 0 1 0 0 1 1 0 0]\n",
      "False Positives (FP): [0 0 0 0 1 0 1 0 5 0 0]\n",
      "Metrics for GAT: {'precision': 0.2424242424242424, 'recall': 0.36363636363636365, 'f1_score': 0.26839826839826836, 'accuracy': 0.36363636363636365, 'specificity': 0.2424242424242424, 'sensitivity': 0.9413223140495867, 'roc_auc': 0.65, 'mcc': 0.35626265159721265}\n",
      "Training STAGE...\n",
      "Epoch 0, Loss: 0.22498512268066406\n",
      "Epoch 1, Loss: 0.07096506655216217\n",
      "Epoch 2, Loss: -0.08266828954219818\n",
      "Epoch 3, Loss: -0.23600585758686066\n",
      "Epoch 4, Loss: -0.38914167881011963\n",
      "Epoch 5, Loss: -0.5421899557113647\n",
      "Epoch 6, Loss: -0.6952948570251465\n",
      "Epoch 7, Loss: -0.8486060500144958\n",
      "Epoch 8, Loss: -1.002273440361023\n",
      "Epoch 9, Loss: -1.1564522981643677\n",
      "Epoch 10, Loss: -1.311306357383728\n",
      "Epoch 11, Loss: -1.4670089483261108\n",
      "Epoch 12, Loss: -1.623742938041687\n",
      "Epoch 13, Loss: -1.7816976308822632\n",
      "Epoch 14, Loss: -1.941066026687622\n",
      "Epoch 15, Loss: -2.1020419597625732\n",
      "Epoch 16, Loss: -2.2648189067840576\n",
      "Epoch 17, Loss: -2.4295895099639893\n",
      "Epoch 18, Loss: -2.5965445041656494\n",
      "Epoch 19, Loss: -2.7658748626708984\n",
      "Epoch 20, Loss: -2.9377694129943848\n",
      "Epoch 21, Loss: -3.112417221069336\n",
      "Epoch 22, Loss: -3.290005922317505\n",
      "Epoch 23, Loss: -3.470722198486328\n",
      "Epoch 24, Loss: -3.6547508239746094\n",
      "Epoch 25, Loss: -3.8422746658325195\n",
      "Epoch 26, Loss: -4.033474922180176\n",
      "Epoch 27, Loss: -4.228528022766113\n",
      "Epoch 28, Loss: -4.427608966827393\n",
      "Epoch 29, Loss: -4.630886077880859\n",
      "Epoch 30, Loss: -4.838526248931885\n",
      "Epoch 31, Loss: -5.050689697265625\n",
      "Epoch 32, Loss: -5.26753044128418\n",
      "Epoch 33, Loss: -5.489200115203857\n",
      "Epoch 34, Loss: -5.715843677520752\n",
      "Epoch 35, Loss: -5.947600841522217\n",
      "Epoch 36, Loss: -6.184605598449707\n",
      "Epoch 37, Loss: -6.426987648010254\n",
      "Epoch 38, Loss: -6.674874305725098\n",
      "Epoch 39, Loss: -6.928384780883789\n",
      "Epoch 40, Loss: -7.18763542175293\n",
      "Epoch 41, Loss: -7.452739238739014\n",
      "Epoch 42, Loss: -7.7238054275512695\n",
      "Epoch 43, Loss: -8.000940322875977\n",
      "Epoch 44, Loss: -8.284244537353516\n",
      "Epoch 45, Loss: -8.573820114135742\n",
      "Epoch 46, Loss: -8.86976432800293\n",
      "Epoch 47, Loss: -9.17216968536377\n",
      "Epoch 48, Loss: -9.481131553649902\n",
      "Epoch 49, Loss: -9.796737670898438\n",
      "Epoch 50, Loss: -10.119080543518066\n",
      "Epoch 51, Loss: -10.448243141174316\n",
      "Epoch 52, Loss: -10.78431224822998\n",
      "Epoch 53, Loss: -11.127372741699219\n",
      "Epoch 54, Loss: -11.477502822875977\n",
      "Epoch 55, Loss: -11.834783554077148\n",
      "Epoch 56, Loss: -12.199295043945312\n",
      "Epoch 57, Loss: -12.571112632751465\n",
      "Epoch 58, Loss: -12.950311660766602\n",
      "Epoch 59, Loss: -13.336962699890137\n",
      "Epoch 60, Loss: -13.73114013671875\n",
      "Epoch 61, Loss: -14.132909774780273\n",
      "Epoch 62, Loss: -14.542341232299805\n",
      "Epoch 63, Loss: -14.959497451782227\n",
      "Epoch 64, Loss: -15.384443283081055\n",
      "Epoch 65, Loss: -15.817238807678223\n",
      "Epoch 66, Loss: -16.257946014404297\n",
      "Epoch 67, Loss: -16.706615447998047\n",
      "Epoch 68, Loss: -17.163307189941406\n",
      "Epoch 69, Loss: -17.628068923950195\n",
      "Epoch 70, Loss: -18.1009521484375\n",
      "Epoch 71, Loss: -18.582008361816406\n",
      "Epoch 72, Loss: -19.0712833404541\n",
      "Epoch 73, Loss: -19.568815231323242\n",
      "Epoch 74, Loss: -20.074649810791016\n",
      "Epoch 75, Loss: -20.588829040527344\n",
      "Epoch 76, Loss: -21.11138153076172\n",
      "Epoch 77, Loss: -21.642353057861328\n",
      "Epoch 78, Loss: -22.18177032470703\n",
      "Epoch 79, Loss: -22.729671478271484\n",
      "Epoch 80, Loss: -23.286081314086914\n",
      "Epoch 81, Loss: -23.851032257080078\n",
      "Epoch 82, Loss: -24.424551010131836\n",
      "Epoch 83, Loss: -25.006662368774414\n",
      "Epoch 84, Loss: -25.59739112854004\n",
      "Epoch 85, Loss: -26.196758270263672\n",
      "Epoch 86, Loss: -26.804792404174805\n",
      "Epoch 87, Loss: -27.421506881713867\n",
      "Epoch 88, Loss: -28.04692268371582\n",
      "Epoch 89, Loss: -28.68105697631836\n",
      "Epoch 90, Loss: -29.323932647705078\n",
      "Epoch 91, Loss: -29.975563049316406\n",
      "Epoch 92, Loss: -30.635961532592773\n",
      "Epoch 93, Loss: -31.305145263671875\n",
      "Epoch 94, Loss: -31.983123779296875\n",
      "Epoch 95, Loss: -32.669918060302734\n",
      "Epoch 96, Loss: -33.365535736083984\n",
      "Epoch 97, Loss: -34.06998825073242\n",
      "Epoch 98, Loss: -34.783287048339844\n",
      "Epoch 99, Loss: -35.50544738769531\n",
      "Validation Loss for STAGE: -0.0004105253319721669\n",
      "Confusion Matrix:\n",
      "[[0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1]]\n",
      "True Negatives (TN): [0 1 1 1 1 0 1 1 1 0 1]\n",
      "False Positives (FP): [0 2 0 0 0 0 0 1 0 0 0]\n",
      "Metrics for STAGE: {'precision': 0.6212121212121212, 'recall': 0.7272727272727273, 'f1_score': 0.6515151515151515, 'accuracy': 0.7272727272727273, 'specificity': 0.6212121212121212, 'sensitivity': 0.9752066115702479, 'roc_auc': 0.85, 'mcc': 0.72693285284751}\n",
      "Training SR-GNN...\n",
      "Epoch 0, Loss: -0.10047490149736404\n",
      "Epoch 1, Loss: -0.25922274589538574\n",
      "Epoch 2, Loss: -0.41783013939857483\n",
      "Epoch 3, Loss: -0.5763864517211914\n",
      "Epoch 4, Loss: -0.7350186705589294\n",
      "Epoch 5, Loss: -0.8938916921615601\n",
      "Epoch 6, Loss: -1.0531946420669556\n",
      "Epoch 7, Loss: -1.2131218910217285\n",
      "Epoch 8, Loss: -1.3738641738891602\n",
      "Epoch 9, Loss: -1.5356075763702393\n",
      "Epoch 10, Loss: -1.698533296585083\n",
      "Epoch 11, Loss: -1.862818717956543\n",
      "Epoch 12, Loss: -2.0286386013031006\n",
      "Epoch 13, Loss: -2.196169137954712\n",
      "Epoch 14, Loss: -2.365584135055542\n",
      "Epoch 15, Loss: -2.5370590686798096\n",
      "Epoch 16, Loss: -2.7107696533203125\n",
      "Epoch 17, Loss: -2.886889696121216\n",
      "Epoch 18, Loss: -3.0655956268310547\n",
      "Epoch 19, Loss: -3.2470626831054688\n",
      "Epoch 20, Loss: -3.431467056274414\n",
      "Epoch 21, Loss: -3.618983268737793\n",
      "Epoch 22, Loss: -3.8097872734069824\n",
      "Epoch 23, Loss: -4.004052639007568\n",
      "Epoch 24, Loss: -4.201951503753662\n",
      "Epoch 25, Loss: -4.403655052185059\n",
      "Epoch 26, Loss: -4.609330177307129\n",
      "Epoch 27, Loss: -4.819141387939453\n",
      "Epoch 28, Loss: -5.033249855041504\n",
      "Epoch 29, Loss: -5.251811504364014\n",
      "Epoch 30, Loss: -5.474979400634766\n",
      "Epoch 31, Loss: -5.702902317047119\n",
      "Epoch 32, Loss: -5.935723781585693\n",
      "Epoch 33, Loss: -6.173583030700684\n",
      "Epoch 34, Loss: -6.416615009307861\n",
      "Epoch 35, Loss: -6.664950847625732\n",
      "Epoch 36, Loss: -6.918715953826904\n",
      "Epoch 37, Loss: -7.178033828735352\n",
      "Epoch 38, Loss: -7.44302225112915\n",
      "Epoch 39, Loss: -7.713796615600586\n",
      "Epoch 40, Loss: -7.99046516418457\n",
      "Epoch 41, Loss: -8.273136138916016\n",
      "Epoch 42, Loss: -8.561912536621094\n",
      "Epoch 43, Loss: -8.856894493103027\n",
      "Epoch 44, Loss: -9.158178329467773\n",
      "Epoch 45, Loss: -9.465858459472656\n",
      "Epoch 46, Loss: -9.780025482177734\n",
      "Epoch 47, Loss: -10.100765228271484\n",
      "Epoch 48, Loss: -10.428165435791016\n",
      "Epoch 49, Loss: -10.76230525970459\n",
      "Epoch 50, Loss: -11.103266716003418\n",
      "Epoch 51, Loss: -11.451128005981445\n",
      "Epoch 52, Loss: -11.805960655212402\n",
      "Epoch 53, Loss: -12.167840003967285\n",
      "Epoch 54, Loss: -12.53683853149414\n",
      "Epoch 55, Loss: -12.9130220413208\n",
      "Epoch 56, Loss: -13.29646110534668\n",
      "Epoch 57, Loss: -13.687219619750977\n",
      "Epoch 58, Loss: -14.085363388061523\n",
      "Epoch 59, Loss: -14.49095630645752\n",
      "Epoch 60, Loss: -14.904056549072266\n",
      "Epoch 61, Loss: -15.324726104736328\n",
      "Epoch 62, Loss: -15.753020286560059\n",
      "Epoch 63, Loss: -16.188995361328125\n",
      "Epoch 64, Loss: -16.632705688476562\n",
      "Epoch 65, Loss: -17.08420181274414\n",
      "Epoch 66, Loss: -17.543533325195312\n",
      "Epoch 67, Loss: -18.0107479095459\n",
      "Epoch 68, Loss: -18.485885620117188\n",
      "Epoch 69, Loss: -18.968994140625\n",
      "Epoch 70, Loss: -19.460113525390625\n",
      "Epoch 71, Loss: -19.95928192138672\n",
      "Epoch 72, Loss: -20.466537475585938\n",
      "Epoch 73, Loss: -20.981916427612305\n",
      "Epoch 74, Loss: -21.505449295043945\n",
      "Epoch 75, Loss: -22.037172317504883\n",
      "Epoch 76, Loss: -22.57711410522461\n",
      "Epoch 77, Loss: -23.125308990478516\n",
      "Epoch 78, Loss: -23.681781768798828\n",
      "Epoch 79, Loss: -24.246559143066406\n",
      "Epoch 80, Loss: -24.819669723510742\n",
      "Epoch 81, Loss: -25.401142120361328\n",
      "Epoch 82, Loss: -25.990989685058594\n",
      "Epoch 83, Loss: -26.589244842529297\n",
      "Epoch 84, Loss: -27.19593048095703\n",
      "Epoch 85, Loss: -27.811065673828125\n",
      "Epoch 86, Loss: -28.434663772583008\n",
      "Epoch 87, Loss: -29.066755294799805\n",
      "Epoch 88, Loss: -29.707351684570312\n",
      "Epoch 89, Loss: -30.356475830078125\n",
      "Epoch 90, Loss: -31.014141082763672\n",
      "Epoch 91, Loss: -31.68036651611328\n",
      "Epoch 92, Loss: -32.355167388916016\n",
      "Epoch 93, Loss: -33.03855895996094\n",
      "Epoch 94, Loss: -33.730552673339844\n",
      "Epoch 95, Loss: -34.4311637878418\n",
      "Epoch 96, Loss: -35.14040756225586\n",
      "Epoch 97, Loss: -35.858299255371094\n",
      "Epoch 98, Loss: -36.584842681884766\n",
      "Epoch 99, Loss: -37.3200569152832\n",
      "Validation Loss for SR-GNN: 0.0007465154048986733\n",
      "Confusion Matrix:\n",
      "[[0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1]]\n",
      "True Negatives (TN): [0 1 1 1 1 0 1 1 1 0 1]\n",
      "False Positives (FP): [0 0 0 0 0 0 1 2 0 0 0]\n",
      "Metrics for SR-GNN: {'precision': 0.6212121212121212, 'recall': 0.7272727272727273, 'f1_score': 0.6515151515151515, 'accuracy': 0.7272727272727273, 'specificity': 0.6212121212121212, 'sensitivity': 0.9752066115702479, 'roc_auc': 0.85, 'mcc': 0.72693285284751}\n",
      "Training DeepWalk...\n",
      "Epoch 0, Loss: -0.10071979463100433\n",
      "Epoch 1, Loss: -0.26367831230163574\n",
      "Epoch 2, Loss: -0.4264688491821289\n",
      "Epoch 3, Loss: -0.5891345739364624\n",
      "Epoch 4, Loss: -0.7517301440238953\n",
      "Epoch 5, Loss: -0.9143388271331787\n",
      "Epoch 6, Loss: -1.077074408531189\n",
      "Epoch 7, Loss: -1.2400784492492676\n",
      "Epoch 8, Loss: -1.4035136699676514\n",
      "Epoch 9, Loss: -1.567561149597168\n",
      "Epoch 10, Loss: -1.7324187755584717\n",
      "Epoch 11, Loss: -1.8982985019683838\n",
      "Epoch 12, Loss: -2.0654194355010986\n",
      "Epoch 13, Loss: -2.2340033054351807\n",
      "Epoch 14, Loss: -2.404271125793457\n",
      "Epoch 15, Loss: -2.576439142227173\n",
      "Epoch 16, Loss: -2.7507200241088867\n",
      "Epoch 17, Loss: -2.9273204803466797\n",
      "Epoch 18, Loss: -3.10644268989563\n",
      "Epoch 19, Loss: -3.2882866859436035\n",
      "Epoch 20, Loss: -3.473048210144043\n",
      "Epoch 21, Loss: -3.660921812057495\n",
      "Epoch 22, Loss: -3.852097749710083\n",
      "Epoch 23, Loss: -4.046762466430664\n",
      "Epoch 24, Loss: -4.245100021362305\n",
      "Epoch 25, Loss: -4.447290897369385\n",
      "Epoch 26, Loss: -4.65350866317749\n",
      "Epoch 27, Loss: -4.863924503326416\n",
      "Epoch 28, Loss: -5.078702926635742\n",
      "Epoch 29, Loss: -5.298005104064941\n",
      "Epoch 30, Loss: -5.52198600769043\n",
      "Epoch 31, Loss: -5.75079345703125\n",
      "Epoch 32, Loss: -5.9845733642578125\n",
      "Epoch 33, Loss: -6.223464488983154\n",
      "Epoch 34, Loss: -6.467598915100098\n",
      "Epoch 35, Loss: -6.717105865478516\n",
      "Epoch 36, Loss: -6.97210693359375\n",
      "Epoch 37, Loss: -7.232719421386719\n",
      "Epoch 38, Loss: -7.4990553855896\n",
      "Epoch 39, Loss: -7.7712249755859375\n",
      "Epoch 40, Loss: -8.049330711364746\n",
      "Epoch 41, Loss: -8.33347225189209\n",
      "Epoch 42, Loss: -8.623747825622559\n",
      "Epoch 43, Loss: -8.920248985290527\n",
      "Epoch 44, Loss: -9.223067283630371\n",
      "Epoch 45, Loss: -9.5322904586792\n",
      "Epoch 46, Loss: -9.848005294799805\n",
      "Epoch 47, Loss: -10.170294761657715\n",
      "Epoch 48, Loss: -10.499238967895508\n",
      "Epoch 49, Loss: -10.834918022155762\n",
      "Epoch 50, Loss: -11.177412033081055\n",
      "Epoch 51, Loss: -11.52679443359375\n",
      "Epoch 52, Loss: -11.883142471313477\n",
      "Epoch 53, Loss: -12.246526718139648\n",
      "Epoch 54, Loss: -12.617020606994629\n",
      "Epoch 55, Loss: -12.994694709777832\n",
      "Epoch 56, Loss: -13.379615783691406\n",
      "Epoch 57, Loss: -13.771852493286133\n",
      "Epoch 58, Loss: -14.171469688415527\n",
      "Epoch 59, Loss: -14.578531265258789\n",
      "Epoch 60, Loss: -14.993096351623535\n",
      "Epoch 61, Loss: -15.415225982666016\n",
      "Epoch 62, Loss: -15.844976425170898\n",
      "Epoch 63, Loss: -16.28240394592285\n",
      "Epoch 64, Loss: -16.72756004333496\n",
      "Epoch 65, Loss: -17.180496215820312\n",
      "Epoch 66, Loss: -17.64126205444336\n",
      "Epoch 67, Loss: -18.109901428222656\n",
      "Epoch 68, Loss: -18.586463928222656\n",
      "Epoch 69, Loss: -19.070987701416016\n",
      "Epoch 70, Loss: -19.563512802124023\n",
      "Epoch 71, Loss: -20.064083099365234\n",
      "Epoch 72, Loss: -20.572729110717773\n",
      "Epoch 73, Loss: -21.08949089050293\n",
      "Epoch 74, Loss: -21.614402770996094\n",
      "Epoch 75, Loss: -22.147497177124023\n",
      "Epoch 76, Loss: -22.688800811767578\n",
      "Epoch 77, Loss: -23.238346099853516\n",
      "Epoch 78, Loss: -23.79616355895996\n",
      "Epoch 79, Loss: -24.362281799316406\n",
      "Epoch 80, Loss: -24.936717987060547\n",
      "Epoch 81, Loss: -25.51950454711914\n",
      "Epoch 82, Loss: -26.11066246032715\n",
      "Epoch 83, Loss: -26.71021842956543\n",
      "Epoch 84, Loss: -27.318185806274414\n",
      "Epoch 85, Loss: -27.934593200683594\n",
      "Epoch 86, Loss: -28.55945587158203\n",
      "Epoch 87, Loss: -29.192798614501953\n",
      "Epoch 88, Loss: -29.834636688232422\n",
      "Epoch 89, Loss: -30.484981536865234\n",
      "Epoch 90, Loss: -31.14385986328125\n",
      "Epoch 91, Loss: -31.811283111572266\n",
      "Epoch 92, Loss: -32.487266540527344\n",
      "Epoch 93, Loss: -33.17182540893555\n",
      "Epoch 94, Loss: -33.86497116088867\n",
      "Epoch 95, Loss: -34.56672286987305\n",
      "Epoch 96, Loss: -35.2770881652832\n",
      "Epoch 97, Loss: -35.9960823059082\n",
      "Epoch 98, Loss: -36.723716735839844\n",
      "Epoch 99, Loss: -37.46000671386719\n",
      "Validation Loss for DeepWalk: 1.930953840201255e-05\n",
      "Confusion Matrix:\n",
      "[[0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1]]\n",
      "True Negatives (TN): [0 1 1 1 1 0 1 1 1 0 1]\n",
      "False Positives (FP): [0 2 1 0 0 0 0 0 0 0 0]\n",
      "Metrics for DeepWalk: {'precision': 0.6212121212121212, 'recall': 0.7272727272727273, 'f1_score': 0.6515151515151515, 'accuracy': 0.7272727272727273, 'specificity': 0.6212121212121212, 'sensitivity': 0.9752066115702479, 'roc_auc': 0.85, 'mcc': 0.72693285284751}\n",
      "Training Node2Vec...\n",
      "Epoch 0, Loss: 0.1429159790277481\n",
      "Epoch 1, Loss: -0.012513110414147377\n",
      "Epoch 2, Loss: -0.16782410442829132\n",
      "Epoch 3, Loss: -0.3231012523174286\n",
      "Epoch 4, Loss: -0.47842562198638916\n",
      "Epoch 5, Loss: -0.6339200139045715\n",
      "Epoch 6, Loss: -0.7897288203239441\n",
      "Epoch 7, Loss: -0.9460104703903198\n",
      "Epoch 8, Loss: -1.1029386520385742\n",
      "Epoch 9, Loss: -1.2606964111328125\n",
      "Epoch 10, Loss: -1.4194718599319458\n",
      "Epoch 11, Loss: -1.5794565677642822\n",
      "Epoch 12, Loss: -1.7408446073532104\n",
      "Epoch 13, Loss: -1.9038331508636475\n",
      "Epoch 14, Loss: -2.068621873855591\n",
      "Epoch 15, Loss: -2.235410690307617\n",
      "Epoch 16, Loss: -2.404402017593384\n",
      "Epoch 17, Loss: -2.575796604156494\n",
      "Epoch 18, Loss: -2.749796152114868\n",
      "Epoch 19, Loss: -2.9266014099121094\n",
      "Epoch 20, Loss: -3.1064093112945557\n",
      "Epoch 21, Loss: -3.2894153594970703\n",
      "Epoch 22, Loss: -3.47581148147583\n",
      "Epoch 23, Loss: -3.665785074234009\n",
      "Epoch 24, Loss: -3.8595190048217773\n",
      "Epoch 25, Loss: -4.057191848754883\n",
      "Epoch 26, Loss: -4.258976936340332\n",
      "Epoch 27, Loss: -4.465042591094971\n",
      "Epoch 28, Loss: -4.675551891326904\n",
      "Epoch 29, Loss: -4.890663146972656\n",
      "Epoch 30, Loss: -5.110530853271484\n",
      "Epoch 31, Loss: -5.33530330657959\n",
      "Epoch 32, Loss: -5.565124988555908\n",
      "Epoch 33, Loss: -5.800136566162109\n",
      "Epoch 34, Loss: -6.040473937988281\n",
      "Epoch 35, Loss: -6.2862677574157715\n",
      "Epoch 36, Loss: -6.537646770477295\n",
      "Epoch 37, Loss: -6.79473352432251\n",
      "Epoch 38, Loss: -7.057649612426758\n",
      "Epoch 39, Loss: -7.326508045196533\n",
      "Epoch 40, Loss: -7.601423263549805\n",
      "Epoch 41, Loss: -7.88250207901001\n",
      "Epoch 42, Loss: -8.169849395751953\n",
      "Epoch 43, Loss: -8.463566780090332\n",
      "Epoch 44, Loss: -8.763751029968262\n",
      "Epoch 45, Loss: -9.070493698120117\n",
      "Epoch 46, Loss: -9.38388729095459\n",
      "Epoch 47, Loss: -9.704020500183105\n",
      "Epoch 48, Loss: -10.03097152709961\n",
      "Epoch 49, Loss: -10.364823341369629\n",
      "Epoch 50, Loss: -10.705653190612793\n",
      "Epoch 51, Loss: -11.053536415100098\n",
      "Epoch 52, Loss: -11.408540725708008\n",
      "Epoch 53, Loss: -11.770739555358887\n",
      "Epoch 54, Loss: -12.140193939208984\n",
      "Epoch 55, Loss: -12.516973495483398\n",
      "Epoch 56, Loss: -12.90113639831543\n",
      "Epoch 57, Loss: -13.292738914489746\n",
      "Epoch 58, Loss: -13.69184398651123\n",
      "Epoch 59, Loss: -14.098504066467285\n",
      "Epoch 60, Loss: -14.512770652770996\n",
      "Epoch 61, Loss: -14.934698104858398\n",
      "Epoch 62, Loss: -15.36433219909668\n",
      "Epoch 63, Loss: -15.801721572875977\n",
      "Epoch 64, Loss: -16.24691390991211\n",
      "Epoch 65, Loss: -16.699949264526367\n",
      "Epoch 66, Loss: -17.160873413085938\n",
      "Epoch 67, Loss: -17.62972640991211\n",
      "Epoch 68, Loss: -18.106548309326172\n",
      "Epoch 69, Loss: -18.59137535095215\n",
      "Epoch 70, Loss: -19.084243774414062\n",
      "Epoch 71, Loss: -19.585187911987305\n",
      "Epoch 72, Loss: -20.0942440032959\n",
      "Epoch 73, Loss: -20.61144256591797\n",
      "Epoch 74, Loss: -21.136817932128906\n",
      "Epoch 75, Loss: -21.670398712158203\n",
      "Epoch 76, Loss: -22.212207794189453\n",
      "Epoch 77, Loss: -22.76228141784668\n",
      "Epoch 78, Loss: -23.32064437866211\n",
      "Epoch 79, Loss: -23.88731575012207\n",
      "Epoch 80, Loss: -24.462331771850586\n",
      "Epoch 81, Loss: -25.045705795288086\n",
      "Epoch 82, Loss: -25.637466430664062\n",
      "Epoch 83, Loss: -26.237634658813477\n",
      "Epoch 84, Loss: -26.846227645874023\n",
      "Epoch 85, Loss: -27.46327018737793\n",
      "Epoch 86, Loss: -28.088783264160156\n",
      "Epoch 87, Loss: -28.722780227661133\n",
      "Epoch 88, Loss: -29.365283966064453\n",
      "Epoch 89, Loss: -30.016307830810547\n",
      "Epoch 90, Loss: -30.675872802734375\n",
      "Epoch 91, Loss: -31.34398651123047\n",
      "Epoch 92, Loss: -32.02067565917969\n",
      "Epoch 93, Loss: -32.70594787597656\n",
      "Epoch 94, Loss: -33.399818420410156\n",
      "Epoch 95, Loss: -34.10230255126953\n",
      "Epoch 96, Loss: -34.813411712646484\n",
      "Epoch 97, Loss: -35.53315734863281\n",
      "Epoch 98, Loss: -36.261558532714844\n",
      "Epoch 99, Loss: -36.99861526489258\n",
      "Validation Loss for Node2Vec: -0.0008835142361931503\n",
      "Confusion Matrix:\n",
      "[[0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 1]]\n",
      "True Negatives (TN): [0 1 1 1 1 0 1 1 1 0 1]\n",
      "False Positives (FP): [0 0 1 0 1 0 0 0 0 0 1]\n",
      "Metrics for Node2Vec: {'precision': 0.5909090909090909, 'recall': 0.7272727272727273, 'f1_score': 0.6363636363636364, 'accuracy': 0.7272727272727273, 'specificity': 0.5909090909090909, 'sensitivity': 0.9752066115702479, 'roc_auc': 0.85, 'mcc': 0.719909182306512}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, matthews_corrcoef, confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/visheshyadav/Documents/GitHub/CoreRec/engine')\n",
    "from core_rec import GraphTransformer, train_model, predict\n",
    "\n",
    "# Load your data\n",
    "labels_df = pd.read_csv('labelele.csv')\n",
    "labels = labels_df['Names'].tolist()\n",
    "label_to_index = {label: idx for idx, label in enumerate(labels)}\n",
    "\n",
    "# Load adjacency matrix\n",
    "adj_matrix = pd.read_csv('label.csv', header=None).values\n",
    "\n",
    "# Create edge index for PyTorch Geometric\n",
    "edge_index = torch_geometric.utils.dense_to_sparse(torch.tensor(adj_matrix, dtype=torch.float))[0]\n",
    "\n",
    "# Create node features (for simplicity, using identity matrix)\n",
    "num_nodes = adj_matrix.shape[0]\n",
    "x = torch.eye(num_nodes, dtype=torch.float)\n",
    "\n",
    "# Create labels (for simplicity, using node indices as labels)\n",
    "y = torch.tensor(range(num_nodes), dtype=torch.long)\n",
    "\n",
    "# Create PyTorch Geometric data object\n",
    "data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "# Define GCN model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_nodes, 16)\n",
    "        self.conv2 = GCNConv(16, num_nodes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Define GAT model\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(num_nodes, 16, heads=8, dropout=0.6)\n",
    "        self.conv2 = GATConv(16 * 8, num_nodes, heads=1, concat=False, dropout=0.6)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Define GraphSAGE model\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(num_nodes, 16)\n",
    "        self.conv2 = SAGEConv(16, num_nodes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Placeholder for other models\n",
    "class TransE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransE, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class TransR(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransR, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class DistMult(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DistMult, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class ComplEx(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ComplEx, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class HAN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HAN, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class MetaPath2Vec(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MetaPath2Vec, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class GCF(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCF, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class GRMF(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GRMF, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class STAGE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(STAGE, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class SRGNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SRGNN, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class DeepWalk(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepWalk, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class Node2Vec(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Node2Vec, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class MetaExploitModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MetaExploitModel, self).__init__()\n",
    "        num_layers = 1\n",
    "        d_model = 128\n",
    "        num_heads = 2\n",
    "        d_feedforward = 512\n",
    "        self.model = GraphTransformer(num_layers, d_model, num_heads, d_feedforward, input_dim, use_weights=True)\n",
    "\n",
    "    def forward(self, data):\n",
    "        adj_matrix = data.x.numpy()  # Assuming data.x is the adjacency matrix\n",
    "        output = self.model(torch.tensor(adj_matrix, dtype=torch.float32))\n",
    "        return output\n",
    "\n",
    "# Placeholder for model evaluation\n",
    "def evaluate_model(model, data):\n",
    "    model.eval()\n",
    "    out = model(data)\n",
    "    pred = out.argmax(dim=1)\n",
    "    y_true = data.y.numpy()\n",
    "    y_pred = pred.numpy()\n",
    "    \n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    y_true_binarized = label_binarize(y_true, classes=np.arange(num_nodes))\n",
    "    y_pred_binarized = label_binarize(y_pred, classes=np.arange(num_nodes))\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_true_binarized, y_pred_binarized, multi_class='ovr')\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn = np.diag(cm)\n",
    "    fp = cm.sum(axis=0) - tn\n",
    "    fn = cm.sum(axis=1) - tn\n",
    "    tp = cm.sum() - (fp + fn + tn)\n",
    "    \n",
    "    # Debugging print statements\n",
    "    print(f\"Confusion Matrix:\\n{cm}\")\n",
    "    print(f\"True Negatives (TN): {tn}\")\n",
    "    print(f\"False Positives (FP): {fp}\")\n",
    "    \n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        specificity = np.mean(np.divide(tn, tn + fp, out=np.zeros_like(tn, dtype=float), where=(tn + fp) != 0))\n",
    "        sensitivity = np.mean(np.divide(tp, tp + fn, out=np.zeros_like(tp, dtype=float), where=(tp + fn) != 0))\n",
    "    \n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"specificity\": specificity,\n",
    "        \"sensitivity\": sensitivity,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"mcc\": mcc\n",
    "    }\n",
    "\n",
    "# List of models to benchmark\n",
    "models_to_benchmark = {\n",
    "    \"CoreRec\": MetaExploitModel(input_dim=adj_matrix.shape[1]) ,\n",
    "    \"GCN\": GCN(),\n",
    "    \"GraphSAGE\": GraphSAGE(),\n",
    "    \"TransE\": TransE(),\n",
    "    \"TransR\": TransR(),\n",
    "    \"DistMult\": DistMult(),\n",
    "    \"ComplEx\": ComplEx(),\n",
    "    \"HAN\": HAN(),\n",
    "    \"MetaPath2Vec\": MetaPath2Vec(),\n",
    "    \"GCF\": GCF(),\n",
    "    \"GRMF\": GRMF(),\n",
    "    \"GAT\": GAT(),\n",
    "    \"STAGE\": STAGE(),\n",
    "    \"SR-GNN\": SRGNN(),\n",
    "    \"DeepWalk\": DeepWalk(),\n",
    "    \"Node2Vec\": Node2Vec()\n",
    "}\n",
    "\n",
    "# Dictionary to store benchmark results\n",
    "benchmark_results = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models_to_benchmark.items():\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    model.train()\n",
    "    print(f\"Training {model_name}...\")\n",
    "    for epoch in range(100):  # Start with 50 epochs\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        if out is None:\n",
    "            print(f\"Model {model_name} returned None output\")\n",
    "            continue\n",
    "        if out.shape != (num_nodes, num_nodes):\n",
    "            print(f\"Unexpected output shape for {model_name}: {out.shape}\")\n",
    "            continue\n",
    "        loss = F.nll_loss(out[train_mask], data.y[train_mask])\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data)\n",
    "        val_loss = F.nll_loss(out[val_mask], data.y[val_mask])\n",
    "        print(f\"Validation Loss for {model_name}: {val_loss.item()}\")\n",
    "    \n",
    "    metrics = evaluate_model(model, data)\n",
    "    print(f\"Metrics for {model_name}: {metrics}\")\n",
    "    benchmark_results[model_name] = metrics\n",
    "\n",
    "# Convert results to DataFrame for easier plotting\n",
    "df = pd.DataFrame(benchmark_results).T\n",
    "\n",
    "# Plot the results with padding between models\n",
    "sns.set(style=\"whitegrid\")\n",
    "palette = sns.color_palette(\"Set2\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "x = np.arange(len(models_to_benchmark))\n",
    "width = 0.08  # Reduce the width of the bars to add padding\n",
    "\n",
    "metrics = df.columns\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax.bar(x + i*width, df[metric], width, label=metric, capsize=5, color=palette[i % len(palette)])\n",
    "\n",
    "ax.set_xlabel('Models', fontsize=14)\n",
    "ax.set_ylabel('Scores', fontsize=14)\n",
    "ax.set_title('Benchmark Results Comparison', fontsize=16, weight='bold')\n",
    "ax.set_xticks(x + width * (len(metrics) - 1) / 2)\n",
    "ax.set_xticklabels(models_to_benchmark.keys(), rotation=90, fontsize=12)\n",
    "ax.legend(fontsize=12, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "ax.yaxis.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "for metric in metrics:\n",
    "    ax.plot(models_to_benchmark.keys(), df[metric], marker='o', label=metric)\n",
    "ax.set_xlabel('Models', fontsize=14)\n",
    "ax.set_ylabel('Scores', fontsize=14)\n",
    "ax.set_title('Benchmark Results Comparison', fontsize=16, weight='bold')\n",
    "ax.legend(fontsize=12, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "ax.yaxis.grid(True)\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "for metric in metrics:\n",
    "    ax.scatter(models_to_benchmark.keys(), df[metric], label=metric)\n",
    "ax.set_xlabel('Models', fontsize=14)\n",
    "ax.set_ylabel('Scores', fontsize=14)\n",
    "ax.set_title('Benchmark Results Comparison', fontsize=16, weight='bold')\n",
    "ax.legend(fontsize=12, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "ax.yaxis.grid(True)\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "sns.violinplot(data=df, ax=ax)\n",
    "ax.set_xlabel('Metrics', fontsize=14)\n",
    "ax.set_ylabel('Scores', fontsize=14)\n",
    "ax.set_title('Benchmark Results Comparison', fontsize=16, weight='bold')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.imshow(df, text_auto=True, aspect=\"auto\", color_continuous_scale='viridis')\n",
    "fig.update_layout(\n",
    "    title='Benchmark Results Comparison',\n",
    "    xaxis_title='Metrics',\n",
    "    yaxis_title='Models',\n",
    "    font=dict(size=11)\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame containing the benchmark results\n",
    "df = pd.DataFrame(benchmark_results).T\n",
    "\n",
    "# Convert DataFrame to markdown table\n",
    "markdown_table = df.to_markdown()\n",
    "\n",
    "# Print the markdown table\n",
    "print(markdown_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Benchmarking** above models with 500node dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CoreRec...\n",
      "Epoch 0, Loss: 0.017112810164690018\n",
      "Epoch 1, Loss: -2.9715843200683594\n",
      "Epoch 2, Loss: -4.801001071929932\n",
      "Epoch 3, Loss: -6.8177409172058105\n",
      "Epoch 4, Loss: -7.961460590362549\n",
      "Epoch 5, Loss: -9.084444046020508\n",
      "Epoch 6, Loss: -10.001160621643066\n",
      "Epoch 7, Loss: -11.197078704833984\n",
      "Epoch 8, Loss: -12.376022338867188\n",
      "Epoch 9, Loss: -13.715489387512207\n",
      "Epoch 10, Loss: -15.03042984008789\n",
      "Epoch 11, Loss: -16.258644104003906\n",
      "Epoch 12, Loss: -17.587514877319336\n",
      "Epoch 13, Loss: -19.317520141601562\n",
      "Epoch 14, Loss: -20.726680755615234\n",
      "Epoch 15, Loss: -22.435157775878906\n",
      "Epoch 16, Loss: -23.98625373840332\n",
      "Epoch 17, Loss: -25.648780822753906\n",
      "Epoch 18, Loss: -27.463428497314453\n",
      "Epoch 19, Loss: -29.281070709228516\n",
      "Epoch 20, Loss: -31.01407241821289\n",
      "Epoch 21, Loss: -33.19861602783203\n",
      "Epoch 22, Loss: -34.78308868408203\n",
      "Epoch 23, Loss: -37.10017013549805\n",
      "Epoch 24, Loss: -39.25001525878906\n",
      "Epoch 25, Loss: -41.56285095214844\n",
      "Epoch 26, Loss: -43.75852584838867\n",
      "Epoch 27, Loss: -46.253150939941406\n",
      "Epoch 28, Loss: -48.64930725097656\n",
      "Epoch 29, Loss: -51.25216293334961\n",
      "Epoch 30, Loss: -54.00820541381836\n",
      "Epoch 31, Loss: -56.47544860839844\n",
      "Epoch 32, Loss: -59.29139709472656\n",
      "Epoch 33, Loss: -62.21992492675781\n",
      "Epoch 34, Loss: -65.14319610595703\n",
      "Epoch 35, Loss: -68.07571411132812\n",
      "Epoch 36, Loss: -71.17483520507812\n",
      "Epoch 37, Loss: -74.30221557617188\n",
      "Epoch 38, Loss: -77.66374969482422\n",
      "Epoch 39, Loss: -80.97847747802734\n",
      "Epoch 40, Loss: -84.27291870117188\n",
      "Epoch 41, Loss: -87.77977752685547\n",
      "Epoch 42, Loss: -91.46033477783203\n",
      "Epoch 43, Loss: -95.16531372070312\n",
      "Epoch 44, Loss: -99.01016998291016\n",
      "Epoch 45, Loss: -102.88485717773438\n",
      "Epoch 46, Loss: -106.85383605957031\n",
      "Epoch 47, Loss: -110.82329559326172\n",
      "Epoch 48, Loss: -114.98991394042969\n",
      "Epoch 49, Loss: -119.2135238647461\n",
      "Epoch 50, Loss: -123.52212524414062\n",
      "Epoch 51, Loss: -127.94464111328125\n",
      "Epoch 52, Loss: -132.44845581054688\n",
      "Epoch 53, Loss: -137.0166778564453\n",
      "Epoch 54, Loss: -141.68727111816406\n",
      "Epoch 55, Loss: -146.45327758789062\n",
      "Epoch 56, Loss: -151.342529296875\n",
      "Epoch 57, Loss: -156.31329345703125\n",
      "Epoch 58, Loss: -161.3642578125\n",
      "Epoch 59, Loss: -166.52981567382812\n",
      "Epoch 60, Loss: -171.7919158935547\n",
      "Epoch 61, Loss: -177.1285400390625\n",
      "Epoch 62, Loss: -182.5982666015625\n",
      "Epoch 63, Loss: -188.15940856933594\n",
      "Epoch 64, Loss: -193.8043212890625\n",
      "Epoch 65, Loss: -199.5483856201172\n",
      "Epoch 66, Loss: -205.38174438476562\n",
      "Epoch 67, Loss: -211.29017639160156\n",
      "Epoch 68, Loss: -217.3248748779297\n",
      "Epoch 69, Loss: -223.51028442382812\n",
      "Epoch 70, Loss: -229.86697387695312\n",
      "Epoch 71, Loss: -236.21217346191406\n",
      "Epoch 72, Loss: -242.67996215820312\n",
      "Epoch 73, Loss: -249.30746459960938\n",
      "Epoch 74, Loss: -255.93626403808594\n",
      "Epoch 75, Loss: -262.7740478515625\n",
      "Epoch 76, Loss: -269.65960693359375\n",
      "Epoch 77, Loss: -276.66278076171875\n",
      "Epoch 78, Loss: -283.7832336425781\n",
      "Epoch 79, Loss: -290.9938659667969\n",
      "Epoch 80, Loss: -298.3404541015625\n",
      "Epoch 81, Loss: -305.763916015625\n",
      "Epoch 82, Loss: -313.3047790527344\n",
      "Epoch 83, Loss: -320.94940185546875\n",
      "Epoch 84, Loss: -328.7252197265625\n",
      "Epoch 85, Loss: -336.5964660644531\n",
      "Epoch 86, Loss: -344.57666015625\n",
      "Epoch 87, Loss: -352.65447998046875\n",
      "Epoch 88, Loss: -360.8603515625\n",
      "Epoch 89, Loss: -369.1708984375\n",
      "Epoch 90, Loss: -377.5946350097656\n",
      "Epoch 91, Loss: -386.12811279296875\n",
      "Epoch 92, Loss: -394.765869140625\n",
      "Epoch 93, Loss: -403.512939453125\n",
      "Epoch 94, Loss: -412.3706359863281\n",
      "Epoch 95, Loss: -421.3231201171875\n",
      "Epoch 96, Loss: -430.3807373046875\n",
      "Epoch 97, Loss: -439.5764465332031\n",
      "Epoch 98, Loss: -448.9553527832031\n",
      "Epoch 99, Loss: -458.40093994140625\n",
      "Validation Loss for CoreRec: 0.00028580366051755846\n",
      "Confusion Matrix:\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "True Negatives (TN): [0 1 1 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "False Positives (FP): [  0   7   0   8  27   0  10  11   5   0 424   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "Metrics for CoreRec: {'precision': 0.0032301748578219165, 'recall': 0.016, 'f1_score': 0.004204219362742918, 'accuracy': 0.016, 'specificity': 0.0032301748578219165, 'sensitivity': 0.9980319999999998, 'roc_auc': 0.5070140280561123, 'mcc': 0.02684225253919734}\n",
      "Training GCN...\n",
      "Epoch 0, Loss: 6.214532852172852\n",
      "Epoch 1, Loss: 6.190690040588379\n",
      "Epoch 2, Loss: 6.1635565757751465\n",
      "Epoch 3, Loss: 6.1314287185668945\n",
      "Epoch 4, Loss: 6.093499183654785\n",
      "Epoch 5, Loss: 6.049318313598633\n",
      "Epoch 6, Loss: 5.998492240905762\n",
      "Epoch 7, Loss: 5.94059944152832\n",
      "Epoch 8, Loss: 5.875219821929932\n",
      "Epoch 9, Loss: 5.801953315734863\n",
      "Epoch 10, Loss: 5.720433712005615\n",
      "Epoch 11, Loss: 5.630331516265869\n",
      "Epoch 12, Loss: 5.531350135803223\n",
      "Epoch 13, Loss: 5.423232555389404\n",
      "Epoch 14, Loss: 5.30576229095459\n",
      "Epoch 15, Loss: 5.178782939910889\n",
      "Epoch 16, Loss: 5.042210578918457\n",
      "Epoch 17, Loss: 4.896051406860352\n",
      "Epoch 18, Loss: 4.740447044372559\n",
      "Epoch 19, Loss: 4.575660705566406\n",
      "Epoch 20, Loss: 4.402143478393555\n",
      "Epoch 21, Loss: 4.22060489654541\n",
      "Epoch 22, Loss: 4.032111167907715\n",
      "Epoch 23, Loss: 3.838238477706909\n",
      "Epoch 24, Loss: 3.6411895751953125\n",
      "Epoch 25, Loss: 3.443881034851074\n",
      "Epoch 26, Loss: 3.2499520778656006\n",
      "Epoch 27, Loss: 3.0636723041534424\n",
      "Epoch 28, Loss: 2.8896079063415527\n",
      "Epoch 29, Loss: 2.7320899963378906\n",
      "Epoch 30, Loss: 2.5945260524749756\n",
      "Epoch 31, Loss: 2.478773832321167\n",
      "Epoch 32, Loss: 2.38484525680542\n",
      "Epoch 33, Loss: 2.31107234954834\n",
      "Epoch 34, Loss: 2.2546634674072266\n",
      "Epoch 35, Loss: 2.2123727798461914\n",
      "Epoch 36, Loss: 2.1810550689697266\n",
      "Epoch 37, Loss: 2.157994270324707\n",
      "Epoch 38, Loss: 2.141019344329834\n",
      "Epoch 39, Loss: 2.128480911254883\n",
      "Epoch 40, Loss: 2.1191697120666504\n",
      "Epoch 41, Loss: 2.112215995788574\n",
      "Epoch 42, Loss: 2.1070003509521484\n",
      "Epoch 43, Loss: 2.103078603744507\n",
      "Epoch 44, Loss: 2.1001315116882324\n",
      "Epoch 45, Loss: 2.097921848297119\n",
      "Epoch 46, Loss: 2.096271514892578\n",
      "Epoch 47, Loss: 2.0950450897216797\n",
      "Epoch 48, Loss: 2.094139337539673\n",
      "Epoch 49, Loss: 2.093475580215454\n",
      "Epoch 50, Loss: 2.0929975509643555\n",
      "Epoch 51, Loss: 2.092664957046509\n",
      "Epoch 52, Loss: 2.092453956604004\n",
      "Epoch 53, Loss: 2.092350959777832\n",
      "Epoch 54, Loss: 2.0923497676849365\n",
      "Epoch 55, Loss: 2.092449188232422\n",
      "Epoch 56, Loss: 2.0926499366760254\n",
      "Epoch 57, Loss: 2.0929534435272217\n",
      "Epoch 58, Loss: 2.0933573246002197\n",
      "Epoch 59, Loss: 2.0938596725463867\n",
      "Epoch 60, Loss: 2.094456195831299\n",
      "Epoch 61, Loss: 2.0951411724090576\n",
      "Epoch 62, Loss: 2.0959086418151855\n",
      "Epoch 63, Loss: 2.0967531204223633\n",
      "Epoch 64, Loss: 2.097670555114746\n",
      "Epoch 65, Loss: 2.098656177520752\n",
      "Epoch 66, Loss: 2.09970760345459\n",
      "Epoch 67, Loss: 2.1008224487304688\n",
      "Epoch 68, Loss: 2.101999521255493\n",
      "Epoch 69, Loss: 2.1032350063323975\n",
      "Epoch 70, Loss: 2.1045258045196533\n",
      "Epoch 71, Loss: 2.1058664321899414\n",
      "Epoch 72, Loss: 2.1072497367858887\n",
      "Epoch 73, Loss: 2.108668088912964\n",
      "Epoch 74, Loss: 2.110110282897949\n",
      "Epoch 75, Loss: 2.1115667819976807\n",
      "Epoch 76, Loss: 2.1130242347717285\n",
      "Epoch 77, Loss: 2.114469528198242\n",
      "Epoch 78, Loss: 2.115889310836792\n",
      "Epoch 79, Loss: 2.1172711849212646\n",
      "Epoch 80, Loss: 2.1186001300811768\n",
      "Epoch 81, Loss: 2.1198649406433105\n",
      "Epoch 82, Loss: 2.12105393409729\n",
      "Epoch 83, Loss: 2.1221559047698975\n",
      "Epoch 84, Loss: 2.123161792755127\n",
      "Epoch 85, Loss: 2.124063014984131\n",
      "Epoch 86, Loss: 2.124852180480957\n",
      "Epoch 87, Loss: 2.1255249977111816\n",
      "Epoch 88, Loss: 2.1260786056518555\n",
      "Epoch 89, Loss: 2.1265106201171875\n",
      "Epoch 90, Loss: 2.1268203258514404\n",
      "Epoch 91, Loss: 2.127009868621826\n",
      "Epoch 92, Loss: 2.1270830631256104\n",
      "Epoch 93, Loss: 2.1270437240600586\n",
      "Epoch 94, Loss: 2.1268985271453857\n",
      "Epoch 95, Loss: 2.126654863357544\n",
      "Epoch 96, Loss: 2.1263201236724854\n",
      "Epoch 97, Loss: 2.125903606414795\n",
      "Epoch 98, Loss: 2.1254162788391113\n",
      "Epoch 99, Loss: 2.124865770339966\n",
      "Validation Loss for GCN: 9.329392433166504\n",
      "Confusion Matrix:\n",
      "[[0 1 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " ...\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "True Negatives (TN): [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "False Positives (FP): [  0 499   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "Metrics for GCN: {'precision': 4e-06, 'recall': 0.002, 'f1_score': 7.984031936127744e-06, 'accuracy': 0.002, 'specificity': 4e-06, 'sensitivity': 0.9960039999999999, 'roc_auc': 0.5, 'mcc': 0.0}\n",
      "Training GraphSAGE...\n",
      "Epoch 0, Loss: 6.242490768432617\n",
      "Epoch 1, Loss: 6.1906352043151855\n",
      "Epoch 2, Loss: 6.137719631195068\n",
      "Epoch 3, Loss: 6.0748162269592285\n",
      "Epoch 4, Loss: 5.996232509613037\n",
      "Epoch 5, Loss: 5.89913272857666\n",
      "Epoch 6, Loss: 5.7818074226379395\n",
      "Epoch 7, Loss: 5.643354415893555\n",
      "Epoch 8, Loss: 5.481807231903076\n",
      "Epoch 9, Loss: 5.295362949371338\n",
      "Epoch 10, Loss: 5.0824809074401855\n",
      "Epoch 11, Loss: 4.84186315536499\n",
      "Epoch 12, Loss: 4.57318639755249\n",
      "Epoch 13, Loss: 4.2773661613464355\n",
      "Epoch 14, Loss: 3.9572224617004395\n",
      "Epoch 15, Loss: 3.6186811923980713\n",
      "Epoch 16, Loss: 3.2721991539001465\n",
      "Epoch 17, Loss: 2.9338085651397705\n",
      "Epoch 18, Loss: 2.625028610229492\n",
      "Epoch 19, Loss: 2.367112398147583\n",
      "Epoch 20, Loss: 2.1719155311584473\n",
      "Epoch 21, Loss: 2.035463571548462\n",
      "Epoch 22, Loss: 1.9423489570617676\n",
      "Epoch 23, Loss: 1.8756052255630493\n",
      "Epoch 24, Loss: 1.8227555751800537\n",
      "Epoch 25, Loss: 1.776611089706421\n",
      "Epoch 26, Loss: 1.7337716817855835\n",
      "Epoch 27, Loss: 1.6929166316986084\n",
      "Epoch 28, Loss: 1.653529167175293\n",
      "Epoch 29, Loss: 1.6150941848754883\n",
      "Epoch 30, Loss: 1.5767388343811035\n",
      "Epoch 31, Loss: 1.5372670888900757\n",
      "Epoch 32, Loss: 1.4954861402511597\n",
      "Epoch 33, Loss: 1.4505828619003296\n",
      "Epoch 34, Loss: 1.4023401737213135\n",
      "Epoch 35, Loss: 1.3515686988830566\n",
      "Epoch 36, Loss: 1.2986369132995605\n",
      "Epoch 37, Loss: 1.244429588317871\n",
      "Epoch 38, Loss: 1.189508318901062\n",
      "Epoch 39, Loss: 1.1339282989501953\n",
      "Epoch 40, Loss: 1.0779293775558472\n",
      "Epoch 41, Loss: 1.0215930938720703\n",
      "Epoch 42, Loss: 0.9650635123252869\n",
      "Epoch 43, Loss: 0.9086571335792542\n",
      "Epoch 44, Loss: 0.8523491024971008\n",
      "Epoch 45, Loss: 0.7966833710670471\n",
      "Epoch 46, Loss: 0.7416595220565796\n",
      "Epoch 47, Loss: 0.6876813173294067\n",
      "Epoch 48, Loss: 0.6358273029327393\n",
      "Epoch 49, Loss: 0.5863599181175232\n",
      "Epoch 50, Loss: 0.5398595333099365\n",
      "Epoch 51, Loss: 0.49638625979423523\n",
      "Epoch 52, Loss: 0.4559354782104492\n",
      "Epoch 53, Loss: 0.41860640048980713\n",
      "Epoch 54, Loss: 0.3835248351097107\n",
      "Epoch 55, Loss: 0.3509185314178467\n",
      "Epoch 56, Loss: 0.32113373279571533\n",
      "Epoch 57, Loss: 0.293637216091156\n",
      "Epoch 58, Loss: 0.26808083057403564\n",
      "Epoch 59, Loss: 0.2447572499513626\n",
      "Epoch 60, Loss: 0.2235223352909088\n",
      "Epoch 61, Loss: 0.20423217117786407\n",
      "Epoch 62, Loss: 0.18673986196517944\n",
      "Epoch 63, Loss: 0.17101576924324036\n",
      "Epoch 64, Loss: 0.15674158930778503\n",
      "Epoch 65, Loss: 0.14391785860061646\n",
      "Epoch 66, Loss: 0.13236798346042633\n",
      "Epoch 67, Loss: 0.12212841212749481\n",
      "Epoch 68, Loss: 0.11297829449176788\n",
      "Epoch 69, Loss: 0.10470505058765411\n",
      "Epoch 70, Loss: 0.09730164706707001\n",
      "Epoch 71, Loss: 0.09068809449672699\n",
      "Epoch 72, Loss: 0.08473353832960129\n",
      "Epoch 73, Loss: 0.07930696755647659\n",
      "Epoch 74, Loss: 0.07432319968938828\n",
      "Epoch 75, Loss: 0.06984396278858185\n",
      "Epoch 76, Loss: 0.0657910704612732\n",
      "Epoch 77, Loss: 0.06212075799703598\n",
      "Epoch 78, Loss: 0.05884215608239174\n",
      "Epoch 79, Loss: 0.055880144238471985\n",
      "Epoch 80, Loss: 0.05320408195257187\n",
      "Epoch 81, Loss: 0.05076571926474571\n",
      "Epoch 82, Loss: 0.04852953553199768\n",
      "Epoch 83, Loss: 0.04648653417825699\n",
      "Epoch 84, Loss: 0.04461707919836044\n",
      "Epoch 85, Loss: 0.04288851097226143\n",
      "Epoch 86, Loss: 0.041300274431705475\n",
      "Epoch 87, Loss: 0.03984696418046951\n",
      "Epoch 88, Loss: 0.03848627582192421\n",
      "Epoch 89, Loss: 0.037242453545331955\n",
      "Epoch 90, Loss: 0.03608774021267891\n",
      "Epoch 91, Loss: 0.03500744327902794\n",
      "Epoch 92, Loss: 0.034009262919425964\n",
      "Epoch 93, Loss: 0.033079203218221664\n",
      "Epoch 94, Loss: 0.03220062330365181\n",
      "Epoch 95, Loss: 0.03136442229151726\n",
      "Epoch 96, Loss: 0.03058139979839325\n",
      "Epoch 97, Loss: 0.029850352555513382\n",
      "Epoch 98, Loss: 0.029155224561691284\n",
      "Epoch 99, Loss: 0.028491925448179245\n",
      "Validation Loss for GraphSAGE: 8.025884628295898\n",
      "Confusion Matrix:\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "True Negatives (TN): [0 1 1 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "False Positives (FP): [  0   0   0   0 492   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "Metrics for GraphSAGE: {'precision': 0.014004056795131845, 'recall': 0.016, 'f1_score': 0.014008097165991901, 'accuracy': 0.016, 'specificity': 0.014004056795131845, 'sensitivity': 0.9980319999999998, 'roc_auc': 0.5070140280561123, 'mcc': 0.08408681703156701}\n",
      "Training TransE...\n",
      "Epoch 0, Loss: 0.3198176622390747\n",
      "Epoch 1, Loss: 0.1628648042678833\n",
      "Epoch 2, Loss: 0.0055930353701114655\n",
      "Epoch 3, Loss: -0.15210789442062378\n",
      "Epoch 4, Loss: -0.3103169798851013\n",
      "Epoch 5, Loss: -0.46911153197288513\n",
      "Epoch 6, Loss: -0.6285871863365173\n",
      "Epoch 7, Loss: -0.788855791091919\n",
      "Epoch 8, Loss: -0.9500400424003601\n",
      "Epoch 9, Loss: -1.1122745275497437\n",
      "Epoch 10, Loss: -1.27570641040802\n",
      "Epoch 11, Loss: -1.4404921531677246\n",
      "Epoch 12, Loss: -1.6067956686019897\n",
      "Epoch 13, Loss: -1.774784803390503\n",
      "Epoch 14, Loss: -1.944629430770874\n",
      "Epoch 15, Loss: -2.1165027618408203\n",
      "Epoch 16, Loss: -2.290578842163086\n",
      "Epoch 17, Loss: -2.4670331478118896\n",
      "Epoch 18, Loss: -2.6460421085357666\n",
      "Epoch 19, Loss: -2.827779769897461\n",
      "Epoch 20, Loss: -3.0124192237854004\n",
      "Epoch 21, Loss: -3.2001326084136963\n",
      "Epoch 22, Loss: -3.391087055206299\n",
      "Epoch 23, Loss: -3.5854501724243164\n",
      "Epoch 24, Loss: -3.783384323120117\n",
      "Epoch 25, Loss: -3.9850502014160156\n",
      "Epoch 26, Loss: -4.190606594085693\n",
      "Epoch 27, Loss: -4.400208950042725\n",
      "Epoch 28, Loss: -4.614010334014893\n",
      "Epoch 29, Loss: -4.832162380218506\n",
      "Epoch 30, Loss: -5.054814338684082\n",
      "Epoch 31, Loss: -5.282112121582031\n",
      "Epoch 32, Loss: -5.514200687408447\n",
      "Epoch 33, Loss: -5.751220226287842\n",
      "Epoch 34, Loss: -5.993310928344727\n",
      "Epoch 35, Loss: -6.240607738494873\n",
      "Epoch 36, Loss: -6.493243217468262\n",
      "Epoch 37, Loss: -6.751347064971924\n",
      "Epoch 38, Loss: -7.015044212341309\n",
      "Epoch 39, Loss: -7.284457683563232\n",
      "Epoch 40, Loss: -7.5597052574157715\n",
      "Epoch 41, Loss: -7.840901851654053\n",
      "Epoch 42, Loss: -8.128158569335938\n",
      "Epoch 43, Loss: -8.42158317565918\n",
      "Epoch 44, Loss: -8.72127914428711\n",
      "Epoch 45, Loss: -9.027347564697266\n",
      "Epoch 46, Loss: -9.339884757995605\n",
      "Epoch 47, Loss: -9.658984184265137\n",
      "Epoch 48, Loss: -9.984737396240234\n",
      "Epoch 49, Loss: -10.317232131958008\n",
      "Epoch 50, Loss: -10.6565523147583\n",
      "Epoch 51, Loss: -11.002778053283691\n",
      "Epoch 52, Loss: -11.355990409851074\n",
      "Epoch 53, Loss: -11.716264724731445\n",
      "Epoch 54, Loss: -12.083673477172852\n",
      "Epoch 55, Loss: -12.45828628540039\n",
      "Epoch 56, Loss: -12.84017276763916\n",
      "Epoch 57, Loss: -13.229394912719727\n",
      "Epoch 58, Loss: -13.626017570495605\n",
      "Epoch 59, Loss: -14.030098915100098\n",
      "Epoch 60, Loss: -14.44170093536377\n",
      "Epoch 61, Loss: -14.860876083374023\n",
      "Epoch 62, Loss: -15.287679672241211\n",
      "Epoch 63, Loss: -15.722161293029785\n",
      "Epoch 64, Loss: -16.164371490478516\n",
      "Epoch 65, Loss: -16.614356994628906\n",
      "Epoch 66, Loss: -17.072168350219727\n",
      "Epoch 67, Loss: -17.537843704223633\n",
      "Epoch 68, Loss: -18.01142692565918\n",
      "Epoch 69, Loss: -18.492961883544922\n",
      "Epoch 70, Loss: -18.982484817504883\n",
      "Epoch 71, Loss: -19.480031967163086\n",
      "Epoch 72, Loss: -19.985641479492188\n",
      "Epoch 73, Loss: -20.49934959411621\n",
      "Epoch 74, Loss: -21.02118682861328\n",
      "Epoch 75, Loss: -21.551189422607422\n",
      "Epoch 76, Loss: -22.08938217163086\n",
      "Epoch 77, Loss: -22.635801315307617\n",
      "Epoch 78, Loss: -23.190465927124023\n",
      "Epoch 79, Loss: -23.753416061401367\n",
      "Epoch 80, Loss: -24.324665069580078\n",
      "Epoch 81, Loss: -24.904245376586914\n",
      "Epoch 82, Loss: -25.49217987060547\n",
      "Epoch 83, Loss: -26.088491439819336\n",
      "Epoch 84, Loss: -26.693201065063477\n",
      "Epoch 85, Loss: -27.30633544921875\n",
      "Epoch 86, Loss: -27.92790412902832\n",
      "Epoch 87, Loss: -28.557941436767578\n",
      "Epoch 88, Loss: -29.196453094482422\n",
      "Epoch 89, Loss: -29.843467712402344\n",
      "Epoch 90, Loss: -30.498992919921875\n",
      "Epoch 91, Loss: -31.163053512573242\n",
      "Epoch 92, Loss: -31.835664749145508\n",
      "Epoch 93, Loss: -32.5168342590332\n",
      "Epoch 94, Loss: -33.20658874511719\n",
      "Epoch 95, Loss: -33.90493392944336\n",
      "Epoch 96, Loss: -34.61188507080078\n",
      "Epoch 97, Loss: -35.327457427978516\n",
      "Epoch 98, Loss: -36.05166244506836\n",
      "Epoch 99, Loss: -36.784515380859375\n",
      "Validation Loss for TransE: -0.0006475097616203129\n",
      "Confusion Matrix:\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "True Negatives (TN): [0 1 1 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "False Positives (FP): [ 0 80 53 47 50  0 56 65 67  0 74  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Metrics for TransE: {'precision': 0.0002640799289767298, 'recall': 0.016, 'f1_score': 0.000519333093735267, 'accuracy': 0.016, 'specificity': 0.0002640799289767298, 'sensitivity': 0.9980319999999998, 'roc_auc': 0.5070140280561123, 'mcc': 0.015015497525102174}\n",
      "Training TransR...\n",
      "Epoch 0, Loss: 0.12130790948867798\n",
      "Epoch 1, Loss: -0.031377583742141724\n",
      "Epoch 2, Loss: -0.1840219348669052\n",
      "Epoch 3, Loss: -0.3367803990840912\n",
      "Epoch 4, Loss: -0.48978763818740845\n",
      "Epoch 5, Loss: -0.6431705951690674\n",
      "Epoch 6, Loss: -0.7970576882362366\n",
      "Epoch 7, Loss: -0.9515796303749084\n",
      "Epoch 8, Loss: -1.106873631477356\n",
      "Epoch 9, Loss: -1.2630844116210938\n",
      "Epoch 10, Loss: -1.420360803604126\n",
      "Epoch 11, Loss: -1.5788568258285522\n",
      "Epoch 12, Loss: -1.7387309074401855\n",
      "Epoch 13, Loss: -1.9001481533050537\n",
      "Epoch 14, Loss: -2.0632777214050293\n",
      "Epoch 15, Loss: -2.2282931804656982\n",
      "Epoch 16, Loss: -2.3953723907470703\n",
      "Epoch 17, Loss: -2.564695119857788\n",
      "Epoch 18, Loss: -2.7364439964294434\n",
      "Epoch 19, Loss: -2.9108026027679443\n",
      "Epoch 20, Loss: -3.0879554748535156\n",
      "Epoch 21, Loss: -3.26808500289917\n",
      "Epoch 22, Loss: -3.451371908187866\n",
      "Epoch 23, Loss: -3.6379945278167725\n",
      "Epoch 24, Loss: -3.828127861022949\n",
      "Epoch 25, Loss: -4.021944522857666\n",
      "Epoch 26, Loss: -4.219611167907715\n",
      "Epoch 27, Loss: -4.421293258666992\n",
      "Epoch 28, Loss: -4.627148628234863\n",
      "Epoch 29, Loss: -4.837335586547852\n",
      "Epoch 30, Loss: -5.052004337310791\n",
      "Epoch 31, Loss: -5.271303653717041\n",
      "Epoch 32, Loss: -5.495375633239746\n",
      "Epoch 33, Loss: -5.724360466003418\n",
      "Epoch 34, Loss: -5.958391189575195\n",
      "Epoch 35, Loss: -6.1975998878479\n",
      "Epoch 36, Loss: -6.442111968994141\n",
      "Epoch 37, Loss: -6.692050933837891\n",
      "Epoch 38, Loss: -6.947535991668701\n",
      "Epoch 39, Loss: -7.208682537078857\n",
      "Epoch 40, Loss: -7.475602626800537\n",
      "Epoch 41, Loss: -7.748406887054443\n",
      "Epoch 42, Loss: -8.027200698852539\n",
      "Epoch 43, Loss: -8.312090873718262\n",
      "Epoch 44, Loss: -8.603177070617676\n",
      "Epoch 45, Loss: -8.90056037902832\n",
      "Epoch 46, Loss: -9.204337120056152\n",
      "Epoch 47, Loss: -9.514602661132812\n",
      "Epoch 48, Loss: -9.831450462341309\n",
      "Epoch 49, Loss: -10.1549711227417\n",
      "Epoch 50, Loss: -10.485255241394043\n",
      "Epoch 51, Loss: -10.822386741638184\n",
      "Epoch 52, Loss: -11.166452407836914\n",
      "Epoch 53, Loss: -11.517533302307129\n",
      "Epoch 54, Loss: -11.875709533691406\n",
      "Epoch 55, Loss: -12.241063117980957\n",
      "Epoch 56, Loss: -12.613666534423828\n",
      "Epoch 57, Loss: -12.993592262268066\n",
      "Epoch 58, Loss: -13.380915641784668\n",
      "Epoch 59, Loss: -13.775703430175781\n",
      "Epoch 60, Loss: -14.178023338317871\n",
      "Epoch 61, Loss: -14.58794116973877\n",
      "Epoch 62, Loss: -15.00551986694336\n",
      "Epoch 63, Loss: -15.43082046508789\n",
      "Epoch 64, Loss: -15.863899230957031\n",
      "Epoch 65, Loss: -16.304813385009766\n",
      "Epoch 66, Loss: -16.753618240356445\n",
      "Epoch 67, Loss: -17.21036148071289\n",
      "Epoch 68, Loss: -17.675098419189453\n",
      "Epoch 69, Loss: -18.147872924804688\n",
      "Epoch 70, Loss: -18.628734588623047\n",
      "Epoch 71, Loss: -19.117719650268555\n",
      "Epoch 72, Loss: -19.614870071411133\n",
      "Epoch 73, Loss: -20.120229721069336\n",
      "Epoch 74, Loss: -20.633832931518555\n",
      "Epoch 75, Loss: -21.15571403503418\n",
      "Epoch 76, Loss: -21.6859130859375\n",
      "Epoch 77, Loss: -22.22445297241211\n",
      "Epoch 78, Loss: -22.77136993408203\n",
      "Epoch 79, Loss: -23.32668685913086\n",
      "Epoch 80, Loss: -23.890439987182617\n",
      "Epoch 81, Loss: -24.4626522064209\n",
      "Epoch 82, Loss: -25.043346405029297\n",
      "Epoch 83, Loss: -25.632545471191406\n",
      "Epoch 84, Loss: -26.230274200439453\n",
      "Epoch 85, Loss: -26.83655548095703\n",
      "Epoch 86, Loss: -27.45140266418457\n",
      "Epoch 87, Loss: -28.07484245300293\n",
      "Epoch 88, Loss: -28.706893920898438\n",
      "Epoch 89, Loss: -29.347566604614258\n",
      "Epoch 90, Loss: -29.99688720703125\n",
      "Epoch 91, Loss: -30.654861450195312\n",
      "Epoch 92, Loss: -31.321516036987305\n",
      "Epoch 93, Loss: -31.996854782104492\n",
      "Epoch 94, Loss: -32.68090057373047\n",
      "Epoch 95, Loss: -33.373653411865234\n",
      "Epoch 96, Loss: -34.07514190673828\n",
      "Epoch 97, Loss: -34.785369873046875\n",
      "Epoch 98, Loss: -35.50434494018555\n",
      "Epoch 99, Loss: -36.232086181640625\n",
      "Validation Loss for TransR: 0.0002447986335027963\n",
      "Confusion Matrix:\n",
      "[[0 1 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "True Negatives (TN): [0 1 1 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "False Positives (FP): [ 0 92 34 98 69  0 68 34 27  0 70  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Metrics for TransR: {'precision': 0.00031314763216270435, 'recall': 0.016, 'f1_score': 0.0006117428890617693, 'accuracy': 0.016, 'specificity': 0.00031314763216270435, 'sensitivity': 0.9980319999999998, 'roc_auc': 0.5070140280561123, 'mcc': 0.015160653192719855}\n",
      "Training DistMult...\n",
      "Epoch 0, Loss: 0.1389608085155487\n",
      "Epoch 1, Loss: -0.03146151453256607\n",
      "Epoch 2, Loss: -0.20159786939620972\n",
      "Epoch 3, Loss: -0.37154120206832886\n",
      "Epoch 4, Loss: -0.5414133667945862\n",
      "Epoch 5, Loss: -0.7113497853279114\n",
      "Epoch 6, Loss: -0.8815006017684937\n",
      "Epoch 7, Loss: -1.05204176902771\n",
      "Epoch 8, Loss: -1.223172903060913\n",
      "Epoch 9, Loss: -1.3951078653335571\n",
      "Epoch 10, Loss: -1.5680664777755737\n",
      "Epoch 11, Loss: -1.7422704696655273\n",
      "Epoch 12, Loss: -1.9179428815841675\n",
      "Epoch 13, Loss: -2.095309257507324\n",
      "Epoch 14, Loss: -2.2745964527130127\n",
      "Epoch 15, Loss: -2.4560303688049316\n",
      "Epoch 16, Loss: -2.6398348808288574\n",
      "Epoch 17, Loss: -2.826227903366089\n",
      "Epoch 18, Loss: -3.015420913696289\n",
      "Epoch 19, Loss: -3.207618236541748\n",
      "Epoch 20, Loss: -3.4030141830444336\n",
      "Epoch 21, Loss: -3.6017978191375732\n",
      "Epoch 22, Loss: -3.8041505813598633\n",
      "Epoch 23, Loss: -4.010247230529785\n",
      "Epoch 24, Loss: -4.220256805419922\n",
      "Epoch 25, Loss: -4.434342384338379\n",
      "Epoch 26, Loss: -4.652662754058838\n",
      "Epoch 27, Loss: -4.875372409820557\n",
      "Epoch 28, Loss: -5.102619171142578\n",
      "Epoch 29, Loss: -5.334547519683838\n",
      "Epoch 30, Loss: -5.571298599243164\n",
      "Epoch 31, Loss: -5.813007354736328\n",
      "Epoch 32, Loss: -6.0598063468933105\n",
      "Epoch 33, Loss: -6.311822414398193\n",
      "Epoch 34, Loss: -6.5691819190979\n",
      "Epoch 35, Loss: -6.832004070281982\n",
      "Epoch 36, Loss: -7.100405216217041\n",
      "Epoch 37, Loss: -7.374500751495361\n",
      "Epoch 38, Loss: -7.654398441314697\n",
      "Epoch 39, Loss: -7.940204620361328\n",
      "Epoch 40, Loss: -8.232020378112793\n",
      "Epoch 41, Loss: -8.529945373535156\n",
      "Epoch 42, Loss: -8.834075927734375\n",
      "Epoch 43, Loss: -9.144501686096191\n",
      "Epoch 44, Loss: -9.461313247680664\n",
      "Epoch 45, Loss: -9.784595489501953\n",
      "Epoch 46, Loss: -10.114433288574219\n",
      "Epoch 47, Loss: -10.450904846191406\n",
      "Epoch 48, Loss: -10.794090270996094\n",
      "Epoch 49, Loss: -11.144062042236328\n",
      "Epoch 50, Loss: -11.500896453857422\n",
      "Epoch 51, Loss: -11.864662170410156\n",
      "Epoch 52, Loss: -12.235428810119629\n",
      "Epoch 53, Loss: -12.613263130187988\n",
      "Epoch 54, Loss: -12.9982328414917\n",
      "Epoch 55, Loss: -13.390397071838379\n",
      "Epoch 56, Loss: -13.78981876373291\n",
      "Epoch 57, Loss: -14.196557998657227\n",
      "Epoch 58, Loss: -14.610671043395996\n",
      "Epoch 59, Loss: -15.032214164733887\n",
      "Epoch 60, Loss: -15.461240768432617\n",
      "Epoch 61, Loss: -15.89780330657959\n",
      "Epoch 62, Loss: -16.34195327758789\n",
      "Epoch 63, Loss: -16.79373550415039\n",
      "Epoch 64, Loss: -17.253202438354492\n",
      "Epoch 65, Loss: -17.720394134521484\n",
      "Epoch 66, Loss: -18.19535255432129\n",
      "Epoch 67, Loss: -18.678129196166992\n",
      "Epoch 68, Loss: -19.168752670288086\n",
      "Epoch 69, Loss: -19.66727066040039\n",
      "Epoch 70, Loss: -20.173715591430664\n",
      "Epoch 71, Loss: -20.68812370300293\n",
      "Epoch 72, Loss: -21.21053123474121\n",
      "Epoch 73, Loss: -21.740968704223633\n",
      "Epoch 74, Loss: -22.279468536376953\n",
      "Epoch 75, Loss: -22.826061248779297\n",
      "Epoch 76, Loss: -23.380775451660156\n",
      "Epoch 77, Loss: -23.943639755249023\n",
      "Epoch 78, Loss: -24.514680862426758\n",
      "Epoch 79, Loss: -25.093921661376953\n",
      "Epoch 80, Loss: -25.681392669677734\n",
      "Epoch 81, Loss: -26.277114868164062\n",
      "Epoch 82, Loss: -26.88111114501953\n",
      "Epoch 83, Loss: -27.493404388427734\n",
      "Epoch 84, Loss: -28.114011764526367\n",
      "Epoch 85, Loss: -28.74295997619629\n",
      "Epoch 86, Loss: -29.380264282226562\n",
      "Epoch 87, Loss: -30.025943756103516\n",
      "Epoch 88, Loss: -30.680017471313477\n",
      "Epoch 89, Loss: -31.342506408691406\n",
      "Epoch 90, Loss: -32.01342010498047\n",
      "Epoch 91, Loss: -32.692771911621094\n",
      "Epoch 92, Loss: -33.38059616088867\n",
      "Epoch 93, Loss: -34.07688903808594\n",
      "Epoch 94, Loss: -34.78166961669922\n",
      "Epoch 95, Loss: -35.49496078491211\n",
      "Epoch 96, Loss: -36.216766357421875\n",
      "Epoch 97, Loss: -36.94709777832031\n",
      "Epoch 98, Loss: -37.68597412109375\n",
      "Epoch 99, Loss: -38.43340301513672\n",
      "Validation Loss for DistMult: 0.00042378169018775225\n",
      "Confusion Matrix:\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "True Negatives (TN): [0 1 1 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "False Positives (FP): [  0  48  50  76  22   0  48 119  80   0  49   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "Metrics for DistMult: {'precision': 0.0003151369117402487, 'recall': 0.016, 'f1_score': 0.0006151415064653619, 'accuracy': 0.016, 'specificity': 0.0003151369117402487, 'sensitivity': 0.9980319999999998, 'roc_auc': 0.5070140280561123, 'mcc': 0.015193977731755178}\n",
      "Training ComplEx...\n",
      "Epoch 0, Loss: 0.13438253104686737\n",
      "Epoch 1, Loss: -0.016871348023414612\n",
      "Epoch 2, Loss: -0.16855420172214508\n",
      "Epoch 3, Loss: -0.32075029611587524\n",
      "Epoch 4, Loss: -0.4735487997531891\n",
      "Epoch 5, Loss: -0.6270541548728943\n",
      "Epoch 6, Loss: -0.7813829183578491\n",
      "Epoch 7, Loss: -0.9366569519042969\n",
      "Epoch 8, Loss: -1.0930017232894897\n",
      "Epoch 9, Loss: -1.2505505084991455\n",
      "Epoch 10, Loss: -1.409447193145752\n",
      "Epoch 11, Loss: -1.569846749305725\n",
      "Epoch 12, Loss: -1.7319138050079346\n",
      "Epoch 13, Loss: -1.8958194255828857\n",
      "Epoch 14, Loss: -2.0617361068725586\n",
      "Epoch 15, Loss: -2.229835271835327\n",
      "Epoch 16, Loss: -2.400287389755249\n",
      "Epoch 17, Loss: -2.573258638381958\n",
      "Epoch 18, Loss: -2.7489163875579834\n",
      "Epoch 19, Loss: -2.9274253845214844\n",
      "Epoch 20, Loss: -3.108949661254883\n",
      "Epoch 21, Loss: -3.293654680252075\n",
      "Epoch 22, Loss: -3.481703519821167\n",
      "Epoch 23, Loss: -3.6732609272003174\n",
      "Epoch 24, Loss: -3.8684887886047363\n",
      "Epoch 25, Loss: -4.0675482749938965\n",
      "Epoch 26, Loss: -4.270598888397217\n",
      "Epoch 27, Loss: -4.4777984619140625\n",
      "Epoch 28, Loss: -4.689300060272217\n",
      "Epoch 29, Loss: -4.905256271362305\n",
      "Epoch 30, Loss: -5.125815391540527\n",
      "Epoch 31, Loss: -5.351122856140137\n",
      "Epoch 32, Loss: -5.5813188552856445\n",
      "Epoch 33, Loss: -5.816540718078613\n",
      "Epoch 34, Loss: -6.056922912597656\n",
      "Epoch 35, Loss: -6.30259370803833\n",
      "Epoch 36, Loss: -6.553678512573242\n",
      "Epoch 37, Loss: -6.810297966003418\n",
      "Epoch 38, Loss: -7.072566986083984\n",
      "Epoch 39, Loss: -7.340599536895752\n",
      "Epoch 40, Loss: -7.614504337310791\n",
      "Epoch 41, Loss: -7.894384860992432\n",
      "Epoch 42, Loss: -8.180344581604004\n",
      "Epoch 43, Loss: -8.472476959228516\n",
      "Epoch 44, Loss: -8.770877838134766\n",
      "Epoch 45, Loss: -9.075638771057129\n",
      "Epoch 46, Loss: -9.386847496032715\n",
      "Epoch 47, Loss: -9.704587936401367\n",
      "Epoch 48, Loss: -10.028943061828613\n",
      "Epoch 49, Loss: -10.359993934631348\n",
      "Epoch 50, Loss: -10.69781494140625\n",
      "Epoch 51, Loss: -11.042486190795898\n",
      "Epoch 52, Loss: -11.394076347351074\n",
      "Epoch 53, Loss: -11.752660751342773\n",
      "Epoch 54, Loss: -12.118303298950195\n",
      "Epoch 55, Loss: -12.49107551574707\n",
      "Epoch 56, Loss: -12.871040344238281\n",
      "Epoch 57, Loss: -13.258261680603027\n",
      "Epoch 58, Loss: -13.652803421020508\n",
      "Epoch 59, Loss: -14.05472183227539\n",
      "Epoch 60, Loss: -14.46407699584961\n",
      "Epoch 61, Loss: -14.880928993225098\n",
      "Epoch 62, Loss: -15.305330276489258\n",
      "Epoch 63, Loss: -15.737334251403809\n",
      "Epoch 64, Loss: -16.1769962310791\n",
      "Epoch 65, Loss: -16.62436294555664\n",
      "Epoch 66, Loss: -17.079486846923828\n",
      "Epoch 67, Loss: -17.542415618896484\n",
      "Epoch 68, Loss: -18.01319694519043\n",
      "Epoch 69, Loss: -18.491872787475586\n",
      "Epoch 70, Loss: -18.97848892211914\n",
      "Epoch 71, Loss: -19.473085403442383\n",
      "Epoch 72, Loss: -19.975704193115234\n",
      "Epoch 73, Loss: -20.48638343811035\n",
      "Epoch 74, Loss: -21.005157470703125\n",
      "Epoch 75, Loss: -21.532068252563477\n",
      "Epoch 76, Loss: -22.06714630126953\n",
      "Epoch 77, Loss: -22.610424041748047\n",
      "Epoch 78, Loss: -23.161930084228516\n",
      "Epoch 79, Loss: -23.721704483032227\n",
      "Epoch 80, Loss: -24.28976058959961\n",
      "Epoch 81, Loss: -24.866138458251953\n",
      "Epoch 82, Loss: -25.450864791870117\n",
      "Epoch 83, Loss: -26.043956756591797\n",
      "Epoch 84, Loss: -26.64543914794922\n",
      "Epoch 85, Loss: -27.25533676147461\n",
      "Epoch 86, Loss: -27.873672485351562\n",
      "Epoch 87, Loss: -28.50046730041504\n",
      "Epoch 88, Loss: -29.135740280151367\n",
      "Epoch 89, Loss: -29.779508590698242\n",
      "Epoch 90, Loss: -30.431795120239258\n",
      "Epoch 91, Loss: -31.092613220214844\n",
      "Epoch 92, Loss: -31.761981964111328\n",
      "Epoch 93, Loss: -32.43991470336914\n",
      "Epoch 94, Loss: -33.126434326171875\n",
      "Epoch 95, Loss: -33.8215446472168\n",
      "Epoch 96, Loss: -34.525264739990234\n",
      "Epoch 97, Loss: -35.23761749267578\n",
      "Epoch 98, Loss: -35.958595275878906\n",
      "Epoch 99, Loss: -36.688228607177734\n",
      "Validation Loss for ComplEx: 0.00010030650446424261\n",
      "Confusion Matrix:\n",
      "[[0 1 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]]\n",
      "True Negatives (TN): [0 1 1 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "False Positives (FP): [  0  75 112  50  46   0  29  73  55   0  52   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "Metrics for ComplEx: {'precision': 0.0002929276107463867, 'recall': 0.016, 'f1_score': 0.0005739072855711225, 'accuracy': 0.016, 'specificity': 0.0002929276107463867, 'sensitivity': 0.9980319999999998, 'roc_auc': 0.5070140280561123, 'mcc': 0.01513552069891726}\n",
      "Training HAN...\n",
      "Epoch 0, Loss: 0.039735063910484314\n",
      "Epoch 1, Loss: -0.12288463115692139\n",
      "Epoch 2, Loss: -0.28553345799446106\n",
      "Epoch 3, Loss: -0.448306679725647\n",
      "Epoch 4, Loss: -0.611285924911499\n",
      "Epoch 5, Loss: -0.7745685577392578\n",
      "Epoch 6, Loss: -0.9382737874984741\n",
      "Epoch 7, Loss: -1.1025362014770508\n",
      "Epoch 8, Loss: -1.2674976587295532\n",
      "Epoch 9, Loss: -1.4333080053329468\n",
      "Epoch 10, Loss: -1.6001313924789429\n",
      "Epoch 11, Loss: -1.7681440114974976\n",
      "Epoch 12, Loss: -1.937530755996704\n",
      "Epoch 13, Loss: -2.108478307723999\n",
      "Epoch 14, Loss: -2.2811717987060547\n",
      "Epoch 15, Loss: -2.455794334411621\n",
      "Epoch 16, Loss: -2.632528305053711\n",
      "Epoch 17, Loss: -2.8115572929382324\n",
      "Epoch 18, Loss: -2.9930648803710938\n",
      "Epoch 19, Loss: -3.1772379875183105\n",
      "Epoch 20, Loss: -3.3642616271972656\n",
      "Epoch 21, Loss: -3.5543222427368164\n",
      "Epoch 22, Loss: -3.7476048469543457\n",
      "Epoch 23, Loss: -3.9442927837371826\n",
      "Epoch 24, Loss: -4.144566535949707\n",
      "Epoch 25, Loss: -4.348602294921875\n",
      "Epoch 26, Loss: -4.556575298309326\n",
      "Epoch 27, Loss: -4.76865291595459\n",
      "Epoch 28, Loss: -4.984999656677246\n",
      "Epoch 29, Loss: -5.205775737762451\n",
      "Epoch 30, Loss: -5.431136131286621\n",
      "Epoch 31, Loss: -5.661230087280273\n",
      "Epoch 32, Loss: -5.896201133728027\n",
      "Epoch 33, Loss: -6.136191368103027\n",
      "Epoch 34, Loss: -6.381332874298096\n",
      "Epoch 35, Loss: -6.631755352020264\n",
      "Epoch 36, Loss: -6.887583255767822\n",
      "Epoch 37, Loss: -7.148938179016113\n",
      "Epoch 38, Loss: -7.415932655334473\n",
      "Epoch 39, Loss: -7.688680648803711\n",
      "Epoch 40, Loss: -7.967289447784424\n",
      "Epoch 41, Loss: -8.251862525939941\n",
      "Epoch 42, Loss: -8.54250431060791\n",
      "Epoch 43, Loss: -8.839306831359863\n",
      "Epoch 44, Loss: -9.142372131347656\n",
      "Epoch 45, Loss: -9.451787948608398\n",
      "Epoch 46, Loss: -9.767648696899414\n",
      "Epoch 47, Loss: -10.090042114257812\n",
      "Epoch 48, Loss: -10.419053077697754\n",
      "Epoch 49, Loss: -10.754766464233398\n",
      "Epoch 50, Loss: -11.097264289855957\n",
      "Epoch 51, Loss: -11.446626663208008\n",
      "Epoch 52, Loss: -11.80292797088623\n",
      "Epoch 53, Loss: -12.16624641418457\n",
      "Epoch 54, Loss: -12.536654472351074\n",
      "Epoch 55, Loss: -12.914223670959473\n",
      "Epoch 56, Loss: -13.299020767211914\n",
      "Epoch 57, Loss: -13.691108703613281\n",
      "Epoch 58, Loss: -14.090553283691406\n",
      "Epoch 59, Loss: -14.497413635253906\n",
      "Epoch 60, Loss: -14.911750793457031\n",
      "Epoch 61, Loss: -15.333614349365234\n",
      "Epoch 62, Loss: -15.763065338134766\n",
      "Epoch 63, Loss: -16.20014762878418\n",
      "Epoch 64, Loss: -16.644916534423828\n",
      "Epoch 65, Loss: -17.0974178314209\n",
      "Epoch 66, Loss: -17.557693481445312\n",
      "Epoch 67, Loss: -18.025787353515625\n",
      "Epoch 68, Loss: -18.501745223999023\n",
      "Epoch 69, Loss: -18.985605239868164\n",
      "Epoch 70, Loss: -19.477405548095703\n",
      "Epoch 71, Loss: -19.977182388305664\n",
      "Epoch 72, Loss: -20.484970092773438\n",
      "Epoch 73, Loss: -21.00080680847168\n",
      "Epoch 74, Loss: -21.52471923828125\n",
      "Epoch 75, Loss: -22.056745529174805\n",
      "Epoch 76, Loss: -22.596914291381836\n",
      "Epoch 77, Loss: -23.14525604248047\n",
      "Epoch 78, Loss: -23.701797485351562\n",
      "Epoch 79, Loss: -24.266571044921875\n",
      "Epoch 80, Loss: -24.839597702026367\n",
      "Epoch 81, Loss: -25.420907974243164\n",
      "Epoch 82, Loss: -26.010528564453125\n",
      "Epoch 83, Loss: -26.60848617553711\n",
      "Epoch 84, Loss: -27.214797973632812\n",
      "Epoch 85, Loss: -27.82949447631836\n",
      "Epoch 86, Loss: -28.452598571777344\n",
      "Epoch 87, Loss: -29.084135055541992\n",
      "Epoch 88, Loss: -29.724124908447266\n",
      "Epoch 89, Loss: -30.372591018676758\n",
      "Epoch 90, Loss: -31.029556274414062\n",
      "Epoch 91, Loss: -31.69504165649414\n",
      "Epoch 92, Loss: -32.36907196044922\n",
      "Epoch 93, Loss: -33.051658630371094\n",
      "Epoch 94, Loss: -33.742828369140625\n",
      "Epoch 95, Loss: -34.44260025024414\n",
      "Epoch 96, Loss: -35.15099334716797\n",
      "Epoch 97, Loss: -35.868011474609375\n",
      "Epoch 98, Loss: -36.593692779541016\n",
      "Epoch 99, Loss: -37.32803726196289\n",
      "Validation Loss for HAN: -0.00040432586683891714\n",
      "Confusion Matrix:\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "True Negatives (TN): [0 1 1 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "False Positives (FP): [ 0 65 51 67 53  0 49 58 80  0 69  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Metrics for HAN: {'precision': 0.0002623744621883538, 'recall': 0.016, 'f1_score': 0.0005160880330601258, 'accuracy': 0.016, 'specificity': 0.0002623744621883538, 'sensitivity': 0.9980319999999998, 'roc_auc': 0.5070140280561123, 'mcc': 0.01500881354238411}\n",
      "Training MetaPath2Vec...\n",
      "Epoch 0, Loss: -0.2243911176919937\n",
      "Epoch 1, Loss: -0.3893994987010956\n",
      "Epoch 2, Loss: -0.5545616149902344\n",
      "Epoch 3, Loss: -0.7199571132659912\n",
      "Epoch 4, Loss: -0.8857061266899109\n",
      "Epoch 5, Loss: -1.0519589185714722\n",
      "Epoch 6, Loss: -1.218880295753479\n",
      "Epoch 7, Loss: -1.3866337537765503\n",
      "Epoch 8, Loss: -1.555382490158081\n",
      "Epoch 9, Loss: -1.7252941131591797\n",
      "Epoch 10, Loss: -1.8965387344360352\n",
      "Epoch 11, Loss: -2.0692899227142334\n",
      "Epoch 12, Loss: -2.2437219619750977\n",
      "Epoch 13, Loss: -2.4200098514556885\n",
      "Epoch 14, Loss: -2.598329782485962\n",
      "Epoch 15, Loss: -2.778858184814453\n",
      "Epoch 16, Loss: -2.9617722034454346\n",
      "Epoch 17, Loss: -3.147247791290283\n",
      "Epoch 18, Loss: -3.3354604244232178\n",
      "Epoch 19, Loss: -3.5265822410583496\n",
      "Epoch 20, Loss: -3.7207837104797363\n",
      "Epoch 21, Loss: -3.918229579925537\n",
      "Epoch 22, Loss: -4.119084358215332\n",
      "Epoch 23, Loss: -4.323507308959961\n",
      "Epoch 24, Loss: -4.5316548347473145\n",
      "Epoch 25, Loss: -4.74368143081665\n",
      "Epoch 26, Loss: -4.959736347198486\n",
      "Epoch 27, Loss: -5.17996883392334\n",
      "Epoch 28, Loss: -5.404522895812988\n",
      "Epoch 29, Loss: -5.633543491363525\n",
      "Epoch 30, Loss: -5.867167949676514\n",
      "Epoch 31, Loss: -6.105534553527832\n",
      "Epoch 32, Loss: -6.3487772941589355\n",
      "Epoch 33, Loss: -6.59702730178833\n",
      "Epoch 34, Loss: -6.850412368774414\n",
      "Epoch 35, Loss: -7.109055995941162\n",
      "Epoch 36, Loss: -7.373080730438232\n",
      "Epoch 37, Loss: -7.642602920532227\n",
      "Epoch 38, Loss: -7.91773796081543\n",
      "Epoch 39, Loss: -8.198596000671387\n",
      "Epoch 40, Loss: -8.485283851623535\n",
      "Epoch 41, Loss: -8.77790641784668\n",
      "Epoch 42, Loss: -9.07656478881836\n",
      "Epoch 43, Loss: -9.381355285644531\n",
      "Epoch 44, Loss: -9.692375183105469\n",
      "Epoch 45, Loss: -10.009716033935547\n",
      "Epoch 46, Loss: -10.33346939086914\n",
      "Epoch 47, Loss: -10.663722038269043\n",
      "Epoch 48, Loss: -11.00055980682373\n",
      "Epoch 49, Loss: -11.344069480895996\n",
      "Epoch 50, Loss: -11.694330215454102\n",
      "Epoch 51, Loss: -12.051424980163574\n",
      "Epoch 52, Loss: -12.41543197631836\n",
      "Epoch 53, Loss: -12.786428451538086\n",
      "Epoch 54, Loss: -13.16448974609375\n",
      "Epoch 55, Loss: -13.549688339233398\n",
      "Epoch 56, Loss: -13.942090034484863\n",
      "Epoch 57, Loss: -14.341768264770508\n",
      "Epoch 58, Loss: -14.748785018920898\n",
      "Epoch 59, Loss: -15.163202285766602\n",
      "Epoch 60, Loss: -15.585082054138184\n",
      "Epoch 61, Loss: -16.014480590820312\n",
      "Epoch 62, Loss: -16.45145606994629\n",
      "Epoch 63, Loss: -16.89606475830078\n",
      "Epoch 64, Loss: -17.348350524902344\n",
      "Epoch 65, Loss: -17.80837059020996\n",
      "Epoch 66, Loss: -18.276165008544922\n",
      "Epoch 67, Loss: -18.75178337097168\n",
      "Epoch 68, Loss: -19.23526954650879\n",
      "Epoch 69, Loss: -19.72666358947754\n",
      "Epoch 70, Loss: -20.22600555419922\n",
      "Epoch 71, Loss: -20.733327865600586\n",
      "Epoch 72, Loss: -21.248676300048828\n",
      "Epoch 73, Loss: -21.77208137512207\n",
      "Epoch 74, Loss: -22.303571701049805\n",
      "Epoch 75, Loss: -22.84318733215332\n",
      "Epoch 76, Loss: -23.390947341918945\n",
      "Epoch 77, Loss: -23.9468936920166\n",
      "Epoch 78, Loss: -24.51104736328125\n",
      "Epoch 79, Loss: -25.08342933654785\n",
      "Epoch 80, Loss: -25.664079666137695\n",
      "Epoch 81, Loss: -26.25301170349121\n",
      "Epoch 82, Loss: -26.85025405883789\n",
      "Epoch 83, Loss: -27.455825805664062\n",
      "Epoch 84, Loss: -28.069747924804688\n",
      "Epoch 85, Loss: -28.692047119140625\n",
      "Epoch 86, Loss: -29.322736740112305\n",
      "Epoch 87, Loss: -29.961841583251953\n",
      "Epoch 88, Loss: -30.609375\n",
      "Epoch 89, Loss: -31.265357971191406\n",
      "Epoch 90, Loss: -31.92980194091797\n",
      "Epoch 91, Loss: -32.60272979736328\n",
      "Epoch 92, Loss: -33.284156799316406\n",
      "Epoch 93, Loss: -33.97409439086914\n",
      "Epoch 94, Loss: -34.67255401611328\n",
      "Epoch 95, Loss: -35.37955856323242\n",
      "Epoch 96, Loss: -36.09511184692383\n",
      "Epoch 97, Loss: -36.81923294067383\n",
      "Epoch 98, Loss: -37.551937103271484\n",
      "Epoch 99, Loss: -38.29322814941406\n",
      "Validation Loss for MetaPath2Vec: 0.0004859760811086744\n",
      "Confusion Matrix:\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "True Negatives (TN): [0 1 1 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "False Positives (FP): [ 0 83 44 90 80  0 27 55 53  0 60  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Metrics for MetaPath2Vec: {'precision': 0.0002918901276824774, 'recall': 0.016, 'f1_score': 0.0005716239687817661, 'accuracy': 0.016, 'specificity': 0.0002918901276824774, 'sensitivity': 0.9980319999999998, 'roc_auc': 0.5070140280561123, 'mcc': 0.015093465979017865}\n",
      "Training GCF...\n",
      "Epoch 0, Loss: -0.19954337179660797\n",
      "Epoch 1, Loss: -0.375061571598053\n",
      "Epoch 2, Loss: -0.5508418083190918\n",
      "Epoch 3, Loss: -0.7269902229309082\n",
      "Epoch 4, Loss: -0.9035825133323669\n",
      "Epoch 5, Loss: -1.0807143449783325\n",
      "Epoch 6, Loss: -1.2585219144821167\n",
      "Epoch 7, Loss: -1.4371665716171265\n",
      "Epoch 8, Loss: -1.616819143295288\n",
      "Epoch 9, Loss: -1.797652006149292\n",
      "Epoch 10, Loss: -1.979836106300354\n",
      "Epoch 11, Loss: -2.163540840148926\n",
      "Epoch 12, Loss: -2.3489344120025635\n",
      "Epoch 13, Loss: -2.5361826419830322\n",
      "Epoch 14, Loss: -2.725450277328491\n",
      "Epoch 15, Loss: -2.916897773742676\n",
      "Epoch 16, Loss: -3.110684633255005\n",
      "Epoch 17, Loss: -3.3069701194763184\n",
      "Epoch 18, Loss: -3.505916118621826\n",
      "Epoch 19, Loss: -3.707684278488159\n",
      "Epoch 20, Loss: -3.9124414920806885\n",
      "Epoch 21, Loss: -4.120356559753418\n",
      "Epoch 22, Loss: -4.33159875869751\n",
      "Epoch 23, Loss: -4.546339988708496\n",
      "Epoch 24, Loss: -4.7647504806518555\n",
      "Epoch 25, Loss: -4.987000465393066\n",
      "Epoch 26, Loss: -5.213255882263184\n",
      "Epoch 27, Loss: -5.4436798095703125\n",
      "Epoch 28, Loss: -5.678431987762451\n",
      "Epoch 29, Loss: -5.917666435241699\n",
      "Epoch 30, Loss: -6.161534786224365\n",
      "Epoch 31, Loss: -6.410181522369385\n",
      "Epoch 32, Loss: -6.6637468338012695\n",
      "Epoch 33, Loss: -6.922367095947266\n",
      "Epoch 34, Loss: -7.1861724853515625\n",
      "Epoch 35, Loss: -7.45529317855835\n",
      "Epoch 36, Loss: -7.7298479080200195\n",
      "Epoch 37, Loss: -8.009956359863281\n",
      "Epoch 38, Loss: -8.295733451843262\n",
      "Epoch 39, Loss: -8.587288856506348\n",
      "Epoch 40, Loss: -8.884729385375977\n",
      "Epoch 41, Loss: -9.188159942626953\n",
      "Epoch 42, Loss: -9.4976806640625\n",
      "Epoch 43, Loss: -9.813385009765625\n",
      "Epoch 44, Loss: -10.135369300842285\n",
      "Epoch 45, Loss: -10.463724136352539\n",
      "Epoch 46, Loss: -10.79853630065918\n",
      "Epoch 47, Loss: -11.139888763427734\n",
      "Epoch 48, Loss: -11.48786735534668\n",
      "Epoch 49, Loss: -11.842548370361328\n",
      "Epoch 50, Loss: -12.204009056091309\n",
      "Epoch 51, Loss: -12.5723237991333\n",
      "Epoch 52, Loss: -12.947563171386719\n",
      "Epoch 53, Loss: -13.329798698425293\n",
      "Epoch 54, Loss: -13.719096183776855\n",
      "Epoch 55, Loss: -14.115519523620605\n",
      "Epoch 56, Loss: -14.51913070678711\n",
      "Epoch 57, Loss: -14.929991722106934\n",
      "Epoch 58, Loss: -15.348158836364746\n",
      "Epoch 59, Loss: -15.773689270019531\n",
      "Epoch 60, Loss: -16.206634521484375\n",
      "Epoch 61, Loss: -16.647050857543945\n",
      "Epoch 62, Loss: -17.094985961914062\n",
      "Epoch 63, Loss: -17.550485610961914\n",
      "Epoch 64, Loss: -18.01359748840332\n",
      "Epoch 65, Loss: -18.4843692779541\n",
      "Epoch 66, Loss: -18.962841033935547\n",
      "Epoch 67, Loss: -19.449052810668945\n",
      "Epoch 68, Loss: -19.94304847717285\n",
      "Epoch 69, Loss: -20.444862365722656\n",
      "Epoch 70, Loss: -20.954532623291016\n",
      "Epoch 71, Loss: -21.47209358215332\n",
      "Epoch 72, Loss: -21.997583389282227\n",
      "Epoch 73, Loss: -22.53103256225586\n",
      "Epoch 74, Loss: -23.072471618652344\n",
      "Epoch 75, Loss: -23.621936798095703\n",
      "Epoch 76, Loss: -24.1794490814209\n",
      "Epoch 77, Loss: -24.74504280090332\n",
      "Epoch 78, Loss: -25.318740844726562\n",
      "Epoch 79, Loss: -25.900577545166016\n",
      "Epoch 80, Loss: -26.490570068359375\n",
      "Epoch 81, Loss: -27.0887451171875\n",
      "Epoch 82, Loss: -27.695133209228516\n",
      "Epoch 83, Loss: -28.30974578857422\n",
      "Epoch 84, Loss: -28.932613372802734\n",
      "Epoch 85, Loss: -29.56375503540039\n",
      "Epoch 86, Loss: -30.203189849853516\n",
      "Epoch 87, Loss: -30.850940704345703\n",
      "Epoch 88, Loss: -31.507022857666016\n",
      "Epoch 89, Loss: -32.17145919799805\n",
      "Epoch 90, Loss: -32.84426498413086\n",
      "Epoch 91, Loss: -33.525455474853516\n",
      "Epoch 92, Loss: -34.21504592895508\n",
      "Epoch 93, Loss: -34.913063049316406\n",
      "Epoch 94, Loss: -35.619510650634766\n",
      "Epoch 95, Loss: -36.33441162109375\n",
      "Epoch 96, Loss: -37.05777359008789\n",
      "Epoch 97, Loss: -37.78961181640625\n",
      "Epoch 98, Loss: -38.529945373535156\n",
      "Epoch 99, Loss: -39.278778076171875\n",
      "Validation Loss for GCF: -9.523300832370296e-05\n",
      "Confusion Matrix:\n",
      "[[0 1 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "True Negatives (TN): [0 1 1 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "False Positives (FP): [ 0 70 65 72 67  0 50 52 42  0 71  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  1  0  1  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Metrics for GCF: {'precision': 0.0002665220103832604, 'recall': 0.016, 'f1_score': 0.0005239828790938638, 'accuracy': 0.016, 'specificity': 0.0002665220103832604, 'sensitivity': 0.9980319759519036, 'roc_auc': 0.5070140280561123, 'mcc': 0.015000350798019826}\n",
      "Training GRMF...\n",
      "Epoch 0, Loss: 0.16116590797901154\n",
      "Epoch 1, Loss: 0.01812833920121193\n",
      "Epoch 2, Loss: -0.12502740323543549\n",
      "Epoch 3, Loss: -0.268445760011673\n",
      "Epoch 4, Loss: -0.41223347187042236\n",
      "Epoch 5, Loss: -0.556517481803894\n",
      "Epoch 6, Loss: -0.7014578580856323\n",
      "Epoch 7, Loss: -0.8472239971160889\n",
      "Epoch 8, Loss: -0.9939753413200378\n",
      "Epoch 9, Loss: -1.1418591737747192\n",
      "Epoch 10, Loss: -1.2910182476043701\n",
      "Epoch 11, Loss: -1.4415982961654663\n",
      "Epoch 12, Loss: -1.5937515497207642\n",
      "Epoch 13, Loss: -1.7476387023925781\n",
      "Epoch 14, Loss: -1.9034286737442017\n",
      "Epoch 15, Loss: -2.0612971782684326\n",
      "Epoch 16, Loss: -2.221424102783203\n",
      "Epoch 17, Loss: -2.3839917182922363\n",
      "Epoch 18, Loss: -2.5491836071014404\n",
      "Epoch 19, Loss: -2.7171826362609863\n",
      "Epoch 20, Loss: -2.8881707191467285\n",
      "Epoch 21, Loss: -3.0623297691345215\n",
      "Epoch 22, Loss: -3.2398383617401123\n",
      "Epoch 23, Loss: -3.4208741188049316\n",
      "Epoch 24, Loss: -3.60561203956604\n",
      "Epoch 25, Loss: -3.7942230701446533\n",
      "Epoch 26, Loss: -3.9868764877319336\n",
      "Epoch 27, Loss: -4.183734893798828\n",
      "Epoch 28, Loss: -4.3849592208862305\n",
      "Epoch 29, Loss: -4.590704441070557\n",
      "Epoch 30, Loss: -4.801121234893799\n",
      "Epoch 31, Loss: -5.016356468200684\n",
      "Epoch 32, Loss: -5.236551761627197\n",
      "Epoch 33, Loss: -5.461845397949219\n",
      "Epoch 34, Loss: -5.6923699378967285\n",
      "Epoch 35, Loss: -5.928255558013916\n",
      "Epoch 36, Loss: -6.169627666473389\n",
      "Epoch 37, Loss: -6.41660737991333\n",
      "Epoch 38, Loss: -6.669315338134766\n",
      "Epoch 39, Loss: -6.927863597869873\n",
      "Epoch 40, Loss: -7.192365646362305\n",
      "Epoch 41, Loss: -7.462929725646973\n",
      "Epoch 42, Loss: -7.739660739898682\n",
      "Epoch 43, Loss: -8.022661209106445\n",
      "Epoch 44, Loss: -8.312031745910645\n",
      "Epoch 45, Loss: -8.607869148254395\n",
      "Epoch 46, Loss: -8.91026782989502\n",
      "Epoch 47, Loss: -9.219321250915527\n",
      "Epoch 48, Loss: -9.535117149353027\n",
      "Epoch 49, Loss: -9.857745170593262\n",
      "Epoch 50, Loss: -10.187291145324707\n",
      "Epoch 51, Loss: -10.52383804321289\n",
      "Epoch 52, Loss: -10.86746597290039\n",
      "Epoch 53, Loss: -11.218254089355469\n",
      "Epoch 54, Loss: -11.576279640197754\n",
      "Epoch 55, Loss: -11.941614151000977\n",
      "Epoch 56, Loss: -12.314330101013184\n",
      "Epoch 57, Loss: -12.694494247436523\n",
      "Epoch 58, Loss: -13.082172393798828\n",
      "Epoch 59, Loss: -13.477429389953613\n",
      "Epoch 60, Loss: -13.880324363708496\n",
      "Epoch 61, Loss: -14.29091739654541\n",
      "Epoch 62, Loss: -14.70926284790039\n",
      "Epoch 63, Loss: -15.135412216186523\n",
      "Epoch 64, Loss: -15.569421768188477\n",
      "Epoch 65, Loss: -16.011337280273438\n",
      "Epoch 66, Loss: -16.46120262145996\n",
      "Epoch 67, Loss: -16.9190673828125\n",
      "Epoch 68, Loss: -17.38497543334961\n",
      "Epoch 69, Loss: -17.85896110534668\n",
      "Epoch 70, Loss: -18.341068267822266\n",
      "Epoch 71, Loss: -18.831336975097656\n",
      "Epoch 72, Loss: -19.32979965209961\n",
      "Epoch 73, Loss: -19.83648681640625\n",
      "Epoch 74, Loss: -20.3514404296875\n",
      "Epoch 75, Loss: -20.874683380126953\n",
      "Epoch 76, Loss: -21.406253814697266\n",
      "Epoch 77, Loss: -21.946168899536133\n",
      "Epoch 78, Loss: -22.49446678161621\n",
      "Epoch 79, Loss: -23.051166534423828\n",
      "Epoch 80, Loss: -23.616296768188477\n",
      "Epoch 81, Loss: -24.189882278442383\n",
      "Epoch 82, Loss: -24.77194595336914\n",
      "Epoch 83, Loss: -25.36250114440918\n",
      "Epoch 84, Loss: -25.961580276489258\n",
      "Epoch 85, Loss: -26.569198608398438\n",
      "Epoch 86, Loss: -27.185373306274414\n",
      "Epoch 87, Loss: -27.810123443603516\n",
      "Epoch 88, Loss: -28.44346809387207\n",
      "Epoch 89, Loss: -29.085426330566406\n",
      "Epoch 90, Loss: -29.736005783081055\n",
      "Epoch 91, Loss: -30.39522933959961\n",
      "Epoch 92, Loss: -31.0631103515625\n",
      "Epoch 93, Loss: -31.73965835571289\n",
      "Epoch 94, Loss: -32.424888610839844\n",
      "Epoch 95, Loss: -33.11882019042969\n",
      "Epoch 96, Loss: -33.82145690917969\n",
      "Epoch 97, Loss: -34.53281021118164\n",
      "Epoch 98, Loss: -35.252899169921875\n",
      "Epoch 99, Loss: -35.98173141479492\n",
      "Validation Loss for GRMF: -0.00016483955550938845\n",
      "Confusion Matrix:\n",
      "[[0 1 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "True Negatives (TN): [0 1 1 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "False Positives (FP): [ 0 49 99 59 75  0 63 40 60  0 47  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Metrics for GRMF: {'precision': 0.0002741331625244639, 'recall': 0.016, 'f1_score': 0.0005384824942549538, 'accuracy': 0.016, 'specificity': 0.0002741331625244639, 'sensitivity': 0.9980319999999998, 'roc_auc': 0.5070140280561123, 'mcc': 0.015065460967616528}\n",
      "Training GAT...\n",
      "Epoch 0, Loss: 6.214812278747559\n",
      "Epoch 1, Loss: 6.158024787902832\n",
      "Epoch 2, Loss: 6.063686370849609\n",
      "Epoch 3, Loss: 5.9058074951171875\n",
      "Epoch 4, Loss: 5.679643630981445\n",
      "Epoch 5, Loss: 5.345221042633057\n",
      "Epoch 6, Loss: 4.99515962600708\n",
      "Epoch 7, Loss: 4.57032585144043\n",
      "Epoch 8, Loss: 4.011458396911621\n",
      "Epoch 9, Loss: 3.499121904373169\n",
      "Epoch 10, Loss: 2.931856393814087\n",
      "Epoch 11, Loss: 2.595672607421875\n",
      "Epoch 12, Loss: 2.309065580368042\n",
      "Epoch 13, Loss: 2.1796376705169678\n",
      "Epoch 14, Loss: 2.1166799068450928\n",
      "Epoch 15, Loss: 2.094024419784546\n",
      "Epoch 16, Loss: 2.087571382522583\n",
      "Epoch 17, Loss: 2.082855463027954\n",
      "Epoch 18, Loss: 2.082448959350586\n",
      "Epoch 19, Loss: 2.0827643871307373\n",
      "Epoch 20, Loss: 2.0835180282592773\n",
      "Epoch 21, Loss: 2.083051919937134\n",
      "Epoch 22, Loss: 2.079983711242676\n",
      "Epoch 23, Loss: 2.0804524421691895\n",
      "Epoch 24, Loss: 2.081812858581543\n",
      "Epoch 25, Loss: 2.084712266921997\n",
      "Epoch 26, Loss: 2.08078932762146\n",
      "Epoch 27, Loss: 2.079526424407959\n",
      "Epoch 28, Loss: 2.079505205154419\n",
      "Epoch 29, Loss: 2.08245587348938\n",
      "Epoch 30, Loss: 2.0838217735290527\n",
      "Epoch 31, Loss: 2.081789493560791\n",
      "Epoch 32, Loss: 2.0810201168060303\n",
      "Epoch 33, Loss: 2.080839157104492\n",
      "Epoch 34, Loss: 2.0816166400909424\n",
      "Epoch 35, Loss: 2.079998731613159\n",
      "Epoch 36, Loss: 2.0822808742523193\n",
      "Epoch 37, Loss: 2.082982063293457\n",
      "Epoch 38, Loss: 2.0842957496643066\n",
      "Epoch 39, Loss: 2.084359884262085\n",
      "Epoch 40, Loss: 2.0846197605133057\n",
      "Epoch 41, Loss: 2.0869531631469727\n",
      "Epoch 42, Loss: 2.0849215984344482\n",
      "Epoch 43, Loss: 2.0906336307525635\n",
      "Epoch 44, Loss: 2.091348648071289\n",
      "Epoch 45, Loss: 2.0954995155334473\n",
      "Epoch 46, Loss: 2.093506336212158\n",
      "Epoch 47, Loss: 2.094716787338257\n",
      "Epoch 48, Loss: 2.1029257774353027\n",
      "Epoch 49, Loss: 2.1087582111358643\n",
      "Epoch 50, Loss: 2.1157548427581787\n",
      "Epoch 51, Loss: 2.1129634380340576\n",
      "Epoch 52, Loss: 2.1078615188598633\n",
      "Epoch 53, Loss: 2.128669261932373\n",
      "Epoch 54, Loss: 2.117966651916504\n",
      "Epoch 55, Loss: 2.1136536598205566\n",
      "Epoch 56, Loss: 2.112360954284668\n",
      "Epoch 57, Loss: 2.1132538318634033\n",
      "Epoch 58, Loss: 2.112226724624634\n",
      "Epoch 59, Loss: 2.106873035430908\n",
      "Epoch 60, Loss: 2.120978355407715\n",
      "Epoch 61, Loss: 2.106618881225586\n",
      "Epoch 62, Loss: 2.099748373031616\n",
      "Epoch 63, Loss: 2.1045610904693604\n",
      "Epoch 64, Loss: 2.0960004329681396\n",
      "Epoch 65, Loss: 2.0967743396759033\n",
      "Epoch 66, Loss: 2.0932085514068604\n",
      "Epoch 67, Loss: 2.0955867767333984\n",
      "Epoch 68, Loss: 2.1010944843292236\n",
      "Epoch 69, Loss: 2.095247507095337\n",
      "Epoch 70, Loss: 2.0909807682037354\n",
      "Epoch 71, Loss: 2.0920183658599854\n",
      "Epoch 72, Loss: 2.0910096168518066\n",
      "Epoch 73, Loss: 2.0896639823913574\n",
      "Epoch 74, Loss: 2.0924441814422607\n",
      "Epoch 75, Loss: 2.0892937183380127\n",
      "Epoch 76, Loss: 2.090176820755005\n",
      "Epoch 77, Loss: 2.0875110626220703\n",
      "Epoch 78, Loss: 2.0885417461395264\n",
      "Epoch 79, Loss: 2.0919864177703857\n",
      "Epoch 80, Loss: 2.087905168533325\n",
      "Epoch 81, Loss: 2.0893919467926025\n",
      "Epoch 82, Loss: 2.088022470474243\n",
      "Epoch 83, Loss: 2.088061571121216\n",
      "Epoch 84, Loss: 2.091416835784912\n",
      "Epoch 85, Loss: 2.088315010070801\n",
      "Epoch 86, Loss: 2.087009906768799\n",
      "Epoch 87, Loss: 2.0878183841705322\n",
      "Epoch 88, Loss: 2.0897939205169678\n",
      "Epoch 89, Loss: 2.0868992805480957\n",
      "Epoch 90, Loss: 2.0861053466796875\n",
      "Epoch 91, Loss: 2.085179567337036\n",
      "Epoch 92, Loss: 2.088142156600952\n",
      "Epoch 93, Loss: 2.087695598602295\n",
      "Epoch 94, Loss: 2.0855488777160645\n",
      "Epoch 95, Loss: 2.0841357707977295\n",
      "Epoch 96, Loss: 2.0854618549346924\n",
      "Epoch 97, Loss: 2.0850183963775635\n",
      "Epoch 98, Loss: 2.0871353149414062\n",
      "Epoch 99, Loss: 2.085963010787964\n",
      "Validation Loss for GAT: 11.579426765441895\n",
      "Confusion Matrix:\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "True Negatives (TN): [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "False Positives (FP): [  0   0   0   0   0   0   0 499   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "Metrics for GAT: {'precision': 4e-06, 'recall': 0.002, 'f1_score': 7.984031936127744e-06, 'accuracy': 0.002, 'specificity': 4e-06, 'sensitivity': 0.9960039999999999, 'roc_auc': 0.5, 'mcc': 0.0}\n",
      "Training STAGE...\n",
      "Epoch 0, Loss: 0.06663314253091812\n",
      "Epoch 1, Loss: -0.09142874926328659\n",
      "Epoch 2, Loss: -0.24962079524993896\n",
      "Epoch 3, Loss: -0.4080886244773865\n",
      "Epoch 4, Loss: -0.5669646263122559\n",
      "Epoch 5, Loss: -0.7263957858085632\n",
      "Epoch 6, Loss: -0.886519730091095\n",
      "Epoch 7, Loss: -1.0474717617034912\n",
      "Epoch 8, Loss: -1.2093945741653442\n",
      "Epoch 9, Loss: -1.3724391460418701\n",
      "Epoch 10, Loss: -1.5367618799209595\n",
      "Epoch 11, Loss: -1.7025234699249268\n",
      "Epoch 12, Loss: -1.869889736175537\n",
      "Epoch 13, Loss: -2.0390336513519287\n",
      "Epoch 14, Loss: -2.2101333141326904\n",
      "Epoch 15, Loss: -2.3833730220794678\n",
      "Epoch 16, Loss: -2.55893874168396\n",
      "Epoch 17, Loss: -2.737016439437866\n",
      "Epoch 18, Loss: -2.9177920818328857\n",
      "Epoch 19, Loss: -3.1014461517333984\n",
      "Epoch 20, Loss: -3.2881555557250977\n",
      "Epoch 21, Loss: -3.4780936241149902\n",
      "Epoch 22, Loss: -3.671428680419922\n",
      "Epoch 23, Loss: -3.8683269023895264\n",
      "Epoch 24, Loss: -4.068950176239014\n",
      "Epoch 25, Loss: -4.2734575271606445\n",
      "Epoch 26, Loss: -4.482006072998047\n",
      "Epoch 27, Loss: -4.694748878479004\n",
      "Epoch 28, Loss: -4.911837100982666\n",
      "Epoch 29, Loss: -5.133415699005127\n",
      "Epoch 30, Loss: -5.359629154205322\n",
      "Epoch 31, Loss: -5.590616226196289\n",
      "Epoch 32, Loss: -5.826510906219482\n",
      "Epoch 33, Loss: -6.067443370819092\n",
      "Epoch 34, Loss: -6.313539505004883\n",
      "Epoch 35, Loss: -6.564920425415039\n",
      "Epoch 36, Loss: -6.82170295715332\n",
      "Epoch 37, Loss: -7.083998680114746\n",
      "Epoch 38, Loss: -7.351917743682861\n",
      "Epoch 39, Loss: -7.625564098358154\n",
      "Epoch 40, Loss: -7.905039310455322\n",
      "Epoch 41, Loss: -8.190441131591797\n",
      "Epoch 42, Loss: -8.481866836547852\n",
      "Epoch 43, Loss: -8.77940559387207\n",
      "Epoch 44, Loss: -9.083149909973145\n",
      "Epoch 45, Loss: -9.393186569213867\n",
      "Epoch 46, Loss: -9.709601402282715\n",
      "Epoch 47, Loss: -10.032479286193848\n",
      "Epoch 48, Loss: -10.36190128326416\n",
      "Epoch 49, Loss: -10.69794750213623\n",
      "Epoch 50, Loss: -11.040698051452637\n",
      "Epoch 51, Loss: -11.390229225158691\n",
      "Epoch 52, Loss: -11.746618270874023\n",
      "Epoch 53, Loss: -12.109936714172363\n",
      "Epoch 54, Loss: -12.480260848999023\n",
      "Epoch 55, Loss: -12.857657432556152\n",
      "Epoch 56, Loss: -13.242199897766113\n",
      "Epoch 57, Loss: -13.633953094482422\n",
      "Epoch 58, Loss: -14.032979965209961\n",
      "Epoch 59, Loss: -14.439352035522461\n",
      "Epoch 60, Loss: -14.853124618530273\n",
      "Epoch 61, Loss: -15.274362564086914\n",
      "Epoch 62, Loss: -15.703120231628418\n",
      "Epoch 63, Loss: -16.13945770263672\n",
      "Epoch 64, Loss: -16.583425521850586\n",
      "Epoch 65, Loss: -17.035079956054688\n",
      "Epoch 66, Loss: -17.494470596313477\n",
      "Epoch 67, Loss: -17.961647033691406\n",
      "Epoch 68, Loss: -18.436656951904297\n",
      "Epoch 69, Loss: -18.919544219970703\n",
      "Epoch 70, Loss: -19.410354614257812\n",
      "Epoch 71, Loss: -19.909130096435547\n",
      "Epoch 72, Loss: -20.41591453552246\n",
      "Epoch 73, Loss: -20.930742263793945\n",
      "Epoch 74, Loss: -21.453655242919922\n",
      "Epoch 75, Loss: -21.984691619873047\n",
      "Epoch 76, Loss: -22.52388572692871\n",
      "Epoch 77, Loss: -23.071273803710938\n",
      "Epoch 78, Loss: -23.62688446044922\n",
      "Epoch 79, Loss: -24.190757751464844\n",
      "Epoch 80, Loss: -24.762924194335938\n",
      "Epoch 81, Loss: -25.34341049194336\n",
      "Epoch 82, Loss: -25.932247161865234\n",
      "Epoch 83, Loss: -26.529464721679688\n",
      "Epoch 84, Loss: -27.13509178161621\n",
      "Epoch 85, Loss: -27.749149322509766\n",
      "Epoch 86, Loss: -28.371665954589844\n",
      "Epoch 87, Loss: -29.002666473388672\n",
      "Epoch 88, Loss: -29.642173767089844\n",
      "Epoch 89, Loss: -30.290212631225586\n",
      "Epoch 90, Loss: -30.94679832458496\n",
      "Epoch 91, Loss: -31.611957550048828\n",
      "Epoch 92, Loss: -32.28570556640625\n",
      "Epoch 93, Loss: -32.96805953979492\n",
      "Epoch 94, Loss: -33.65903854370117\n",
      "Epoch 95, Loss: -34.35865783691406\n",
      "Epoch 96, Loss: -35.06693649291992\n",
      "Epoch 97, Loss: -35.78388214111328\n",
      "Epoch 98, Loss: -36.50951385498047\n",
      "Epoch 99, Loss: -37.24384307861328\n",
      "Validation Loss for STAGE: 0.0005164071917533875\n",
      "Confusion Matrix:\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "True Negatives (TN): [0 1 1 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "False Positives (FP): [ 0 51 75 60 53  0 75 40 59  0 79  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Metrics for STAGE: {'precision': 0.00026803086083005697, 'recall': 0.016, 'f1_score': 0.0005268057855481235, 'accuracy': 0.016, 'specificity': 0.00026803086083005697, 'sensitivity': 0.9980319999999998, 'roc_auc': 0.5070140280561123, 'mcc': 0.015027164177813544}\n",
      "Training SR-GNN...\n",
      "Epoch 0, Loss: 0.1268148422241211\n",
      "Epoch 1, Loss: -0.030032701790332794\n",
      "Epoch 2, Loss: -0.18697874248027802\n",
      "Epoch 3, Loss: -0.3441098630428314\n",
      "Epoch 4, Loss: -0.5015583038330078\n",
      "Epoch 5, Loss: -0.6594526171684265\n",
      "Epoch 6, Loss: -0.8179062008857727\n",
      "Epoch 7, Loss: -0.9770300388336182\n",
      "Epoch 8, Loss: -1.1369495391845703\n",
      "Epoch 9, Loss: -1.2978062629699707\n",
      "Epoch 10, Loss: -1.4597538709640503\n",
      "Epoch 11, Loss: -1.6229528188705444\n",
      "Epoch 12, Loss: -1.7875686883926392\n",
      "Epoch 13, Loss: -1.9537689685821533\n",
      "Epoch 14, Loss: -2.1217234134674072\n",
      "Epoch 15, Loss: -2.291602611541748\n",
      "Epoch 16, Loss: -2.4635775089263916\n",
      "Epoch 17, Loss: -2.637817859649658\n",
      "Epoch 18, Loss: -2.81449294090271\n",
      "Epoch 19, Loss: -2.9937691688537598\n",
      "Epoch 20, Loss: -3.175811767578125\n",
      "Epoch 21, Loss: -3.360783100128174\n",
      "Epoch 22, Loss: -3.548844575881958\n",
      "Epoch 23, Loss: -3.7401552200317383\n",
      "Epoch 24, Loss: -3.934875249862671\n",
      "Epoch 25, Loss: -4.133161544799805\n",
      "Epoch 26, Loss: -4.335172176361084\n",
      "Epoch 27, Loss: -4.541065692901611\n",
      "Epoch 28, Loss: -4.750997543334961\n",
      "Epoch 29, Loss: -4.965123653411865\n",
      "Epoch 30, Loss: -5.183598518371582\n",
      "Epoch 31, Loss: -5.406574726104736\n",
      "Epoch 32, Loss: -5.634200096130371\n",
      "Epoch 33, Loss: -5.866623401641846\n",
      "Epoch 34, Loss: -6.103986740112305\n",
      "Epoch 35, Loss: -6.346429824829102\n",
      "Epoch 36, Loss: -6.594087600708008\n",
      "Epoch 37, Loss: -6.847090721130371\n",
      "Epoch 38, Loss: -7.105566024780273\n",
      "Epoch 39, Loss: -7.369634628295898\n",
      "Epoch 40, Loss: -7.639415264129639\n",
      "Epoch 41, Loss: -7.915019512176514\n",
      "Epoch 42, Loss: -8.196558952331543\n",
      "Epoch 43, Loss: -8.484135627746582\n",
      "Epoch 44, Loss: -8.777854919433594\n",
      "Epoch 45, Loss: -9.077811241149902\n",
      "Epoch 46, Loss: -9.384101867675781\n",
      "Epoch 47, Loss: -9.696819305419922\n",
      "Epoch 48, Loss: -10.016053199768066\n",
      "Epoch 49, Loss: -10.341891288757324\n",
      "Epoch 50, Loss: -10.674420356750488\n",
      "Epoch 51, Loss: -11.01372241973877\n",
      "Epoch 52, Loss: -11.359879493713379\n",
      "Epoch 53, Loss: -11.712968826293945\n",
      "Epoch 54, Loss: -12.07307243347168\n",
      "Epoch 55, Loss: -12.440261840820312\n",
      "Epoch 56, Loss: -12.814610481262207\n",
      "Epoch 57, Loss: -13.196187973022461\n",
      "Epoch 58, Loss: -13.585062980651855\n",
      "Epoch 59, Loss: -13.981304168701172\n",
      "Epoch 60, Loss: -14.384969711303711\n",
      "Epoch 61, Loss: -14.796127319335938\n",
      "Epoch 62, Loss: -15.214835166931152\n",
      "Epoch 63, Loss: -15.641148567199707\n",
      "Epoch 64, Loss: -16.075124740600586\n",
      "Epoch 65, Loss: -16.516820907592773\n",
      "Epoch 66, Loss: -16.966283798217773\n",
      "Epoch 67, Loss: -17.42357063293457\n",
      "Epoch 68, Loss: -17.88872528076172\n",
      "Epoch 69, Loss: -18.361799240112305\n",
      "Epoch 70, Loss: -18.84284019470215\n",
      "Epoch 71, Loss: -19.331892013549805\n",
      "Epoch 72, Loss: -19.82900047302246\n",
      "Epoch 73, Loss: -20.334209442138672\n",
      "Epoch 74, Loss: -20.847564697265625\n",
      "Epoch 75, Loss: -21.369102478027344\n",
      "Epoch 76, Loss: -21.898866653442383\n",
      "Epoch 77, Loss: -22.436893463134766\n",
      "Epoch 78, Loss: -22.983219146728516\n",
      "Epoch 79, Loss: -23.53788948059082\n",
      "Epoch 80, Loss: -24.10092544555664\n",
      "Epoch 81, Loss: -24.67237091064453\n",
      "Epoch 82, Loss: -25.25225067138672\n",
      "Epoch 83, Loss: -25.840600967407227\n",
      "Epoch 84, Loss: -26.43744468688965\n",
      "Epoch 85, Loss: -27.042816162109375\n",
      "Epoch 86, Loss: -27.656726837158203\n",
      "Epoch 87, Loss: -28.279220581054688\n",
      "Epoch 88, Loss: -28.91029930114746\n",
      "Epoch 89, Loss: -29.549999237060547\n",
      "Epoch 90, Loss: -30.19833755493164\n",
      "Epoch 91, Loss: -30.855331420898438\n",
      "Epoch 92, Loss: -31.520999908447266\n",
      "Epoch 93, Loss: -32.19535446166992\n",
      "Epoch 94, Loss: -32.87841796875\n",
      "Epoch 95, Loss: -33.57020568847656\n",
      "Epoch 96, Loss: -34.270729064941406\n",
      "Epoch 97, Loss: -34.97999572753906\n",
      "Epoch 98, Loss: -35.69803237915039\n",
      "Epoch 99, Loss: -36.42483901977539\n",
      "Validation Loss for SR-GNN: 0.00011358162737451494\n",
      "Confusion Matrix:\n",
      "[[0 1 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "True Negatives (TN): [0 1 1 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "False Positives (FP): [ 0 51 73 44 63  0 41 56 75  0 89  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Metrics for SR-GNN: {'precision': 0.0002724277885462096, 'recall': 0.016, 'f1_score': 0.0005351928836835615, 'accuracy': 0.016, 'specificity': 0.0002724277885462096, 'sensitivity': 0.9980319999999998, 'roc_auc': 0.5070140280561123, 'mcc': 0.015048496605759786}\n",
      "Training DeepWalk...\n",
      "Epoch 0, Loss: 0.21610024571418762\n",
      "Epoch 1, Loss: 0.06489945203065872\n",
      "Epoch 2, Loss: -0.08598083257675171\n",
      "Epoch 3, Loss: -0.23671555519104004\n",
      "Epoch 4, Loss: -0.3874139189720154\n",
      "Epoch 5, Loss: -0.5382027626037598\n",
      "Epoch 6, Loss: -0.689228892326355\n",
      "Epoch 7, Loss: -0.8406429290771484\n",
      "Epoch 8, Loss: -0.992601752281189\n",
      "Epoch 9, Loss: -1.145270586013794\n",
      "Epoch 10, Loss: -1.298822045326233\n",
      "Epoch 11, Loss: -1.4534320831298828\n",
      "Epoch 12, Loss: -1.6092829704284668\n",
      "Epoch 13, Loss: -1.7665660381317139\n",
      "Epoch 14, Loss: -1.9254822731018066\n",
      "Epoch 15, Loss: -2.086240291595459\n",
      "Epoch 16, Loss: -2.2490532398223877\n",
      "Epoch 17, Loss: -2.4141335487365723\n",
      "Epoch 18, Loss: -2.5816917419433594\n",
      "Epoch 19, Loss: -2.751932382583618\n",
      "Epoch 20, Loss: -2.9250566959381104\n",
      "Epoch 21, Loss: -3.1012582778930664\n",
      "Epoch 22, Loss: -3.2807271480560303\n",
      "Epoch 23, Loss: -3.4636483192443848\n",
      "Epoch 24, Loss: -3.6502013206481934\n",
      "Epoch 25, Loss: -3.8405637741088867\n",
      "Epoch 26, Loss: -4.034905433654785\n",
      "Epoch 27, Loss: -4.233396053314209\n",
      "Epoch 28, Loss: -4.436197280883789\n",
      "Epoch 29, Loss: -4.643467903137207\n",
      "Epoch 30, Loss: -4.8553619384765625\n",
      "Epoch 31, Loss: -5.072028160095215\n",
      "Epoch 32, Loss: -5.293610572814941\n",
      "Epoch 33, Loss: -5.520247936248779\n",
      "Epoch 34, Loss: -5.752074241638184\n",
      "Epoch 35, Loss: -5.989220142364502\n",
      "Epoch 36, Loss: -6.2318115234375\n",
      "Epoch 37, Loss: -6.479968070983887\n",
      "Epoch 38, Loss: -6.733807563781738\n",
      "Epoch 39, Loss: -6.993443965911865\n",
      "Epoch 40, Loss: -7.258988380432129\n",
      "Epoch 41, Loss: -7.530545711517334\n",
      "Epoch 42, Loss: -7.8082194328308105\n",
      "Epoch 43, Loss: -8.092113494873047\n",
      "Epoch 44, Loss: -8.382323265075684\n",
      "Epoch 45, Loss: -8.678946495056152\n",
      "Epoch 46, Loss: -8.982076644897461\n",
      "Epoch 47, Loss: -9.291804313659668\n",
      "Epoch 48, Loss: -9.608219146728516\n",
      "Epoch 49, Loss: -9.931408882141113\n",
      "Epoch 50, Loss: -10.261459350585938\n",
      "Epoch 51, Loss: -10.598451614379883\n",
      "Epoch 52, Loss: -10.942472457885742\n",
      "Epoch 53, Loss: -11.293595314025879\n",
      "Epoch 54, Loss: -11.651904106140137\n",
      "Epoch 55, Loss: -12.017473220825195\n",
      "Epoch 56, Loss: -12.390374183654785\n",
      "Epoch 57, Loss: -12.770681381225586\n",
      "Epoch 58, Loss: -13.158466339111328\n",
      "Epoch 59, Loss: -13.553792953491211\n",
      "Epoch 60, Loss: -13.956727981567383\n",
      "Epoch 61, Loss: -14.367334365844727\n",
      "Epoch 62, Loss: -14.785674095153809\n",
      "Epoch 63, Loss: -15.211803436279297\n",
      "Epoch 64, Loss: -15.645776748657227\n",
      "Epoch 65, Loss: -16.087648391723633\n",
      "Epoch 66, Loss: -16.5374698638916\n",
      "Epoch 67, Loss: -16.995290756225586\n",
      "Epoch 68, Loss: -17.461149215698242\n",
      "Epoch 69, Loss: -17.935096740722656\n",
      "Epoch 70, Loss: -18.41717529296875\n",
      "Epoch 71, Loss: -18.907419204711914\n",
      "Epoch 72, Loss: -19.405872344970703\n",
      "Epoch 73, Loss: -19.912565231323242\n",
      "Epoch 74, Loss: -20.427536010742188\n",
      "Epoch 75, Loss: -20.950817108154297\n",
      "Epoch 76, Loss: -21.482439041137695\n",
      "Epoch 77, Loss: -22.022430419921875\n",
      "Epoch 78, Loss: -22.570819854736328\n",
      "Epoch 79, Loss: -23.127634048461914\n",
      "Epoch 80, Loss: -23.692899703979492\n",
      "Epoch 81, Loss: -24.26664161682129\n",
      "Epoch 82, Loss: -24.8488826751709\n",
      "Epoch 83, Loss: -25.439645767211914\n",
      "Epoch 84, Loss: -26.038949966430664\n",
      "Epoch 85, Loss: -26.646821975708008\n",
      "Epoch 86, Loss: -27.263267517089844\n",
      "Epoch 87, Loss: -27.888320922851562\n",
      "Epoch 88, Loss: -28.521987915039062\n",
      "Epoch 89, Loss: -29.164287567138672\n",
      "Epoch 90, Loss: -29.815242767333984\n",
      "Epoch 91, Loss: -30.474864959716797\n",
      "Epoch 92, Loss: -31.14316749572754\n",
      "Epoch 93, Loss: -31.820158004760742\n",
      "Epoch 94, Loss: -32.505863189697266\n",
      "Epoch 95, Loss: -33.200286865234375\n",
      "Epoch 96, Loss: -33.9034423828125\n",
      "Epoch 97, Loss: -34.61534118652344\n",
      "Epoch 98, Loss: -35.335994720458984\n",
      "Epoch 99, Loss: -36.06541442871094\n",
      "Validation Loss for DeepWalk: -0.0006836038664914668\n",
      "Confusion Matrix:\n",
      "[[0 0 1 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "True Negatives (TN): [0 1 1 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "False Positives (FP): [ 0 66 56 55 64  0 64 55 64  0 68  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Metrics for DeepWalk: {'precision': 0.0002576602365495429, 'recall': 0.016, 'f1_score': 0.0005071009628071654, 'accuracy': 0.016, 'specificity': 0.0002576602365495429, 'sensitivity': 0.9980319999999998, 'roc_auc': 0.5070140280561123, 'mcc': 0.014988334942907383}\n",
      "Training Node2Vec...\n",
      "Epoch 0, Loss: -0.17327135801315308\n",
      "Epoch 1, Loss: -0.32322007417678833\n",
      "Epoch 2, Loss: -0.4731464982032776\n",
      "Epoch 3, Loss: -0.6232244372367859\n",
      "Epoch 4, Loss: -0.7736895680427551\n",
      "Epoch 5, Loss: -0.9247058629989624\n",
      "Epoch 6, Loss: -1.076405644416809\n",
      "Epoch 7, Loss: -1.2289258241653442\n",
      "Epoch 8, Loss: -1.3824139833450317\n",
      "Epoch 9, Loss: -1.5370254516601562\n",
      "Epoch 10, Loss: -1.6929187774658203\n",
      "Epoch 11, Loss: -1.8502541780471802\n",
      "Epoch 12, Loss: -2.009192943572998\n",
      "Epoch 13, Loss: -2.169898748397827\n",
      "Epoch 14, Loss: -2.3325397968292236\n",
      "Epoch 15, Loss: -2.497288227081299\n",
      "Epoch 16, Loss: -2.6643190383911133\n",
      "Epoch 17, Loss: -2.833810806274414\n",
      "Epoch 18, Loss: -3.0059447288513184\n",
      "Epoch 19, Loss: -3.180901527404785\n",
      "Epoch 20, Loss: -3.3588621616363525\n",
      "Epoch 21, Loss: -3.5400068759918213\n",
      "Epoch 22, Loss: -3.7245142459869385\n",
      "Epoch 23, Loss: -3.9125587940216064\n",
      "Epoch 24, Loss: -4.104312419891357\n",
      "Epoch 25, Loss: -4.29994535446167\n",
      "Epoch 26, Loss: -4.499622344970703\n",
      "Epoch 27, Loss: -4.70350456237793\n",
      "Epoch 28, Loss: -4.911752223968506\n",
      "Epoch 29, Loss: -5.12451696395874\n",
      "Epoch 30, Loss: -5.341951370239258\n",
      "Epoch 31, Loss: -5.564202308654785\n",
      "Epoch 32, Loss: -5.791412353515625\n",
      "Epoch 33, Loss: -6.0237226486206055\n",
      "Epoch 34, Loss: -6.261268615722656\n",
      "Epoch 35, Loss: -6.504181861877441\n",
      "Epoch 36, Loss: -6.75259256362915\n",
      "Epoch 37, Loss: -7.006625652313232\n",
      "Epoch 38, Loss: -7.2664031982421875\n",
      "Epoch 39, Loss: -7.532041072845459\n",
      "Epoch 40, Loss: -7.80365514755249\n",
      "Epoch 41, Loss: -8.081354141235352\n",
      "Epoch 42, Loss: -8.36524486541748\n",
      "Epoch 43, Loss: -8.65542984008789\n",
      "Epoch 44, Loss: -8.952008247375488\n",
      "Epoch 45, Loss: -9.255074501037598\n",
      "Epoch 46, Loss: -9.564722061157227\n",
      "Epoch 47, Loss: -9.881038665771484\n",
      "Epoch 48, Loss: -10.204111099243164\n",
      "Epoch 49, Loss: -10.534019470214844\n",
      "Epoch 50, Loss: -10.870844841003418\n",
      "Epoch 51, Loss: -11.2146635055542\n",
      "Epoch 52, Loss: -11.565549850463867\n",
      "Epoch 53, Loss: -11.923576354980469\n",
      "Epoch 54, Loss: -12.28880786895752\n",
      "Epoch 55, Loss: -12.661312103271484\n",
      "Epoch 56, Loss: -13.041154861450195\n",
      "Epoch 57, Loss: -13.428394317626953\n",
      "Epoch 58, Loss: -13.82309341430664\n",
      "Epoch 59, Loss: -14.225306510925293\n",
      "Epoch 60, Loss: -14.635090827941895\n",
      "Epoch 61, Loss: -15.052497863769531\n",
      "Epoch 62, Loss: -15.477583885192871\n",
      "Epoch 63, Loss: -15.910392761230469\n",
      "Epoch 64, Loss: -16.35097885131836\n",
      "Epoch 65, Loss: -16.79938507080078\n",
      "Epoch 66, Loss: -17.255653381347656\n",
      "Epoch 67, Loss: -17.719833374023438\n",
      "Epoch 68, Loss: -18.191965103149414\n",
      "Epoch 69, Loss: -18.672086715698242\n",
      "Epoch 70, Loss: -19.160240173339844\n",
      "Epoch 71, Loss: -19.656461715698242\n",
      "Epoch 72, Loss: -20.160783767700195\n",
      "Epoch 73, Loss: -20.673246383666992\n",
      "Epoch 74, Loss: -21.193878173828125\n",
      "Epoch 75, Loss: -21.722713470458984\n",
      "Epoch 76, Loss: -22.259782791137695\n",
      "Epoch 77, Loss: -22.805112838745117\n",
      "Epoch 78, Loss: -23.358734130859375\n",
      "Epoch 79, Loss: -23.920669555664062\n",
      "Epoch 80, Loss: -24.490947723388672\n",
      "Epoch 81, Loss: -25.069591522216797\n",
      "Epoch 82, Loss: -25.656625747680664\n",
      "Epoch 83, Loss: -26.252073287963867\n",
      "Epoch 84, Loss: -26.855955123901367\n",
      "Epoch 85, Loss: -27.46828842163086\n",
      "Epoch 86, Loss: -28.08909797668457\n",
      "Epoch 87, Loss: -28.71839714050293\n",
      "Epoch 88, Loss: -29.3562068939209\n",
      "Epoch 89, Loss: -30.002548217773438\n",
      "Epoch 90, Loss: -30.65743637084961\n",
      "Epoch 91, Loss: -31.320880889892578\n",
      "Epoch 92, Loss: -31.992897033691406\n",
      "Epoch 93, Loss: -32.67350387573242\n",
      "Epoch 94, Loss: -33.36272430419922\n",
      "Epoch 95, Loss: -34.06055450439453\n",
      "Epoch 96, Loss: -34.76701736450195\n",
      "Epoch 97, Loss: -35.48212432861328\n",
      "Epoch 98, Loss: -36.20588684082031\n",
      "Epoch 99, Loss: -36.93830871582031\n",
      "Validation Loss for Node2Vec: 0.0001591839245520532\n",
      "Confusion Matrix:\n",
      "[[0 0 1 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "True Negatives (TN): [0 1 1 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "False Positives (FP): [ 0 70 61 86 31  0 76 53 71  0 44  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Metrics for Node2Vec: {'precision': 0.0002811488695810478, 'recall': 0.016, 'f1_score': 0.0005514746520106855, 'accuracy': 0.016, 'specificity': 0.0002811488695810478, 'sensitivity': 0.9980319999999998, 'roc_auc': 0.5070140280561123, 'mcc': 0.015060379550715939}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, matthews_corrcoef, confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/visheshyadav/Documents/GitHub/CoreRec/engine')\n",
    "from core_rec import GraphTransformer, train_model, predict\n",
    "\n",
    "# Load your data\n",
    "labels_df = pd.read_csv('data_mother/500label.csv')\n",
    "labels = labels_df['Names'].tolist()\n",
    "label_to_index = {label: idx for idx, label in enumerate(labels)}\n",
    "\n",
    "# Load adjacency matrix\n",
    "adj_matrix = pd.read_csv('data_mother/wgtlabel.csv', header=None).values\n",
    "\n",
    "# Create edge index for PyTorch Geometric\n",
    "edge_index = torch_geometric.utils.dense_to_sparse(torch.tensor(adj_matrix, dtype=torch.float))[0]\n",
    "\n",
    "# Create node features (for simplicity, using identity matrix)\n",
    "num_nodes = adj_matrix.shape[0]\n",
    "x = torch.eye(num_nodes, dtype=torch.float)\n",
    "\n",
    "# Create labels (for simplicity, using node indices as labels)\n",
    "y = torch.tensor(range(num_nodes), dtype=torch.long)\n",
    "\n",
    "# Create PyTorch Geometric data object\n",
    "data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "# Define GCN model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_nodes, 16)\n",
    "        self.conv2 = GCNConv(16, num_nodes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Define GAT model\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(num_nodes, 16, heads=8, dropout=0.6)\n",
    "        self.conv2 = GATConv(16 * 8, num_nodes, heads=1, concat=False, dropout=0.6)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Define GraphSAGE model\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(num_nodes, 16)\n",
    "        self.conv2 = SAGEConv(16, num_nodes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Placeholder for other models\n",
    "class TransE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransE, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class TransR(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransR, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class DistMult(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DistMult, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class ComplEx(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ComplEx, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class HAN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HAN, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class MetaPath2Vec(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MetaPath2Vec, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class GCF(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCF, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class GRMF(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GRMF, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class STAGE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(STAGE, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class SRGNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SRGNN, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class DeepWalk(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepWalk, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class Node2Vec(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Node2Vec, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class MetaExploitModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MetaExploitModel, self).__init__()\n",
    "        num_layers = 1\n",
    "        d_model = 128\n",
    "        num_heads = 2\n",
    "        d_feedforward = 512\n",
    "        self.model = GraphTransformer(num_layers, d_model, num_heads, d_feedforward, input_dim, use_weights=True)\n",
    "\n",
    "    def forward(self, data):\n",
    "        adj_matrix = data.x.numpy()  # Assuming data.x is the adjacency matrix\n",
    "        output = self.model(torch.tensor(adj_matrix, dtype=torch.float32))\n",
    "        return output\n",
    "\n",
    "# Placeholder for model evaluation\n",
    "def evaluate_model(model, data):\n",
    "    model.eval()\n",
    "    out = model(data)\n",
    "    pred = out.argmax(dim=1)\n",
    "    y_true = data.y.numpy()\n",
    "    y_pred = pred.numpy()\n",
    "    \n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    y_true_binarized = label_binarize(y_true, classes=np.arange(num_nodes))\n",
    "    y_pred_binarized = label_binarize(y_pred, classes=np.arange(num_nodes))\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_true_binarized, y_pred_binarized, multi_class='ovr')\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn = np.diag(cm)\n",
    "    fp = cm.sum(axis=0) - tn\n",
    "    fn = cm.sum(axis=1) - tn\n",
    "    tp = cm.sum() - (fp + fn + tn)\n",
    "    \n",
    "    # Debugging print statements\n",
    "    print(f\"Confusion Matrix:\\n{cm}\")\n",
    "    print(f\"True Negatives (TN): {tn}\")\n",
    "    print(f\"False Positives (FP): {fp}\")\n",
    "    \n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        specificity = np.mean(np.divide(tn, tn + fp, out=np.zeros_like(tn, dtype=float), where=(tn + fp) != 0))\n",
    "        sensitivity = np.mean(np.divide(tp, tp + fn, out=np.zeros_like(tp, dtype=float), where=(tp + fn) != 0))\n",
    "    \n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"specificity\": specificity,\n",
    "        \"sensitivity\": sensitivity,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"mcc\": mcc\n",
    "    }\n",
    "\n",
    "# List of models to benchmark\n",
    "models_to_benchmark = {\n",
    "    \"CoreRec\": MetaExploitModel(input_dim=adj_matrix.shape[1]) ,\n",
    "    \"GCN\": GCN(),\n",
    "    \"GraphSAGE\": GraphSAGE(),\n",
    "    \"TransE\": TransE(),\n",
    "    \"TransR\": TransR(),\n",
    "    \"DistMult\": DistMult(),\n",
    "    \"ComplEx\": ComplEx(),\n",
    "    \"HAN\": HAN(),\n",
    "    \"MetaPath2Vec\": MetaPath2Vec(),\n",
    "    \"GCF\": GCF(),\n",
    "    \"GRMF\": GRMF(),\n",
    "    \"GAT\": GAT(),\n",
    "    \"STAGE\": STAGE(),\n",
    "    \"SR-GNN\": SRGNN(),\n",
    "    \"DeepWalk\": DeepWalk(),\n",
    "    \"Node2Vec\": Node2Vec()\n",
    "}\n",
    "\n",
    "# Dictionary to store benchmark results\n",
    "benchmark_results = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models_to_benchmark.items():\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    model.train()\n",
    "    print(f\"Training {model_name}...\")\n",
    "    for epoch in range(100):  # Start with 50 epochs\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        if out is None:\n",
    "            print(f\"Model {model_name} returned None output\")\n",
    "            continue\n",
    "        if out.shape != (num_nodes, num_nodes):\n",
    "            print(f\"Unexpected output shape for {model_name}: {out.shape}\")\n",
    "            continue\n",
    "        loss = F.nll_loss(out[train_mask], data.y[train_mask])\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data)\n",
    "        val_loss = F.nll_loss(out[val_mask], data.y[val_mask])\n",
    "        print(f\"Validation Loss for {model_name}: {val_loss.item()}\")\n",
    "    \n",
    "    metrics = evaluate_model(model, data)\n",
    "    print(f\"Metrics for {model_name}: {metrics}\")\n",
    "    benchmark_results[model_name] = metrics\n",
    "\n",
    "# Convert results to DataFrame for easier plotting\n",
    "df = pd.DataFrame(benchmark_results).T\n",
    "\n",
    "# Plot the results with padding between models\n",
    "sns.set(style=\"whitegrid\")\n",
    "palette = sns.color_palette(\"Set2\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "x = np.arange(len(models_to_benchmark))\n",
    "width = 0.08  # Reduce the width of the bars to add padding\n",
    "\n",
    "metrics = df.columns\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax.bar(x + i*width, df[metric], width, label=metric, capsize=5, color=palette[i % len(palette)])\n",
    "\n",
    "ax.set_xlabel('Models', fontsize=14)\n",
    "ax.set_ylabel('Scores', fontsize=14)\n",
    "ax.set_title('Benchmark Results Comparison', fontsize=16, weight='bold')\n",
    "ax.set_xticks(x + width * (len(metrics) - 1) / 2)\n",
    "ax.set_xticklabels(models_to_benchmark.keys(), rotation=90, fontsize=12)\n",
    "ax.legend(fontsize=12, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "ax.yaxis.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "for metric in metrics:\n",
    "    ax.plot(models_to_benchmark.keys(), df[metric], marker='o', label=metric)\n",
    "ax.set_xlabel('Models', fontsize=14)\n",
    "ax.set_ylabel('Scores', fontsize=14)\n",
    "ax.set_title('Benchmark Results Comparison', fontsize=16, weight='bold')\n",
    "ax.legend(fontsize=12, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "ax.yaxis.grid(True)\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|              |   precision |   recall |    f1_score |   accuracy |   specificity |   sensitivity |   roc_auc |       mcc |\n",
      "|:-------------|------------:|---------:|------------:|-----------:|--------------:|--------------:|----------:|----------:|\n",
      "| CoreRec      | 0.00323017  |    0.016 | 0.00420422  |      0.016 |   0.00323017  |      0.998032 |  0.507014 | 0.0268423 |\n",
      "| GCN          | 4e-06       |    0.002 | 7.98403e-06 |      0.002 |   4e-06       |      0.996004 |  0.5      | 0         |\n",
      "| GraphSAGE    | 0.0140041   |    0.016 | 0.0140081   |      0.016 |   0.0140041   |      0.998032 |  0.507014 | 0.0840868 |\n",
      "| TransE       | 0.00026408  |    0.016 | 0.000519333 |      0.016 |   0.00026408  |      0.998032 |  0.507014 | 0.0150155 |\n",
      "| TransR       | 0.000313148 |    0.016 | 0.000611743 |      0.016 |   0.000313148 |      0.998032 |  0.507014 | 0.0151607 |\n",
      "| DistMult     | 0.000315137 |    0.016 | 0.000615142 |      0.016 |   0.000315137 |      0.998032 |  0.507014 | 0.015194  |\n",
      "| ComplEx      | 0.000292928 |    0.016 | 0.000573907 |      0.016 |   0.000292928 |      0.998032 |  0.507014 | 0.0151355 |\n",
      "| HAN          | 0.000262374 |    0.016 | 0.000516088 |      0.016 |   0.000262374 |      0.998032 |  0.507014 | 0.0150088 |\n",
      "| MetaPath2Vec | 0.00029189  |    0.016 | 0.000571624 |      0.016 |   0.00029189  |      0.998032 |  0.507014 | 0.0150935 |\n",
      "| GCF          | 0.000266522 |    0.016 | 0.000523983 |      0.016 |   0.000266522 |      0.998032 |  0.507014 | 0.0150004 |\n",
      "| GRMF         | 0.000274133 |    0.016 | 0.000538482 |      0.016 |   0.000274133 |      0.998032 |  0.507014 | 0.0150655 |\n",
      "| GAT          | 4e-06       |    0.002 | 7.98403e-06 |      0.002 |   4e-06       |      0.996004 |  0.5      | 0         |\n",
      "| STAGE        | 0.000268031 |    0.016 | 0.000526806 |      0.016 |   0.000268031 |      0.998032 |  0.507014 | 0.0150272 |\n",
      "| SR-GNN       | 0.000272428 |    0.016 | 0.000535193 |      0.016 |   0.000272428 |      0.998032 |  0.507014 | 0.0150485 |\n",
      "| DeepWalk     | 0.00025766  |    0.016 | 0.000507101 |      0.016 |   0.00025766  |      0.998032 |  0.507014 | 0.0149883 |\n",
      "| Node2Vec     | 0.000281149 |    0.016 | 0.000551475 |      0.016 |   0.000281149 |      0.998032 |  0.507014 | 0.0150604 |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame containing the benchmark results\n",
    "df = pd.DataFrame(benchmark_results).T\n",
    "\n",
    "# Convert DataFrame to markdown table\n",
    "markdown_table = df.to_markdown()\n",
    "\n",
    "# Print the markdown table\n",
    "print(markdown_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark Adam&eric scr & JaccardIndex scr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import adjusted_rand_score, jaccard_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/visheshyadav/Documents/GitHub/CoreRec/engine')\n",
    "from core_rec import GraphTransformer, train_model, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define GCN model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_nodes, 16)\n",
    "        self.conv2 = GCNConv(16, num_nodes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Define GAT model\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(num_nodes, 16, heads=8, dropout=0.6)\n",
    "        self.conv2 = GATConv(16 * 8, num_nodes, heads=1, concat=False, dropout=0.6)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Define GraphSAGE model\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(num_nodes, 16)\n",
    "        self.conv2 = SAGEConv(16, num_nodes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Placeholder for other models\n",
    "class TransE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransE, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class TransR(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransR, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class DistMult(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DistMult, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class ComplEx(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ComplEx, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class HAN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HAN, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class MetaPath2Vec(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MetaPath2Vec, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class GCF(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCF, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class GRMF(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GRMF, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class STAGE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(STAGE, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class SRGNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SRGNN, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class DeepWalk(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepWalk, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class Node2Vec(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Node2Vec, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class MetaExploitModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MetaExploitModel, self).__init__()\n",
    "        num_layers = 1\n",
    "        d_model = 128\n",
    "        num_heads = 2\n",
    "        d_feedforward = 512\n",
    "        self.model = GraphTransformer(num_layers, d_model, num_heads, d_feedforward, input_dim, use_weights=True)\n",
    "\n",
    "    def forward(self, data):\n",
    "        adj_matrix = data.x.numpy()  # Assuming data.x is the adjacency matrix\n",
    "        output = self.model(torch.tensor(adj_matrix, dtype=torch.float32))\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for jaccard index //adam nd eric not working\n",
    "def evaluate_model_ari_jaccard(model, data):\n",
    "    model.eval()\n",
    "    out = model(data)\n",
    "    pred = out.argmax(dim=1)\n",
    "    y_true = data.y.numpy()\n",
    "    y_pred = pred.numpy()\n",
    "    \n",
    "    print(f\"True Labels: {y_true}\")\n",
    "    print(f\"Predicted Labels: {y_pred}\")\n",
    "    \n",
    "    jaccard = jaccard_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    return {\n",
    "        \"jaccard\": jaccard\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Donot run below cell in CPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CoreRec...\n",
      "Epoch 0, Loss: -2.5872141122817993e-05\n",
      "Epoch 1, Loss: -2.98258638381958\n",
      "Epoch 2, Loss: -4.819379806518555\n",
      "Epoch 3, Loss: -6.443193435668945\n",
      "Epoch 4, Loss: -7.98840856552124\n",
      "Epoch 5, Loss: -9.076559066772461\n",
      "Epoch 6, Loss: -10.225074768066406\n",
      "Epoch 7, Loss: -11.353041648864746\n",
      "Epoch 8, Loss: -12.519213676452637\n",
      "Epoch 9, Loss: -13.793668746948242\n",
      "Epoch 10, Loss: -15.109587669372559\n",
      "Epoch 11, Loss: -16.54354476928711\n",
      "Epoch 12, Loss: -17.991994857788086\n",
      "Epoch 13, Loss: -19.516260147094727\n",
      "Epoch 14, Loss: -20.93100929260254\n",
      "Epoch 15, Loss: -22.605377197265625\n",
      "Epoch 16, Loss: -23.912872314453125\n",
      "Epoch 17, Loss: -25.878969192504883\n",
      "Epoch 18, Loss: -27.310131072998047\n",
      "Epoch 19, Loss: -29.493539810180664\n",
      "Epoch 20, Loss: -31.141788482666016\n",
      "Epoch 21, Loss: -33.32502746582031\n",
      "Epoch 22, Loss: -35.300865173339844\n",
      "Epoch 23, Loss: -37.420249938964844\n",
      "Epoch 24, Loss: -39.64004898071289\n",
      "Epoch 25, Loss: -41.81160354614258\n",
      "Epoch 26, Loss: -44.3198356628418\n",
      "Epoch 27, Loss: -46.59397888183594\n",
      "Epoch 28, Loss: -49.089111328125\n",
      "Epoch 29, Loss: -51.66794204711914\n",
      "Epoch 30, Loss: -54.25666427612305\n",
      "Epoch 31, Loss: -57.11636734008789\n",
      "Epoch 32, Loss: -59.751670837402344\n",
      "Epoch 33, Loss: -62.60789108276367\n",
      "Epoch 34, Loss: -65.26229858398438\n",
      "Epoch 35, Loss: -68.13624572753906\n",
      "Epoch 36, Loss: -71.78076171875\n",
      "Epoch 37, Loss: -74.68160247802734\n",
      "Epoch 38, Loss: -78.403564453125\n",
      "Epoch 39, Loss: -81.51807403564453\n",
      "Epoch 40, Loss: -85.12821960449219\n",
      "Epoch 41, Loss: -88.65647888183594\n",
      "Epoch 42, Loss: -92.20939636230469\n",
      "Epoch 43, Loss: -95.95417022705078\n",
      "Epoch 44, Loss: -99.91455078125\n",
      "Epoch 45, Loss: -103.78105163574219\n",
      "Epoch 46, Loss: -107.76896667480469\n",
      "Epoch 47, Loss: -111.9447021484375\n",
      "Epoch 48, Loss: -116.09858703613281\n",
      "Epoch 49, Loss: -120.39347076416016\n",
      "Validation Loss for CoreRec: -0.009467042051255703\n",
      "True Labels: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
      " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
      " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
      " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
      " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
      " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
      " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
      " 486 487 488 489 490 491 492 493 494 495 496 497 498 499]\n",
      "Predicted Labels: [ 8  1  2  3  4  7  6  7  8  6 10  6  6  8  7  6  6 10  7  6  6  7  6  6\n",
      "  6  7  7  6  7  7  6  6  6 10  6  7  6  6  6  6  6  6  6 10  6  6  7  6\n",
      "  6  6 10  7 10  6  6  6  6  7  6  6 10 10  6  8 10  6  6  6  6  7  7  6\n",
      "  7 10  6  6  6  6  6  7  6  6  6  7  6  6 10  6  6  8 10  8  6  8  6  7\n",
      "  6  7  1  6  6 10  6  6  6  6  7  6  6  6 10  6  6  8  6  6 10 10  6  6\n",
      "  6 10  6  6  6 10  6  6  6  6  6  6 10  6  6  6  6  6  6  6 10  6 10  6\n",
      "  7  6 10  6 10  6  6  6  7  6  6  6  6  8 10  6  6  7 10  6  1  6  6  7\n",
      "  7  6  6  6  6 10 10 10  6  7  6  6 10  7  6  6  6  6  6  6  6  7 10 10\n",
      "  6  6  6  6  6  1  6  6  8  6 10  6  6  6  6  6 10  6  6  6  6  6  6  7\n",
      " 10  7  6  6  8  7 10 10  6  7 10  6 10  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6 10  7  6  6 10  6  6  6  6  6 10\n",
      "  6  6  6  6  6 10 10  6  6 10  7  7  6  6 10  6  6  6  6  6  7 10  6  6\n",
      "  6  6  6  6  7  6  6  6  6  6 10  6 10  6 10  6  6  6  6  6  7  6  6  6\n",
      "  6  6  6 10 10  7  6  6 10  6  6  6 10  6 10  6  6  6 10  6  8  7  6 10\n",
      "  6  6  6  7  6  7  6  6  6  6  6  6  6  7  6  6  7  6 10  6  6  6 10  6\n",
      " 10  6  6  6  1  6  6  6  6  6  8  6  6  6 10  6  6  6 10 10  6 10  6  6\n",
      "  6  6  6  6  6 10  6  8 10 10  6  6  6  8  8  6  6 10  7  6  6  6  6  6\n",
      " 10  6  6  6  6  6  6  6  6  6  6  6 10  6  6  6  6  6  6  6  6  6 10 10\n",
      "  6  6  6  6  6  6  6  6  6  6  6  7  6  6  6  7  7  6  6  7  6  7  7 10\n",
      "  6 10  7  6  7  6  6  6  6  6  6  6  6 10  6 10  6  6  6  6  6  6  6 10\n",
      "  6  6  7  6  6  6  8  1 10  6  6  6 10 10  6  6  6  6  7  6]\n",
      "Metrics for CoreRec: {'jaccard': 0.0065179108385821005}\n",
      "Training GCN...\n",
      "Epoch 0, Loss: 6.214698791503906\n",
      "Epoch 1, Loss: 6.193216323852539\n",
      "Epoch 2, Loss: 6.170596599578857\n",
      "Epoch 3, Loss: 6.14614725112915\n",
      "Epoch 4, Loss: 6.119647979736328\n",
      "Epoch 5, Loss: 6.091001033782959\n",
      "Epoch 6, Loss: 6.060119152069092\n",
      "Epoch 7, Loss: 6.02690315246582\n",
      "Epoch 8, Loss: 5.991170883178711\n",
      "Epoch 9, Loss: 5.952672004699707\n",
      "Epoch 10, Loss: 5.911105632781982\n",
      "Epoch 11, Loss: 5.8661041259765625\n",
      "Epoch 12, Loss: 5.817272663116455\n",
      "Epoch 13, Loss: 5.764229774475098\n",
      "Epoch 14, Loss: 5.706586837768555\n",
      "Epoch 15, Loss: 5.643958568572998\n",
      "Epoch 16, Loss: 5.575948238372803\n",
      "Epoch 17, Loss: 5.502159595489502\n",
      "Epoch 18, Loss: 5.42219352722168\n",
      "Epoch 19, Loss: 5.335667610168457\n",
      "Epoch 20, Loss: 5.242249488830566\n",
      "Epoch 21, Loss: 5.141669273376465\n",
      "Epoch 22, Loss: 5.033719539642334\n",
      "Epoch 23, Loss: 4.918259143829346\n",
      "Epoch 24, Loss: 4.795225620269775\n",
      "Epoch 25, Loss: 4.664657115936279\n",
      "Epoch 26, Loss: 4.526708126068115\n",
      "Epoch 27, Loss: 4.381678104400635\n",
      "Epoch 28, Loss: 4.230053424835205\n",
      "Epoch 29, Loss: 4.072542667388916\n",
      "Epoch 30, Loss: 3.9101402759552\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# Start with 50 epochs\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 31\u001b[0m     out \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m returned None output\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[82], line 12\u001b[0m, in \u001b[0;36mGCN.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     10\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x, edge_index)\n\u001b[1;32m     11\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[0;32m---> 12\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x, edge_index)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlog_softmax(x, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch_geometric/nn/conv/gcn_conv.py:263\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    260\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x)\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[0;32m--> 263\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropagate(edge_index, x\u001b[38;5;241m=\u001b[39mx, edge_weight\u001b[38;5;241m=\u001b[39medge_weight)\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    266\u001b[0m     out \u001b[38;5;241m=\u001b[39m out \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\n",
      "File \u001b[0;32m/var/folders/yf/20z1hn994jd04q4kl0gpgh740000gn/T/torch_geometric.nn.conv.gcn_conv_GCNConv_propagate_nhuertqz.py:230\u001b[0m, in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, x, edge_weight, size)\u001b[0m\n\u001b[1;32m    221\u001b[0m             kwargs \u001b[38;5;241m=\u001b[39m CollectArgs(\n\u001b[1;32m    222\u001b[0m                 x_j\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mx_j,\n\u001b[1;32m    223\u001b[0m                 edge_weight\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39medge_weight,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    226\u001b[0m                 dim_size\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdim_size\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    227\u001b[0m             )\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# End Aggregate Forward Pre Hook #######################################\u001b[39;00m\n\u001b[0;32m--> 230\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregate(\n\u001b[1;32m    231\u001b[0m     out,\n\u001b[1;32m    232\u001b[0m     index\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mindex,\n\u001b[1;32m    233\u001b[0m     ptr\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mptr,\n\u001b[1;32m    234\u001b[0m     dim_size\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mdim_size,\n\u001b[1;32m    235\u001b[0m )\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# Begin Aggregate Forward Hook #########################################\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:625\u001b[0m, in \u001b[0;36mMessagePassing.aggregate\u001b[0;34m(self, inputs, index, ptr, dim_size)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maggregate\u001b[39m(\n\u001b[1;32m    609\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    610\u001b[0m     inputs: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    613\u001b[0m     dim_size: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    614\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    615\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Aggregates messages from neighbors as\u001b[39;00m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;124;03m    :math:`\\bigoplus_{j \\in \\mathcal{N}(i)}`.\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;124;03m    as specified in :meth:`__init__` by the :obj:`aggr` argument.\u001b[39;00m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 625\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggr_module(inputs, index, ptr\u001b[38;5;241m=\u001b[39mptr, dim_size\u001b[38;5;241m=\u001b[39mdim_size,\n\u001b[1;32m    626\u001b[0m                             dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch_geometric/experimental.py:117\u001b[0m, in \u001b[0;36mdisable_dynamic_shapes.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_experimental_mode_enabled(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisable_dynamic_shapes\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m required_arg \u001b[38;5;129;01min\u001b[39;00m required_args:\n\u001b[1;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m required_args_pos[required_arg]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch_geometric/nn/aggr/base.py:128\u001b[0m, in \u001b[0;36mAggregation.__call__\u001b[0;34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     dim_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(index\u001b[38;5;241m.\u001b[39mmax()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(x, index\u001b[38;5;241m=\u001b[39mindex, ptr\u001b[38;5;241m=\u001b[39mptr, dim_size\u001b[38;5;241m=\u001b[39mdim_size,\n\u001b[1;32m    129\u001b[0m                             dim\u001b[38;5;241m=\u001b[39mdim, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch_geometric/nn/aggr/basic.py:22\u001b[0m, in \u001b[0;36mSumAggregation.forward\u001b[0;34m(self, x, index, ptr, dim_size, dim)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor, index: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     20\u001b[0m             ptr: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, dim_size: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     21\u001b[0m             dim: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce(x, index, ptr, dim_size, dim, reduce\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch_geometric/nn/aggr/base.py:182\u001b[0m, in \u001b[0;36mAggregation.reduce\u001b[0;34m(self, x, index, ptr, dim_size, dim, reduce)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    181\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAggregation requires \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to be specified\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scatter(x, index, dim, dim_size, reduce)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:75\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     74\u001b[0m     index \u001b[38;5;241m=\u001b[39m broadcast(index, src, dim)\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m src\u001b[38;5;241m.\u001b[39mnew_zeros(size)\u001b[38;5;241m.\u001b[39mscatter_add_(dim, index, src)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     78\u001b[0m     count \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mnew_zeros(dim_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# List of models to benchmark\n",
    "models_to_benchmark = {\n",
    "    \"CoreRec\": MetaExploitModel(input_dim=adj_matrix.shape[1]),\n",
    "    \"GCN\": GCN(),\n",
    "    \"GraphSAGE\": GraphSAGE(),\n",
    "    \"TransE\": TransE(),\n",
    "    \"TransR\": TransR(),\n",
    "    \"DistMult\": DistMult(),\n",
    "    \"ComplEx\": ComplEx(),\n",
    "    \"HAN\": HAN(),\n",
    "    \"MetaPath2Vec\": MetaPath2Vec(),\n",
    "    \"GCF\": GCF(),\n",
    "    \"GRMF\": GRMF(),\n",
    "    \"GAT\": GAT(),\n",
    "    \"STAGE\": STAGE(),\n",
    "    \"SR-GNN\": SRGNN(),\n",
    "    \"DeepWalk\": DeepWalk(),\n",
    "    \"Node2Vec\": Node2Vec()\n",
    "}\n",
    "\n",
    "# Dictionary to store benchmark results\n",
    "benchmark_results = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models_to_benchmark.items():\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    model.train()\n",
    "    print(f\"Training {model_name}...\")\n",
    "    for epoch in range(50):  # Start with 50 epochs\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        if out is None:\n",
    "            print(f\"Model {model_name} returned None output\")\n",
    "            continue\n",
    "        if out.shape != (num_nodes, num_nodes):\n",
    "            print(f\"Unexpected output shape for {model_name}: {out.shape}\")\n",
    "            continue\n",
    "        loss = F.nll_loss(out[train_mask], data.y[train_mask])\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data)\n",
    "        val_loss = F.nll_loss(out[val_mask], data.y[val_mask])\n",
    "        print(f\"Validation Loss for {model_name}: {val_loss.item()}\")\n",
    "    \n",
    "    metrics = evaluate_model_ari_jaccard(model, data)\n",
    "    print(f\"Metrics for {model_name}: {metrics}\")\n",
    "    benchmark_results[model_name] = metrics\n",
    "# Convert results to DataFrame for easier plotting\n",
    "df = pd.DataFrame(benchmark_results).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(benchmark_results).T\n",
    "print(df.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
