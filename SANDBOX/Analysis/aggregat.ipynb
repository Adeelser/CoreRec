{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv, MetaPath2Vec, Node2Vec, HANConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, matthews_corrcoef, confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch_geometric.loader import DataLoader\n",
    "import signal\n",
    "import psutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append('/Users/visheshyadav/Documents/GitHub/CoreRec/engine')\n",
    "from core_rec import GraphTransformer, train_model, predict\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/visheshyadav/Documents/GitHub/CoreRec/engine/torch_nn')\n",
    "from torch_nn import *\n",
    "\n",
    "# # Load your data\n",
    "# labels_df = pd.read_csv('labelele.csv')\n",
    "# labels = labels_df['Names'].tolist()\n",
    "# label_to_index = {label: idx for idx, label in enumerate(labels)}\n",
    "\n",
    "# Load adjacency matrix\n",
    "adj_matrix = pd.read_csv('data_mother/500label.csv', header=None).values\n",
    "# adj_matrix=np.loadtxt('data_mother/wgtlabel.csv', delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create edge index for PyTorch Geometric\n",
    "edge_index = torch_geometric.utils.dense_to_sparse(torch.tensor(adj_matrix, dtype=torch.float))[0]\n",
    "\n",
    "# Create node features (for simplicity, using identity matrix)\n",
    "num_nodes = adj_matrix.shape[0]\n",
    "x = torch.eye(num_nodes, dtype=torch.float)\n",
    "\n",
    "# Create labels (for simplicity, using node indices as labels)\n",
    "y = torch.tensor(range(num_nodes), dtype=torch.long)\n",
    "\n",
    "# Create PyTorch Geometric data object\n",
    "data = Data(x=x, edge_index=edge_index, y=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define GCN model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_nodes, 16)\n",
    "        self.conv2 = GCNConv(16, num_nodes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(num_features, 16, heads=8, dropout=0.6)\n",
    "        self.conv2 = GATConv(16 * 8, num_classes, heads=1, concat=False, dropout=0.6)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Define GraphSAGE model\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(num_nodes, 16)\n",
    "        self.conv2 = SAGEConv(16, num_nodes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Define TransE model\n",
    "class TransE(torch.nn.Module):\n",
    "    def __init__(self, num_entities, num_relations, embedding_dim):\n",
    "        super(TransE, self).__init__()\n",
    "        self.entity_embedding = torch.nn.Embedding(num_entities, embedding_dim)\n",
    "        self.relation_embedding = torch.nn.Embedding(num_relations, embedding_dim)\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        torch.nn.init.xavier_uniform_(self.entity_embedding.weight.data)\n",
    "        torch.nn.init.xavier_uniform_(self.relation_embedding.weight.data)\n",
    "\n",
    "    def forward(self, head, relation, tail):\n",
    "        head_emb = self.entity_embedding(head)\n",
    "        relation_emb = self.relation_embedding(relation)\n",
    "        tail_emb = self.entity_embedding(tail)\n",
    "        score = torch.norm(head_emb + relation_emb - tail_emb, p=1, dim=1)\n",
    "        return score\n",
    "\n",
    "# Define TransR model\n",
    "class TransR(torch.nn.Module):\n",
    "    def __init__(self, num_entities, num_relations, embedding_dim):\n",
    "        super(TransR, self).__init__()\n",
    "        self.entity_embedding = torch.nn.Embedding(num_entities, embedding_dim)\n",
    "        self.relation_embedding = torch.nn.Embedding(num_relations, embedding_dim)\n",
    "        self.projection_matrix = torch.nn.Parameter(torch.Tensor(num_relations, embedding_dim, embedding_dim))\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        torch.nn.init.xavier_uniform_(self.entity_embedding.weight.data)\n",
    "        torch.nn.init.xavier_uniform_(self.relation_embedding.weight.data)\n",
    "        torch.nn.init.xavier_uniform_(self.projection_matrix.data)\n",
    "\n",
    "    def forward(self, head, relation, tail):\n",
    "        head_emb = self.entity_embedding(head)\n",
    "        relation_emb = self.relation_embedding(relation)\n",
    "        tail_emb = self.entity_embedding(tail)\n",
    "        proj_matrix = self.projection_matrix[relation]\n",
    "        head_proj = torch.bmm(proj_matrix, head_emb.unsqueeze(2)).squeeze(2)\n",
    "        tail_proj = torch.bmm(proj_matrix, tail_emb.unsqueeze(2)).squeeze(2)\n",
    "        score = torch.norm(head_proj + relation_emb - tail_proj, p=1, dim=1)\n",
    "        return score\n",
    "\n",
    "# Define DistMult model\n",
    "class DistMult(torch.nn.Module):\n",
    "    def __init__(self, num_entities, num_relations, embedding_dim):\n",
    "        super(DistMult, self).__init__()\n",
    "        self.entity_embedding = torch.nn.Embedding(num_entities, embedding_dim)\n",
    "        self.relation_embedding = torch.nn.Embedding(num_relations, embedding_dim)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        torch.nn.init.xavier_uniform_(self.entity_embedding.weight.data)\n",
    "        torch.nn.init.xavier_uniform_(self.relation_embedding.weight.data)\n",
    "\n",
    "    def forward(self, head, relation, tail):\n",
    "        head_emb = self.entity_embedding(head)\n",
    "        relation_emb = self.relation_embedding(relation)\n",
    "        tail_emb = self.entity_embedding(tail)\n",
    "        score = torch.sum(head_emb * relation_emb * tail_emb, dim=1)\n",
    "        return score\n",
    "\n",
    "# Define ComplEx model\n",
    "class ComplEx(torch.nn.Module):\n",
    "    def __init__(self, num_entities, num_relations, embedding_dim):\n",
    "        super(ComplEx, self).__init__()\n",
    "        self.entity_embedding = torch.nn.Embedding(num_entities, embedding_dim * 2)\n",
    "        self.relation_embedding = torch.nn.Embedding(num_relations, embedding_dim * 2)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        torch.nn.init.xavier_uniform_(self.entity_embedding.weight.data)\n",
    "        torch.nn.init.xavier_uniform_(self.relation_embedding.weight.data)\n",
    "\n",
    "    def forward(self, head, relation, tail):\n",
    "        head_emb = self.entity_embedding(head)\n",
    "        relation_emb = self.relation_embedding(relation)\n",
    "        tail_emb = self.entity_embedding(tail)\n",
    "        head_real, head_imag = torch.chunk(head_emb, 2, dim=1)\n",
    "        relation_real, relation_imag = torch.chunk(relation_emb, 2, dim=1)\n",
    "        tail_real, tail_imag = torch.chunk(tail_emb, 2, dim=1)\n",
    "        score = torch.sum(\n",
    "            head_real * relation_real * tail_real +\n",
    "            head_real * relation_imag * tail_imag +\n",
    "            head_imag * relation_real * tail_imag -\n",
    "            head_imag * relation_imag * tail_real, dim=1)\n",
    "        return score\n",
    "\n",
    "# Define HAN model\n",
    "class HAN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_meta_paths, metadata):\n",
    "        super(HAN, self).__init__()\n",
    "        self.conv1 = HANConv(in_channels, 16, num_meta_paths, metadata=metadata)\n",
    "        self.conv2 = HANConv(16, out_channels, num_meta_paths, metadata=metadata)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x = self.conv1(x_dict, edge_index_dict)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index_dict)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "# Define MetaPath2Vec model\n",
    "class MetaPath2VecModel(torch.nn.Module):\n",
    "    def __init__(self, edge_index, embedding_dim, walk_length, context_size, walks_per_node, num_nodes):\n",
    "        super(MetaPath2VecModel, self).__init__()\n",
    "        self.model = MetaPath2Vec(edge_index, embedding_dim, walk_length, context_size, walks_per_node, num_nodes)\n",
    "\n",
    "    def forward(self, pos_rw, neg_rw):\n",
    "        return self.model(pos_rw, neg_rw)\n",
    "\n",
    "# Define GCF model\n",
    "class GCF(torch.nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim):\n",
    "        super(GCF, self).__init__()\n",
    "        self.user_embedding = torch.nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = torch.nn.Embedding(num_items, embedding_dim)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        torch.nn.init.xavier_uniform_(self.user_embedding.weight.data)\n",
    "        torch.nn.init.xavier_uniform_(self.item_embedding.weight.data)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        user_emb = self.user_embedding(user)\n",
    "        item_emb = self.item_embedding(item)\n",
    "        score = torch.sum(user_emb * item_emb, dim=1)\n",
    "        return score\n",
    "\n",
    "# Define GRMF model\n",
    "class GRMF(torch.nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim):\n",
    "        super(GRMF, self).__init__()\n",
    "        self.user_embedding = torch.nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = torch.nn.Embedding(num_items, embedding_dim)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        torch.nn.init.xavier_uniform_(self.user_embedding.weight.data)\n",
    "        torch.nn.init.xavier_uniform_(self.item_embedding.weight.data)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        user_emb = self.user_embedding(user)\n",
    "        item_emb = self.item_embedding(item)\n",
    "        score = torch.sum(user_emb * item_emb, dim=1)\n",
    "        return score\n",
    "\n",
    "# Define STAGE model\n",
    "class STAGE(torch.nn.Module):\n",
    "    def __init__(self, num_nodes, embedding_dim):\n",
    "        super(STAGE, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, embedding_dim)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        torch.nn.init.xavier_uniform_(self.embedding.weight.data)\n",
    "\n",
    "    def forward(self, node, time):\n",
    "        node_emb = self.embedding(node)\n",
    "        time_emb = self.embedding(time)\n",
    "        score = torch.sum(node_emb * time_emb, dim=1)\n",
    "        return score\n",
    "\n",
    "# Define SRGNN model\n",
    "class SRGNN(torch.nn.Module):\n",
    "    def __init__(self, num_nodes, embedding_dim):\n",
    "        super(SRGNN, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, embedding_dim)\n",
    "        self.gnn = GNNConv(embedding_dim, embedding_dim)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        torch.nn.init.xavier_uniform_(self.embedding.weight.data)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.embedding(x)\n",
    "        x = self.gnn(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# Define Node2Vec model\n",
    "class Node2VecModel(torch.nn.Module):\n",
    "    def __init__(self, edge_index, embedding_dim, walk_length, context_size, walks_per_node, num_nodes):\n",
    "        super(Node2VecModel, self).__init__()\n",
    "        self.model = Node2Vec(edge_index, embedding_dim, walk_length, context_size, walks_per_node, num_nodes)\n",
    "\n",
    "    def forward(self, pos_rw, neg_rw):\n",
    "        return self.model(pos_rw, neg_rw)\n",
    "\n",
    "# Define MetaExploitModel\n",
    "class MetaExploitModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MetaExploitModel, self).__init__()\n",
    "        num_layers = 1\n",
    "        d_model = 128\n",
    "        num_heads = 2\n",
    "        d_feedforward = 512\n",
    "        self.model = GraphTransformer(num_layers, d_model, num_heads, d_feedforward, input_dim, use_weights=True)\n",
    "\n",
    "    def forward(self, data):\n",
    "        adj_matrix = data.x.numpy()  # Assuming data.x is the adjacency matrix\n",
    "        adj_matrix = torch.tensor(adj_matrix, dtype=torch.float32)\n",
    "        print(f\"adj_matrix shape: {adj_matrix.shape}\")\n",
    "        output = self.model(adj_matrix)\n",
    "        return output\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 16  # Reduce batch size to lower memory usage\n",
    "\n",
    "# Create DataLoader for mini-batch training\n",
    "data_list = [data]  # Assuming 'data' is a single Data object, wrap it in a list\n",
    "loader = DataLoader(data_list, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(model, data):\n",
    "    model.eval()\n",
    "    out = model(data)\n",
    "    pred = out.argmax(dim=1)\n",
    "    y_true = data.y.numpy()\n",
    "    y_pred = pred.numpy()\n",
    "    \n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    y_true_binarized = label_binarize(y_true, classes=np.arange(num_nodes))\n",
    "    y_pred_binarized = label_binarize(y_pred, classes=np.arange(num_nodes))\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_true_binarized, y_pred_binarized, multi_class='ovr')\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn = np.diag(cm)\n",
    "    fp = cm.sum(axis=0) - tn\n",
    "    fn = cm.sum(axis=1) - tn\n",
    "    tp = cm.sum() - (fp + fn + tn)\n",
    "    \n",
    "    # Debugging print statements\n",
    "    print(f\"Confusion Matrix:\\n{cm}\")\n",
    "    print(f\"True Negatives (TN): {tn}\")\n",
    "    print(f\"False Positives (FP): {fp}\")\n",
    "    \n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        specificity = np.mean(np.divide(tn, tn + fp, out=np.zeros_like(tn, dtype=float), where=(tn + fp) != 0))\n",
    "        sensitivity = np.mean(np.divide(tp, tp + fn, out=np.zeros_like(tp, dtype=float), where=(tp + fn) != 0))\n",
    "    \n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"specificity\": specificity,\n",
    "        \"sensitivity\": sensitivity,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"mcc\": mcc\n",
    "    }\n",
    "\n",
    "# # Define models to benchmark\n",
    "# models_to_benchmark = {\n",
    "#     \"GCN\": GCN(),\n",
    "#     \"GAT\": GAT(),\n",
    "#     \"GraphSAGE\": GraphSAGE(),\n",
    "#     \"TransE\": TransE(num_entities=num_nodes, num_relations=1, embedding_dim=16),\n",
    "#     \"TransR\": TransR(num_entities=num_nodes, num_relations=1, embedding_dim=16),\n",
    "#     # \"DistMult\": DistMult(num_entities=num_nodes, num_relations=1, embedding_dim=16),\n",
    "#     \"ComplEx\": ComplEx(num_entities=num_nodes, num_relations=1, embedding_dim=16),\n",
    "#     # \"HAN\": HAN(in_channels={'node_type': num_nodes}, out_channels=num_nodes, num_meta_paths=1, metadata=(['node_type'], ['edge_type'])),\n",
    "#     # \"MetaPath2Vec\": MetaPath2VecModel(edge_index=edge_index, embedding_dim=16, walk_length=5, context_size=3, walks_per_node=2, num_nodes=num_nodes),\n",
    "#     \"GCF\": GCF(num_users=num_nodes, num_items=num_nodes, embedding_dim=16),\n",
    "#     \"GRMF\": GRMF(num_users=num_nodes, num_items=num_nodes, embedding_dim=16),\n",
    "#     \"STAGE\": STAGE(num_nodes=num_nodes, embedding_dim=16),\n",
    "#     # \"SRGNN\": SRGNN(num_nodes=num_nodes, embedding_dim=16),\n",
    "#     # \"Node2Vec\": Node2VecModel(edge_index=edge_index, embedding_dim=16, walk_length=5, context_size=3, walks_per_node=2, num_nodes=num_nodes),\n",
    "#     \"CoreRec\": MetaExploitModel(input_dim=num_nodes)\n",
    "# }\n",
    "\n",
    "# # Dictionary to store benchmark results\n",
    "# benchmark_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_triplets(adj_matrix):\n",
    "    triplets = []\n",
    "    num_nodes = adj_matrix.shape[0]\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            if adj_matrix[i, j] > 0:\n",
    "                triplets.append((i, 0, j))  # Assuming a single relation type with index 0\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GCN...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 6.2146077156066895\n",
      "Epoch 1, Loss: 6.214608192443848\n",
      "Epoch 2, Loss: 6.214608192443848\n",
      "Epoch 3, Loss: 6.2146077156066895\n",
      "Epoch 4, Loss: 6.214608192443848\n",
      "Epoch 5, Loss: 6.2146077156066895\n",
      "Epoch 6, Loss: 6.214608192443848\n",
      "Epoch 7, Loss: 6.214607238769531\n",
      "Epoch 8, Loss: 6.2146077156066895\n",
      "Epoch 9, Loss: 6.2146077156066895\n",
      "Validation Loss for GCN: 6.214608192443848\n",
      "Model output for GCN:\n",
      "tensor([[-6.2144, -6.2144, -6.2143,  ..., -6.2143, -6.2146, -6.2148],\n",
      "        [-6.2144, -6.2144, -6.2143,  ..., -6.2143, -6.2146, -6.2148],\n",
      "        [-6.2144, -6.2144, -6.2143,  ..., -6.2143, -6.2146, -6.2148],\n",
      "        ...,\n",
      "        [-6.2144, -6.2144, -6.2143,  ..., -6.2143, -6.2146, -6.2148],\n",
      "        [-6.2144, -6.2144, -6.2143,  ..., -6.2143, -6.2146, -6.2148],\n",
      "        [-6.2144, -6.2144, -6.2143,  ..., -6.2143, -6.2146, -6.2148]])\n",
      "Predictions for GCN:\n",
      "tensor([485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
      "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
      "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
      "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
      "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
      "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
      "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
      "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
      "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
      "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
      "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
      "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
      "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
      "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
      "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
      "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
      "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
      "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
      "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
      "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
      "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
      "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
      "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
      "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
      "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
      "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
      "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
      "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
      "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
      "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
      "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
      "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
      "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
      "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
      "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
      "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/visheshyadav/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "True Negatives (TN): [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "False Positives (FP): [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 499\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "Metrics for GCN: {'precision': 4e-06, 'recall': 0.002, 'f1_score': 7.984031936127744e-06, 'accuracy': 0.002, 'specificity': 4e-06, 'sensitivity': 0.9960039999999999, 'roc_auc': 0.5, 'mcc': 0.0}\n",
      "Training GAT...\n",
      "Epoch 0, Loss: 6.2344651222229\n",
      "Epoch 1, Loss: 6.226944446563721\n",
      "Epoch 2, Loss: 6.222994327545166\n",
      "Epoch 3, Loss: 6.218853950500488\n",
      "Epoch 4, Loss: 6.216915607452393\n",
      "Epoch 5, Loss: 6.21679162979126\n",
      "Epoch 6, Loss: 6.215930938720703\n",
      "Epoch 7, Loss: 6.21523380279541\n",
      "Epoch 8, Loss: 6.214996814727783\n",
      "Epoch 9, Loss: 6.215158462524414\n",
      "Validation Loss for GAT: 6.215031147003174\n",
      "Model output for GAT:\n",
      "tensor([[-6.2026, -6.1977, -6.2442,  ..., -6.2318, -6.2453, -6.1835],\n",
      "        [-6.2026, -6.1977, -6.2442,  ..., -6.2318, -6.2453, -6.1835],\n",
      "        [-6.2026, -6.1977, -6.2442,  ..., -6.2318, -6.2453, -6.1835],\n",
      "        ...,\n",
      "        [-6.2026, -6.1977, -6.2442,  ..., -6.2318, -6.2454, -6.1835],\n",
      "        [-6.2026, -6.1977, -6.2442,  ..., -6.2318, -6.2454, -6.1835],\n",
      "        [-6.2026, -6.1977, -6.2442,  ..., -6.2318, -6.2454, -6.1835]])\n",
      "Predictions for GAT:\n",
      "tensor([346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346,\n",
      "        346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346,\n",
      "        346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346,\n",
      "        346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346,\n",
      "        346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346,\n",
      "        346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346,\n",
      "        346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346,\n",
      "        346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346,\n",
      "        346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346,\n",
      "        346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346,\n",
      "        346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346,\n",
      "        346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346,\n",
      "        346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346,\n",
      "        346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346,\n",
      "        346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346,\n",
      "        346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346,\n",
      "        346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346,\n",
      "        346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346,\n",
      "        346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346,\n",
      "        346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346,\n",
      "        346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346,\n",
      "        346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346,\n",
      "        346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346,\n",
      "        346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346,\n",
      "        346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346,\n",
      "        346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346,\n",
      "        346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346,\n",
      "        346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346,\n",
      "        346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346,\n",
      "        346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346,\n",
      "        346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346,\n",
      "        346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346,\n",
      "        346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346,\n",
      "        346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346,\n",
      "        346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346, 346,\n",
      "        346, 346, 346, 346, 346, 346, 346, 346, 346, 346])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/visheshyadav/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "True Negatives (TN): [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "False Positives (FP): [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0 499   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "Metrics for GAT: {'precision': 4e-06, 'recall': 0.002, 'f1_score': 7.984031936127744e-06, 'accuracy': 0.002, 'specificity': 4e-06, 'sensitivity': 0.9960039999999999, 'roc_auc': 0.5, 'mcc': 0.0}\n",
      "Training GraphSAGE...\n",
      "Epoch 0, Loss: 6.269606590270996\n",
      "Epoch 1, Loss: 6.240473747253418\n",
      "Epoch 2, Loss: 6.2122721672058105\n",
      "Epoch 3, Loss: 6.184936046600342\n",
      "Epoch 4, Loss: 6.158398628234863\n",
      "Epoch 5, Loss: 6.132745742797852\n",
      "Epoch 6, Loss: 6.107785224914551\n",
      "Epoch 7, Loss: 6.083280563354492\n",
      "Epoch 8, Loss: 6.059046745300293\n",
      "Epoch 9, Loss: 6.034964084625244\n",
      "Validation Loss for GraphSAGE: 6.010903835296631\n",
      "Model output for GraphSAGE:\n",
      "tensor([[-6.4624, -6.2713, -6.2128,  ..., -6.0755, -6.1680, -7.0231],\n",
      "        [-6.5717, -6.2158, -6.1562,  ..., -6.1386, -6.2636, -7.1722],\n",
      "        [-6.3806, -6.5293, -6.0126,  ..., -6.1773, -6.2596, -6.8631],\n",
      "        ...,\n",
      "        [-6.3959, -6.6865, -6.5314,  ..., -6.0741, -6.2269, -6.8042],\n",
      "        [-6.8372, -6.2683, -5.7330,  ..., -6.3330, -5.9257, -7.2039],\n",
      "        [-6.7299, -6.4541, -5.9598,  ..., -5.8814, -6.6028, -6.6471]])\n",
      "Predictions for GraphSAGE:\n",
      "tensor([255, 146, 212, 114, 111, 152, 111, 114, 152, 111,  21,  87, 255, 111,\n",
      "        267,  15,  21, 111, 152, 212, 135, 111, 212,  87,  87, 166, 111, 111,\n",
      "        114,  87,  87, 111, 111, 267, 304, 115, 111, 386, 255, 386,  87, 111,\n",
      "        111, 111, 255,  87,  87, 409, 212, 152, 255, 255, 152, 111,  87, 111,\n",
      "        152, 255,  57, 111, 111,  87,  87, 458, 111, 212, 152, 111, 111, 114,\n",
      "        212, 386, 111, 152, 152, 152, 255, 111, 111,  87, 111, 152,  87, 152,\n",
      "        111, 111,  87,  87,  57, 255, 115, 111, 111, 111, 111, 111, 183,  87,\n",
      "         87, 111, 111, 114, 166, 255, 114, 304, 255, 114, 111, 152,  87, 111,\n",
      "        250, 152,  87,  87, 111,  87, 211,  87, 152, 111, 255, 111, 318, 255,\n",
      "        152, 212, 212, 111, 287, 212, 111,  87, 255, 304, 212, 255, 304, 152,\n",
      "        111,  87, 111, 197, 114, 255, 111, 152, 111, 114, 114, 167, 183, 114,\n",
      "        377, 111,  87, 255, 152, 275,  87, 111, 212, 255, 111, 152, 111, 111,\n",
      "        152, 146, 152, 212, 111, 111, 152, 152, 111, 255, 111, 212, 111, 212,\n",
      "         87, 111, 111, 114, 237, 111, 188, 111, 152, 304, 152, 255, 152, 255,\n",
      "        152,  87, 111, 152, 367,  87, 111, 111, 212, 488, 212, 391, 212,  87,\n",
      "        212, 212, 212, 304, 152, 183, 111, 253, 111, 237, 212, 111,  87,  87,\n",
      "         87, 111, 318, 114, 111, 111, 355, 152, 152, 111,  87, 255, 212, 255,\n",
      "        111, 111, 255, 212, 111, 114, 111, 212, 114, 481, 255, 111, 152, 255,\n",
      "        255,  87, 166, 111,  23, 152, 111,  67,  87, 111, 212, 212,  87, 111,\n",
      "         87, 212, 446,  10, 275, 446,  23, 111, 152, 183, 255, 152,  67, 255,\n",
      "        400, 183, 111, 183, 212, 212, 152, 287, 114, 391,  87, 111, 111, 146,\n",
      "        212, 111, 152, 152, 255, 111,  67,  21,  87, 287, 117, 111,  57, 391,\n",
      "         23, 111, 391, 212, 111, 212,  21, 111, 152,  87, 183, 111,  87, 111,\n",
      "        146, 146, 111, 212, 212, 152, 152, 391,  87, 111, 355, 212,  87, 111,\n",
      "        367, 183, 111, 114, 212, 318, 111, 111, 114, 111, 111,  87, 111,  87,\n",
      "         87, 111, 212,  21, 386, 212, 255,  87, 114, 111, 212, 212, 212, 409,\n",
      "        111, 111, 114,  87,  87, 212, 304, 117, 255, 111,  54, 111, 237, 212,\n",
      "         87, 348, 111, 255, 111,  87,  87, 212,  15,   2, 111, 152, 152, 391,\n",
      "        391, 409, 111,  87,  21, 152, 237, 255, 391, 166, 255, 111, 111, 111,\n",
      "        255, 111,  87, 255, 478, 114, 197, 255, 391, 255, 166, 237,  87, 267,\n",
      "        237,  87, 212, 111, 212, 146, 114, 212, 111, 111, 117,  87, 114, 117,\n",
      "         87, 111, 212, 152, 111, 114, 391,  87, 212,  87, 111, 212, 111, 152,\n",
      "        152, 391, 259,  67, 152, 255, 212, 183, 183, 114, 111, 183,  87,  87,\n",
      "        152,  87, 212,  23, 114, 237, 152,  87,  87, 188, 391, 152, 111,  87,\n",
      "        114, 255, 255,  87, 111, 391, 114, 111, 146, 241, 255, 255, 152, 212,\n",
      "        114, 212, 212, 267, 255,  48, 152, 212, 287, 237])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/visheshyadav/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "True Negatives (TN): [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "False Positives (FP): [  0   0   1   0   0   0   0   0   0   0   1   0   0   0   0   1   0   0\n",
      "   0   0   0   6   0   4   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
      "   1   0   0   3   0   0   0   0   0   0   0   0   0   4   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  67   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0 123   0   0  29   2   0   4   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0\n",
      "   0   0   7   0   0   0   0   0  54   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   5   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0  11   0   0   0   0   1   0   0   0   0   0   0   0   0   2\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   1  55   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   8   0   0   0   1   0   0   0   0   0   0   0   0   1   0\n",
      "   0   1   0  45   0   0   0   1   0   0   0   0   0   0   0   4   0   0\n",
      "   0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   0   3\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   7   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   3   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   1   0   0   0   0   0   0   2   0   0   0   0\n",
      "   0   0   0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   1\n",
      "   0   0   0   0   0   0   0   0   4   0   0   0   0  12   0   0   0   0\n",
      "   0   0   0   0   1   0   0   0   0   0   0   0   0   3   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0\n",
      "   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   1   0   0   1   0   0   0   0\n",
      "   0   0   1   0   0   0   0   0   0   0   0   0   0   0]\n",
      "Metrics for GraphSAGE: {'precision': 0.0027351012365243866, 'recall': 0.014, 'f1_score': 0.003912527405470197, 'accuracy': 0.014, 'specificity': 0.0027351012365243866, 'sensitivity': 0.9980260418096204, 'roc_auc': 0.5060120240480962, 'mcc': 0.012793345410196388}\n",
      "Training MetaExploit...\n",
      "adj_matrix shape: torch.Size([500, 500])\n",
      "Epoch 0, Loss: 0.005234778393059969\n",
      "adj_matrix shape: torch.Size([500, 500])\n",
      "Epoch 1, Loss: -0.38718587160110474\n",
      "adj_matrix shape: torch.Size([500, 500])\n",
      "Epoch 2, Loss: -0.7634432911872864\n",
      "adj_matrix shape: torch.Size([500, 500])\n",
      "Epoch 3, Loss: -1.1313484907150269\n",
      "adj_matrix shape: torch.Size([500, 500])\n",
      "Epoch 4, Loss: -1.4951202869415283\n",
      "adj_matrix shape: torch.Size([500, 500])\n",
      "Epoch 5, Loss: -1.8458079099655151\n",
      "adj_matrix shape: torch.Size([500, 500])\n",
      "Epoch 6, Loss: -2.179076671600342\n",
      "adj_matrix shape: torch.Size([500, 500])\n",
      "Epoch 7, Loss: -2.5080432891845703\n",
      "adj_matrix shape: torch.Size([500, 500])\n",
      "Epoch 8, Loss: -2.8362035751342773\n",
      "adj_matrix shape: torch.Size([500, 500])\n",
      "Epoch 9, Loss: -3.1513967514038086\n",
      "adj_matrix shape: torch.Size([500, 500])\n",
      "Validation Loss for MetaExploit: -3.491065502166748\n",
      "Model output for MetaExploit:\n",
      "tensor([[ 2.8424,  1.5836,  0.5698,  ...,  0.9574, -0.4633, -0.4876],\n",
      "        [ 0.8607,  4.1000,  0.6702,  ...,  0.6668,  0.0246,  0.2803],\n",
      "        [ 1.4224,  0.2912,  2.3467,  ...,  1.1161, -0.1206,  0.6369],\n",
      "        ...,\n",
      "        [ 0.1237, -0.2403,  0.3853,  ...,  4.4328, -0.0551,  0.5793],\n",
      "        [-0.1659,  0.3365, -0.0400,  ...,  0.4659,  3.3286, -0.1146],\n",
      "        [ 0.5551,  0.2864,  1.6924,  ...,  0.5692, -0.4917,  2.5160]])\n",
      "Predictions for MetaExploit:\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499])\n",
      "adj_matrix shape: torch.Size([500, 500])\n",
      "Confusion Matrix:\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 1]]\n",
      "True Negatives (TN): [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "False Positives (FP): [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Metrics for MetaExploit: {'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'accuracy': 1.0, 'specificity': 1.0, 'sensitivity': 1.0, 'roc_auc': 1.0, 'mcc': 1.0}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "node_classification_models = {\n",
    "    \"GCN\": GCN(),\n",
    "    \"GAT\": GAT(num_features=num_nodes, num_classes=num_nodes),\n",
    "    \"GraphSAGE\": GraphSAGE(),\n",
    "    \"MetaExploit\": MetaExploitModel(input_dim=num_nodes)\n",
    "}\n",
    "\n",
    "knowledge_graph_models = {\n",
    "    # \"TransE\": TransE(num_entities=num_nodes, num_relations=1, embedding_dim=16),\n",
    "    # \"TransR\": TransR(num_entities=num_nodes, num_relations=1, embedding_dim=16),\n",
    "    # \"DistMult\": DistMult(num_entities=num_nodes, num_relations=1, embedding_dim=16),\n",
    "    # \"ComplEx\": ComplEx(num_entities=num_nodes, num_relations=1, embedding_dim=16)\n",
    "}\n",
    "\n",
    "# Dictionary to store benchmark results\n",
    "benchmark_results = {}\n",
    "# \n",
    "# Adjust learning rate and add weight decay for regularization\n",
    "\n",
    "# Ensure data normalization\n",
    "data.x = (data.x - data.x.mean()) / data.x.std()\n",
    "\n",
    "# Check for class imbalance and apply class weighting if necessary\n",
    "class_counts = np.bincount(data.y.numpy())\n",
    "class_weights = 1.0 / class_counts\n",
    "sample_weights = class_weights[data.y.numpy()]\n",
    "sampler = torch.utils.data.WeightedRandomSampler(sample_weights, len(sample_weights))\n",
    "\n",
    "# Create DataLoader with sampler\n",
    "loader = DataLoader(data_list, batch_size=batch_size, sampler=sampler)\n",
    "# \n",
    "\n",
    "\n",
    "# Train and evaluate node classification models\n",
    "for model_name, model in node_classification_models.items():\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)  # Adjusted learning rate\n",
    "    model.train()\n",
    "    print(f\"Training {model_name}...\")\n",
    "    for epoch in range(10):  # Start with 50 epochs\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        if out is None:\n",
    "            print(f\"Model {model_name} returned None output\")\n",
    "            continue\n",
    "        if out.shape != (num_nodes, num_nodes):\n",
    "            print(f\"Unexpected output shape for {model_name}: {out.shape}\")\n",
    "            continue\n",
    "        loss = F.nll_loss(out, data.y)  # Removed train_mask for simplicity\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data)\n",
    "        val_loss = F.nll_loss(out, data.y)  # Removed val_mask for simplicity\n",
    "        print(f\"Validation Loss for {model_name}: {val_loss.item()}\")\n",
    "    \n",
    "    # Debugging: Print model output and predictions\n",
    "    print(f\"Model output for {model_name}:\\n{out}\")\n",
    "    pred = out.argmax(dim=1)\n",
    "    print(f\"Predictions for {model_name}:\\n{pred}\")\n",
    "    \n",
    "    metrics = evaluate_model(model, data)\n",
    "    print(f\"Metrics for {model_name}: {metrics}\")\n",
    "    benchmark_results[model_name] = metrics\n",
    "\n",
    "# Generate triplets from the adjacency matrix\n",
    "def generate_triplets(adj_matrix):\n",
    "    triplets = []\n",
    "    num_nodes = adj_matrix.shape[0]\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            if adj_matrix[i, j] > 0:\n",
    "                triplets.append((i, 0, j))  # Assuming a single relation type with index 0\n",
    "    return triplets\n",
    "\n",
    "triplets = generate_triplets(adj_matrix)\n",
    "triplets = torch.tensor(triplets, dtype=torch.long)\n",
    "\n",
    "if(model_name==\"MetaExploit\"):\n",
    "    # Train and evaluate knowledge graph models\n",
    "    for model_name, model in knowledge_graph_models.items():\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)  # Adjusted learning rate\n",
    "        model.train()\n",
    "        print(f\"Training {model_name}...\")\n",
    "        for epoch in range(10):  # Start with 50 epochs\n",
    "            optimizer.zero_grad()\n",
    "            # Sample a batch of triplets\n",
    "            batch_indices = torch.randint(0, len(triplets), (batch_size,))\n",
    "            batch_triplets = triplets[batch_indices]\n",
    "            head, relation, tail = batch_triplets[:, 0], batch_triplets[:, 1], batch_triplets[:, 2]\n",
    "            score = model(head, relation, tail)\n",
    "            loss = F.margin_ranking_loss(score, torch.zeros_like(score), torch.ones_like(score))  # Use margin ranking loss\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            batch_indices = torch.randint(0, len(triplets), (batch_size,))\n",
    "            batch_triplets = triplets[batch_indices]\n",
    "            head, relation, tail = batch_triplets[:, 0], batch_triplets[:, 1], batch_triplets[:, 2]\n",
    "            score = model(head, relation, tail)\n",
    "            val_loss = F.margin_ranking_loss(score, torch.zeros_like(score), torch.ones_like(score))  # Use margin ranking loss\n",
    "            print(f\"Validation Loss for {model_name}: {val_loss.item()}\")\n",
    "        \n",
    "        # Debugging: Print model output and predictions\n",
    "        print(f\"Model output for {model_name}:\\n{score}\")\n",
    "        \n",
    "        # Simplified metrics for demonstration\n",
    "        metrics = {\n",
    "            \"precision\": 0.0,\n",
    "            \"recall\": 0.0,\n",
    "            \"f1_score\": 0.0,\n",
    "            \"accuracy\": 0.0,\n",
    "            \"specificity\": 0.0,\n",
    "            \"sensitivity\": 0.0,\n",
    "            \"roc_auc\": 0.0,\n",
    "            \"mcc\": 0.0\n",
    "        }\n",
    "        print(f\"Metrics for {model_name}: {metrics}\")\n",
    "        benchmark_results[model_name] = metrics\n",
    "elif(model_name==\"GAT\"):\n",
    "    # Assuming `dataset` and `data` are already defined and loaded\n",
    "    # num_features = dataset.num_features  # number of input features\n",
    "    # num_classes = dataset.num_classes    # number of classes to predict\n",
    "\n",
    "    model = GAT(adj_matrix, adj_matrix)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(200):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "else:\n",
    "    # Adjust learning rate and add weight decay for regularization\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=5e-4)\n",
    "\n",
    "    # Ensure data normalization\n",
    "    data.x = (data.x - data.x.mean()) / data.x.std()\n",
    "\n",
    "    # Check for class imbalance and apply class weighting if necessary\n",
    "    class_counts = np.bincount(data.y.numpy())\n",
    "    class_weights = 1.0 / class_counts\n",
    "    sample_weights = class_weights[data.y.numpy()]\n",
    "    sampler = torch.utils.data.WeightedRandomSampler(sample_weights, len(sample_weights))\n",
    "\n",
    "    # Create DataLoader with sampler\n",
    "    loader = DataLoader(data_list, batch_size=batch_size, sampler=sampler)\n",
    "\n",
    "    # Train and evaluate node classification models\n",
    "    for model_name, model in node_classification_models.items():\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)  # Adjusted learning rate and weight decay\n",
    "        model.train()\n",
    "        print(f\"Training {model_name}...\")\n",
    "        for epoch in range(50):  # Increase the number of epochs\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data)\n",
    "            if out is None:\n",
    "                print(f\"Model {model_name} returned None output\")\n",
    "                continue\n",
    "            if out.shape != (num_nodes, num_nodes):\n",
    "                print(f\"Unexpected output shape for {model_name}: {out.shape}\")\n",
    "                continue\n",
    "            loss = F.nll_loss(out, data.y)  # Removed train_mask for simplicity\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = model(data)\n",
    "            val_loss = F.nll_loss(out, data.y)  # Removed val_mask for simplicity\n",
    "            print(f\"Validation Loss for {model_name}: {val_loss.item()}\")\n",
    "        \n",
    "        # Debugging: Print model output and predictions\n",
    "        print(f\"Model output for {model_name}:\\n{out}\")\n",
    "        pred = out.argmax(dim=1)\n",
    "        print(f\"Predictions for {model_name}:\\n{pred}\")\n",
    "        \n",
    "        metrics = evaluate_model(model, data)\n",
    "        print(f\"Metrics for {model_name}: {metrics}\")\n",
    "        benchmark_results[model_name] = metrics\n",
    "\n",
    "\n",
    "# Convert results to DataFrame for easier plotting\n",
    "df = pd.DataFrame(benchmark_results).T\n",
    "\n",
    "# Plot the results with padding between models\n",
    "sns.set(style=\"whitegrid\")\n",
    "palette = sns.color_palette(\"Set2\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "x = np.arange(len(benchmark_results))\n",
    "width = 0.08  # Reduce the width of the bars to add padding\n",
    "\n",
    "metrics = df.columns\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax.bar(x + i*width, df[metric], width, label=metric, capsize=5, color=palette[i % len(palette)])\n",
    "\n",
    "ax.set_xlabel('Models', fontsize=14)\n",
    "ax.set_ylabel('Scores', fontsize=14)\n",
    "ax.set_title('Benchmark Results Comparison', fontsize=16, weight='bold')\n",
    "ax.set_xticks(x + width * (len(metrics) - 1) / 2)\n",
    "ax.set_xticklabels(benchmark_results.keys(), rotation=90, fontsize=12)\n",
    "ax.legend(fontsize=12, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "ax.yaxis.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
