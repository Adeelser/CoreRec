{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# frequency of Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load recommendations\n",
    "with open('json/recommendations_meta_exploit.json', 'r') as f:\n",
    "    recommendations_meta_exploit = json.load(f)\n",
    "\n",
    "with open('json/recommendations_transe.json', 'r') as f:\n",
    "    recommendations_transe = json.load(f)\n",
    "\n",
    "with open('json/recommendations_transr.json', 'r') as f:\n",
    "    recommendations_transr = json.load(f)\n",
    "\n",
    "# Aggregate recommendations\n",
    "all_labels = list(recommendations_meta_exploit.keys())\n",
    "aggregated_recommendations = {\n",
    "    'label': all_labels,\n",
    "    'meta_exploit': [recommendations_meta_exploit[label] for label in all_labels],\n",
    "    'transe': [recommendations_transe[label] for label in all_labels],\n",
    "    'transr': [recommendations_transr[label] for label in all_labels]\n",
    "}\n",
    "\n",
    "# Save aggregated recommendations to a file\n",
    "with open('aggregated_recommendations.json', 'w') as f:\n",
    "    json.dump(aggregated_recommendations, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load aggregated recommendations\n",
    "with open('aggregated_recommendations.json', 'r') as f:\n",
    "    aggregated_recommendations = json.load(f)\n",
    "\n",
    "labels = aggregated_recommendations['label']\n",
    "meta_exploit_recs = aggregated_recommendations['meta_exploit']\n",
    "transe_recs = aggregated_recommendations['transe']\n",
    "transr_recs = aggregated_recommendations['transr']\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Define the positions for the bars\n",
    "x = np.arange(len(labels))\n",
    "width = 0.25\n",
    "\n",
    "# Plot the bars\n",
    "rects1 = ax.bar(x - width, [len(recs) for recs in meta_exploit_recs], width, label='CoreRec_ch100')\n",
    "rects2 = ax.bar(x, [len(recs) for recs in transe_recs], width, label='TransE')\n",
    "rects3 = ax.bar(x + width, [len(recs) for recs in transr_recs], width, label='TransR')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "ax.set_xlabel('Labels')\n",
    "ax.set_ylabel('Number of Recommendations')\n",
    "ax.set_title('Number of Recommendations by Model')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels, rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "# Function to add labels on the bars\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User User Comparision Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "\n",
    "# Load the labels\n",
    "labels = pd.read_csv('labelele.csv')['Names'].tolist()\n",
    "labels = [label.strip() for label in labels]  # Strip whitespace from labels\n",
    "\n",
    "# Create a mapping from labels to indices\n",
    "label_to_index = {label: idx for idx, label in enumerate(labels)}\n",
    "\n",
    "# Load the models\n",
    "transr_model = torch.load('transr_model.pth')\n",
    "transe_model = torch.load('transe_model.pth')\n",
    "\n",
    "def get_top_recommendation(model, node, labels, label_to_index):\n",
    "    relation = 'connected_to'\n",
    "    possible_triples = np.array([[node, relation, target] for target in labels if target != node])\n",
    "    possible_triples_indices = np.array([[label_to_index[h], 0, label_to_index[t]] for h, r, t in possible_triples])\n",
    "    possible_triples_tensor = torch.tensor(possible_triples_indices, dtype=torch.long)\n",
    "    scores = model.predict_hrt(possible_triples_tensor)\n",
    "    scores_np = scores.detach().numpy()\n",
    "    top_index = np.argmax(scores_np)\n",
    "    top_triple = possible_triples_indices[top_index]\n",
    "    similar_node = labels[top_triple[2]]\n",
    "    return similar_node\n",
    "\n",
    "# Get recommendations for each node using both models\n",
    "recommendations = {'TransE': {}, 'TransR': {}}\n",
    "for node in labels:\n",
    "    recommendations['TransE'][node] = get_top_recommendation(transe_model, node, labels, label_to_index)\n",
    "    recommendations['TransR'][node] = get_top_recommendation(transr_model, node, labels, label_to_index)\n",
    "\n",
    "# Save recommendations to a file\n",
    "with open('recommendations_transe.json', 'w') as f:\n",
    "    json.dump(recommendations['TransE'], f)\n",
    "\n",
    "with open('recommendations_transr.json', 'w') as f:\n",
    "    json.dump(recommendations['TransR'], f)\n",
    "\n",
    "# Print recommendations for verification\n",
    "print(\"TransE Recommendations:\", recommendations['TransE'])\n",
    "print(\"TransR Recommendations:\", recommendations['TransR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load recommendations\n",
    "with open('json/recommendations_meta_exploit.json', 'r') as f:\n",
    "    recommendations_meta_exploit = json.load(f)\n",
    "\n",
    "with open('json/recommendations_transe.json', 'r') as f:\n",
    "    recommendations_transe = json.load(f)\n",
    "\n",
    "with open('json/recommendations_transr.json', 'r') as f:\n",
    "    recommendations_transr = json.load(f)\n",
    "\n",
    "# Aggregate recommendations\n",
    "all_labels = list(recommendations_meta_exploit.keys())\n",
    "aggregated_recommendations = {\n",
    "    'label': all_labels,\n",
    "    'meta_exploit': [recommendations_meta_exploit[label] for label in all_labels],\n",
    "    'transe': [recommendations_transe[label] for label in all_labels],\n",
    "    'transr': [recommendations_transr[label] for label in all_labels]\n",
    "}\n",
    "\n",
    "# Save aggregated recommendations to a file\n",
    "with open('json/aggregated_recommendations.json', 'w') as f:\n",
    "    json.dump(aggregated_recommendations, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load aggregated recommendations\n",
    "with open('json/aggregated_recommendations.json', 'r') as f:\n",
    "    aggregated_recommendations = json.load(f)\n",
    "\n",
    "labels = aggregated_recommendations['label']\n",
    "meta_exploit_recs = aggregated_recommendations['meta_exploit']\n",
    "transe_recs = aggregated_recommendations['transe']\n",
    "transr_recs = aggregated_recommendations['transr']\n",
    "\n",
    "# Create a graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes\n",
    "for label in labels:\n",
    "    G.add_node(label)\n",
    "\n",
    "# Add edges for Meta Exploit recommendations\n",
    "for i, label in enumerate(labels):\n",
    "    for rec in meta_exploit_recs[i]:\n",
    "        G.add_edge(label, rec, label='Meta Exploit')\n",
    "\n",
    "# Add edges for TransE recommendations\n",
    "for i, label in enumerate(labels):\n",
    "    for rec in transe_recs[i]:\n",
    "        G.add_edge(label, rec, label='TransE')\n",
    "\n",
    "# Add edges for TransR recommendations\n",
    "for i, label in enumerate(labels):\n",
    "    for rec in transr_recs[i]:\n",
    "        G.add_edge(label, rec, label='TransR')\n",
    "\n",
    "# Draw the graph\n",
    "pos = nx.spring_layout(G)\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "# Draw nodes\n",
    "nx.draw_networkx_nodes(G, pos, node_size=700)\n",
    "\n",
    "# Draw edges with different colors for each model\n",
    "edges_meta_exploit = [(u, v) for u, v, d in G.edges(data=True) if d['label'] == 'Meta Exploit']\n",
    "edges_transe = [(u, v) for u, v, d in G.edges(data=True) if d['label'] == 'TransE']\n",
    "edges_transr = [(u, v) for u, v, d in G.edges(data=True) if d['label'] == 'TransR']\n",
    "\n",
    "nx.draw_networkx_edges(G, pos, edgelist=edges_meta_exploit, edge_color='r', label='Meta Exploit')\n",
    "nx.draw_networkx_edges(G, pos, edgelist=edges_transe, edge_color='g', label='TransE')\n",
    "nx.draw_networkx_edges(G, pos, edgelist=edges_transr, edge_color='b', label='TransR')\n",
    "\n",
    "# Draw labels\n",
    "nx.draw_networkx_labels(G, pos, font_size=12)\n",
    "\n",
    "# Add legend\n",
    "plt.legend(['Meta Exploit', 'TransE', 'TransR'], loc='upper left')\n",
    "\n",
    "# Show the plot\n",
    "plt.title('User-User Graph for Recommendations')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load aggregated recommendations\n",
    "with open('aggregated_recommendations.json', 'r') as f:\n",
    "    aggregated_recommendations = json.load(f)\n",
    "\n",
    "labels = aggregated_recommendations['label']\n",
    "meta_exploit_recs = aggregated_recommendations['meta_exploit']\n",
    "transe_recs = aggregated_recommendations['transe']\n",
    "transr_recs = aggregated_recommendations['transr']\n",
    "\n",
    "# Count the number of recommendations each label received from each model\n",
    "meta_exploit_counts = [len(recs) for recs in meta_exploit_recs]\n",
    "transe_counts = [len(recs) for recs in transe_recs]\n",
    "transr_counts = [len(recs) for recs in transr_recs]\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Define the positions for the bars\n",
    "x = np.arange(len(labels))\n",
    "\n",
    "# Plot the stacked bars\n",
    "ax.bar(x, meta_exploit_counts, label='Meta Exploit', color='r')\n",
    "ax.bar(x, transe_counts, bottom=meta_exploit_counts, label='TransE', color='g')\n",
    "ax.bar(x, transr_counts, bottom=np.array(meta_exploit_counts) + np.array(transe_counts), label='TransR', color='b')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "ax.set_xlabel('Labels')\n",
    "ax.set_ylabel('Number of Recommendations')\n",
    "ax.set_title('Number of Recommendations by Model (Stacked)')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels, rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Example benchmark results (replace with actual data)\n",
    "benchmark_results = {\n",
    "    \"Meta Exploit\": {\"precision\": 0.85, \"recall\": 0.80, \"f1_score\": 0.82, \"accuracy\": 0.88, \"specificity\": 0.84, \"sensitivity\": 0.81},\n",
    "    \"TransE\": {\"precision\": 0.88, \"recall\": 0.83, \"f1_score\": 0.85, \"accuracy\": 0.90, \"specificity\": 0.86, \"sensitivity\": 0.84},\n",
    "    \"TransR\": {\"precision\": 0.87, \"recall\": 0.82, \"f1_score\": 0.84, \"accuracy\": 0.89, \"specificity\": 0.85, \"sensitivity\": 0.83}\n",
    "}\n",
    "\n",
    "# Extract metrics\n",
    "models = list(benchmark_results.keys())\n",
    "metrics = list(benchmark_results[models[0]].keys())\n",
    "data = {metric: [benchmark_results[model][metric] for model in models] for metric in metrics}\n",
    "\n",
    "# Create a DataFrame for easier plotting\n",
    "df = pd.DataFrame(data, index=models)\n",
    "\n",
    "# Set the style and color palette\n",
    "sns.set(style=\"whitegrid\")\n",
    "palette = sns.color_palette(\"Set2\")\n",
    "\n",
    "# Plot the bar chart\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "\n",
    "# Define the positions for the bars\n",
    "x = np.arange(len(models))\n",
    "width = 0.12  # Adjust width to fit more bars\n",
    "\n",
    "# Plot bars for each metric with error bars (assuming some hypothetical standard deviations)\n",
    "std_dev = {\n",
    "    \"precision\": [0.02, 0.01, 0.015],\n",
    "    \"recall\": [0.03, 0.02, 0.025],\n",
    "    \"f1_score\": [0.025, 0.015, 0.02],\n",
    "    \"accuracy\": [0.01, 0.01, 0.01],\n",
    "    \"specificity\": [0.02, 0.015, 0.02],\n",
    "    \"sensitivity\": [0.03, 0.025, 0.03]\n",
    "}\n",
    "\n",
    "rects1 = ax.bar(x - 2*width, df['precision'], width, yerr=std_dev['precision'], label='Precision', capsize=5, color=palette[0])\n",
    "rects2 = ax.bar(x - width, df['recall'], width, yerr=std_dev['recall'], label='Recall', capsize=5, color=palette[1])\n",
    "rects3 = ax.bar(x, df['f1_score'], width, yerr=std_dev['f1_score'], label='F1 Score', capsize=5, color=palette[2])\n",
    "rects4 = ax.bar(x + width, df['accuracy'], width, yerr=std_dev['accuracy'], label='Accuracy', capsize=5, color=palette[3])\n",
    "rects5 = ax.bar(x + 2*width, df['specificity'], width, yerr=std_dev['specificity'], label='Specificity', capsize=5, color=palette[4])\n",
    "rects6 = ax.bar(x + 3*width, df['sensitivity'], width, yerr=std_dev['sensitivity'], label='Sensitivity', capsize=5, color=palette[5])\n",
    "\n",
    "# Add labels, title, and legend\n",
    "ax.set_xlabel('Models', fontsize=14)\n",
    "ax.set_ylabel('Scores', fontsize=14)\n",
    "ax.set_title('Benchmark Results Comparison', fontsize=16, weight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models, fontsize=12)\n",
    "ax.legend(fontsize=12, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Add grid lines\n",
    "ax.yaxis.grid(True)\n",
    "\n",
    "# Function to add labels on the bars\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.2f}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=12, weight='bold')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "autolabel(rects4)\n",
    "autolabel(rects5)\n",
    "autolabel(rects6)\n",
    "\n",
    "# Adjust layout for better fit\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Example benchmark results (replace with actual data)\n",
    "benchmark_results = {\n",
    "    \"Meta Exploit\": {\"precision\": 0.85, \"recall\": 0.80, \"f1_score\": 0.82},\n",
    "    \"TransE\": {\"precision\": 0.88, \"recall\": 0.83, \"f1_score\": 0.85},\n",
    "    \"TransR\": {\"precision\": 0.87, \"recall\": 0.82, \"f1_score\": 0.84}\n",
    "}\n",
    "\n",
    "# Extract metrics\n",
    "models = list(benchmark_results.keys())\n",
    "metrics = list(benchmark_results[models[0]].keys())\n",
    "data = {metric: [benchmark_results[model][metric] for model in models] for metric in metrics}\n",
    "\n",
    "# Create a DataFrame for easier plotting\n",
    "df = pd.DataFrame(data, index=models)\n",
    "\n",
    "# Set the style and color palette\n",
    "sns.set(style=\"whitegrid\")\n",
    "palette = sns.color_palette(\"Set2\")\n",
    "\n",
    "# Plot the bar chart\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Define the positions for the bars\n",
    "x = np.arange(len(models))\n",
    "width = 0.2\n",
    "\n",
    "# Plot bars for each metric with error bars (assuming some hypothetical standard deviations)\n",
    "std_dev = {\n",
    "    \"precision\": [0.02, 0.01, 0.015],\n",
    "    \"recall\": [0.03, 0.02, 0.025],\n",
    "    \"f1_score\": [0.025, 0.015, 0.02]\n",
    "}\n",
    "\n",
    "rects1 = ax.bar(x - width, df['precision'], width, yerr=std_dev['precision'], label='Precision', capsize=5, color=palette[0])\n",
    "rects2 = ax.bar(x, df['recall'], width, yerr=std_dev['recall'], label='Recall', capsize=5, color=palette[1])\n",
    "rects3 = ax.bar(x + width, df['f1_score'], width, yerr=std_dev['f1_score'], label='F1 Score', capsize=5, color=palette[2])\n",
    "\n",
    "# Add labels, title, and legend\n",
    "ax.set_xlabel('Models', fontsize=14)\n",
    "ax.set_ylabel('Scores', fontsize=14)\n",
    "ax.set_title('Benchmark Results Comparison', fontsize=16, weight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models, fontsize=12)\n",
    "ax.legend(fontsize=12)\n",
    "\n",
    "# Add grid lines\n",
    "ax.yaxis.grid(True)\n",
    "\n",
    "# Function to add labels on the bars\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.2f}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=12, weight='bold')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Metric             | Meta Exploit | TransE | TransR |\n",
    "|--------------------|--------------|--------|--------|\n",
    "| Precision          | 0.85         | 0.88   | 0.87   |\n",
    "| Recall             | 0.80         | 0.83   | 0.82   |\n",
    "| F1 Score           | 0.82         | 0.85   | 0.84   |\n",
    "| Accuracy           | 0.88         | 0.90   | 0.89   |\n",
    "| Specificity        | 0.84         | 0.86   | 0.85   |\n",
    "| Sensitivity        | 0.81         | 0.84   | 0.83   |\n",
    "| ROC AUC            | 0.87         | 0.89   | 0.88   |\n",
    "| MCC                | 0.75         | 0.78   | 0.77   |\n",
    "| Balanced Accuracy  | 0.85         | 0.87   | 0.86   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load your data\n",
    "labels = pd.read_csv('labelele.csv')['Names'].tolist()\n",
    "labels = [label.strip() for label in labels]\n",
    "label_to_index = {label: idx for idx, label in enumerate(labels)}\n",
    "\n",
    "# Placeholder for model loading and training\n",
    "def load_and_train_model(model_name):\n",
    "    # Implement model loading and training here\n",
    "    pass\n",
    "\n",
    "# Placeholder for model evaluation\n",
    "def evaluate_model(model, labels, label_to_index):\n",
    "    # Implement model evaluation here\n",
    "    return {\n",
    "        \"precision\": np.random.rand(),\n",
    "        \"recall\": np.random.rand(),\n",
    "        \"f1_score\": np.random.rand(),\n",
    "        \"accuracy\": np.random.rand(),\n",
    "        \"specificity\": np.random.rand(),\n",
    "        \"sensitivity\": np.random.rand()\n",
    "    }\n",
    "\n",
    "# List of models to benchmark\n",
    "models_to_benchmark = [\n",
    "    \"GCN\", \"GAT\", \"GraphSAGE\", \"TransE\", \"TransR\", \"DistMult\", \"ComplEx\",\n",
    "    \"HAN\", \"MetaPath2Vec\", \"GCF\", \"GRMF\", \"STAGE\", \"SR-GNN\", \"DeepWalk\", \"Node2Vec\"\n",
    "]\n",
    "\n",
    "# Dictionary to store benchmark results\n",
    "benchmark_results = {}\n",
    "\n",
    "# Benchmark each model\n",
    "for model_name in models_to_benchmark:\n",
    "    model = load_and_train_model(model_name)\n",
    "    benchmark_results[model_name] = evaluate_model(model, labels, label_to_index)\n",
    "\n",
    "# Convert results to DataFrame for easier plotting\n",
    "df = pd.DataFrame(benchmark_results).T\n",
    "\n",
    "# Plot the results\n",
    "sns.set(style=\"whitegrid\")\n",
    "palette = sns.color_palette(\"Set2\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "x = np.arange(len(models_to_benchmark))\n",
    "width = 0.12\n",
    "\n",
    "metrics = df.columns\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax.bar(x + i*width, df[metric], width, label=metric, capsize=5, color=palette[i % len(palette)])\n",
    "\n",
    "ax.set_xlabel('Models', fontsize=14)\n",
    "ax.set_ylabel('Scores', fontsize=14)\n",
    "ax.set_title('Benchmark Results Comparison', fontsize=16, weight='bold')\n",
    "ax.set_xticks(x + width * (len(metrics) - 1) / 2)\n",
    "ax.set_xticklabels(models_to_benchmark, rotation=90, fontsize=12)\n",
    "ax.legend(fontsize=12, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "ax.yaxis.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Benching GCN, GAT, GraphSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load your data\n",
    "labels_df = pd.read_csv('labelele.csv')\n",
    "labels = labels_df['Names'].tolist()\n",
    "label_to_index = {label: idx for idx, label in enumerate(labels)}\n",
    "\n",
    "# Load adjacency matrix\n",
    "adj_matrix = pd.read_csv('label.csv', header=None).values\n",
    "\n",
    "# Create edge index for PyTorch Geometric\n",
    "edge_index = torch_geometric.utils.dense_to_sparse(torch.tensor(adj_matrix, dtype=torch.float))[0]\n",
    "\n",
    "# Create node features (for simplicity, using identity matrix)\n",
    "num_nodes = adj_matrix.shape[0]\n",
    "x = torch.eye(num_nodes, dtype=torch.float)\n",
    "\n",
    "# Create labels (for simplicity, using node indices as labels)\n",
    "y = torch.tensor(range(num_nodes), dtype=torch.long)\n",
    "\n",
    "# Create PyTorch Geometric data object\n",
    "data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "# Define GCN model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_nodes, 16)\n",
    "        self.conv2 = GCNConv(16, num_nodes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Define GAT model\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(num_nodes, 16, heads=8, dropout=0.6)\n",
    "        self.conv2 = GATConv(16 * 8, num_nodes, heads=1, concat=False, dropout=0.6)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Define GraphSAGE model\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(num_nodes, 16)\n",
    "        self.conv2 = SAGEConv(16, num_nodes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Placeholder for model evaluation\n",
    "def evaluate_model(model, data):\n",
    "    model.eval()\n",
    "    out = model(data)\n",
    "    pred = out.argmax(dim=1)\n",
    "    y_true = data.y.numpy()\n",
    "    y_pred = pred.numpy()\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"accuracy\": accuracy\n",
    "    }\n",
    "\n",
    "# List of models to benchmark\n",
    "models_to_benchmark = {\n",
    "    \"GCN\": GCN(),\n",
    "    \"GAT\": GAT(),\n",
    "    \"GraphSAGE\": GraphSAGE()\n",
    "    # Add other models here\n",
    "}\n",
    "\n",
    "# Dictionary to store benchmark results\n",
    "benchmark_results = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models_to_benchmark.items():\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    model.train()\n",
    "    for epoch in range(200):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    benchmark_results[model_name] = evaluate_model(model, data)\n",
    "\n",
    "# Convert results to DataFrame for easier plotting\n",
    "df = pd.DataFrame(benchmark_results).T\n",
    "\n",
    "# Plot the results\n",
    "sns.set(style=\"whitegrid\")\n",
    "palette = sns.color_palette(\"Set2\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "x = np.arange(len(models_to_benchmark))\n",
    "width = 0.12\n",
    "\n",
    "metrics = df.columns\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax.bar(x + i*width, df[metric], width, label=metric, capsize=5, color=palette[i % len(palette)])\n",
    "\n",
    "ax.set_xlabel('Models', fontsize=14)\n",
    "ax.set_ylabel('Scores', fontsize=14)\n",
    "ax.set_title('Benchmark Results Comparison', fontsize=16, weight='bold')\n",
    "ax.set_xticks(x + width * (len(metrics) - 1) / 2)\n",
    "ax.set_xticklabels(models_to_benchmark.keys(), rotation=90, fontsize=12)\n",
    "ax.legend(fontsize=12, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "ax.yaxis.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# benching family of state of the art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'SANDBOX/Analysis/data_mother/500label.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Load your data\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m labels_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSANDBOX/Analysis/data_mother/500label.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNames\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     15\u001b[0m label_to_index \u001b[38;5;241m=\u001b[39m {label: idx \u001b[38;5;28;01mfor\u001b[39;00m idx, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(labels)}\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'SANDBOX/Analysis/data_mother/500label.csv'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load your data\n",
    "labels_df = pd.read_csv('SANDBOX/Analysis/data_mother/500label.csv')\n",
    "labels = labels_df['Names'].tolist()\n",
    "label_to_index = {label: idx for idx, label in enumerate(labels)}\n",
    "\n",
    "# Load adjacency matrix\n",
    "adj_matrix = pd.read_csv('SANDBOX/Analysis/data_mother/wgtlabel.csv', header=None).values\n",
    "\n",
    "# Create edge index for PyTorch Geometric\n",
    "edge_index = torch_geometric.utils.dense_to_sparse(torch.tensor(adj_matrix, dtype=torch.float))[0]\n",
    "\n",
    "# Create node features (for simplicity, using identity matrix)\n",
    "num_nodes = adj_matrix.shape[0]\n",
    "x = torch.eye(num_nodes, dtype=torch.float)\n",
    "\n",
    "# Create labels (for simplicity, using node indices as labels)\n",
    "y = torch.tensor(range(num_nodes), dtype=torch.long)\n",
    "\n",
    "# Create PyTorch Geometric data object\n",
    "data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "# Define GCN model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_nodes, 16)\n",
    "        self.conv2 = GCNConv(16, num_nodes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Define GAT model\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(num_nodes, 16, heads=8, dropout=0.6)\n",
    "        self.conv2 = GATConv(16 * 8, num_nodes, heads=1, concat=False, dropout=0.6)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Define GraphSAGE model\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(num_nodes, 16)\n",
    "        self.conv2 = SAGEConv(16, num_nodes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Placeholder for other models\n",
    "class TransE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransE, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class TransR(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransR, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class DistMult(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DistMult, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class ComplEx(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ComplEx, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class HAN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HAN, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class MetaPath2Vec(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MetaPath2Vec, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class GCF(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCF, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class GRMF(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GRMF, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class STAGE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(STAGE, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class SRGNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SRGNN, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class DeepWalk(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepWalk, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class Node2Vec(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Node2Vec, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "# Placeholder for model evaluation\n",
    "def evaluate_model(model, data):\n",
    "    model.eval()\n",
    "    out = model(data)\n",
    "    pred = out.argmax(dim=1)\n",
    "    y_true = data.y.numpy()\n",
    "    y_pred = pred.numpy()\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"accuracy\": accuracy\n",
    "    }\n",
    "\n",
    "# List of models to benchmark\n",
    "models_to_benchmark = {\n",
    "    \"GCN\": GCN(),\n",
    "    \"GAT\": GAT(),\n",
    "    \"GraphSAGE\": GraphSAGE(),\n",
    "    \"TransE\": TransE(),\n",
    "    \"TransR\": TransR(),\n",
    "    \"DistMult\": DistMult(),\n",
    "    \"ComplEx\": ComplEx(),\n",
    "    \"HAN\": HAN(),\n",
    "    \"MetaPath2Vec\": MetaPath2Vec(),\n",
    "    \"GCF\": GCF(),\n",
    "    \"GRMF\": GRMF(),\n",
    "    \"STAGE\": STAGE(),\n",
    "    \"SR-GNN\": SRGNN(),\n",
    "    \"DeepWalk\": DeepWalk(),\n",
    "    \"Node2Vec\": Node2Vec()\n",
    "}\n",
    "\n",
    "# Dictionary to store benchmark results\n",
    "benchmark_results = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models_to_benchmark.items():\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    model.train()\n",
    "    for epoch in range(200):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    benchmark_results[model_name] = evaluate_model(model, data)\n",
    "\n",
    "# Convert results to DataFrame for easier plotting\n",
    "df = pd.DataFrame(benchmark_results).T\n",
    "\n",
    "# Plot the results\n",
    "sns.set(style=\"whitegrid\")\n",
    "palette = sns.color_palette(\"Set2\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "x = np.arange(len(models_to_benchmark))\n",
    "width = 0.12\n",
    "\n",
    "metrics = df.columns\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax.bar(x + i*width, df[metric], width, label=metric, capsize=5, color=palette[i % len(palette)])\n",
    "\n",
    "ax.set_xlabel('Models', fontsize=14)\n",
    "ax.set_ylabel('Scores', fontsize=14)\n",
    "ax.set_title('Benchmark Results Comparison', fontsize=16, weight='bold')\n",
    "ax.set_xticks(x + width * (len(metrics) - 1) / 2)\n",
    "ax.set_xticklabels(models_to_benchmark.keys(), rotation=90, fontsize=12)\n",
    "ax.legend(fontsize=12, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "ax.yaxis.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "# This will suppress warnings for the current cell\n",
    "%config Application.verbose_crash=True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Benchmarking** above models with CoreRec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CoreRec...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_mask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 298\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected output shape for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 298\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnll_loss(out[train_mask], data\u001b[38;5;241m.\u001b[39my[train_mask])\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    300\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_mask' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, matthews_corrcoef, confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/visheshyadav/Documents/GitHub/CoreRec/engine')\n",
    "from core_rec import GraphTransformer, train_model, predict\n",
    "\n",
    "# Load your data\n",
    "labels_df = pd.read_csv('labelele.csv')\n",
    "labels = labels_df['Names'].tolist()\n",
    "label_to_index = {label: idx for idx, label in enumerate(labels)}\n",
    "\n",
    "# Load adjacency matrix\n",
    "adj_matrix = pd.read_csv('label.csv', header=None).values\n",
    "# adj_matrix=np.loadtxt('SANDBOX/Analysis/data_mother/large_network.csv', delimiter=',', skiprows=1)\n",
    "\n",
    "# Create edge index for PyTorch Geometric\n",
    "edge_index = torch_geometric.utils.dense_to_sparse(torch.tensor(adj_matrix, dtype=torch.float))[0]\n",
    "\n",
    "# Create node features (for simplicity, using identity matrix)\n",
    "num_nodes = adj_matrix.shape[0]\n",
    "x = torch.eye(num_nodes, dtype=torch.float)\n",
    "\n",
    "# Create labels (for simplicity, using node indices as labels)\n",
    "y = torch.tensor(range(num_nodes), dtype=torch.long)\n",
    "\n",
    "# Create PyTorch Geometric data object\n",
    "data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "# Define GCN model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_nodes, 16)\n",
    "        self.conv2 = GCNConv(16, num_nodes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Define GAT model\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(num_nodes, 16, heads=8, dropout=0.6)\n",
    "        self.conv2 = GATConv(16 * 8, num_nodes, heads=1, concat=False, dropout=0.6)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Define GraphSAGE model\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(num_nodes, 16)\n",
    "        self.conv2 = SAGEConv(16, num_nodes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Placeholder for other models\n",
    "class TransE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransE, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class TransR(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransR, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class DistMult(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DistMult, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class ComplEx(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ComplEx, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class HAN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HAN, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class MetaPath2Vec(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MetaPath2Vec, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class GCF(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCF, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class GRMF(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GRMF, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class STAGE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(STAGE, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class SRGNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SRGNN, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class DeepWalk(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepWalk, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class Node2Vec(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Node2Vec, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class MetaExploitModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MetaExploitModel, self).__init__()\n",
    "        num_layers = 1\n",
    "        d_model = 128\n",
    "        num_heads = 2\n",
    "        d_feedforward = 512\n",
    "        self.model = GraphTransformer(num_layers, d_model, num_heads, d_feedforward, input_dim, use_weights=True)\n",
    "\n",
    "    def forward(self, data):\n",
    "        adj_matrix = data.x.numpy()  # Assuming data.x is the adjacency matrix\n",
    "        output = self.model(torch.tensor(adj_matrix, dtype=torch.float32))\n",
    "        return output\n",
    "\n",
    "# Placeholder for model evaluation\n",
    "def evaluate_model(model, data):\n",
    "    model.eval()\n",
    "    out = model(data)\n",
    "    pred = out.argmax(dim=1)\n",
    "    y_true = data.y.numpy()\n",
    "    y_pred = pred.numpy()\n",
    "    \n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    y_true_binarized = label_binarize(y_true, classes=np.arange(num_nodes))\n",
    "    y_pred_binarized = label_binarize(y_pred, classes=np.arange(num_nodes))\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_true_binarized, y_pred_binarized, multi_class='ovr')\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn = np.diag(cm)\n",
    "    fp = cm.sum(axis=0) - tn\n",
    "    fn = cm.sum(axis=1) - tn\n",
    "    tp = cm.sum() - (fp + fn + tn)\n",
    "    \n",
    "    # Debugging print statements\n",
    "    print(f\"Confusion Matrix:\\n{cm}\")\n",
    "    print(f\"True Negatives (TN): {tn}\")\n",
    "    print(f\"False Positives (FP): {fp}\")\n",
    "    \n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        specificity = np.mean(np.divide(tn, tn + fp, out=np.zeros_like(tn, dtype=float), where=(tn + fp) != 0))\n",
    "        sensitivity = np.mean(np.divide(tp, tp + fn, out=np.zeros_like(tp, dtype=float), where=(tp + fn) != 0))\n",
    "    \n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"specificity\": specificity,\n",
    "        \"sensitivity\": sensitivity,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"mcc\": mcc\n",
    "    }\n",
    "\n",
    "# List of models to benchmark\n",
    "models_to_benchmark = {\n",
    "    \"CoreRec\": MetaExploitModel(input_dim=adj_matrix.shape[1]) ,\n",
    "    \"GCN\": GCN(),\n",
    "    \"GraphSAGE\": GraphSAGE(),\n",
    "    \"TransE\": TransE(),\n",
    "    \"TransR\": TransR(),\n",
    "    \"DistMult\": DistMult(),\n",
    "    \"ComplEx\": ComplEx(),\n",
    "    \"HAN\": HAN(),\n",
    "    \"MetaPath2Vec\": MetaPath2Vec(),\n",
    "    \"GCF\": GCF(),\n",
    "    \"GRMF\": GRMF(),\n",
    "    \"GAT\": GAT(),\n",
    "    \"STAGE\": STAGE(),\n",
    "    \"SR-GNN\": SRGNN(),\n",
    "    \"DeepWalk\": DeepWalk(),\n",
    "    \"Node2Vec\": Node2Vec()\n",
    "}\n",
    "\n",
    "# Dictionary to store benchmark results\n",
    "benchmark_results = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models_to_benchmark.items():\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    model.train()\n",
    "    print(f\"Training {model_name}...\")\n",
    "    for epoch in range(100):  # Start with 50 epochs\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        if out is None:\n",
    "            print(f\"Model {model_name} returned None output\")\n",
    "            continue\n",
    "        if out.shape != (num_nodes, num_nodes):\n",
    "            print(f\"Unexpected output shape for {model_name}: {out.shape}\")\n",
    "            continue\n",
    "        loss = F.nll_loss(out[train_mask], data.y[train_mask])\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data)\n",
    "        val_loss = F.nll_loss(out[val_mask], data.y[val_mask])\n",
    "        print(f\"Validation Loss for {model_name}: {val_loss.item()}\")\n",
    "    \n",
    "    metrics = evaluate_model(model, data)\n",
    "    print(f\"Metrics for {model_name}: {metrics}\")\n",
    "    benchmark_results[model_name] = metrics\n",
    "\n",
    "# Convert results to DataFrame for easier plotting\n",
    "df = pd.DataFrame(benchmark_results).T\n",
    "\n",
    "# Plot the results with padding between models\n",
    "sns.set(style=\"whitegrid\")\n",
    "palette = sns.color_palette(\"Set2\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "x = np.arange(len(models_to_benchmark))\n",
    "width = 0.08  # Reduce the width of the bars to add padding\n",
    "\n",
    "metrics = df.columns\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax.bar(x + i*width, df[metric], width, label=metric, capsize=5, color=palette[i % len(palette)])\n",
    "\n",
    "ax.set_xlabel('Models', fontsize=14)\n",
    "ax.set_ylabel('Scores', fontsize=14)\n",
    "ax.set_title('Benchmark Results Comparison', fontsize=16, weight='bold')\n",
    "ax.set_xticks(x + width * (len(metrics) - 1) / 2)\n",
    "ax.set_xticklabels(models_to_benchmark.keys(), rotation=90, fontsize=12)\n",
    "ax.legend(fontsize=12, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "ax.yaxis.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "for metric in metrics:\n",
    "    ax.plot(models_to_benchmark.keys(), df[metric], marker='o', label=metric)\n",
    "ax.set_xlabel('Models', fontsize=14)\n",
    "ax.set_ylabel('Scores', fontsize=14)\n",
    "ax.set_title('Benchmark Results Comparison', fontsize=16, weight='bold')\n",
    "ax.legend(fontsize=12, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "ax.yaxis.grid(True)\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "for metric in metrics:\n",
    "    ax.scatter(models_to_benchmark.keys(), df[metric], label=metric)\n",
    "ax.set_xlabel('Models', fontsize=14)\n",
    "ax.set_ylabel('Scores', fontsize=14)\n",
    "ax.set_title('Benchmark Results Comparison', fontsize=16, weight='bold')\n",
    "ax.legend(fontsize=12, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "ax.yaxis.grid(True)\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "sns.violinplot(data=df, ax=ax)\n",
    "ax.set_xlabel('Metrics', fontsize=14)\n",
    "ax.set_ylabel('Scores', fontsize=14)\n",
    "ax.set_title('Benchmark Results Comparison', fontsize=16, weight='bold')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.imshow(df, text_auto=True, aspect=\"auto\", color_continuous_scale='viridis')\n",
    "fig.update_layout(\n",
    "    title='Benchmark Results Comparison',\n",
    "    xaxis_title='Metrics',\n",
    "    yaxis_title='Models',\n",
    "    font=dict(size=11)\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame containing the benchmark results\n",
    "df = pd.DataFrame(benchmark_results).T\n",
    "\n",
    "# Convert DataFrame to markdown table\n",
    "markdown_table = df.to_markdown()\n",
    "\n",
    "# Print the markdown table\n",
    "print(markdown_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Benchmarking** above models with 500node dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CoreRec...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_mask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 297\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected output shape for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 297\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnll_loss(out[train_mask], data\u001b[38;5;241m.\u001b[39my[train_mask])\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    299\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_mask' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, matthews_corrcoef, confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/visheshyadav/Documents/GitHub/CoreRec/engine')\n",
    "from core_rec import GraphTransformer, train_model, predict\n",
    "\n",
    "# Load your data\n",
    "labels_df = pd.read_csv('data_mother/name500label.csv')\n",
    "labels = labels_df['Names'].tolist()\n",
    "label_to_index = {label: idx for idx, label in enumerate(labels)}\n",
    "\n",
    "# Load adjacency matrix\n",
    "adj_matrix = pd.read_csv('data_mother/500label.csv', header=None).values\n",
    "\n",
    "# Create edge index for PyTorch Geometric\n",
    "edge_index = torch_geometric.utils.dense_to_sparse(torch.tensor(adj_matrix, dtype=torch.float))[0]\n",
    "\n",
    "# Create node features (for simplicity, using identity matrix)\n",
    "num_nodes = adj_matrix.shape[0]\n",
    "x = torch.eye(num_nodes, dtype=torch.float)\n",
    "\n",
    "# Create labels (for simplicity, using node indices as labels)\n",
    "y = torch.tensor(range(num_nodes), dtype=torch.long)\n",
    "\n",
    "# Create PyTorch Geometric data object\n",
    "data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "# Define GCN model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_nodes, 16)\n",
    "        self.conv2 = GCNConv(16, num_nodes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Define GAT model\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(num_nodes, 16, heads=8, dropout=0.6)\n",
    "        self.conv2 = GATConv(16 * 8, num_nodes, heads=1, concat=False, dropout=0.6)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Define GraphSAGE model\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(num_nodes, 16)\n",
    "        self.conv2 = SAGEConv(16, num_nodes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Placeholder for other models\n",
    "class TransE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransE, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class TransR(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransR, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class DistMult(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DistMult, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class ComplEx(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ComplEx, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class HAN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HAN, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class MetaPath2Vec(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MetaPath2Vec, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class GCF(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCF, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class GRMF(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GRMF, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class STAGE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(STAGE, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class SRGNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SRGNN, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class DeepWalk(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepWalk, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class Node2Vec(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Node2Vec, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class MetaExploitModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MetaExploitModel, self).__init__()\n",
    "        num_layers = 1\n",
    "        d_model = 128\n",
    "        num_heads = 2\n",
    "        d_feedforward = 512\n",
    "        self.model = GraphTransformer(num_layers, d_model, num_heads, d_feedforward, input_dim, use_weights=True)\n",
    "\n",
    "    def forward(self, data):\n",
    "        adj_matrix = data.x.numpy()  # Assuming data.x is the adjacency matrix\n",
    "        output = self.model(torch.tensor(adj_matrix, dtype=torch.float32))\n",
    "        return output\n",
    "\n",
    "# Placeholder for model evaluation\n",
    "def evaluate_model(model, data):\n",
    "    model.eval()\n",
    "    out = model(data)\n",
    "    pred = out.argmax(dim=1)\n",
    "    y_true = data.y.numpy()\n",
    "    y_pred = pred.numpy()\n",
    "    \n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    y_true_binarized = label_binarize(y_true, classes=np.arange(num_nodes))\n",
    "    y_pred_binarized = label_binarize(y_pred, classes=np.arange(num_nodes))\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_true_binarized, y_pred_binarized, multi_class='ovr')\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn = np.diag(cm)\n",
    "    fp = cm.sum(axis=0) - tn\n",
    "    fn = cm.sum(axis=1) - tn\n",
    "    tp = cm.sum() - (fp + fn + tn)\n",
    "    \n",
    "    # Debugging print statements\n",
    "    print(f\"Confusion Matrix:\\n{cm}\")\n",
    "    print(f\"True Negatives (TN): {tn}\")\n",
    "    print(f\"False Positives (FP): {fp}\")\n",
    "    \n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        specificity = np.mean(np.divide(tn, tn + fp, out=np.zeros_like(tn, dtype=float), where=(tn + fp) != 0))\n",
    "        sensitivity = np.mean(np.divide(tp, tp + fn, out=np.zeros_like(tp, dtype=float), where=(tp + fn) != 0))\n",
    "    \n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"specificity\": specificity,\n",
    "        \"sensitivity\": sensitivity,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"mcc\": mcc\n",
    "    }\n",
    "\n",
    "# List of models to benchmark\n",
    "models_to_benchmark = {\n",
    "    \"CoreRec\": MetaExploitModel(input_dim=adj_matrix.shape[1]) ,\n",
    "    \"GCN\": GCN(),\n",
    "    \"GraphSAGE\": GraphSAGE(),\n",
    "    \"TransE\": TransE(),\n",
    "    \"TransR\": TransR(),\n",
    "    \"DistMult\": DistMult(),\n",
    "    \"ComplEx\": ComplEx(),\n",
    "    \"HAN\": HAN(),\n",
    "    \"MetaPath2Vec\": MetaPath2Vec(),\n",
    "    \"GCF\": GCF(),\n",
    "    \"GRMF\": GRMF(),\n",
    "    \"GAT\": GAT(),\n",
    "    \"STAGE\": STAGE(),\n",
    "    \"SR-GNN\": SRGNN(),\n",
    "    \"DeepWalk\": DeepWalk(),\n",
    "    \"Node2Vec\": Node2Vec()\n",
    "}\n",
    "\n",
    "# Dictionary to store benchmark results\n",
    "benchmark_results = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models_to_benchmark.items():\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    model.train()\n",
    "    print(f\"Training {model_name}...\")\n",
    "    for epoch in range(100):  # Start with 50 epochs\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        if out is None:\n",
    "            print(f\"Model {model_name} returned None output\")\n",
    "            continue\n",
    "        if out.shape != (num_nodes, num_nodes):\n",
    "            print(f\"Unexpected output shape for {model_name}: {out.shape}\")\n",
    "            continue\n",
    "        loss = F.nll_loss(out[train_mask], data.y[train_mask])\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data)\n",
    "        val_loss = F.nll_loss(out[val_mask], data.y[val_mask])\n",
    "        print(f\"Validation Loss for {model_name}: {val_loss.item()}\")\n",
    "    \n",
    "    metrics = evaluate_model(model, data)\n",
    "    print(f\"Metrics for {model_name}: {metrics}\")\n",
    "    benchmark_results[model_name] = metrics\n",
    "\n",
    "# Convert results to DataFrame for easier plotting\n",
    "df = pd.DataFrame(benchmark_results).T\n",
    "\n",
    "# Plot the results with padding between models\n",
    "sns.set(style=\"whitegrid\")\n",
    "palette = sns.color_palette(\"Set2\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "x = np.arange(len(models_to_benchmark))\n",
    "width = 0.08  # Reduce the width of the bars to add padding\n",
    "\n",
    "metrics = df.columns\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax.bar(x + i*width, df[metric], width, label=metric, capsize=5, color=palette[i % len(palette)])\n",
    "\n",
    "ax.set_xlabel('Models', fontsize=14)\n",
    "ax.set_ylabel('Scores', fontsize=14)\n",
    "ax.set_title('Benchmark Results Comparison', fontsize=16, weight='bold')\n",
    "ax.set_xticks(x + width * (len(metrics) - 1) / 2)\n",
    "ax.set_xticklabels(models_to_benchmark.keys(), rotation=90, fontsize=12)\n",
    "ax.legend(fontsize=12, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "ax.yaxis.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "for metric in metrics:\n",
    "    ax.plot(models_to_benchmark.keys(), df[metric], marker='o', label=metric)\n",
    "ax.set_xlabel('Models', fontsize=14)\n",
    "ax.set_ylabel('Scores', fontsize=14)\n",
    "ax.set_title('Benchmark Results Comparison', fontsize=16, weight='bold')\n",
    "ax.legend(fontsize=12, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "ax.yaxis.grid(True)\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame containing the benchmark results\n",
    "df = pd.DataFrame(benchmark_results).T\n",
    "\n",
    "# Convert DataFrame to markdown table\n",
    "markdown_table = df.to_markdown()\n",
    "\n",
    "# Print the markdown table\n",
    "print(markdown_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark Adam&eric scr & JaccardIndex scr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import adjusted_rand_score, jaccard_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/visheshyadav/Documents/GitHub/CoreRec/engine')\n",
    "from core_rec import GraphTransformer, train_model, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define GCN model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_nodes, 16)\n",
    "        self.conv2 = GCNConv(16, num_nodes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Define GAT model\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(num_nodes, 16, heads=8, dropout=0.6)\n",
    "        self.conv2 = GATConv(16 * 8, num_nodes, heads=1, concat=False, dropout=0.6)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Define GraphSAGE model\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(num_nodes, 16)\n",
    "        self.conv2 = SAGEConv(16, num_nodes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Placeholder for other models\n",
    "class TransE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransE, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class TransR(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransR, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class DistMult(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DistMult, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class ComplEx(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ComplEx, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class HAN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HAN, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class MetaPath2Vec(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MetaPath2Vec, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class GCF(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCF, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class GRMF(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GRMF, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class STAGE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(STAGE, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class SRGNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SRGNN, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class DeepWalk(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepWalk, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class Node2Vec(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Node2Vec, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class MetaExploitModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MetaExploitModel, self).__init__()\n",
    "        num_layers = 1\n",
    "        d_model = 128\n",
    "        num_heads = 2\n",
    "        d_feedforward = 512\n",
    "        self.model = GraphTransformer(num_layers, d_model, num_heads, d_feedforward, input_dim, use_weights=True)\n",
    "\n",
    "    def forward(self, data):\n",
    "        adj_matrix = data.x.numpy()  # Assuming data.x is the adjacency matrix\n",
    "        output = self.model(torch.tensor(adj_matrix, dtype=torch.float32))\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for jaccard index //adam nd eric not working\n",
    "def evaluate_model_ari_jaccard(model, data):\n",
    "    model.eval()\n",
    "    out = model(data)\n",
    "    pred = out.argmax(dim=1)\n",
    "    y_true = data.y.numpy()\n",
    "    y_pred = pred.numpy()\n",
    "    \n",
    "    print(f\"True Labels: {y_true}\")\n",
    "    print(f\"Predicted Labels: {y_pred}\")\n",
    "    \n",
    "    jaccard = jaccard_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    return {\n",
    "        \"jaccard\": jaccard\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Donot run below cell in CPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of models to benchmark\n",
    "models_to_benchmark = {\n",
    "    \"CoreRec\": MetaExploitModel(input_dim=adj_matrix.shape[1]),\n",
    "    \"GCN\": GCN(),\n",
    "    \"GraphSAGE\": GraphSAGE(),\n",
    "    \"TransE\": TransE(),\n",
    "    \"TransR\": TransR(),\n",
    "    \"DistMult\": DistMult(),\n",
    "    \"ComplEx\": ComplEx(),\n",
    "    \"HAN\": HAN(),\n",
    "    \"MetaPath2Vec\": MetaPath2Vec(),\n",
    "    \"GCF\": GCF(),\n",
    "    \"GRMF\": GRMF(),\n",
    "    \"GAT\": GAT(),\n",
    "    \"STAGE\": STAGE(),\n",
    "    \"SR-GNN\": SRGNN(),\n",
    "    \"DeepWalk\": DeepWalk(),\n",
    "    \"Node2Vec\": Node2Vec()\n",
    "}\n",
    "\n",
    "# Dictionary to store benchmark results\n",
    "benchmark_results = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models_to_benchmark.items():\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    model.train()\n",
    "    print(f\"Training {model_name}...\")\n",
    "    for epoch in range(50):  # Start with 50 epochs\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        if out is None:\n",
    "            print(f\"Model {model_name} returned None output\")\n",
    "            continue\n",
    "        if out.shape != (num_nodes, num_nodes):\n",
    "            print(f\"Unexpected output shape for {model_name}: {out.shape}\")\n",
    "            continue\n",
    "        loss = F.nll_loss(out[train_mask], data.y[train_mask])\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data)\n",
    "        val_loss = F.nll_loss(out[val_mask], data.y[val_mask])\n",
    "        print(f\"Validation Loss for {model_name}: {val_loss.item()}\")\n",
    "    \n",
    "    metrics = evaluate_model_ari_jaccard(model, data)\n",
    "    print(f\"Metrics for {model_name}: {metrics}\")\n",
    "    benchmark_results[model_name] = metrics\n",
    "# Convert results to DataFrame for easier plotting\n",
    "df = pd.DataFrame(benchmark_results).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(benchmark_results).T\n",
    "print(df.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
