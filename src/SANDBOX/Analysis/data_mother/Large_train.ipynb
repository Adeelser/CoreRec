{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, matthews_corrcoef, confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/visheshyadav/Documents/GitHub/CoreRec/engine')\n",
    "from core_rec import GraphTransformer, train_model, predict\n",
    "\n",
    "\n",
    "\n",
    "# Load adjacency matrix\n",
    "# adj_matrix = pd.read_csv('label.csv', header=None).values\n",
    "adj_matrix=np.loadtxt('large_network.csv', delimiter=',', skiprows=1)\n",
    "\n",
    "# Create node features with a smaller dimension\n",
    "num_nodes = adj_matrix.shape[0]\n",
    "feature_dim = 16  # Define a smaller feature dimension\n",
    "x = torch.randn((num_nodes, feature_dim), dtype=torch.float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adj_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ... existing code ...\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Create node features with a smaller dimension\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m num_nodes \u001b[38;5;241m=\u001b[39m adj_matrix\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m feature_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m  \u001b[38;5;66;03m# Define a smaller feature dimension\u001b[39;00m\n\u001b[1;32m      6\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn((num_nodes, feature_dim), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'adj_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "# ... existing code ...\n",
    "\n",
    "# Create node features with a smaller dimension\n",
    "num_nodes = adj_matrix.shape[0]\n",
    "feature_dim = 16  # Define a smaller feature dimension\n",
    "x = torch.randn((num_nodes, feature_dim), dtype=torch.float)\n",
    "\n",
    "# ... existing code ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:125] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 90000000000000000 bytes. Error code 12 (Cannot allocate memory)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Create node features (for simplicity, using identity matrix)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m num_nodes \u001b[38;5;241m=\u001b[39m adj_matrix\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meye(num_nodes, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Create labels (for simplicity, using node indices as labels)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mrange\u001b[39m(num_nodes), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:125] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 90000000000000000 bytes. Error code 12 (Cannot allocate memory)"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create edge index for PyTorch Geometric\n",
    "edge_index = torch_geometric.utils.dense_to_sparse(torch.tensor(adj_matrix, dtype=torch.float))[0]\n",
    "\n",
    "# Create node features (for simplicity, using identity matrix)\n",
    "num_nodes = adj_matrix.shape[0]\n",
    "x = torch.eye(num_nodes, dtype=torch.float)\n",
    "\n",
    "# Create labels (for simplicity, using node indices as labels)\n",
    "y = torch.tensor(range(num_nodes), dtype=torch.long)\n",
    "\n",
    "# Create PyTorch Geometric data object\n",
    "data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "# Define GCN model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_nodes, 16)\n",
    "        self.conv2 = GCNConv(16, num_nodes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Define GAT model\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(num_nodes, 16, heads=8, dropout=0.6)\n",
    "        self.conv2 = GATConv(16 * 8, num_nodes, heads=1, concat=False, dropout=0.6)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Define GraphSAGE model\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(num_nodes, 16)\n",
    "        self.conv2 = SAGEConv(16, num_nodes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Placeholder for other models\n",
    "class TransE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransE, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class TransR(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransR, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class DistMult(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DistMult, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class ComplEx(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ComplEx, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class HAN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HAN, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class MetaPath2Vec(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MetaPath2Vec, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class GCF(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCF, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class GRMF(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GRMF, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class STAGE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(STAGE, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class SRGNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SRGNN, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class DeepWalk(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepWalk, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class Node2Vec(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Node2Vec, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, 16)\n",
    "        self.linear = torch.nn.Linear(16, num_nodes)  # Add a linear layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.x.argmax(dim=1))\n",
    "        return self.linear(x)\n",
    "\n",
    "class MetaExploitModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MetaExploitModel, self).__init__()\n",
    "        num_layers = 1\n",
    "        d_model = 128\n",
    "        num_heads = 2\n",
    "        d_feedforward = 512\n",
    "        self.model = GraphTransformer(num_layers, d_model, num_heads, d_feedforward, input_dim, use_weights=True)\n",
    "\n",
    "    def forward(self, data):\n",
    "        adj_matrix = data.x.numpy()  # Assuming data.x is the adjacency matrix\n",
    "        output = self.model(torch.tensor(adj_matrix, dtype=torch.float32))\n",
    "        return output\n",
    "\n",
    "# Placeholder for model evaluation\n",
    "def evaluate_model(model, data):\n",
    "    model.eval()\n",
    "    out = model(data)\n",
    "    pred = out.argmax(dim=1)\n",
    "    y_true = data.y.numpy()\n",
    "    y_pred = pred.numpy()\n",
    "    \n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    y_true_binarized = label_binarize(y_true, classes=np.arange(num_nodes))\n",
    "    y_pred_binarized = label_binarize(y_pred, classes=np.arange(num_nodes))\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_true_binarized, y_pred_binarized, multi_class='ovr')\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn = np.diag(cm)\n",
    "    fp = cm.sum(axis=0) - tn\n",
    "    fn = cm.sum(axis=1) - tn\n",
    "    tp = cm.sum() - (fp + fn + tn)\n",
    "    \n",
    "    # Debugging print statements\n",
    "    print(f\"Confusion Matrix:\\n{cm}\")\n",
    "    print(f\"True Negatives (TN): {tn}\")\n",
    "    print(f\"False Positives (FP): {fp}\")\n",
    "    \n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        specificity = np.mean(np.divide(tn, tn + fp, out=np.zeros_like(tn, dtype=float), where=(tn + fp) != 0))\n",
    "        sensitivity = np.mean(np.divide(tp, tp + fn, out=np.zeros_like(tp, dtype=float), where=(tp + fn) != 0))\n",
    "    \n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"specificity\": specificity,\n",
    "        \"sensitivity\": sensitivity,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"mcc\": mcc\n",
    "    }\n",
    "\n",
    "# List of models to benchmark\n",
    "models_to_benchmark = {\n",
    "    \"CoreRec\": MetaExploitModel(input_dim=adj_matrix.shape[1]) ,\n",
    "    \"GCN\": GCN(),\n",
    "    \"GraphSAGE\": GraphSAGE(),\n",
    "    \"TransE\": TransE(),\n",
    "    \"TransR\": TransR(),\n",
    "    \"DistMult\": DistMult(),\n",
    "    \"ComplEx\": ComplEx(),\n",
    "    \"HAN\": HAN(),\n",
    "    \"MetaPath2Vec\": MetaPath2Vec(),\n",
    "    \"GCF\": GCF(),\n",
    "    \"GRMF\": GRMF(),\n",
    "    \"GAT\": GAT(),\n",
    "    \"STAGE\": STAGE(),\n",
    "    \"SR-GNN\": SRGNN(),\n",
    "    \"DeepWalk\": DeepWalk(),\n",
    "    \"Node2Vec\": Node2Vec()\n",
    "}\n",
    "\n",
    "# Dictionary to store benchmark results\n",
    "benchmark_results = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models_to_benchmark.items():\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    model.train()\n",
    "    print(f\"Training {model_name}...\")\n",
    "    for epoch in range(100):  # Start with 50 epochs\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        if out is None:\n",
    "            print(f\"Model {model_name} returned None output\")\n",
    "            continue\n",
    "        if out.shape != (num_nodes, num_nodes):\n",
    "            print(f\"Unexpected output shape for {model_name}: {out.shape}\")\n",
    "            continue\n",
    "        loss = F.nll_loss(out[train_mask], data.y[train_mask])\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data)\n",
    "        val_loss = F.nll_loss(out[val_mask], data.y[val_mask])\n",
    "        print(f\"Validation Loss for {model_name}: {val_loss.item()}\")\n",
    "    \n",
    "    metrics = evaluate_model(model, data)\n",
    "    print(f\"Metrics for {model_name}: {metrics}\")\n",
    "    benchmark_results[model_name] = metrics\n",
    "\n",
    "# Convert results to DataFrame for easier plotting\n",
    "df = pd.DataFrame(benchmark_results).T\n",
    "\n",
    "# Plot the results with padding between models\n",
    "sns.set(style=\"whitegrid\")\n",
    "palette = sns.color_palette(\"Set2\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "x = np.arange(len(models_to_benchmark))\n",
    "width = 0.08  # Reduce the width of the bars to add padding\n",
    "\n",
    "metrics = df.columns\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax.bar(x + i*width, df[metric], width, label=metric, capsize=5, color=palette[i % len(palette)])\n",
    "\n",
    "ax.set_xlabel('Models', fontsize=14)\n",
    "ax.set_ylabel('Scores', fontsize=14)\n",
    "ax.set_title('Benchmark Results Comparison', fontsize=16, weight='bold')\n",
    "ax.set_xticks(x + width * (len(metrics) - 1) / 2)\n",
    "ax.set_xticklabels(models_to_benchmark.keys(), rotation=90, fontsize=12)\n",
    "ax.legend(fontsize=12, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "ax.yaxis.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 92) (1236328013.py, line 92)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 92\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"Cell \\u001b[0;32mIn[4], line 6\\u001b[0m\\n\\u001b[1;32m      4\\u001b[0m \\u001b[38;5;66;03m# Create node features (for simplicity, using identity matrix)\\u001b[39;00m\\n\\u001b[1;32m      5\\u001b[0m num_nodes \\u001b[38;5;241m=\\u001b[39m adj_matrix\\u001b[38;5;241m.\\u001b[39mshape[\\u001b[38;5;241m0\\u001b[39m]\\n\\u001b[0;32m----> 6\\u001b[0m x \\u001b[38;5;241m=\\u001b[39m torch\\u001b[38;5;241m.\\u001b[39meye(num_nodes, dtype\\u001b[38;5;241m=\\u001b[\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 92)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
