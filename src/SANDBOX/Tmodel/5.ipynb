{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pickle\n",
    "from scipy.sparse import csr_matrix\n",
    "import operator\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd try graphsage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Number of users: 21716\n",
      "Number of items: 3101\n",
      "Total interactions: 195444\n"
     ]
    }
   ],
   "source": [
    "# Graph sage : Training completed. Best HR: 0.6124, Best NDCG: 0.3914\n",
    "\n",
    "\n",
    "class GraphSAGERecommender(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim, hidden_dim, num_layers=2, dropout=0.2):\n",
    "        super(GraphSAGERecommender, self).__init__()\n",
    "        \n",
    "        # Increase embedding dimensions\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "        \n",
    "        # Add batch normalization\n",
    "        self.bn_user = nn.BatchNorm1d(embedding_dim)\n",
    "        self.bn_item = nn.BatchNorm1d(embedding_dim)\n",
    "        \n",
    "        # Deeper MLP with residual connections\n",
    "        self.layers = nn.ModuleList()\n",
    "        input_dim = embedding_dim * 2\n",
    "        \n",
    "        for i in range(num_layers):\n",
    "            self.layers.append(nn.Sequential(\n",
    "                nn.Linear(input_dim if i == 0 else hidden_dim, hidden_dim),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout)\n",
    "            ))\n",
    "        \n",
    "        # Prediction layers\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(hidden_dim + embedding_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            \n",
    "    def forward(self, user_ids, item_ids):\n",
    "        # Get and normalize embeddings\n",
    "        user_emb = self.bn_user(self.user_embedding(user_ids))\n",
    "        item_emb = self.bn_item(self.item_embedding(item_ids))\n",
    "        \n",
    "        # Initial concatenation\n",
    "        x = torch.cat([user_emb, item_emb], dim=1)\n",
    "        \n",
    "        # Store original input for residual connection\n",
    "        original_input = x\n",
    "        \n",
    "        # Pass through MLP layers with residual connections\n",
    "        for layer in self.layers:\n",
    "            x = layer(x) + x if x.size() == layer(x).size() else layer(x)\n",
    "        \n",
    "        # Concatenate with original embeddings for final prediction\n",
    "        x = torch.cat([x, original_input], dim=1)\n",
    "        return self.predictor(x).squeeze()\n",
    "\n",
    "\n",
    "class BeibeiDataset(Dataset):\n",
    "    def __init__(self, file_path, num_negative=8):  # Increased negative samples\n",
    "        self.data = pd.read_csv(file_path, sep=' ', header=None, names=['user_id', 'item_id', 'label'], skiprows=1)\n",
    "        \n",
    "        # Create mappings\n",
    "        self.user_map = {id_: idx for idx, id_ in enumerate(self.data['user_id'].unique())}\n",
    "        self.item_map = {id_: idx for idx, id_ in enumerate(self.data['item_id'].unique())}\n",
    "        \n",
    "        # Map IDs\n",
    "        self.data['user_id'] = self.data['user_id'].map(self.user_map)\n",
    "        self.data['item_id'] = self.data['item_id'].map(self.item_map)\n",
    "        \n",
    "        self.num_users = len(self.user_map)\n",
    "        self.num_items = len(self.item_map)\n",
    "        self.num_negative = num_negative\n",
    "        \n",
    "        # Create user-items dictionary\n",
    "        self.user_items = self.create_user_items_dict()\n",
    "        \n",
    "        # Add negative samples with improved sampling strategy\n",
    "        self.data = self.add_negative_samples()\n",
    "        \n",
    "    def create_user_items_dict(self):\n",
    "        return {user_id: set(self.data[self.data['user_id'] == user_id]['item_id']) \n",
    "                for user_id in range(self.num_users)}\n",
    "        \n",
    "    def add_negative_samples(self):\n",
    "        negative_samples = []\n",
    "        all_items = set(range(self.num_items))\n",
    "        \n",
    "        # Calculate item popularity\n",
    "        item_counts = self.data['item_id'].value_counts()\n",
    "        item_probs = 1 / (item_counts + 1)  # Add 1 to avoid division by zero\n",
    "        item_probs = item_probs / item_probs.sum()\n",
    "        \n",
    "        for user_id in self.user_items:\n",
    "            pos_items = self.user_items[user_id]\n",
    "            neg_items = list(all_items - pos_items)\n",
    "            \n",
    "            if len(neg_items) > 0:\n",
    "                # Calculate sampling probabilities for negative items\n",
    "                neg_probs = item_probs[neg_items]\n",
    "                neg_probs = neg_probs / neg_probs.sum()\n",
    "                \n",
    "                # Sample negative items based on popularity\n",
    "                num_neg = min(len(neg_items), self.num_negative)\n",
    "                sampled_neg = np.random.choice(\n",
    "                    neg_items, \n",
    "                    size=num_neg, \n",
    "                    replace=False,\n",
    "                    p=neg_probs\n",
    "                )\n",
    "                \n",
    "                for item_id in sampled_neg:\n",
    "                    negative_samples.append([user_id, item_id, 0])\n",
    "        \n",
    "        neg_df = pd.DataFrame(negative_samples, columns=['user_id', 'item_id', 'label'])\n",
    "        return pd.concat([self.data, neg_df], ignore_index=True).sample(frac=1)\n",
    "\n",
    "\n",
    "# First, initialize the dataset\n",
    "print(\"Loading dataset...\")\n",
    "file_path = '/Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei.txt'\n",
    "dataset = BeibeiDataset(file_path)\n",
    "\n",
    "# Print dataset statistics\n",
    "print(f\"Number of users: {dataset.num_users}\")\n",
    "print(f\"Number of items: {dataset.num_items}\")\n",
    "print(f\"Total interactions: {len(dataset.data)}\")\n",
    "\n",
    "# Training configuration\n",
    "config = {\n",
    "    'embedding_dim': 128,\n",
    "    'hidden_dim': 256,\n",
    "    'num_layers': 3,\n",
    "    'dropout': 0.3,\n",
    "    'batch_size': 1,\n",
    "    'learning_rate': 0.001,\n",
    "    'weight_decay': 1e-4,\n",
    "    'num_epochs': 30\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = GraphSAGERecommender(\n",
    "    num_users=dataset.num_users,\n",
    "    num_items=dataset.num_items,\n",
    "    embedding_dim=config['embedding_dim'],\n",
    "    hidden_dim=config['hidden_dim'],\n",
    "    num_layers=config['num_layers'],\n",
    "    dropout=config['dropout']\n",
    ").to(device)\n",
    "\n",
    "# Optimizer and scheduler setup\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=config['learning_rate'],\n",
    "    weight_decay=config['weight_decay']\n",
    ")\n",
    "\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=config['num_epochs'],\n",
    "    eta_min=1e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, k=10):\n",
    "    \"\"\"\n",
    "    Evaluate the model using HR@k and NDCG@k\n",
    "    \"\"\"\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for user_ids, item_ids, labels in test_loader:\n",
    "            user_ids = user_ids.to(device)\n",
    "            item_ids = item_ids.to(device)\n",
    "            \n",
    "            # Get positive items (where label == 1)\n",
    "            positive_mask = labels == 1\n",
    "            test_users = user_ids[positive_mask]\n",
    "            test_items = item_ids[positive_mask]\n",
    "            \n",
    "            for user_id, true_item in zip(test_users, test_items):\n",
    "                # Generate 99 negative items + 1 positive item\n",
    "                neg_items = torch.tensor([i for i in range(dataset.num_items) if i != true_item])\n",
    "                neg_items = neg_items[torch.randperm(len(neg_items))[:99]]\n",
    "                eval_items = torch.cat([neg_items, true_item.unsqueeze(0)])\n",
    "                \n",
    "                # Create user tensor of same length as eval_items\n",
    "                user_tensor = user_id.repeat(100).to(device)\n",
    "                item_tensor = eval_items.to(device)\n",
    "                \n",
    "                # Get predictions\n",
    "                predictions = model(user_tensor, item_tensor)\n",
    "                \n",
    "                # Get ranking of the true item\n",
    "                _, indices = torch.sort(predictions, descending=True)\n",
    "                rank = (indices == 99).nonzero().item()  # 99 is the index of true_item\n",
    "                \n",
    "                # Calculate HR@k and NDCG@k\n",
    "                hits.append(1 if rank < k else 0)\n",
    "                ndcgs.append(1 / np.log2(rank + 2) if rank < k else 0)\n",
    "    \n",
    "    return np.mean(hits), np.mean(ndcgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.0229\n",
      "HR@10: 0.1531 (Best: 0.0000)\n",
      "NDCG@10: 0.0762 (Best: 0.0000)\n",
      "Epoch 2, Loss: 0.6680\n",
      "HR@10: 0.2128 (Best: 0.1531)\n",
      "NDCG@10: 0.1124 (Best: 0.0762)\n",
      "Epoch 3, Loss: 0.5120\n",
      "HR@10: 0.2893 (Best: 0.2128)\n",
      "NDCG@10: 0.1568 (Best: 0.1124)\n",
      "Epoch 4, Loss: 0.4726\n",
      "HR@10: 0.3777 (Best: 0.2893)\n",
      "NDCG@10: 0.2070 (Best: 0.1568)\n",
      "Epoch 5, Loss: 0.4612\n",
      "HR@10: 0.4470 (Best: 0.3777)\n",
      "NDCG@10: 0.2535 (Best: 0.2070)\n",
      "Epoch 6, Loss: 0.4438\n",
      "HR@10: 0.5078 (Best: 0.4470)\n",
      "NDCG@10: 0.2911 (Best: 0.2535)\n",
      "Epoch 7, Loss: 0.4097\n",
      "HR@10: 0.5322 (Best: 0.5078)\n",
      "NDCG@10: 0.3088 (Best: 0.2911)\n",
      "Epoch 8, Loss: 0.3717\n",
      "HR@10: 0.5612 (Best: 0.5322)\n",
      "NDCG@10: 0.3252 (Best: 0.3088)\n",
      "Epoch 9, Loss: 0.3310\n",
      "HR@10: 0.5756 (Best: 0.5612)\n",
      "NDCG@10: 0.3390 (Best: 0.3252)\n",
      "Epoch 10, Loss: 0.3034\n",
      "HR@10: 0.5846 (Best: 0.5756)\n",
      "NDCG@10: 0.3483 (Best: 0.3390)\n",
      "Epoch 11, Loss: 0.2858\n",
      "HR@10: 0.5889 (Best: 0.5846)\n",
      "NDCG@10: 0.3555 (Best: 0.3483)\n",
      "Epoch 12, Loss: 0.2734\n",
      "HR@10: 0.5957 (Best: 0.5889)\n",
      "NDCG@10: 0.3638 (Best: 0.3555)\n",
      "Epoch 13, Loss: 0.2695\n",
      "HR@10: 0.5962 (Best: 0.5957)\n",
      "NDCG@10: 0.3680 (Best: 0.3638)\n",
      "Epoch 14, Loss: 0.2624\n",
      "HR@10: 0.6008 (Best: 0.5962)\n",
      "NDCG@10: 0.3745 (Best: 0.3680)\n",
      "Epoch 15, Loss: 0.2526\n",
      "HR@10: 0.5980 (Best: 0.6008)\n",
      "NDCG@10: 0.3749 (Best: 0.3745)\n",
      "Epoch 16, Loss: 0.2424\n",
      "HR@10: 0.5964 (Best: 0.6008)\n",
      "NDCG@10: 0.3807 (Best: 0.3749)\n",
      "Epoch 17, Loss: 0.2285\n",
      "HR@10: 0.5941 (Best: 0.6008)\n",
      "NDCG@10: 0.3836 (Best: 0.3807)\n",
      "Epoch 18, Loss: 0.2152\n",
      "HR@10: 0.5916 (Best: 0.6008)\n",
      "NDCG@10: 0.3827 (Best: 0.3836)\n",
      "Epoch 19, Loss: 0.2014\n",
      "HR@10: 0.5894 (Best: 0.6008)\n",
      "NDCG@10: 0.3803 (Best: 0.3836)\n",
      "Epoch 20, Loss: 0.1915\n",
      "HR@10: 0.5868 (Best: 0.6008)\n",
      "NDCG@10: 0.3820 (Best: 0.3836)\n",
      "Training completed. Best HR: 0.6008, Best NDCG: 0.3836\n"
     ]
    }
   ],
   "source": [
    "# Graph sage : Training completed. Best HR: 0.6124, Best NDCG: 0.3914\n",
    "\n",
    "class BeibeiDataset(Dataset):\n",
    "    def __init__(self, file_path, num_negative=4):\n",
    "        # Read the data\n",
    "        self.data = pd.read_csv(file_path, sep=' ', header=None, names=['user_id', 'item_id', 'label'], skiprows=1)\n",
    "        \n",
    "        # Create mappings for user and item IDs\n",
    "        self.user_map = {id_: idx for idx, id_ in enumerate(self.data['user_id'].unique())}\n",
    "        self.item_map = {id_: idx for idx, id_ in enumerate(self.data['item_id'].unique())}\n",
    "        \n",
    "        # Map IDs to indices\n",
    "        self.data['user_id'] = self.data['user_id'].map(self.user_map)\n",
    "        self.data['item_id'] = self.data['item_id'].map(self.item_map)\n",
    "        \n",
    "        self.num_users = len(self.user_map)\n",
    "        self.num_items = len(self.item_map)\n",
    "        self.num_negative = num_negative\n",
    "        \n",
    "        # Create user-items dictionary\n",
    "        self.user_items = self.create_user_items_dict()\n",
    "        \n",
    "        # Add negative samples\n",
    "        self.data = self.add_negative_samples()\n",
    "        \n",
    "    def create_user_items_dict(self):\n",
    "        user_items = {}\n",
    "        for user_id in range(self.num_users):\n",
    "            user_items[user_id] = set(self.data[self.data['user_id'] == user_id]['item_id'])\n",
    "        return user_items\n",
    "        \n",
    "    def add_negative_samples(self):\n",
    "        negative_samples = []\n",
    "        all_items = set(range(self.num_items))\n",
    "        \n",
    "        for user_id in self.user_items:\n",
    "            # Get items this user hasn't interacted with\n",
    "            negative_items = list(all_items - self.user_items[user_id])\n",
    "            \n",
    "            # Sample negative items\n",
    "            if len(negative_items) > 0:\n",
    "                num_neg = min(len(negative_items), self.num_negative)\n",
    "                sampled_neg = np.random.choice(negative_items, num_neg, replace=False)\n",
    "                \n",
    "                # Add negative samples\n",
    "                for item_id in sampled_neg:\n",
    "                    negative_samples.append([user_id, item_id, 0])\n",
    "        \n",
    "        # Convert to DataFrame and combine with positive samples\n",
    "        neg_df = pd.DataFrame(negative_samples, columns=['user_id', 'item_id', 'label'])\n",
    "        return pd.concat([self.data, neg_df], ignore_index=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        return (\n",
    "            torch.tensor(row['user_id'], dtype=torch.long),\n",
    "            torch.tensor(row['item_id'], dtype=torch.long),\n",
    "            torch.tensor(row['label'], dtype=torch.float)\n",
    "        )\n",
    "\n",
    "# Load and preprocess data\n",
    "dataset = BeibeiDataset('/Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei.txt')\n",
    "\n",
    "# Create data loaders\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Initialize model with correct number of users and items\n",
    "model = GraphSAGERecommender(\n",
    "    num_users=dataset.num_users,\n",
    "    num_items=dataset.num_items,\n",
    "    embedding_dim=64,\n",
    "    hidden_dim=128,\n",
    "    num_layers=2,\n",
    "    dropout=0.2\n",
    ").to(device)\n",
    "\n",
    "# Rest of the training code remains the same\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "# Modified DataLoader with batch_size equal to dataset size\n",
    "train_loader = DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "\n",
    "# Training loop without batches\n",
    "best_hr = 0\n",
    "best_ndcg = 0\n",
    "\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    \n",
    "    # Get all data at once\n",
    "    user_ids, item_ids, labels = next(iter(train_loader))\n",
    "    user_ids = user_ids.to(device)\n",
    "    item_ids = item_ids.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    # Forward pass\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(user_ids, item_ids)\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        hr, ndcg = evaluate_model(model, test_loader)\n",
    "    \n",
    "    print(f\"HR@10: {hr:.4f} (Best: {best_hr:.4f})\")\n",
    "    print(f\"NDCG@10: {ndcg:.4f} (Best: {best_ndcg:.4f})\")\n",
    "    \n",
    "    # Update best metrics\n",
    "    best_hr = max(best_hr, hr)\n",
    "    best_ndcg = max(best_ndcg, ndcg)\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(loss.item())\n",
    "\n",
    "print(f\"Training completed. Best HR: {best_hr:.4f}, Best NDCG: {best_ndcg:.4f}\")\n",
    "\n",
    "# graph sage ++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch 15, Loss: 0.1466, HR@10: 0.1048, NDCG@10: 0.0479\n",
    "\n",
    "\n",
    "\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from torch_geometric.data import Data\n",
    "# from torch_geometric.nn import SAGEConv\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# # Load the BeibeiDataset\n",
    "# dataset = BeibeiDataset('/Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei.txt')\n",
    "\n",
    "# # Get user and item IDs from the dataset\n",
    "# user_ids = dataset.data['user_id'].values\n",
    "# item_ids = dataset.data['item_id'].values\n",
    "\n",
    "# # Create edges\n",
    "# edge_index = torch.tensor([\n",
    "#     [u for u in user_ids],  # User nodes\n",
    "#     [i + dataset.num_users for i in item_ids]   # Item nodes (offset by num_users)\n",
    "# ], dtype=torch.long)\n",
    "\n",
    "# # Node features\n",
    "# num_users = dataset.num_users\n",
    "# num_items = dataset.num_items\n",
    "# num_nodes = num_users + num_items\n",
    "# x = torch.randn(num_nodes, 64)  # Increased feature dimension to match embedding_dim\n",
    "\n",
    "# # Create PyTorch Geometric data object\n",
    "# graph_data = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "# class ImprovedGraphSAGE(torch.nn.Module):\n",
    "#     def __init__(self, num_users, num_items, embedding_dim, hidden_dim, dropout=0.3):\n",
    "#         super(ImprovedGraphSAGE, self).__init__()\n",
    "        \n",
    "#         self.user_embedding = torch.nn.Embedding(num_users, embedding_dim)\n",
    "#         self.item_embedding = torch.nn.Embedding(num_items, embedding_dim)\n",
    "        \n",
    "#         self.conv1 = SAGEConv(embedding_dim, hidden_dim)\n",
    "#         self.conv2 = SAGEConv(hidden_dim, hidden_dim)\n",
    "#         self.conv3 = SAGEConv(hidden_dim, hidden_dim)\n",
    "        \n",
    "#         self.bn1 = torch.nn.BatchNorm1d(hidden_dim)\n",
    "#         self.bn2 = torch.nn.BatchNorm1d(hidden_dim)\n",
    "#         self.bn3 = torch.nn.BatchNorm1d(hidden_dim)\n",
    "        \n",
    "#         self.predictor = torch.nn.Sequential(\n",
    "#             torch.nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "#             torch.nn.ReLU(),\n",
    "#             torch.nn.Dropout(dropout),\n",
    "#             torch.nn.Linear(hidden_dim, 1)\n",
    "#         )\n",
    "        \n",
    "#         self.dropout = dropout\n",
    "#         self._init_weights()\n",
    "        \n",
    "#     def _init_weights(self):\n",
    "#         for m in self.modules():\n",
    "#             if isinstance(m, torch.nn.Linear):\n",
    "#                 torch.nn.init.xavier_uniform_(m.weight)\n",
    "#                 if m.bias is not None:\n",
    "#                     torch.nn.init.zeros_(m.bias)\n",
    "#             elif isinstance(m, torch.nn.Embedding):\n",
    "#                 torch.nn.init.normal_(m.weight, std=0.01)\n",
    "\n",
    "#     def forward(self, x, edge_index, user_indices, item_indices):\n",
    "#         # Get initial embeddings\n",
    "#         user_emb = self.user_embedding(user_indices)\n",
    "#         item_emb = self.item_embedding(item_indices)\n",
    "        \n",
    "#         # Update node features with embeddings\n",
    "#         x = torch.cat([\n",
    "#             self.user_embedding.weight,\n",
    "#             self.item_embedding.weight\n",
    "#         ], dim=0)\n",
    "        \n",
    "#         # Process through GraphSAGE layers\n",
    "#         x = self.conv1(x, edge_index)\n",
    "#         x = self.bn1(x)\n",
    "#         x = F.leaky_relu(x)\n",
    "#         x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        \n",
    "#         x = self.conv2(x, edge_index)\n",
    "#         x = self.bn2(x)\n",
    "#         x = F.leaky_relu(x)\n",
    "#         x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        \n",
    "#         x = self.conv3(x, edge_index)\n",
    "#         x = self.bn3(x)\n",
    "#         x = F.leaky_relu(x)\n",
    "        \n",
    "#         # Get final embeddings\n",
    "#         user_final = x[:num_users][user_indices]\n",
    "#         item_final = x[num_users:][item_indices]\n",
    "        \n",
    "#         # Combine embeddings\n",
    "#         combined = torch.cat([user_final, item_final], dim=1)\n",
    "#         return self.predictor(combined).squeeze()\n",
    "\n",
    "# def calculate_metrics(model, test_data, k=10):\n",
    "#     hits = []\n",
    "#     ndcgs = []\n",
    "    \n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         pos_samples = test_data[test_data['label'] == 1]\n",
    "        \n",
    "#         for _, row in pos_samples.iterrows():\n",
    "#             user_idx = row['user_id']\n",
    "#             true_item = row['item_id']\n",
    "            \n",
    "#             # Calculate scores for all items\n",
    "#             user_tensor = torch.LongTensor([user_idx]).repeat(dataset.num_items).to(device)\n",
    "#             item_tensor = torch.LongTensor(range(dataset.num_items)).to(device)\n",
    "            \n",
    "#             scores = model(graph_data.x, graph_data.edge_index, user_tensor, item_tensor)\n",
    "            \n",
    "#             # Get top-k items\n",
    "#             _, top_items = torch.topk(scores, k)\n",
    "#             top_items = top_items.cpu().numpy()\n",
    "            \n",
    "#             # Calculate metrics\n",
    "#             hit = 1 if true_item in top_items else 0\n",
    "#             hits.append(hit)\n",
    "            \n",
    "#             if hit:\n",
    "#                 rank = np.where(top_items == true_item)[0][0]\n",
    "#                 ndcg = 1 / np.log2(rank + 2)\n",
    "#             else:\n",
    "#                 ndcg = 0\n",
    "#             ndcgs.append(ndcg)\n",
    "    \n",
    "#     return np.mean(hits), np.mean(ndcgs)\n",
    "\n",
    "# # Setup device\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# graph_data = graph_data.to(device)\n",
    "\n",
    "# # Data splitting\n",
    "# pos_data = dataset.data[dataset.data['label'] == 1]\n",
    "# neg_data = dataset.data[dataset.data['label'] == 0]\n",
    "\n",
    "# test_size_pos = int(0.2 * len(pos_data))\n",
    "# train_pos = pos_data.iloc[:-test_size_pos]\n",
    "# test_pos = pos_data.iloc[-test_size_pos:]\n",
    "\n",
    "# test_size_neg = int(0.2 * len(neg_data))\n",
    "# train_neg = neg_data.iloc[:-test_size_neg]\n",
    "# test_neg = neg_data.iloc[-test_size_neg:]\n",
    "\n",
    "# train_data = pd.concat([train_pos, train_neg]).sample(frac=1, random_state=42)\n",
    "# test_data = pd.concat([test_pos, test_neg]).sample(frac=1, random_state=42)\n",
    "\n",
    "# print(f\"Train set size: {len(train_data)}, positive samples: {len(train_pos)}\")\n",
    "# print(f\"Test set size: {len(test_data)}, positive samples: {len(test_pos)}\")\n",
    "\n",
    "# # Initialize model\n",
    "# model = ImprovedGraphSAGE(\n",
    "#     num_users=dataset.num_users,\n",
    "#     num_items=dataset.num_items,\n",
    "#     embedding_dim=64,\n",
    "#     hidden_dim=128\n",
    "# ).to(device)\n",
    "\n",
    "# # Training setup\n",
    "# criterion = torch.nn.BCEWithLogitsLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "# # scheduler = torch.optim.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "# # Training loop\n",
    "# best_hr = 0\n",
    "# best_ndcg = 0\n",
    "\n",
    "# for epoch in range(50):\n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "    \n",
    "#     # Process in batches\n",
    "#     batch_size = 1024\n",
    "#     for start_idx in range(0, len(train_data), batch_size):\n",
    "#         end_idx = min(start_idx + batch_size, len(train_data))\n",
    "#         batch_data = train_data.iloc[start_idx:end_idx]\n",
    "        \n",
    "#         user_ids = torch.LongTensor(batch_data['user_id'].values).to(device)\n",
    "#         item_ids = torch.LongTensor(batch_data['item_id'].values).to(device)\n",
    "#         labels = torch.FloatTensor(batch_data['label'].values).to(device)\n",
    "        \n",
    "#         # Forward pass\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(graph_data.x, graph_data.edge_index, user_ids, item_ids)\n",
    "#         loss = criterion(outputs, labels)\n",
    "        \n",
    "#         # Backward pass\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         total_loss += loss.item()\n",
    "    \n",
    "#     avg_loss = total_loss / (len(train_data) / batch_size)\n",
    "    \n",
    "#     # Evaluation\n",
    "#     if (epoch + 1) % 5 == 0:\n",
    "#         hr, ndcg = calculate_metrics(model, test_data)\n",
    "#         print(f'Epoch {epoch + 1}, Loss: {avg_loss:.4f}, HR@10: {hr:.4f}, NDCG@10: {ndcg:.4f}')\n",
    "        \n",
    "#         best_hr = max(best_hr, hr)\n",
    "#         best_ndcg = max(best_ndcg, ndcg)\n",
    "#         scheduler.step(avg_loss)\n",
    "\n",
    "# print(f\"Training completed. Best HR@10: {best_hr:.4f}, Best NDCG@10: {best_ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rough biasMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 86865, positive samples: 17373\n",
      "Test set size: 21715, positive samples: 4343\n",
      "Epoch 10, Loss: 0.0613\n",
      "Epoch 20, Loss: 0.0121\n",
      "Epoch 30, Loss: 0.0046\n",
      "Epoch 40, Loss: 0.0022\n",
      "Epoch 50, Loss: 0.0012\n",
      "Epoch 60, Loss: 0.0006\n",
      "Epoch 70, Loss: 0.0004\n",
      "Epoch 80, Loss: 0.0002\n",
      "Epoch 90, Loss: 0.0001\n",
      "Epoch 100, Loss: 0.0001\n",
      "Evaluating 4343 positive samples...\n",
      "HR@10: 0.0258, NDCG@10: 0.0130\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initialize device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load dataset\n",
    "dataset = BeibeiDataset('/Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei.txt')\n",
    "\n",
    "# Calculate global mean of labels\n",
    "global_mean = dataset.data['label'].mean()\n",
    "\n",
    "# Modified BiasMF class\n",
    "class BiasMF(torch.nn.Module):\n",
    "    def __init__(self, num_users, num_items, latent_dim, global_mean):\n",
    "        super(BiasMF, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.latent_dim = latent_dim\n",
    "        self.mu = global_mean\n",
    "\n",
    "        self.user_embedding = torch.nn.Embedding(self.num_users, self.latent_dim)\n",
    "        self.item_embedding = torch.nn.Embedding(self.num_items, self.latent_dim)\n",
    "\n",
    "        self.user_bias = torch.nn.Embedding(self.num_users, 1)\n",
    "        self.user_bias.weight.data = torch.zeros(self.num_users, 1).float()\n",
    "        self.item_bias = torch.nn.Embedding(self.num_items, 1)\n",
    "        self.item_bias.weight.data = torch.zeros(self.num_items, 1).float()\n",
    "\n",
    "    def forward(self, user_indices, item_indices):\n",
    "        user_vec = self.user_embedding(user_indices)\n",
    "        item_vec = self.item_embedding(item_indices)\n",
    "        dot = torch.mul(user_vec, item_vec).sum(dim=1)\n",
    "\n",
    "        rating = dot + self.mu + self.user_bias(user_indices).view(-1) + self.item_bias(item_indices).view(-1)\n",
    "\n",
    "        return rating\n",
    "\n",
    "# Initialize model with individual parameters\n",
    "model = BiasMF(\n",
    "    num_users=dataset.num_users,\n",
    "    num_items=dataset.num_items,\n",
    "    latent_dim=16,\n",
    "    global_mean=global_mean\n",
    ").to(device)\n",
    "\n",
    "# Rest of the code remains the same\n",
    "# Split data\n",
    "pos_data = dataset.data[dataset.data['label'] == 1]\n",
    "neg_data = dataset.data[dataset.data['label'] == 0]\n",
    "\n",
    "# Split positive samples\n",
    "test_size_pos = int(0.2 * len(pos_data))\n",
    "train_pos = pos_data.iloc[:-test_size_pos]\n",
    "test_pos = pos_data.iloc[-test_size_pos:]\n",
    "\n",
    "# Split negative samples\n",
    "test_size_neg = int(0.2 * len(neg_data))\n",
    "train_neg = neg_data.iloc[:-test_size_neg]\n",
    "test_neg = neg_data.iloc[-test_size_neg:]\n",
    "\n",
    "# Combine splits\n",
    "train_data = pd.concat([train_pos, train_neg]).sample(frac=1, random_state=42)\n",
    "test_data = pd.concat([test_pos, test_neg]).sample(frac=1, random_state=42)\n",
    "\n",
    "print(f\"Train set size: {len(train_data)}, positive samples: {len(train_pos)}\")\n",
    "print(f\"Test set size: {len(test_data)}, positive samples: {len(test_pos)}\")\n",
    "\n",
    "# Training setup\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Convert data to tensors\n",
    "train_users = torch.LongTensor(train_data['user_id'].values).to(device)\n",
    "train_items = torch.LongTensor(train_data['item_id'].values).to(device)\n",
    "train_labels = torch.FloatTensor(train_data['label'].values).to(device)\n",
    "\n",
    "# Training loop\n",
    "batch_size = 1024\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    # Process in batches\n",
    "    for start_idx in range(0, len(train_users), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(train_users))\n",
    "        \n",
    "        user_batch = train_users[start_idx:end_idx]\n",
    "        item_batch = train_items[start_idx:end_idx]\n",
    "        label_batch = train_labels[start_idx:end_idx]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(user_batch, item_batch)\n",
    "        loss = criterion(predictions, label_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        avg_loss = total_loss / (len(train_users) / batch_size)\n",
    "        print(f'Epoch {epoch + 1}, Loss: {avg_loss:.4f}')\n",
    "\n",
    "\n",
    "def calculate_metrics(model, test_data, k=10):\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Get positive samples from test data\n",
    "        pos_samples = test_data[test_data['label'] == 1]\n",
    "        \n",
    "        if len(pos_samples) == 0:\n",
    "            print(\"No positive samples found in test data!\")\n",
    "            return 0.0, 0.0\n",
    "            \n",
    "        print(f\"Evaluating {len(pos_samples)} positive samples...\")\n",
    "        \n",
    "        for _, row in pos_samples.iterrows():\n",
    "            user_idx = row['user_id']\n",
    "            true_item = row['item_id']\n",
    "            \n",
    "            try:\n",
    "                # Calculate scores for all items\n",
    "                user_tensor = torch.LongTensor([user_idx]).repeat(dataset.num_items).to(device)\n",
    "                item_tensor = torch.LongTensor(range(dataset.num_items)).to(device)\n",
    "                \n",
    "                scores = model(user_tensor, item_tensor)\n",
    "                \n",
    "                # Get top-k items\n",
    "                _, top_items = torch.topk(scores, k)\n",
    "                top_items = top_items.cpu().numpy()\n",
    "                \n",
    "                # Calculate metrics\n",
    "                hit = 1 if true_item in top_items else 0\n",
    "                hits.append(hit)\n",
    "                \n",
    "                if hit:\n",
    "                    rank = np.where(top_items == true_item)[0][0]\n",
    "                    ndcg = 1 / np.log2(rank + 2)\n",
    "                else:\n",
    "                    ndcg = 0\n",
    "                ndcgs.append(ndcg)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing user {user_idx}, item {true_item}: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    if not hits:\n",
    "        print(\"No valid predictions were made!\")\n",
    "        return 0.0, 0.0\n",
    "        \n",
    "    return np.mean(hits), np.mean(ndcgs)\n",
    "\n",
    "# Calculate metrics\n",
    "hr, ndcg = calculate_metrics(model, test_data, k=10)\n",
    "print(f'HR@10: {hr:.4f}, NDCG@10: {ndcg:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.0731\n",
      "Evaluating 4343 positive samples...\n",
      "HR@10: 0.1025, NDCG@10: 0.0542\n",
      "Epoch 20, Loss: 0.0123\n",
      "Evaluating 4343 positive samples...\n",
      "HR@10: 0.1073, NDCG@10: 0.0550\n",
      "Epoch 30, Loss: 0.0051\n",
      "Evaluating 4343 positive samples...\n",
      "HR@10: 0.1078, NDCG@10: 0.0553\n",
      "Epoch 40, Loss: 0.0035\n",
      "Evaluating 4343 positive samples...\n",
      "HR@10: 0.1068, NDCG@10: 0.0544\n",
      "Epoch 50, Loss: 0.0025\n",
      "Evaluating 4343 positive samples...\n",
      "HR@10: 0.1082, NDCG@10: 0.0546\n",
      "Epoch 60, Loss: 0.0022\n",
      "Evaluating 4343 positive samples...\n",
      "HR@10: 0.1091, NDCG@10: 0.0558\n",
      "Epoch 70, Loss: 0.0020\n",
      "Evaluating 4343 positive samples...\n",
      "HR@10: 0.1073, NDCG@10: 0.0520\n",
      "Epoch 80, Loss: 0.0015\n",
      "Evaluating 4343 positive samples...\n",
      "HR@10: 0.1059, NDCG@10: 0.0548\n",
      "Epoch 90, Loss: 0.0014\n",
      "Evaluating 4343 positive samples...\n",
      "HR@10: 0.1050, NDCG@10: 0.0529\n",
      "Epoch 100, Loss: 0.0012\n",
      "Evaluating 4343 positive samples...\n",
      "HR@10: 0.1052, NDCG@10: 0.0513\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initialize device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load dataset\n",
    "dataset = BeibeiDataset('/Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei.txt')\n",
    "\n",
    "# Calculate global mean of labels\n",
    "global_mean = dataset.data['label'].mean()\n",
    "# Remove the second model initialization and use only EnhancedBiasMF\n",
    "class EnhancedBiasMF(torch.nn.Module):\n",
    "    def __init__(self, num_users, num_items, latent_dim, global_mean, dropout=0.2):\n",
    "        super(EnhancedBiasMF, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.latent_dim = latent_dim\n",
    "        self.mu = global_mean\n",
    "        \n",
    "        # Embeddings\n",
    "        self.user_embedding = torch.nn.Embedding(num_users, latent_dim)\n",
    "        self.item_embedding = torch.nn.Embedding(num_items, latent_dim)\n",
    "        torch.nn.init.xavier_uniform_(self.user_embedding.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.item_embedding.weight)\n",
    "        \n",
    "        # Bias terms\n",
    "        self.user_bias = torch.nn.Embedding(num_users, 1)\n",
    "        self.item_bias = torch.nn.Embedding(num_items, 1)\n",
    "        torch.nn.init.zeros_(self.user_bias.weight)\n",
    "        torch.nn.init.zeros_(self.item_bias.weight)\n",
    "        \n",
    "        # MLP layers\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(latent_dim * 2, latent_dim),\n",
    "            torch.nn.BatchNorm1d(latent_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(dropout),\n",
    "            torch.nn.Linear(latent_dim, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, user_indices, item_indices):\n",
    "        # Get embeddings\n",
    "        user_vec = self.user_embedding(user_indices)\n",
    "        item_vec = self.item_embedding(item_indices)\n",
    "        \n",
    "        # Get biases\n",
    "        user_bias = self.user_bias(user_indices).squeeze()\n",
    "        item_bias = self.item_bias(item_indices).squeeze()\n",
    "        \n",
    "        # Combine embeddings\n",
    "        concat = torch.cat([user_vec, item_vec], dim=1)\n",
    "        \n",
    "        # MLP prediction\n",
    "        mlp_output = self.mlp(concat).squeeze()\n",
    "        \n",
    "        # Final prediction\n",
    "        rating = mlp_output + self.mu + user_bias + item_bias\n",
    "        \n",
    "        return rating\n",
    "\n",
    "# Model and training configuration\n",
    "config = {\n",
    "    'latent_dim': 64,\n",
    "    'batch_size': 2048,\n",
    "    'num_epochs': 100,\n",
    "    'learning_rate': 0.001,\n",
    "    'weight_decay': 1e-5,\n",
    "    'dropout': 0.2\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "model = EnhancedBiasMF(\n",
    "    num_users=dataset.num_users,\n",
    "    num_items=dataset.num_items,\n",
    "    latent_dim=config['latent_dim'],\n",
    "    global_mean=global_mean,\n",
    "    dropout=config['dropout']\n",
    ").to(device)\n",
    "\n",
    "# Training setup\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=config['learning_rate'],\n",
    "    weight_decay=config['weight_decay']\n",
    ")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(config['num_epochs']):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for start_idx in range(0, len(train_users), config['batch_size']):\n",
    "        end_idx = min(start_idx + config['batch_size'], len(train_users))\n",
    "        \n",
    "        user_batch = train_users[start_idx:end_idx]\n",
    "        item_batch = train_items[start_idx:end_idx]\n",
    "        label_batch = train_labels[start_idx:end_idx]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(user_batch, item_batch)\n",
    "        loss = criterion(predictions, label_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / (len(train_users) / config['batch_size'])\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch {epoch + 1}, Loss: {avg_loss:.4f}')\n",
    "        # Evaluate on validation set\n",
    "        hr, ndcg = calculate_metrics(model, test_data, k=10)\n",
    "        print(f'HR@10: {hr:.4f}, NDCG@10: {ndcg:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 4343 positive samples...\n",
      "Epoch 1:\n",
      "Loss: 3.0106\n",
      "HR@10: 0.0035, NDCG@10: 0.0014\n",
      "Evaluating 4343 positive samples...\n",
      "Epoch 2:\n",
      "Loss: 0.1343\n",
      "HR@10: 0.0037, NDCG@10: 0.0016\n",
      "Evaluating 4343 positive samples...\n",
      "Epoch 3:\n",
      "Loss: 0.0417\n",
      "HR@10: 0.0037, NDCG@10: 0.0016\n",
      "Evaluating 4343 positive samples...\n",
      "Epoch 4:\n",
      "Loss: 0.0225\n",
      "HR@10: 0.0037, NDCG@10: 0.0015\n",
      "Evaluating 4343 positive samples...\n",
      "Epoch 5:\n",
      "Loss: 0.0141\n",
      "HR@10: 0.0035, NDCG@10: 0.0014\n",
      "Evaluating 4343 positive samples...\n",
      "Epoch 6:\n",
      "Loss: 0.0109\n",
      "HR@10: 0.0035, NDCG@10: 0.0014\n",
      "Evaluating 4343 positive samples...\n",
      "Epoch 7:\n",
      "Loss: 0.0093\n",
      "HR@10: 0.0035, NDCG@10: 0.0014\n",
      "Early stopping triggered\n",
      "Training completed. Best HR@10: 0.0037\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initialize device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load dataset\n",
    "dataset = BeibeiDataset('/Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei.txt')\n",
    "\n",
    "# Calculate global mean of labels\n",
    "global_mean = dataset.data['label'].mean()\n",
    "# Remove the second model initialization and use only EnhancedBiasMF\n",
    "class BiasMF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, latent_dim, global_mean, dropout=0.1):\n",
    "        super(BiasMF, self).__init__()\n",
    "        \n",
    "        # Basic parameters\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.latent_dim = latent_dim\n",
    "        self.global_mean = global_mean\n",
    "        \n",
    "        # Embeddings initialization with Xavier/Glorot\n",
    "        self.user_embedding = nn.Embedding(num_users, latent_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, latent_dim)\n",
    "        nn.init.xavier_uniform_(self.user_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.item_embedding.weight)\n",
    "        \n",
    "        # Bias terms\n",
    "        self.user_bias = nn.Embedding(num_users, 1)\n",
    "        self.item_bias = nn.Embedding(num_items, 1)\n",
    "        nn.init.zeros_(self.user_bias.weight)\n",
    "        nn.init.zeros_(self.item_bias.weight)\n",
    "        \n",
    "        # Regularization\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Layer normalization for better stability\n",
    "        self.layer_norm = nn.LayerNorm(latent_dim)\n",
    "        \n",
    "    def forward(self, user_indices, item_indices):\n",
    "        # Get embeddings\n",
    "        user_vec = self.dropout(self.user_embedding(user_indices))\n",
    "        item_vec = self.dropout(self.item_embedding(item_indices))\n",
    "        \n",
    "        # Apply layer normalization\n",
    "        user_vec = self.layer_norm(user_vec)\n",
    "        item_vec = self.layer_norm(item_vec)\n",
    "        \n",
    "        # Get biases\n",
    "        user_b = self.user_bias(user_indices).squeeze()\n",
    "        item_b = self.item_bias(item_indices).squeeze()\n",
    "        \n",
    "        # Compute dot product\n",
    "        dot = torch.sum(user_vec * item_vec, dim=1)\n",
    "        \n",
    "        # Final prediction\n",
    "        pred = self.global_mean + dot + user_b + item_b\n",
    "        return pred\n",
    "\n",
    "# Training configuration\n",
    "config = {\n",
    "    'latent_dim': 64,\n",
    "    'batch_size': 1024,\n",
    "    'num_epochs': 50,\n",
    "    'learning_rate': 0.001,\n",
    "    'weight_decay': 1e-5,\n",
    "    'dropout': 0.1\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "model = BiasMF(\n",
    "    num_users=dataset.num_users,\n",
    "    num_items=dataset.num_items,\n",
    "    latent_dim=config['latent_dim'],\n",
    "    global_mean=global_mean,\n",
    "    dropout=config['dropout']\n",
    ").to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "\n",
    "# Training loop with early stopping\n",
    "best_hr = 0\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(config['num_epochs']):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    # Training\n",
    "    for start_idx in range(0, len(train_users), config['batch_size']):\n",
    "        end_idx = min(start_idx + config['batch_size'], len(train_users))\n",
    "        \n",
    "        user_batch = train_users[start_idx:end_idx]\n",
    "        item_batch = train_items[start_idx:end_idx]\n",
    "        label_batch = train_labels[start_idx:end_idx]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(user_batch, item_batch)\n",
    "        loss = criterion(predictions, label_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "    \n",
    "    # Validation\n",
    "    avg_loss = total_loss / num_batches\n",
    "    hr, ndcg = calculate_metrics(model, test_data)\n",
    "    \n",
    "    print(f'Epoch {epoch + 1}:')\n",
    "    print(f'Loss: {avg_loss:.4f}')\n",
    "    print(f'HR@10: {hr:.4f}, NDCG@10: {ndcg:.4f}')\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(avg_loss)\n",
    "    \n",
    "    # Early stopping\n",
    "    if hr > best_hr:\n",
    "        best_hr = hr\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "print(f\"Training completed. Best HR@10: {best_hr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Initializing dataset...\n",
      "Loading training data from: /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/\n",
      "Loading behavior: pv from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_pv\n",
      "Loaded pv matrix with shape: (21716, 7977)\n",
      "Loading behavior: cart from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_cart\n",
      "Loaded cart matrix with shape: (21716, 7977)\n",
      "Loading behavior: buy from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_buy\n",
      "Loaded buy matrix with shape: (21716, 7977)\n",
      "Dataset dimensions: 21716 users, 7977 items\n",
      "Loading test data from: /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/tst_int\n",
      "Number of test users: 10000\n",
      "Preparing training instances...\n",
      "Processing user 0/21716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yf/20z1hn994jd04q4kl0gpgh740000gn/T/ipykernel_1586/3372765655.py:96: DeprecationWarning: Please import `csr_matrix` from the `scipy.sparse` namespace; the `scipy.sparse.csr` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  mat = pickle.load(fs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing user 1000/21716\n",
      "Processing user 2000/21716\n",
      "Processing user 3000/21716\n",
      "Processing user 4000/21716\n",
      "Processing user 5000/21716\n",
      "Processing user 6000/21716\n",
      "Processing user 7000/21716\n",
      "Processing user 8000/21716\n",
      "Processing user 9000/21716\n",
      "Processing user 10000/21716\n",
      "Processing user 11000/21716\n",
      "Processing user 12000/21716\n",
      "Processing user 13000/21716\n",
      "Processing user 14000/21716\n",
      "Processing user 15000/21716\n",
      "Processing user 16000/21716\n",
      "Processing user 17000/21716\n",
      "Processing user 18000/21716\n",
      "Processing user 19000/21716\n",
      "Processing user 20000/21716\n",
      "Processing user 21000/21716\n",
      "Generated 1414300 training instances\n",
      "Initializing model...\n",
      "Preparing training tensors...\n",
      "Starting training...\n",
      "\n",
      "Epoch 1/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0067\n",
      "Batch 200: Loss = 0.0031\n",
      "Batch 300: Loss = 0.0010\n",
      "Batch 400: Loss = 0.0004\n",
      "Batch 500: Loss = 0.0003\n",
      "Batch 600: Loss = 0.0002\n",
      "Batch 700: Loss = 0.0001\n",
      "Batch 800: Loss = 0.0001\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0001\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 1 completed. Average loss: 0.0124\n",
      "\n",
      "Epoch 2/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 2 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 3/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 3 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 4/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 4 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 5/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 5 completed. Average loss: 0.0000\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 1000000 test instances\n",
      "Evaluating 10000 users...\n",
      "Evaluating user 0/10000\n",
      "Evaluating user 1000/10000\n",
      "Evaluating user 2000/10000\n",
      "Evaluating user 3000/10000\n",
      "Evaluating user 4000/10000\n",
      "Evaluating user 5000/10000\n",
      "Evaluating user 6000/10000\n",
      "Evaluating user 7000/10000\n",
      "Evaluating user 8000/10000\n",
      "Evaluating user 9000/10000\n",
      "HR@10: 0.0541, NDCG@10: 0.0246\n",
      "New best HR achieved!\n",
      "\n",
      "Epoch 6/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 6 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 7/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 7 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 8/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 8 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 9/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 9 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 10/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 10 completed. Average loss: 0.0000\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 1000000 test instances\n",
      "Evaluating 10000 users...\n",
      "Evaluating user 0/10000\n",
      "Evaluating user 1000/10000\n",
      "Evaluating user 2000/10000\n",
      "Evaluating user 3000/10000\n",
      "Evaluating user 4000/10000\n",
      "Evaluating user 5000/10000\n",
      "Evaluating user 6000/10000\n",
      "Evaluating user 7000/10000\n",
      "Evaluating user 8000/10000\n",
      "Evaluating user 9000/10000\n",
      "HR@10: 0.0498, NDCG@10: 0.0228\n",
      "\n",
      "Epoch 11/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 11 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 12/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 12 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 13/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 13 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 14/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 14 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 15/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 15 completed. Average loss: 0.0000\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 1000000 test instances\n",
      "Evaluating 10000 users...\n",
      "Evaluating user 0/10000\n",
      "Evaluating user 1000/10000\n",
      "Evaluating user 2000/10000\n",
      "Evaluating user 3000/10000\n",
      "Evaluating user 4000/10000\n",
      "Evaluating user 5000/10000\n",
      "Evaluating user 6000/10000\n",
      "Evaluating user 7000/10000\n",
      "Evaluating user 8000/10000\n",
      "Evaluating user 9000/10000\n",
      "HR@10: 0.0488, NDCG@10: 0.0222\n",
      "\n",
      "Epoch 16/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 16 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 17/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 17 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 18/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 18 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 19/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 19 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 20/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 20 completed. Average loss: 0.0000\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 1000000 test instances\n",
      "Evaluating 10000 users...\n",
      "Evaluating user 0/10000\n",
      "Evaluating user 1000/10000\n",
      "Evaluating user 2000/10000\n",
      "Evaluating user 3000/10000\n",
      "Evaluating user 4000/10000\n",
      "Evaluating user 5000/10000\n",
      "Evaluating user 6000/10000\n",
      "Evaluating user 7000/10000\n",
      "Evaluating user 8000/10000\n",
      "Evaluating user 9000/10000\n",
      "HR@10: 0.0503, NDCG@10: 0.0223\n",
      "\n",
      "Epoch 21/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 21 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 22/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 22 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 23/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 23 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 24/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 24 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 25/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 25 completed. Average loss: 0.0000\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 1000000 test instances\n",
      "Evaluating 10000 users...\n",
      "Evaluating user 0/10000\n",
      "Evaluating user 1000/10000\n",
      "Evaluating user 2000/10000\n",
      "Evaluating user 3000/10000\n",
      "Evaluating user 4000/10000\n",
      "Evaluating user 5000/10000\n",
      "Evaluating user 6000/10000\n",
      "Evaluating user 7000/10000\n",
      "Evaluating user 8000/10000\n",
      "Evaluating user 9000/10000\n",
      "HR@10: 0.0484, NDCG@10: 0.0223\n",
      "\n",
      "Epoch 26/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 26 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 27/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 27 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 28/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 28 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 29/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 29 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 30/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 30 completed. Average loss: 0.0000\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 1000000 test instances\n",
      "Evaluating 10000 users...\n",
      "Evaluating user 0/10000\n",
      "Evaluating user 1000/10000\n",
      "Evaluating user 2000/10000\n",
      "Evaluating user 3000/10000\n",
      "Evaluating user 4000/10000\n",
      "Evaluating user 5000/10000\n",
      "Evaluating user 6000/10000\n",
      "Evaluating user 7000/10000\n",
      "Evaluating user 8000/10000\n",
      "Evaluating user 9000/10000\n",
      "HR@10: 0.0480, NDCG@10: 0.0221\n",
      "\n",
      "Epoch 31/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 31 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 32/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 32 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 33/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 33 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 34/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 34 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 35/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 35 completed. Average loss: 0.0000\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 1000000 test instances\n",
      "Evaluating 10000 users...\n",
      "Evaluating user 0/10000\n",
      "Evaluating user 1000/10000\n",
      "Evaluating user 2000/10000\n",
      "Evaluating user 3000/10000\n",
      "Evaluating user 4000/10000\n",
      "Evaluating user 5000/10000\n",
      "Evaluating user 6000/10000\n",
      "Evaluating user 7000/10000\n",
      "Evaluating user 8000/10000\n",
      "Evaluating user 9000/10000\n",
      "HR@10: 0.0483, NDCG@10: 0.0216\n",
      "\n",
      "Epoch 36/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 36 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 37/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 37 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 38/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 38 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 39/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 39 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 40/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 40 completed. Average loss: 0.0000\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 1000000 test instances\n",
      "Evaluating 10000 users...\n",
      "Evaluating user 0/10000\n",
      "Evaluating user 1000/10000\n",
      "Evaluating user 2000/10000\n",
      "Evaluating user 3000/10000\n",
      "Evaluating user 4000/10000\n",
      "Evaluating user 5000/10000\n",
      "Evaluating user 6000/10000\n",
      "Evaluating user 7000/10000\n",
      "Evaluating user 8000/10000\n",
      "Evaluating user 9000/10000\n",
      "HR@10: 0.0471, NDCG@10: 0.0216\n",
      "\n",
      "Epoch 41/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 41 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 42/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 42 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 43/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 43 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 44/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 44 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 45/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 45 completed. Average loss: 0.0000\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 1000000 test instances\n",
      "Evaluating 10000 users...\n",
      "Evaluating user 0/10000\n",
      "Evaluating user 1000/10000\n",
      "Evaluating user 2000/10000\n",
      "Evaluating user 3000/10000\n",
      "Evaluating user 4000/10000\n",
      "Evaluating user 5000/10000\n",
      "Evaluating user 6000/10000\n",
      "Evaluating user 7000/10000\n",
      "Evaluating user 8000/10000\n",
      "Evaluating user 9000/10000\n",
      "HR@10: 0.0473, NDCG@10: 0.0216\n",
      "\n",
      "Epoch 46/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 46 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 47/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 47 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 48/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 48 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 49/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 49 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 50/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Batch 1300: Loss = 0.0000\n",
      "Epoch 50 completed. Average loss: 0.0000\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 1000000 test instances\n",
      "Evaluating 10000 users...\n",
      "Evaluating user 0/10000\n",
      "Evaluating user 1000/10000\n",
      "Evaluating user 2000/10000\n",
      "Evaluating user 3000/10000\n",
      "Evaluating user 4000/10000\n",
      "Evaluating user 5000/10000\n",
      "Evaluating user 6000/10000\n",
      "Evaluating user 7000/10000\n",
      "Evaluating user 8000/10000\n",
      "Evaluating user 9000/10000\n",
      "HR@10: 0.0471, NDCG@10: 0.0211\n",
      "\n",
      "Training completed.\n",
      "Best HR@10: 0.0541\n",
      "Best NDCG@10: 0.0246\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy.sparse import csr_matrix\n",
    "import os\n",
    "\n",
    "# Initialize device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "class MultiBehaviorBiasMF(nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_behaviors, latent_dim=64, dropout=0.1):\n",
    "        super(MultiBehaviorBiasMF, self).__init__()\n",
    "        \n",
    "        self.n_behaviors = n_behaviors\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # User and item embeddings\n",
    "        self.user_embedding = nn.Embedding(n_users, latent_dim)\n",
    "        self.item_embedding = nn.Embedding(n_items, latent_dim)\n",
    "        \n",
    "        # Behavior-specific embeddings\n",
    "        self.behavior_embeddings = nn.ModuleList([\n",
    "            nn.Embedding(2, latent_dim) for _ in range(n_behaviors)\n",
    "        ])\n",
    "        \n",
    "        # Bias terms\n",
    "        self.user_bias = nn.Embedding(n_users, 1)\n",
    "        self.item_bias = nn.Embedding(n_items, 1)\n",
    "        \n",
    "        # MLP for combining behavior signals\n",
    "        self.behavior_mlp = nn.Sequential(\n",
    "            nn.Linear(latent_dim * (2 + n_behaviors), latent_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(latent_dim, 1)\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.user_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.item_embedding.weight)\n",
    "        for beh_emb in self.behavior_embeddings:\n",
    "            nn.init.xavier_uniform_(beh_emb.weight)\n",
    "        nn.init.zeros_(self.user_bias.weight)\n",
    "        nn.init.zeros_(self.item_bias.weight)\n",
    "        \n",
    "    def forward(self, user_indices, item_indices, behavior_data):\n",
    "        # Get basic embeddings\n",
    "        user_emb = self.user_embedding(user_indices)\n",
    "        item_emb = self.item_embedding(item_indices)\n",
    "        \n",
    "        # Get behavior embeddings\n",
    "        behavior_embs = []\n",
    "        for i in range(self.n_behaviors):\n",
    "            beh_data = behavior_data[:, i].long()\n",
    "            beh_emb = self.behavior_embeddings[i](beh_data)\n",
    "            behavior_embs.append(beh_emb)\n",
    "        \n",
    "        # Combine all embeddings\n",
    "        combined = torch.cat([user_emb, item_emb] + behavior_embs, dim=1)\n",
    "        \n",
    "        # Get prediction\n",
    "        pred = self.behavior_mlp(combined).squeeze()\n",
    "        \n",
    "        # Add biases\n",
    "        pred = pred + self.user_bias(user_indices).squeeze()\n",
    "        pred = pred + self.item_bias(item_indices).squeeze()\n",
    "        \n",
    "        return pred\n",
    "\n",
    "class MultiBehaviorDataset:\n",
    "    def __init__(self, data_path='/Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/'):\n",
    "        self.data_path = data_path\n",
    "        self.behaviors = ['pv', 'cart', 'buy']\n",
    "        self.trn_file = data_path + 'trn_'\n",
    "        self.tst_file = data_path + 'tst_'\n",
    "        \n",
    "        # Load the data during initialization\n",
    "        self.load_training_data()\n",
    "        self.load_test_data()\n",
    "        \n",
    "    def load_training_data(self):\n",
    "        print(\"Loading training data from:\", self.data_path)\n",
    "        self.trn_mats = []\n",
    "        for beh in self.behaviors:\n",
    "            path = self.trn_file + beh\n",
    "            print(f\"Loading behavior: {beh} from {path}\")\n",
    "            if not os.path.exists(path):\n",
    "                raise FileNotFoundError(f\"File not found: {path}\")\n",
    "            with open(path, 'rb') as fs:\n",
    "                mat = pickle.load(fs)\n",
    "                if not isinstance(mat, csr_matrix):\n",
    "                    mat = csr_matrix(mat)\n",
    "                mat = (mat != 0).astype(np.float32)\n",
    "                self.trn_mats.append(mat)\n",
    "                print(f\"Loaded {beh} matrix with shape: {mat.shape}\")\n",
    "        \n",
    "        self.trn_label = 1 * (self.trn_mats[-1] != 0)\n",
    "        self.n_users, self.n_items = self.trn_mats[0].shape\n",
    "        self.n_behaviors = len(self.behaviors)\n",
    "        print(f\"Dataset dimensions: {self.n_users} users, {self.n_items} items\")\n",
    "        \n",
    "    def load_test_data(self):\n",
    "        test_path = self.tst_file + 'int'\n",
    "        print(f\"Loading test data from: {test_path}\")\n",
    "        if not os.path.exists(test_path):\n",
    "            raise FileNotFoundError(f\"File not found: {test_path}\")\n",
    "        with open(test_path, 'rb') as fs:\n",
    "            self.tst_int = np.array(pickle.load(fs))\n",
    "        \n",
    "        self.tst_users = np.reshape(np.argwhere(self.tst_int != None), [-1])\n",
    "        print(f\"Number of test users: {len(self.tst_users)}\")\n",
    "        \n",
    "    def prepare_train_instances(self):\n",
    "        print(\"Preparing training instances...\")\n",
    "        train_data = []\n",
    "        \n",
    "        for user in range(self.n_users):\n",
    "            if user % 1000 == 0:\n",
    "                print(f\"Processing user {user}/{self.n_users}\")\n",
    "                \n",
    "            pos_items = self.trn_label[user].indices\n",
    "            \n",
    "            if len(pos_items) > 0:\n",
    "                for item in pos_items:\n",
    "                    behaviors = [float(mat[user, item]) for mat in self.trn_mats]\n",
    "                    train_data.append([user, item, 1.0] + behaviors)\n",
    "                    \n",
    "                    all_items = set(range(self.n_items))\n",
    "                    pos_items_set = set(pos_items)\n",
    "                    neg_items_pool = list(all_items - pos_items_set)\n",
    "                    \n",
    "                    if len(neg_items_pool) >= 4:\n",
    "                        neg_items = np.random.choice(neg_items_pool, size=4, replace=False)\n",
    "                        for neg_item in neg_items:\n",
    "                            behaviors = [float(mat[user, neg_item]) for mat in self.trn_mats]\n",
    "                            train_data.append([user, neg_item, 0.0] + behaviors)\n",
    "        \n",
    "        if len(train_data) == 0:\n",
    "            raise ValueError(\"No training instances were generated!\")\n",
    "            \n",
    "        print(f\"Generated {len(train_data)} training instances\")\n",
    "        return np.array(train_data)\n",
    "\n",
    "    def get_test_instances(self):\n",
    "        print(\"Preparing test instances...\")\n",
    "        test_instances = []\n",
    "        for user in self.tst_users:\n",
    "            pos_item = self.tst_int[user]\n",
    "            if pos_item is not None:\n",
    "                test_instances.append([user, pos_item, 1.0])\n",
    "                \n",
    "                try:\n",
    "                    all_items = set(range(self.n_items))\n",
    "                    pos_items_train = set(self.trn_label[user].indices)\n",
    "                    pos_items_train.add(pos_item)\n",
    "                    neg_items_pool = list(all_items - pos_items_train)\n",
    "                    \n",
    "                    n_neg_samples = min(99, len(neg_items_pool))\n",
    "                    if n_neg_samples > 0:\n",
    "                        neg_items = np.random.choice(neg_items_pool, size=n_neg_samples, replace=False)\n",
    "                        for neg_item in neg_items:\n",
    "                            test_instances.append([user, neg_item, 0.0])\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing user {user}: {str(e)}\")\n",
    "                    continue\n",
    "        \n",
    "        if len(test_instances) == 0:\n",
    "            raise ValueError(\"No test instances were generated!\")\n",
    "            \n",
    "        print(f\"Generated {len(test_instances)} test instances\")\n",
    "        return np.array(test_instances)\n",
    "\n",
    "def evaluate_model(model, dataset, test_instances, k=10):\n",
    "    model.eval()\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    \n",
    "    test_users = {}\n",
    "    for instance in test_instances:\n",
    "        user, item, label = instance\n",
    "        if user not in test_users:\n",
    "            test_users[user] = {'pos': [], 'neg': []}\n",
    "        if label == 1.0:\n",
    "            test_users[user]['pos'].append(item)\n",
    "        else:\n",
    "            test_users[user]['neg'].append(item)\n",
    "    \n",
    "    print(f\"Evaluating {len(test_users)} users...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, user in enumerate(test_users):\n",
    "            if i % 1000 == 0:\n",
    "                print(f\"Evaluating user {i}/{len(test_users)}\")\n",
    "                \n",
    "            items = test_users[user]['pos'] + test_users[user]['neg']\n",
    "            if not items:\n",
    "                continue\n",
    "                \n",
    "            user_tensor = torch.LongTensor([user] * len(items)).to(device)\n",
    "            item_tensor = torch.LongTensor(items).to(device)\n",
    "            behavior_tensor = torch.zeros(len(items), dataset.n_behaviors).to(device)\n",
    "            \n",
    "            try:\n",
    "                predictions = model(user_tensor, item_tensor, behavior_tensor)\n",
    "                predictions = predictions.cpu().numpy()\n",
    "                \n",
    "                pos_items = set(test_users[user]['pos'])\n",
    "                item_score_dict = {items[i]: predictions[i] for i in range(len(items))}\n",
    "                item_score_pair_sorted = sorted(item_score_dict.items(), key=lambda x: x[1], reverse=True)[0:k]\n",
    "                items_sorted = [x[0] for x in item_score_pair_sorted]\n",
    "                \n",
    "                hit = len(set(items_sorted) & pos_items) > 0\n",
    "                hits.append(hit)\n",
    "                \n",
    "                ndcg = 0\n",
    "                for i, item in enumerate(items_sorted):\n",
    "                    if item in pos_items:\n",
    "                        ndcg = 1 / np.log2(i + 2)\n",
    "                        break\n",
    "                ndcgs.append(ndcg)\n",
    "            except Exception as e:\n",
    "                print(f\"Error evaluating user {user}: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    if not hits:\n",
    "        return 0.0, 0.0\n",
    "        \n",
    "    return np.mean(hits), np.mean(ndcgs)\n",
    "\n",
    "def main():\n",
    "    print(\"Initializing dataset...\")\n",
    "    dataset = MultiBehaviorDataset()\n",
    "    train_data = dataset.prepare_train_instances()\n",
    "\n",
    "    config = {\n",
    "        'latent_dim': 64,\n",
    "        'batch_size': 1024,\n",
    "        'num_epochs': 50,\n",
    "        'learning_rate': 0.001,\n",
    "        'weight_decay': 1e-5,\n",
    "        'dropout': 0.1\n",
    "    }\n",
    "\n",
    "    print(\"Initializing model...\")\n",
    "    model = MultiBehaviorBiasMF(\n",
    "        n_users=dataset.n_users,\n",
    "        n_items=dataset.n_items,\n",
    "        n_behaviors=dataset.n_behaviors,\n",
    "        latent_dim=config['latent_dim'],\n",
    "        dropout=config['dropout']\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(), \n",
    "        lr=config['learning_rate'], \n",
    "        weight_decay=config['weight_decay']\n",
    "    )\n",
    "\n",
    "    print(\"Preparing training tensors...\")\n",
    "    train_users = torch.LongTensor(train_data[:, 0]).to(device)\n",
    "    train_items = torch.LongTensor(train_data[:, 1]).to(device)\n",
    "    train_labels = torch.FloatTensor(train_data[:, 2]).to(device)\n",
    "    train_behaviors = torch.FloatTensor(train_data[:, 3:]).to(device)\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    best_hr = 0\n",
    "    best_ndcg = 0\n",
    "    \n",
    "    for epoch in range(config['num_epochs']):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch + 1}/{config['num_epochs']}\")\n",
    "        print(\"Training...\")\n",
    "        \n",
    "        for start_idx in range(0, len(train_users), config['batch_size']):\n",
    "            end_idx = min(start_idx + config['batch_size'], len(train_users))\n",
    "            \n",
    "            user_batch = train_users[start_idx:end_idx]\n",
    "            item_batch = train_items[start_idx:end_idx]\n",
    "            label_batch = train_labels[start_idx:end_idx]\n",
    "            behavior_batch = train_behaviors[start_idx:end_idx]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(user_batch, item_batch, behavior_batch)\n",
    "            loss = criterion(predictions, label_batch)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "            if num_batches % 100 == 0:\n",
    "                print(f\"Batch {num_batches}: Loss = {loss.item():.4f}\")\n",
    "        \n",
    "        avg_loss = total_loss / num_batches\n",
    "        print(f\"Epoch {epoch + 1} completed. Average loss: {avg_loss:.4f}\")\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(\"\\nEvaluating...\")\n",
    "            test_instances = dataset.get_test_instances()\n",
    "            hr, ndcg = evaluate_model(model, dataset, test_instances)\n",
    "            print(f'HR@10: {hr:.4f}, NDCG@10: {ndcg:.4f}')\n",
    "            \n",
    "            if hr > best_hr:\n",
    "                best_hr = hr\n",
    "                best_ndcg = ndcg\n",
    "                print(\"New best HR achieved!\")\n",
    "                \n",
    "    print(f\"\\nTraining completed.\")\n",
    "    print(f\"Best HR@10: {best_hr:.4f}\")\n",
    "    print(f\"Best NDCG@10: {best_ndcg:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Initializing dataset...\n",
      "Loading training data from: /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/\n",
      "Loading behavior: pv from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_pv\n",
      "Loaded pv matrix with shape: (21716, 7977)\n",
      "Loading behavior: cart from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_cart\n",
      "Loaded cart matrix with shape: (21716, 7977)\n",
      "Loading behavior: buy from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_buy\n",
      "Loaded buy matrix with shape: (21716, 7977)\n",
      "Dataset dimensions: 21716 users, 7977 items\n",
      "Loading test data from: /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/tst_int\n",
      "Number of test users: 10000\n",
      "Preparing training instances...\n",
      "Processing user 0/21716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yf/20z1hn994jd04q4kl0gpgh740000gn/T/ipykernel_1586/2901519435.py:107: DeprecationWarning: Please import `csr_matrix` from the `scipy.sparse` namespace; the `scipy.sparse.csr` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  mat = pickle.load(fs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing user 1000/21716\n",
      "Processing user 2000/21716\n",
      "Processing user 3000/21716\n",
      "Processing user 4000/21716\n",
      "Processing user 5000/21716\n",
      "Processing user 6000/21716\n",
      "Processing user 7000/21716\n",
      "Processing user 8000/21716\n",
      "Processing user 9000/21716\n",
      "Processing user 10000/21716\n",
      "Processing user 11000/21716\n",
      "Processing user 12000/21716\n",
      "Processing user 13000/21716\n",
      "Processing user 14000/21716\n",
      "Processing user 15000/21716\n",
      "Processing user 16000/21716\n",
      "Processing user 17000/21716\n",
      "Processing user 18000/21716\n",
      "Processing user 19000/21716\n",
      "Processing user 20000/21716\n",
      "Processing user 21000/21716\n",
      "Generated 1414300 training instances\n",
      "Train size: 1272870, Validation size: 141430\n",
      "Initializing model...\n",
      "Preparing training tensors...\n",
      "Starting training...\n",
      "\n",
      "Epoch 1/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0062\n",
      "Batch 200: Loss = 0.0014\n",
      "Batch 300: Loss = 0.0008\n",
      "Batch 400: Loss = 0.0003\n",
      "Batch 500: Loss = 0.0002\n",
      "Batch 600: Loss = 0.0005\n",
      "Batch 700: Loss = 0.0001\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 1 completed. Average loss: 0.0120\n",
      "\n",
      "Epoch 2/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 2 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 3/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 3 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 4/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 4 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 5/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 5 completed. Average loss: 0.0000\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 1000000 test instances\n",
      "Evaluating 10000 users...\n",
      "Evaluating user 0/10000\n",
      "Evaluating user 1000/10000\n",
      "Evaluating user 2000/10000\n",
      "Evaluating user 3000/10000\n",
      "Evaluating user 4000/10000\n",
      "Evaluating user 5000/10000\n",
      "Evaluating user 6000/10000\n",
      "Evaluating user 7000/10000\n",
      "Evaluating user 8000/10000\n",
      "Evaluating user 9000/10000\n",
      "HR@10: 0.3937, NDCG@10: 0.2160\n",
      "Model saved to saved_models/model_20241228_203851.pth\n",
      "New best HR achieved!\n",
      "\n",
      "Epoch 6/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 6 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 7/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 7 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 8/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 8 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 9/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 9 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 10/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 10 completed. Average loss: 0.0000\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 1000000 test instances\n",
      "Evaluating 10000 users...\n",
      "Evaluating user 0/10000\n",
      "Evaluating user 1000/10000\n",
      "Evaluating user 2000/10000\n",
      "Evaluating user 3000/10000\n",
      "Evaluating user 4000/10000\n",
      "Evaluating user 5000/10000\n",
      "Evaluating user 6000/10000\n",
      "Evaluating user 7000/10000\n",
      "Evaluating user 8000/10000\n",
      "Evaluating user 9000/10000\n",
      "HR@10: 0.3674, NDCG@10: 0.2011\n",
      "\n",
      "Epoch 11/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 11 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 12/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 12 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 13/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 13 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 14/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 14 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 15/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 15 completed. Average loss: 0.0000\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 1000000 test instances\n",
      "Evaluating 10000 users...\n",
      "Evaluating user 0/10000\n",
      "Evaluating user 1000/10000\n",
      "Evaluating user 2000/10000\n",
      "Evaluating user 3000/10000\n",
      "Evaluating user 4000/10000\n",
      "Evaluating user 5000/10000\n",
      "Evaluating user 6000/10000\n",
      "Evaluating user 7000/10000\n",
      "Evaluating user 8000/10000\n",
      "Evaluating user 9000/10000\n",
      "HR@10: 0.3430, NDCG@10: 0.1925\n",
      "\n",
      "Epoch 16/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 16 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 17/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 17 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 18/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 18 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 19/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 19 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 20/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 20 completed. Average loss: 0.0000\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 1000000 test instances\n",
      "Evaluating 10000 users...\n",
      "Evaluating user 0/10000\n",
      "Evaluating user 1000/10000\n",
      "Evaluating user 2000/10000\n",
      "Evaluating user 3000/10000\n",
      "Evaluating user 4000/10000\n",
      "Evaluating user 5000/10000\n",
      "Evaluating user 6000/10000\n",
      "Evaluating user 7000/10000\n",
      "Evaluating user 8000/10000\n",
      "Evaluating user 9000/10000\n",
      "HR@10: 0.3431, NDCG@10: 0.1936\n",
      "\n",
      "Epoch 21/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 21 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 22/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 22 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 23/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 23 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 24/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 24 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 25/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 25 completed. Average loss: 0.0000\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 1000000 test instances\n",
      "Evaluating 10000 users...\n",
      "Evaluating user 0/10000\n",
      "Evaluating user 1000/10000\n",
      "Evaluating user 2000/10000\n",
      "Evaluating user 3000/10000\n",
      "Evaluating user 4000/10000\n",
      "Evaluating user 5000/10000\n",
      "Evaluating user 6000/10000\n",
      "Evaluating user 7000/10000\n",
      "Evaluating user 8000/10000\n",
      "Evaluating user 9000/10000\n",
      "HR@10: 0.3449, NDCG@10: 0.1934\n",
      "Epoch 00005: reducing learning rate of group 0 to 5.0000e-04.\n",
      "\n",
      "Epoch 26/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 26 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 27/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 27 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 28/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 28 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 29/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 29 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 30/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 30 completed. Average loss: 0.0000\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 1000000 test instances\n",
      "Evaluating 10000 users...\n",
      "Evaluating user 0/10000\n",
      "Evaluating user 1000/10000\n",
      "Evaluating user 2000/10000\n",
      "Evaluating user 3000/10000\n",
      "Evaluating user 4000/10000\n",
      "Evaluating user 5000/10000\n",
      "Evaluating user 6000/10000\n",
      "Evaluating user 7000/10000\n",
      "Evaluating user 8000/10000\n",
      "Evaluating user 9000/10000\n",
      "HR@10: 0.3429, NDCG@10: 0.1911\n",
      "\n",
      "Epoch 31/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 31 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 32/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 32 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 33/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 33 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 34/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 34 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 35/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 35 completed. Average loss: 0.0000\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 1000000 test instances\n",
      "Evaluating 10000 users...\n",
      "Evaluating user 0/10000\n",
      "Evaluating user 1000/10000\n",
      "Evaluating user 2000/10000\n",
      "Evaluating user 3000/10000\n",
      "Evaluating user 4000/10000\n",
      "Evaluating user 5000/10000\n",
      "Evaluating user 6000/10000\n",
      "Evaluating user 7000/10000\n",
      "Evaluating user 8000/10000\n",
      "Evaluating user 9000/10000\n",
      "HR@10: 0.3412, NDCG@10: 0.1917\n",
      "\n",
      "Epoch 36/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 36 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 37/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 37 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 38/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 38 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 39/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 39 completed. Average loss: 0.0000\n",
      "\n",
      "Epoch 40/50\n",
      "Training...\n",
      "Batch 100: Loss = 0.0000\n",
      "Batch 200: Loss = 0.0000\n",
      "Batch 300: Loss = 0.0000\n",
      "Batch 400: Loss = 0.0000\n",
      "Batch 500: Loss = 0.0000\n",
      "Batch 600: Loss = 0.0000\n",
      "Batch 700: Loss = 0.0000\n",
      "Batch 800: Loss = 0.0000\n",
      "Batch 900: Loss = 0.0000\n",
      "Batch 1000: Loss = 0.0000\n",
      "Batch 1100: Loss = 0.0000\n",
      "Batch 1200: Loss = 0.0000\n",
      "Epoch 40 completed. Average loss: 0.0000\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 1000000 test instances\n",
      "Evaluating 10000 users...\n",
      "Evaluating user 0/10000\n",
      "Evaluating user 1000/10000\n",
      "Evaluating user 2000/10000\n",
      "Evaluating user 3000/10000\n",
      "Evaluating user 4000/10000\n",
      "Evaluating user 5000/10000\n",
      "Evaluating user 6000/10000\n",
      "Evaluating user 7000/10000\n",
      "Evaluating user 8000/10000\n",
      "Evaluating user 9000/10000\n",
      "HR@10: 0.3437, NDCG@10: 0.1909\n",
      "Early stopping triggered\n",
      "\n",
      "Training completed.\n",
      "Best HR@10: 0.3937\n",
      "Best NDCG@10: 0.2160\n",
      "Model saved to: saved_models/model_20241228_203851.pth\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy.sparse import csr_matrix\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_hr = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, hr):\n",
    "        if self.best_hr is None:\n",
    "            self.best_hr = hr\n",
    "        elif hr < self.best_hr + self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_hr = hr\n",
    "            self.counter = 0\n",
    "\n",
    "class MultiBehaviorBiasMF(nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_behaviors, latent_dim=64, dropout=0.1):\n",
    "        super(MultiBehaviorBiasMF, self).__init__()\n",
    "        \n",
    "        self.n_behaviors = n_behaviors\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # User and item embeddings\n",
    "        self.user_embedding = nn.Embedding(n_users, latent_dim)\n",
    "        self.item_embedding = nn.Embedding(n_items, latent_dim)\n",
    "        \n",
    "        # Behavior-specific embeddings\n",
    "        self.behavior_embeddings = nn.ModuleList([\n",
    "            nn.Embedding(2, latent_dim) for _ in range(n_behaviors)\n",
    "        ])\n",
    "        \n",
    "        # Bias terms\n",
    "        self.user_bias = nn.Embedding(n_users, 1)\n",
    "        self.item_bias = nn.Embedding(n_items, 1)\n",
    "        \n",
    "        # MLP for combining behavior signals\n",
    "        self.behavior_mlp = nn.Sequential(\n",
    "            nn.Linear(latent_dim * (2 + n_behaviors), latent_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(latent_dim, 1)\n",
    "        )\n",
    "        \n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.user_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.item_embedding.weight)\n",
    "        for beh_emb in self.behavior_embeddings:\n",
    "            nn.init.xavier_uniform_(beh_emb.weight)\n",
    "        nn.init.zeros_(self.user_bias.weight)\n",
    "        nn.init.zeros_(self.item_bias.weight)\n",
    "        \n",
    "    def forward(self, user_indices, item_indices, behavior_data):\n",
    "        user_emb = self.user_embedding(user_indices)\n",
    "        item_emb = self.item_embedding(item_indices)\n",
    "        \n",
    "        behavior_embs = []\n",
    "        for i in range(self.n_behaviors):\n",
    "            beh_data = behavior_data[:, i].long()\n",
    "            beh_emb = self.behavior_embeddings[i](beh_data)\n",
    "            behavior_embs.append(beh_emb)\n",
    "        \n",
    "        combined = torch.cat([user_emb, item_emb] + behavior_embs, dim=1)\n",
    "        pred = self.behavior_mlp(combined).squeeze()\n",
    "        pred = pred + self.user_bias(user_indices).squeeze()\n",
    "        pred = pred + self.item_bias(item_indices).squeeze()\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "class MultiBehaviorDataset:\n",
    "    def __init__(self, data_path='/Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/'):\n",
    "        self.data_path = data_path\n",
    "        self.behaviors = ['pv', 'cart', 'buy']\n",
    "        self.trn_file = data_path + 'trn_'\n",
    "        self.tst_file = data_path + 'tst_'\n",
    "        \n",
    "        self.load_training_data()\n",
    "        self.load_test_data()\n",
    "        \n",
    "    def load_training_data(self):\n",
    "        print(\"Loading training data from:\", self.data_path)\n",
    "        self.trn_mats = []\n",
    "        for beh in self.behaviors:\n",
    "            path = self.trn_file + beh\n",
    "            print(f\"Loading behavior: {beh} from {path}\")\n",
    "            if not os.path.exists(path):\n",
    "                raise FileNotFoundError(f\"File not found: {path}\")\n",
    "            with open(path, 'rb') as fs:\n",
    "                mat = pickle.load(fs)\n",
    "                if not isinstance(mat, csr_matrix):\n",
    "                    mat = csr_matrix(mat)\n",
    "                mat = (mat != 0).astype(np.float32)\n",
    "                self.trn_mats.append(mat)\n",
    "                print(f\"Loaded {beh} matrix with shape: {mat.shape}\")\n",
    "        \n",
    "        self.trn_label = 1 * (self.trn_mats[-1] != 0)\n",
    "        self.n_users, self.n_items = self.trn_mats[0].shape\n",
    "        self.n_behaviors = len(self.behaviors)\n",
    "        print(f\"Dataset dimensions: {self.n_users} users, {self.n_items} items\")\n",
    "        \n",
    "    def load_test_data(self):\n",
    "        test_path = self.tst_file + 'int'\n",
    "        print(f\"Loading test data from: {test_path}\")\n",
    "        if not os.path.exists(test_path):\n",
    "            raise FileNotFoundError(f\"File not found: {test_path}\")\n",
    "        with open(test_path, 'rb') as fs:\n",
    "            self.tst_int = np.array(pickle.load(fs))\n",
    "        \n",
    "        self.tst_users = np.reshape(np.argwhere(self.tst_int != None), [-1])\n",
    "        print(f\"Number of test users: {len(self.tst_users)}\")\n",
    "\n",
    "    def prepare_train_instances(self):\n",
    "        print(\"Preparing training instances...\")\n",
    "        train_data = []\n",
    "        \n",
    "        for user in range(self.n_users):\n",
    "            if user % 1000 == 0:\n",
    "                print(f\"Processing user {user}/{self.n_users}\")\n",
    "                \n",
    "            pos_items = self.trn_label[user].indices\n",
    "            \n",
    "            if len(pos_items) > 0:\n",
    "                for item in pos_items:\n",
    "                    behaviors = [float(mat[user, item]) for mat in self.trn_mats]\n",
    "                    train_data.append([user, item, 1.0] + behaviors)\n",
    "                    \n",
    "                    all_items = set(range(self.n_items))\n",
    "                    pos_items_set = set(pos_items)\n",
    "                    neg_items_pool = list(all_items - pos_items_set)\n",
    "                    \n",
    "                    if len(neg_items_pool) >= 4:\n",
    "                        neg_items = np.random.choice(neg_items_pool, size=4, replace=False)\n",
    "                        for neg_item in neg_items:\n",
    "                            behaviors = [float(mat[user, neg_item]) for mat in self.trn_mats]\n",
    "                            train_data.append([user, neg_item, 0.0] + behaviors)\n",
    "        \n",
    "        if len(train_data) == 0:\n",
    "            raise ValueError(\"No training instances were generated!\")\n",
    "            \n",
    "        print(f\"Generated {len(train_data)} training instances\")\n",
    "        return np.array(train_data)\n",
    "\n",
    "    def get_test_instances(self):\n",
    "        print(\"Preparing test instances...\")\n",
    "        test_instances = []\n",
    "        for user in self.tst_users:\n",
    "            pos_item = self.tst_int[user]\n",
    "            if pos_item is not None:\n",
    "                test_instances.append([user, pos_item, 1.0])\n",
    "                \n",
    "                try:\n",
    "                    all_items = set(range(self.n_items))\n",
    "                    pos_items_train = set(self.trn_label[user].indices)\n",
    "                    pos_items_train.add(pos_item)\n",
    "                    neg_items_pool = list(all_items - pos_items_train)\n",
    "                    \n",
    "                    n_neg_samples = min(99, len(neg_items_pool))\n",
    "                    if n_neg_samples > 0:\n",
    "                        neg_items = np.random.choice(neg_items_pool, size=n_neg_samples, replace=False)\n",
    "                        for neg_item in neg_items:\n",
    "                            test_instances.append([user, neg_item, 0.0])\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing user {user}: {str(e)}\")\n",
    "                    continue\n",
    "        \n",
    "        if len(test_instances) == 0:\n",
    "            raise ValueError(\"No test instances were generated!\")\n",
    "            \n",
    "        print(f\"Generated {len(test_instances)} test instances\")\n",
    "        return np.array(test_instances)\n",
    "    \n",
    "def save_model(model, optimizer, epoch, hr, ndcg, path):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'hr': hr,\n",
    "        'ndcg': ndcg,\n",
    "    }, path)\n",
    "    print(f\"Model saved to {path}\")\n",
    "\n",
    "def load_model(model, optimizer, path):\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    return checkpoint['epoch'], checkpoint['hr'], checkpoint['ndcg']\n",
    "\n",
    "def split_train_val(train_data, val_ratio=0.1):\n",
    "    indices = np.random.permutation(len(train_data))\n",
    "    val_size = int(len(train_data) * val_ratio)\n",
    "    val_indices = indices[:val_size]\n",
    "    train_indices = indices[val_size:]\n",
    "    return train_data[train_indices], train_data[val_indices]\n",
    "\n",
    "def evaluate_model(model, dataset, test_instances, k=10):\n",
    "    model.eval()\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    \n",
    "    test_users = {}\n",
    "    for instance in test_instances:\n",
    "        user, item, label = instance\n",
    "        if user not in test_users:\n",
    "            test_users[user] = {'pos': [], 'neg': []}\n",
    "        if label == 1.0:\n",
    "            test_users[user]['pos'].append(item)\n",
    "        else:\n",
    "            test_users[user]['neg'].append(item)\n",
    "    \n",
    "    print(f\"Evaluating {len(test_users)} users...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, user in enumerate(test_users):\n",
    "            if i % 1000 == 0:\n",
    "                print(f\"Evaluating user {i}/{len(test_users)}\")\n",
    "                \n",
    "            items = test_users[user]['pos'] + test_users[user]['neg']\n",
    "            if not items:\n",
    "                continue\n",
    "                \n",
    "            user_tensor = torch.LongTensor([user] * len(items)).to(device)\n",
    "            item_tensor = torch.LongTensor(items).to(device)\n",
    "            behavior_tensor = torch.zeros(len(items), dataset.n_behaviors).to(device)\n",
    "            \n",
    "            try:\n",
    "                predictions = model(user_tensor, item_tensor, behavior_tensor)\n",
    "                predictions = predictions.cpu().numpy()\n",
    "                \n",
    "                pos_items = set(test_users[user]['pos'])\n",
    "                item_score_dict = {items[i]: predictions[i] for i in range(len(items))}\n",
    "                item_score_pair_sorted = sorted(item_score_dict.items(), key=lambda x: x[1], reverse=True)[0:k]\n",
    "                items_sorted = [x[0] for x in item_score_pair_sorted]\n",
    "                \n",
    "                hit = len(set(items_sorted) & pos_items) > 0\n",
    "                hits.append(hit)\n",
    "                \n",
    "                ndcg = 0\n",
    "                for i, item in enumerate(items_sorted):\n",
    "                    if item in pos_items:\n",
    "                        ndcg = 1 / np.log2(i + 2)\n",
    "                        break\n",
    "                ndcgs.append(ndcg)\n",
    "            except Exception as e:\n",
    "                print(f\"Error evaluating user {user}: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    if not hits:\n",
    "        return 0.0, 0.0\n",
    "        \n",
    "    return np.mean(hits), np.mean(ndcgs)\n",
    "\n",
    "def main():\n",
    "    # Configuration\n",
    "    config = {\n",
    "        'latent_dim': 64,\n",
    "        'batch_size': 1024,\n",
    "        'num_epochs': 50,\n",
    "        'learning_rate': 0.001,\n",
    "        'weight_decay': 1e-5,\n",
    "        'dropout': 0.1,\n",
    "        'patience': 7,\n",
    "        'val_ratio': 0.1,\n",
    "        'eval_every': 5\n",
    "    }\n",
    "    \n",
    "    # Create timestamp for model saving\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    model_dir = 'saved_models'\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    model_path = os.path.join(model_dir, f'model_{timestamp}.pth')\n",
    "\n",
    "    print(\"Initializing dataset...\")\n",
    "    dataset = MultiBehaviorDataset()\n",
    "    train_data = dataset.prepare_train_instances()\n",
    "    \n",
    "    # Split into train and validation\n",
    "    train_data, val_data = split_train_val(train_data, config['val_ratio'])\n",
    "    print(f\"Train size: {len(train_data)}, Validation size: {len(val_data)}\")\n",
    "\n",
    "    print(\"Initializing model...\")\n",
    "    model = MultiBehaviorBiasMF(\n",
    "        n_users=dataset.n_users,\n",
    "        n_items=dataset.n_items,\n",
    "        n_behaviors=dataset.n_behaviors,\n",
    "        latent_dim=config['latent_dim'],\n",
    "        dropout=config['dropout']\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(), \n",
    "        lr=config['learning_rate'], \n",
    "        weight_decay=config['weight_decay']\n",
    "    )\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', factor=0.5, patience=3, verbose=True\n",
    "    )\n",
    "\n",
    "    print(\"Preparing training tensors...\")\n",
    "    train_users = torch.LongTensor(train_data[:, 0]).to(device)\n",
    "    train_items = torch.LongTensor(train_data[:, 1]).to(device)\n",
    "    train_labels = torch.FloatTensor(train_data[:, 2]).to(device)\n",
    "    train_behaviors = torch.FloatTensor(train_data[:, 3:]).to(device)\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    early_stopping = EarlyStopping(patience=config['patience'])\n",
    "    best_hr = 0\n",
    "    best_ndcg = 0\n",
    "    \n",
    "    for epoch in range(config['num_epochs']):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch + 1}/{config['num_epochs']}\")\n",
    "        print(\"Training...\")\n",
    "        \n",
    "        for start_idx in range(0, len(train_users), config['batch_size']):\n",
    "            end_idx = min(start_idx + config['batch_size'], len(train_users))\n",
    "            \n",
    "            user_batch = train_users[start_idx:end_idx]\n",
    "            item_batch = train_items[start_idx:end_idx]\n",
    "            label_batch = train_labels[start_idx:end_idx]\n",
    "            behavior_batch = train_behaviors[start_idx:end_idx]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(user_batch, item_batch, behavior_batch)\n",
    "            loss = criterion(predictions, label_batch)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "            if num_batches % 100 == 0:\n",
    "                print(f\"Batch {num_batches}: Loss = {loss.item():.4f}\")\n",
    "        \n",
    "        avg_loss = total_loss / num_batches\n",
    "        print(f\"Epoch {epoch + 1} completed. Average loss: {avg_loss:.4f}\")\n",
    "        \n",
    "        if (epoch + 1) % config['eval_every'] == 0:\n",
    "            print(\"\\nEvaluating...\")\n",
    "            test_instances = dataset.get_test_instances()\n",
    "            hr, ndcg = evaluate_model(model, dataset, test_instances)\n",
    "            print(f'HR@10: {hr:.4f}, NDCG@10: {ndcg:.4f}')\n",
    "            \n",
    "            # Update learning rate\n",
    "            scheduler.step(hr)\n",
    "            \n",
    "            if hr > best_hr:\n",
    "                best_hr = hr\n",
    "                best_ndcg = ndcg\n",
    "                save_model(model, optimizer, epoch, hr, ndcg, model_path)\n",
    "                print(\"New best HR achieved!\")\n",
    "            \n",
    "            early_stopping(hr)\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping triggered\")\n",
    "                break\n",
    "                \n",
    "    print(f\"\\nTraining completed.\")\n",
    "    print(f\"Best HR@10: {best_hr:.4f}\")\n",
    "    print(f\"Best NDCG@10: {best_ndcg:.4f}\")\n",
    "    print(f\"Model saved to: {model_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from here it started regressing to true results and balance neg sample s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphTransformerV2(nn.Module):\n",
    "    def __init__(self, num_layers, d_model, num_heads, d_feedforward, input_dim, num_weights=10, use_weights=True, dropout=0.1):\n",
    "        super(GraphTransformerV2, self).__init__()\n",
    "        self.num_weights = num_weights\n",
    "        self.use_weights = use_weights\n",
    "        self.input_dim = input_dim\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # Input projection layers\n",
    "        self.input_linear = Linear(input_dim, d_model)\n",
    "        self.dng_projection = Linear(input_dim, d_model)\n",
    "        \n",
    "        self.encoder_layer = TransformerEncoderLayer(\n",
    "            d_model=d_model, \n",
    "            nhead=num_heads, \n",
    "            dim_feedforward=d_feedforward, \n",
    "            dropout=dropout, \n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Final output layers\n",
    "        self.pre_output = Linear(d_model, d_model)\n",
    "        self.output_linear = Linear(d_model, 1)\n",
    "        \n",
    "        self.dropout = Dropout(dropout)\n",
    "        self.layer_norm = LayerNorm(d_model)\n",
    "        \n",
    "        if self.use_weights:\n",
    "            self.weight_linears = ModuleList([Linear(input_dim, d_model) for _ in range(num_weights)])\n",
    "\n",
    "    def compute_neighborhood_similarity(self, adjacency_matrix, x):\n",
    "        try:\n",
    "            binary_adj = (adjacency_matrix > 0).float()\n",
    "            intersection = binary_adj @ binary_adj.T\n",
    "            row_sums = binary_adj.sum(dim=1, keepdim=True)\n",
    "            col_sums = binary_adj.sum(dim=0, keepdim=True)\n",
    "            union = row_sums + col_sums.T - intersection\n",
    "            similarity = intersection / (union + 1e-8)\n",
    "            return similarity @ x\n",
    "        except RuntimeError:\n",
    "            return torch.zeros_like(x)\n",
    "\n",
    "    def project_graph_metrics(self, graph_metrics, target_dim):\n",
    "        if graph_metrics.size(1) < target_dim:\n",
    "            repeats = (target_dim + graph_metrics.size(1) - 1) // graph_metrics.size(1)\n",
    "            graph_metrics = graph_metrics.repeat(1, repeats)[:, :target_dim]\n",
    "        elif graph_metrics.size(1) > target_dim:\n",
    "            graph_metrics = graph_metrics[:, :target_dim]\n",
    "        return graph_metrics\n",
    "\n",
    "    def forward(self, x, adjacency_matrix, graph_metrics, weights=None):\n",
    "        adjacency_matrix = adjacency_matrix.float()\n",
    "        graph_metrics = graph_metrics.float()\n",
    "        batch_size, input_dim = x.shape\n",
    "        \n",
    "        if adjacency_matrix.size(0) != batch_size or adjacency_matrix.size(1) != batch_size:\n",
    "            adjacency_matrix = torch.eye(batch_size, device=x.device)\n",
    "\n",
    "        try:\n",
    "            # Direct connections\n",
    "            direct_scores = adjacency_matrix @ x\n",
    "            \n",
    "            # Neighborhood similarity\n",
    "            neighborhood_similarity = self.compute_neighborhood_similarity(adjacency_matrix, x)\n",
    "            \n",
    "            # Graph structure scores\n",
    "            if graph_metrics.dim() == 2:\n",
    "                graph_metrics_projected = self.project_graph_metrics(graph_metrics, input_dim)\n",
    "                graph_structure_scores = graph_metrics_projected * x\n",
    "            else:\n",
    "                graph_structure_scores = torch.zeros_like(x)\n",
    "\n",
    "            # Combine DNG scores and project to d_model dimension\n",
    "            dng_scores = direct_scores + neighborhood_similarity + graph_structure_scores\n",
    "            dng_scores = self.dng_projection(dng_scores)  # Project to d_model dimension\n",
    "            \n",
    "            # Process input through transformer\n",
    "            if self.use_weights and weights is not None:\n",
    "                weighted_x = torch.zeros_like(x)\n",
    "                for i, weight in enumerate(weights.T):\n",
    "                    weighted_x += self.weight_linears[i](x) * weight.unsqueeze(1)\n",
    "                transformer_input = weighted_x\n",
    "            else:\n",
    "                transformer_input = self.input_linear(x)  # Project to d_model dimension\n",
    "\n",
    "            # Apply transformer\n",
    "            transformer_input = self.layer_norm(transformer_input)\n",
    "            transformer_output = self.transformer_encoder(transformer_input.unsqueeze(1)).squeeze(1)\n",
    "            \n",
    "            # Combine transformer output with DNG scores\n",
    "            combined = transformer_output + dng_scores\n",
    "            combined = self.dropout(combined)\n",
    "            \n",
    "            # Final output processing\n",
    "            output = self.pre_output(combined)\n",
    "            output = F.relu(output)\n",
    "            output = self.output_linear(output)\n",
    "            \n",
    "            return output.squeeze(-1)  # Return [batch_size] tensor\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            print(f\"RuntimeError during forward pass: {e}\")\n",
    "            print(f\"x shape: {x.shape}, adjacency_matrix shape: {adjacency_matrix.shape}, graph_metrics shape: {graph_metrics.shape}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing dataset...\n",
      "Loading training data from: /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/\n",
      "Loading behavior: pv from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_pv\n",
      "Loading behavior: cart from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_cart\n",
      "Loading behavior: buy from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_buy\n",
      "Dataset dimensions: 21716 users, 7977 items\n",
      "Loading test data from: /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/tst_int\n",
      "Using 10000 test users\n",
      "Preparing training instances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yf/20z1hn994jd04q4kl0gpgh740000gn/T/ipykernel_51372/4014312047.py:155: DeprecationWarning: Please import `csr_matrix` from the `scipy.sparse` namespace; the `scipy.sparse.csr` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  mat = pickle.load(fs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 6000 training instances\n",
      "Using 6000 training instances\n",
      "Preparing training tensors...\n",
      "Starting training...\n",
      "Training completed in 134.28s\n",
      "Training loss: 28.4724\n",
      "\n",
      "Starting evaluation...\n",
      "Preparing test instances...\n",
      "Generated 1000000 test instances\n",
      "Evaluating 1000000 instances in 2000 chunks...\n",
      "Processing chunk 1/2000\n",
      "Processing chunk 51/2000\n",
      "Processing chunk 101/2000\n",
      "Processing chunk 151/2000\n",
      "Processing chunk 201/2000\n",
      "Processing chunk 251/2000\n",
      "Processing chunk 301/2000\n",
      "Processing chunk 351/2000\n",
      "Processing chunk 401/2000\n",
      "Processing chunk 451/2000\n",
      "Processing chunk 501/2000\n",
      "Processing chunk 551/2000\n",
      "Processing chunk 601/2000\n",
      "Processing chunk 651/2000\n",
      "Processing chunk 701/2000\n",
      "Processing chunk 751/2000\n",
      "Processing chunk 801/2000\n",
      "Processing chunk 851/2000\n",
      "Processing chunk 901/2000\n",
      "Processing chunk 951/2000\n",
      "Processing chunk 1001/2000\n",
      "Processing chunk 1051/2000\n",
      "Processing chunk 1101/2000\n",
      "Processing chunk 1151/2000\n",
      "Processing chunk 1201/2000\n",
      "Processing chunk 1251/2000\n",
      "Processing chunk 1301/2000\n",
      "Processing chunk 1351/2000\n",
      "Processing chunk 1401/2000\n",
      "Processing chunk 1451/2000\n",
      "Processing chunk 1501/2000\n",
      "Processing chunk 1551/2000\n",
      "Processing chunk 1601/2000\n",
      "Processing chunk 1651/2000\n",
      "Processing chunk 1701/2000\n",
      "Processing chunk 1751/2000\n",
      "Processing chunk 1801/2000\n",
      "Processing chunk 1851/2000\n",
      "Processing chunk 1901/2000\n",
      "Processing chunk 1951/2000\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 10000\n",
      "Number of hits: 3411\n",
      "Average HR@50: 0.3411\n",
      "Average NDCG@50: 0.3411\n",
      "Evaluation completed in 111.74s\n",
      "HR@50: 0.3411\n",
      "NDCG@50: 0.3411\n"
     ]
    }
   ],
   "source": [
    "MAX_U = 50000\n",
    "TOP_N = 50\n",
    "# --\n",
    "CHUNK_S=100\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "TRAIN_SAMP=5000\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import Linear, Dropout, LayerNorm\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import ModuleList\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from datetime import datetime\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "class GraphTransformerV2(nn.Module):\n",
    "    def __init__(self, num_layers, d_model, num_heads, d_feedforward, input_dim, num_weights=10, use_weights=True, dropout=0.1):\n",
    "        super(GraphTransformerV2, self).__init__()\n",
    "        self.num_weights = num_weights\n",
    "        self.use_weights = use_weights\n",
    "        self.input_dim = input_dim\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # Input projection layers\n",
    "        self.input_linear = Linear(input_dim, d_model)\n",
    "        self.dng_projection = Linear(input_dim, d_model)\n",
    "        \n",
    "        self.encoder_layer = TransformerEncoderLayer(\n",
    "            d_model=d_model, \n",
    "            nhead=num_heads, \n",
    "            dim_feedforward=d_feedforward, \n",
    "            dropout=dropout, \n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Final output layers\n",
    "        self.pre_output = Linear(d_model, d_model)\n",
    "        self.output_linear = Linear(d_model, 1)\n",
    "        \n",
    "        self.dropout = Dropout(dropout)\n",
    "        self.layer_norm = LayerNorm(d_model)\n",
    "        \n",
    "        if self.use_weights:\n",
    "            self.weight_linears = ModuleList([Linear(input_dim, d_model) for _ in range(num_weights)])\n",
    "\n",
    "    def compute_neighborhood_similarity(self, adjacency_matrix, x):\n",
    "        try:\n",
    "            binary_adj = (adjacency_matrix > 0).float()\n",
    "            intersection = binary_adj @ binary_adj.T\n",
    "            row_sums = binary_adj.sum(dim=1, keepdim=True)\n",
    "            col_sums = binary_adj.sum(dim=0, keepdim=True)\n",
    "            union = row_sums + col_sums.T - intersection\n",
    "            similarity = intersection / (union + 1e-8)\n",
    "            return similarity @ x\n",
    "        except RuntimeError:\n",
    "            return torch.zeros_like(x)\n",
    "\n",
    "    def project_graph_metrics(self, graph_metrics, target_dim):\n",
    "        if graph_metrics.size(1) < target_dim:\n",
    "            repeats = (target_dim + graph_metrics.size(1) - 1) // graph_metrics.size(1)\n",
    "            graph_metrics = graph_metrics.repeat(1, repeats)[:, :target_dim]\n",
    "        elif graph_metrics.size(1) > target_dim:\n",
    "            graph_metrics = graph_metrics[:, :target_dim]\n",
    "        return graph_metrics\n",
    "\n",
    "    def forward(self, x, adjacency_matrix, graph_metrics, weights=None):\n",
    "        adjacency_matrix = adjacency_matrix.float()\n",
    "        graph_metrics = graph_metrics.float()\n",
    "        batch_size, input_dim = x.shape\n",
    "        \n",
    "        if adjacency_matrix.size(0) != batch_size or adjacency_matrix.size(1) != batch_size:\n",
    "            adjacency_matrix = torch.eye(batch_size, device=x.device)\n",
    "\n",
    "        try:\n",
    "            # Direct connections\n",
    "            direct_scores = adjacency_matrix @ x\n",
    "            \n",
    "            # Neighborhood similarity\n",
    "            neighborhood_similarity = self.compute_neighborhood_similarity(adjacency_matrix, x)\n",
    "            \n",
    "            # Graph structure scores\n",
    "            if graph_metrics.dim() == 2:\n",
    "                graph_metrics_projected = self.project_graph_metrics(graph_metrics, input_dim)\n",
    "                graph_structure_scores = graph_metrics_projected * x\n",
    "            else:\n",
    "                graph_structure_scores = torch.zeros_like(x)\n",
    "\n",
    "            # Combine DNG scores and project to d_model dimension\n",
    "            dng_scores = direct_scores + neighborhood_similarity + graph_structure_scores\n",
    "            dng_scores = self.dng_projection(dng_scores)  # Project to d_model dimension\n",
    "            \n",
    "            # Process input through transformer\n",
    "            if self.use_weights and weights is not None:\n",
    "                weighted_x = torch.zeros_like(x)\n",
    "                for i, weight in enumerate(weights.T):\n",
    "                    weighted_x += self.weight_linears[i](x) * weight.unsqueeze(1)\n",
    "                transformer_input = weighted_x\n",
    "            else:\n",
    "                transformer_input = self.input_linear(x)  # Project to d_model dimension\n",
    "\n",
    "            # Apply transformer\n",
    "            transformer_input = self.layer_norm(transformer_input)\n",
    "            transformer_output = self.transformer_encoder(transformer_input.unsqueeze(1)).squeeze(1)\n",
    "            \n",
    "            # Combine transformer output with DNG scores\n",
    "            combined = transformer_output + dng_scores\n",
    "            combined = self.dropout(combined)\n",
    "            \n",
    "            # Final output processing\n",
    "            output = self.pre_output(combined)\n",
    "            output = F.relu(output)\n",
    "            output = self.output_linear(output)\n",
    "            \n",
    "            return output.squeeze(-1)  # Return [batch_size] tensor\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            print(f\"RuntimeError during forward pass: {e}\")\n",
    "            print(f\"x shape: {x.shape}, adjacency_matrix shape: {adjacency_matrix.shape}, graph_metrics shape: {graph_metrics.shape}\")\n",
    "            raise\n",
    "\n",
    "# cropped dataset\n",
    "class MultiBehaviorDataset:\n",
    "    def __init__(self, data_path='/Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/', max_users=10000):\n",
    "        self.data_path = data_path\n",
    "        self.behaviors = ['pv', 'cart', 'buy']\n",
    "        self.trn_file = data_path + 'trn_'\n",
    "        self.tst_file = data_path + 'tst_'\n",
    "        self.max_users = max_users  # Limit number of users\n",
    "        \n",
    "        self.load_training_data()\n",
    "        self.load_test_data()\n",
    "    \n",
    "    def load_training_data(self):\n",
    "        print(\"Loading training data from:\", self.data_path)\n",
    "        self.trn_mats = []\n",
    "        for beh in self.behaviors:\n",
    "            path = self.trn_file + beh\n",
    "            print(f\"Loading behavior: {beh} from {path}\")\n",
    "            if not os.path.exists(path):\n",
    "                raise FileNotFoundError(f\"File not found: {path}\")\n",
    "            with open(path, 'rb') as fs:\n",
    "                mat = pickle.load(fs)\n",
    "                if not isinstance(mat, csr_matrix):\n",
    "                    mat = csr_matrix(mat)\n",
    "                mat = (mat != 0).astype(np.float32)\n",
    "                self.trn_mats.append(mat)\n",
    "        \n",
    "        self.trn_label = 1 * (self.trn_mats[-1] != 0)\n",
    "        self.n_users, self.n_items = self.trn_mats[0].shape\n",
    "        self.n_behaviors = len(self.behaviors)\n",
    "        print(f\"Dataset dimensions: {self.n_users} users, {self.n_items} items\")\n",
    "\n",
    "    def create_adjacency_matrix(self, users):\n",
    "        \"\"\"Optimized adjacency matrix creation\"\"\"\n",
    "        batch_size = len(users)\n",
    "        adj_matrix = torch.zeros(batch_size, batch_size, device=device)\n",
    "        \n",
    "        # Pre-compute user item sets\n",
    "        user_item_sets = []\n",
    "        for user in users:\n",
    "            user_items = set()\n",
    "            for mat in self.trn_mats:\n",
    "                user_items.update(mat[user].indices)\n",
    "            user_item_sets.append(user_items)\n",
    "        \n",
    "        # Compute similarities in parallel\n",
    "        for i in range(batch_size):\n",
    "            if not user_item_sets[i]:\n",
    "                continue\n",
    "            for j in range(i+1, batch_size):\n",
    "                if user_item_sets[j]:\n",
    "                    jaccard = len(user_item_sets[i] & user_item_sets[j]) / len(user_item_sets[i] | user_item_sets[j])\n",
    "                    adj_matrix[i,j] = adj_matrix[j,i] = jaccard\n",
    "        \n",
    "        return adj_matrix\n",
    "\n",
    "    def create_graph_metrics(self, users):\n",
    "        \"\"\"Optimized graph metrics creation\"\"\"\n",
    "        metrics = torch.zeros(len(users), 3, device=device)\n",
    "        \n",
    "        # Vectorized computation\n",
    "        for i, user in enumerate(users):\n",
    "            interactions = np.array([mat[user].nnz for mat in self.trn_mats])\n",
    "            metrics[i,0] = sum(interactions) / 100\n",
    "            metrics[i,1] = (interactions > 0).sum() / len(self.behaviors)\n",
    "            metrics[i,2] = interactions[-1] / max(interactions[0], 1)\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "    def prepare_train_instances(self, max_samples=5000):\n",
    "        \"\"\"Optimized training instance preparation\"\"\"\n",
    "        print(\"Preparing training instances...\")\n",
    "        train_data = []\n",
    "        \n",
    "        # Randomly select users\n",
    "        selected_users = np.random.choice(min(self.n_users, self.max_users), size=min(1000, self.max_users), replace=False)\n",
    "        \n",
    "        for user in selected_users:\n",
    "            pos_items = self.trn_label[user].indices[:2]  # Limit positive items\n",
    "            \n",
    "            if len(pos_items) > 0:\n",
    "                for item in pos_items:\n",
    "                    behaviors = [float(mat[user, item]) for mat in self.trn_mats]\n",
    "                    train_data.append([user, item, 1.0] + behaviors)\n",
    "                    \n",
    "                    # Limited negative sampling\n",
    "                    neg_items = np.random.choice(self.n_items, size=2, replace=False)\n",
    "                    for neg_item in neg_items:\n",
    "                        behaviors = [float(mat[user, neg_item]) for mat in self.trn_mats]\n",
    "                        train_data.append([user, neg_item, 0.0] + behaviors)\n",
    "                        \n",
    "                    if len(train_data) >= max_samples:\n",
    "                        break\n",
    "            \n",
    "            if len(train_data) >= max_samples:\n",
    "                break\n",
    "        \n",
    "        print(f\"Generated {len(train_data)} training instances\")\n",
    "        return np.array(train_data)\n",
    "    \n",
    "    def load_test_data(self):\n",
    "        \"\"\"Load test data\"\"\"\n",
    "        test_path = self.tst_file + 'int'\n",
    "        print(f\"Loading test data from: {test_path}\")\n",
    "        if not os.path.exists(test_path):\n",
    "            raise FileNotFoundError(f\"File not found: {test_path}\")\n",
    "        with open(test_path, 'rb') as fs:\n",
    "            self.tst_int = np.array(pickle.load(fs))\n",
    "        \n",
    "        self.tst_users = np.reshape(np.argwhere(self.tst_int != None), [-1])\n",
    "        # Limit test users for faster processing\n",
    "        self.tst_users = self.tst_users[:min(len(self.tst_users), self.max_users)]\n",
    "        print(f\"Using {len(self.tst_users)} test users\")\n",
    "\n",
    "    def get_test_instances(self, num_neg_samples=99):\n",
    "        \"\"\"Generate test instances with negative sampling\"\"\"\n",
    "        print(\"Preparing test instances...\")\n",
    "        test_instances = []\n",
    "        \n",
    "        for user in self.tst_users:\n",
    "            pos_item = self.tst_int[user]\n",
    "            if pos_item is not None:\n",
    "                # Add positive instance\n",
    "                test_instances.append([user, pos_item, 1.0])\n",
    "                \n",
    "                # Add negative instances\n",
    "                try:\n",
    "                    # Get all items and remove positive items\n",
    "                    all_items = set(range(self.n_items))\n",
    "                    pos_items_train = set(self.trn_label[user].indices)\n",
    "                    pos_items_train.add(pos_item)\n",
    "                    neg_items_pool = list(all_items - pos_items_train)\n",
    "                    \n",
    "                    # Sample negative items\n",
    "                    n_neg = min(num_neg_samples, len(neg_items_pool))\n",
    "                    if n_neg > 0:\n",
    "                        neg_items = np.random.choice(neg_items_pool, size=n_neg, replace=False)\n",
    "                        for neg_item in neg_items:\n",
    "                            test_instances.append([user, neg_item, 0.0])\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing test user {user}: {str(e)}\")\n",
    "                    continue\n",
    "                \n",
    "                # Limit the number of test instances for faster processing\n",
    "                if len(test_instances) >= self.max_users * 100:\n",
    "                    break\n",
    "        \n",
    "        if not test_instances:\n",
    "            raise ValueError(\"No test instances were generated!\")\n",
    "            \n",
    "        test_instances = np.array(test_instances)\n",
    "        print(f\"Generated {len(test_instances)} test instances\")\n",
    "        return test_instances\n",
    "\n",
    "def evaluate_model(model, dataset, test_instances, k=10):\n",
    "    \"\"\"Improved evaluation function with better metrics calculation\"\"\"\n",
    "    model.eval()\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    \n",
    "    # Process test instances in smaller chunks\n",
    "    chunk_size = CHUNK_S\n",
    "    test_chunks = [test_instances[i:i + chunk_size] for i in range(0, len(test_instances), chunk_size)]\n",
    "    \n",
    "    print(f\"Evaluating {len(test_instances)} instances in {len(test_chunks)} chunks...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for chunk_idx, chunk in enumerate(test_chunks):\n",
    "            if chunk_idx % 50 == 0:  # Reduced frequency of progress updates\n",
    "                print(f\"Processing chunk {chunk_idx + 1}/{len(test_chunks)}\")\n",
    "            \n",
    "            # Group by user and ensure we have both positive and negative items\n",
    "            user_items = {}\n",
    "            for inst in chunk:\n",
    "                user = int(inst[0])\n",
    "                item = int(inst[1])\n",
    "                label = float(inst[2])\n",
    "                \n",
    "                if user not in user_items:\n",
    "                    user_items[user] = {'pos': [], 'neg': [], 'all_items': [], 'all_scores': []}\n",
    "                \n",
    "                user_items[user]['all_items'].append(item)\n",
    "                if label > 0.5:\n",
    "                    user_items[user]['pos'].append(item)\n",
    "                else:\n",
    "                    user_items[user]['neg'].append(item)\n",
    "            \n",
    "            # Process each user that has both positive and negative items\n",
    "            for user, data in user_items.items():\n",
    "                if not data['pos'] or not data['neg']:\n",
    "                    continue\n",
    "                \n",
    "                items = data['all_items']\n",
    "                batch_size = len(items)\n",
    "                \n",
    "                # Create input features\n",
    "                behaviors = torch.zeros(batch_size, dataset.n_behaviors, device=device)\n",
    "                for i, item in enumerate(items):\n",
    "                    for j, mat in enumerate(dataset.trn_mats):\n",
    "                        behaviors[i, j] = float(mat[user, item])\n",
    "                \n",
    "                x = torch.cat([\n",
    "                    behaviors,\n",
    "                    torch.zeros(batch_size, model.input_dim - behaviors.size(1), device=device)\n",
    "                ], dim=1)\n",
    "                \n",
    "                # Simplified adjacency matrix for evaluation\n",
    "                adj_matrix = torch.eye(batch_size, device=device)\n",
    "                graph_metrics = dataset.create_graph_metrics([user] * batch_size)\n",
    "                \n",
    "                try:\n",
    "                    predictions = model(x, adj_matrix, graph_metrics)\n",
    "                    predictions = predictions.cpu().numpy().flatten()\n",
    "                    \n",
    "                    # Store all scores\n",
    "                    for item, score in zip(items, predictions):\n",
    "                        data['all_scores'].append((item, score))\n",
    "                    \n",
    "                    # Sort items by score\n",
    "                    sorted_items = [x[0] for x in sorted(data['all_scores'], key=lambda x: x[1], reverse=True)]\n",
    "                    recommended_items = sorted_items[:k]\n",
    "                    \n",
    "                    # Calculate HR\n",
    "                    hit = False\n",
    "                    for pos_item in data['pos']:\n",
    "                        if pos_item in recommended_items:\n",
    "                            hit = True\n",
    "                            break\n",
    "                    hits.append(hit)\n",
    "                    \n",
    "                    # Calculate NDCG\n",
    "                    dcg = 0\n",
    "                    idcg = 1  # Ideal DCG for one relevant item\n",
    "                    for i, item in enumerate(recommended_items):\n",
    "                        if item in data['pos']:\n",
    "                            dcg += 1 / np.log2(i + 2)\n",
    "                    ndcg = dcg / idcg\n",
    "                    ndcgs.append(ndcg)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error evaluating user {user}: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    hr = np.mean(hits) if hits else 0\n",
    "    ndcg = np.mean(ndcgs) if ndcgs else 0\n",
    "    \n",
    "    # Print detailed statistics\n",
    "    print(f\"\\nEvaluation Statistics:\")\n",
    "    print(f\"Total users evaluated: {len(hits)}\")\n",
    "    print(f\"Number of hits: {sum(hits)}\")\n",
    "    print(f\"Average HR@{k}: {hr:.4f}\")\n",
    "    print(f\"Average NDCG@{k}: {ndcg:.4f}\")\n",
    "    \n",
    "    return hr, ndcg\n",
    "\n",
    "def get_test_instances(self, num_neg_samples=99):\n",
    "    \"\"\"Improved test instance generation\"\"\"\n",
    "    print(\"Preparing test instances...\")\n",
    "    test_instances = []\n",
    "    max_test_users = 1000  # Limit number of test users\n",
    "    \n",
    "    # Randomly sample test users if there are too many\n",
    "    test_users = self.tst_users\n",
    "    if len(test_users) > max_test_users:\n",
    "        test_users = np.random.choice(test_users, max_test_users, replace=False)\n",
    "    \n",
    "    for user in test_users:\n",
    "        user = int(user)\n",
    "        pos_item = self.tst_int[user]\n",
    "        if pos_item is not None:\n",
    "            pos_item = int(pos_item)\n",
    "            test_instances.append([user, pos_item, 1.0])\n",
    "            \n",
    "            try:\n",
    "                # Get negative items\n",
    "                all_items = set(range(self.n_items))\n",
    "                pos_items = set(int(x) for x in self.trn_label[user].indices)\n",
    "                pos_items.add(pos_item)\n",
    "                neg_items_pool = list(all_items - pos_items)\n",
    "                \n",
    "                # Sample negative items\n",
    "                n_neg = min(num_neg_samples, len(neg_items_pool))\n",
    "                if n_neg > 0:\n",
    "                    neg_items = np.random.choice(neg_items_pool, size=n_neg, replace=False)\n",
    "                    for neg_item in neg_items:\n",
    "                        test_instances.append([user, int(neg_item), 0.0])\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing test user {user}: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    if not test_instances:\n",
    "        raise ValueError(\"No test instances were generated!\")\n",
    "    \n",
    "    test_instances = np.array(test_instances)\n",
    "    print(f\"Generated {len(test_instances)} test instances\")\n",
    "    print(f\"Number of unique users: {len(set(test_instances[:,0]))}\")\n",
    "    return test_instances\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Configuration\n",
    "    config = {\n",
    "        'd_model': 32,\n",
    "        'num_heads': 2,\n",
    "        'num_layers': 1,\n",
    "        'd_feedforward': 64,\n",
    "        'input_dim': 64,\n",
    "        'num_weights': 3,\n",
    "        'learning_rate': 0.001,\n",
    "        'weight_decay': 1e-6,\n",
    "        'dropout': 0.1,\n",
    "        'gradient_clip': 1.0,\n",
    "        'max_samples': MAX_U,\n",
    "        'eval_k': TOP_N\n",
    "    }\n",
    "    \n",
    "    print(\"Initializing dataset...\")\n",
    "    dataset = MultiBehaviorDataset(max_users=MAX_U)\n",
    "    train_data = dataset.prepare_train_instances(max_samples=config['max_samples'])\n",
    "    \n",
    "    print(f\"Using {len(train_data)} training instances\")\n",
    "\n",
    "    model = GraphTransformerV2(\n",
    "        num_layers=config['num_layers'],\n",
    "        d_model=config['d_model'],\n",
    "        num_heads=config['num_heads'],\n",
    "        d_feedforward=config['d_feedforward'],\n",
    "        input_dim=config['input_dim'],\n",
    "        num_weights=config['num_weights'],\n",
    "        dropout=config['dropout']\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "    print(\"Preparing training tensors...\")\n",
    "    users = torch.LongTensor(train_data[:, 0]).to(device)\n",
    "    items = torch.LongTensor(train_data[:, 1]).to(device)\n",
    "    labels = torch.FloatTensor(train_data[:, 2]).to(device)\n",
    "    behaviors = torch.FloatTensor(train_data[:, 3:]).to(device)\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    try:\n",
    "        model.train()\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        # Training\n",
    "        x = torch.cat([\n",
    "            behaviors,\n",
    "            torch.zeros(len(users), config['input_dim'] - behaviors.size(1), device=device)\n",
    "        ], dim=1)\n",
    "        \n",
    "        adj_matrix = dataset.create_adjacency_matrix(users)\n",
    "        graph_metrics = dataset.create_graph_metrics(users)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(x, adj_matrix, graph_metrics)\n",
    "        predictions = predictions.view(-1)\n",
    "        labels = labels.view(-1)\n",
    "        \n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), config['gradient_clip'])\n",
    "        optimizer.step()\n",
    "        \n",
    "        training_time = (datetime.now() - start_time).total_seconds()\n",
    "        print(f\"Training completed in {training_time:.2f}s\")\n",
    "        print(f\"Training loss: {loss.item():.4f}\")\n",
    "        \n",
    "        # Evaluation\n",
    "        print(\"\\nStarting evaluation...\")\n",
    "        eval_start_time = datetime.now()\n",
    "        \n",
    "        test_instances = dataset.get_test_instances()\n",
    "        hr, ndcg = evaluate_model(model, dataset, test_instances, k=config['eval_k'])\n",
    "        \n",
    "        eval_time = (datetime.now() - eval_start_time).total_seconds()\n",
    "        print(f\"Evaluation completed in {eval_time:.2f}s\")\n",
    "        print(f\"HR@{config['eval_k']}: {hr:.4f}\")\n",
    "        print(f\"NDCG@{config['eval_k']}: {ndcg:.4f}\")\n",
    "        \n",
    "        # Save results\n",
    "        results = {\n",
    "            'training_time': training_time,\n",
    "            'eval_time': eval_time,\n",
    "            'training_loss': loss.item(),\n",
    "            'hr': hr,\n",
    "            'ndcg': ndcg\n",
    "        }\n",
    "        \n",
    "        # Save to file\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        with open(f'results_{timestamp}.txt', 'w') as f:\n",
    "            for key, value in results.items():\n",
    "                f.write(f\"{key}: {value}\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during training: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing dataset...\n",
      "Loading training data from: /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/\n",
      "Loading behavior: pv from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_pv\n",
      "Loading behavior: cart from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_cart\n",
      "Loading behavior: buy from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_buy\n",
      "Dataset dimensions: 21716 users, 7977 items\n",
      "Loading test data from: /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/tst_int\n",
      "Using 5000 test users\n",
      "Preparing training instances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yf/20z1hn994jd04q4kl0gpgh740000gn/T/ipykernel_51372/232119517.py:145: DeprecationWarning: Please import `csr_matrix` from the `scipy.sparse` namespace; the `scipy.sparse.csr` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  mat = pickle.load(fs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 5001 training instances\n",
      "Using 5001 training instances\n",
      "Preparing training tensors...\n",
      "Starting training...\n",
      "Training completed in 97.93s\n",
      "Training loss: 6.3975\n",
      "\n",
      "Starting evaluation...\n",
      "Preparing test instances...\n",
      "Generated 500000 test instances\n",
      "Evaluating 500000 instances in 5000 chunks...\n",
      "Processing chunk 1/5000\n",
      "Processing chunk 51/5000\n",
      "Processing chunk 101/5000\n",
      "Processing chunk 151/5000\n",
      "Processing chunk 201/5000\n",
      "Processing chunk 251/5000\n",
      "Processing chunk 301/5000\n",
      "Processing chunk 351/5000\n",
      "Processing chunk 401/5000\n",
      "Processing chunk 451/5000\n",
      "Processing chunk 501/5000\n",
      "Processing chunk 551/5000\n",
      "Processing chunk 601/5000\n",
      "Processing chunk 651/5000\n",
      "Processing chunk 701/5000\n",
      "Processing chunk 751/5000\n",
      "Processing chunk 801/5000\n",
      "Processing chunk 851/5000\n",
      "Processing chunk 901/5000\n",
      "Processing chunk 951/5000\n",
      "Processing chunk 1001/5000\n",
      "Processing chunk 1051/5000\n",
      "Processing chunk 1101/5000\n",
      "Processing chunk 1151/5000\n",
      "Processing chunk 1201/5000\n",
      "Processing chunk 1251/5000\n",
      "Processing chunk 1301/5000\n",
      "Processing chunk 1351/5000\n",
      "Processing chunk 1401/5000\n",
      "Processing chunk 1451/5000\n",
      "Processing chunk 1501/5000\n",
      "Processing chunk 1551/5000\n",
      "Processing chunk 1601/5000\n",
      "Processing chunk 1651/5000\n",
      "Processing chunk 1701/5000\n",
      "Processing chunk 1751/5000\n",
      "Processing chunk 1801/5000\n",
      "Processing chunk 1851/5000\n",
      "Processing chunk 1901/5000\n",
      "Processing chunk 1951/5000\n",
      "Processing chunk 2001/5000\n",
      "Processing chunk 2051/5000\n",
      "Processing chunk 2101/5000\n",
      "Processing chunk 2151/5000\n",
      "Processing chunk 2201/5000\n",
      "Processing chunk 2251/5000\n",
      "Processing chunk 2301/5000\n",
      "Processing chunk 2351/5000\n",
      "Processing chunk 2401/5000\n",
      "Processing chunk 2451/5000\n",
      "Processing chunk 2501/5000\n",
      "Processing chunk 2551/5000\n",
      "Processing chunk 2601/5000\n",
      "Processing chunk 2651/5000\n",
      "Processing chunk 2701/5000\n",
      "Processing chunk 2751/5000\n",
      "Processing chunk 2801/5000\n",
      "Processing chunk 2851/5000\n",
      "Processing chunk 2901/5000\n",
      "Processing chunk 2951/5000\n",
      "Processing chunk 3001/5000\n",
      "Processing chunk 3051/5000\n",
      "Processing chunk 3101/5000\n",
      "Processing chunk 3151/5000\n",
      "Processing chunk 3201/5000\n",
      "Processing chunk 3251/5000\n",
      "Processing chunk 3301/5000\n",
      "Processing chunk 3351/5000\n",
      "Processing chunk 3401/5000\n",
      "Processing chunk 3451/5000\n",
      "Processing chunk 3501/5000\n",
      "Processing chunk 3551/5000\n",
      "Processing chunk 3601/5000\n",
      "Processing chunk 3651/5000\n",
      "Processing chunk 3701/5000\n",
      "Processing chunk 3751/5000\n",
      "Processing chunk 3801/5000\n",
      "Processing chunk 3851/5000\n",
      "Processing chunk 3901/5000\n",
      "Processing chunk 3951/5000\n",
      "Processing chunk 4001/5000\n",
      "Processing chunk 4051/5000\n",
      "Processing chunk 4101/5000\n",
      "Processing chunk 4151/5000\n",
      "Processing chunk 4201/5000\n",
      "Processing chunk 4251/5000\n",
      "Processing chunk 4301/5000\n",
      "Processing chunk 4351/5000\n",
      "Processing chunk 4401/5000\n",
      "Processing chunk 4451/5000\n",
      "Processing chunk 4501/5000\n",
      "Processing chunk 4551/5000\n",
      "Processing chunk 4601/5000\n",
      "Processing chunk 4651/5000\n",
      "Processing chunk 4701/5000\n",
      "Processing chunk 4751/5000\n",
      "Processing chunk 4801/5000\n",
      "Processing chunk 4851/5000\n",
      "Processing chunk 4901/5000\n",
      "Processing chunk 4951/5000\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 5000\n",
      "Number of hits: 5000\n",
      "Average HR@60: 1.0000\n",
      "Average NDCG@60: 0.8957\n",
      "Evaluation completed in 55.27s\n",
      "HR@60: 1.0000\n",
      "NDCG@60: 0.8957\n"
     ]
    }
   ],
   "source": [
    "USR=5000\n",
    "TOP_N=60\n",
    "\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import Linear, Dropout, LayerNorm\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import ModuleList\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from datetime import datetime\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "class GraphTransformerV2(nn.Module):\n",
    "    def __init__(self, num_layers, d_model, num_heads, d_feedforward, input_dim, num_weights=10, use_weights=True, dropout=0.1):\n",
    "        super(GraphTransformerV2, self).__init__()\n",
    "        self.num_weights = num_weights\n",
    "        self.use_weights = use_weights\n",
    "        self.input_dim = input_dim\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # Input projection layers\n",
    "        self.input_linear = Linear(input_dim, d_model)\n",
    "        self.dng_projection = Linear(input_dim, d_model)\n",
    "        \n",
    "        self.encoder_layer = TransformerEncoderLayer(\n",
    "            d_model=d_model, \n",
    "            nhead=num_heads, \n",
    "            dim_feedforward=d_feedforward, \n",
    "            dropout=dropout, \n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Final output layers\n",
    "        self.pre_output = Linear(d_model, d_model)\n",
    "        self.output_linear = Linear(d_model, 1)\n",
    "        \n",
    "        self.dropout = Dropout(dropout)\n",
    "        self.layer_norm = LayerNorm(d_model)\n",
    "        \n",
    "        if self.use_weights:\n",
    "            self.weight_linears = ModuleList([Linear(input_dim, d_model) for _ in range(num_weights)])\n",
    "\n",
    "    def compute_neighborhood_similarity(self, adjacency_matrix, x):\n",
    "        try:\n",
    "            binary_adj = (adjacency_matrix > 0).float()\n",
    "            intersection = binary_adj @ binary_adj.T\n",
    "            row_sums = binary_adj.sum(dim=1, keepdim=True)\n",
    "            col_sums = binary_adj.sum(dim=0, keepdim=True)\n",
    "            union = row_sums + col_sums.T - intersection\n",
    "            similarity = intersection / (union + 1e-8)\n",
    "            return similarity @ x\n",
    "        except RuntimeError:\n",
    "            return torch.zeros_like(x)\n",
    "\n",
    "    def project_graph_metrics(self, graph_metrics, target_dim):\n",
    "        if graph_metrics.size(1) < target_dim:\n",
    "            repeats = (target_dim + graph_metrics.size(1) - 1) // graph_metrics.size(1)\n",
    "            graph_metrics = graph_metrics.repeat(1, repeats)[:, :target_dim]\n",
    "        elif graph_metrics.size(1) > target_dim:\n",
    "            graph_metrics = graph_metrics[:, :target_dim]\n",
    "        return graph_metrics\n",
    "\n",
    "    def forward(self, x, adjacency_matrix, graph_metrics, weights=None):\n",
    "        adjacency_matrix = adjacency_matrix.float()\n",
    "        graph_metrics = graph_metrics.float()\n",
    "        batch_size, input_dim = x.shape\n",
    "        \n",
    "        if adjacency_matrix.size(0) != batch_size or adjacency_matrix.size(1) != batch_size:\n",
    "            adjacency_matrix = torch.eye(batch_size, device=x.device)\n",
    "\n",
    "        try:\n",
    "            # Direct connections\n",
    "            direct_scores = adjacency_matrix @ x\n",
    "            \n",
    "            # Neighborhood similarity\n",
    "            neighborhood_similarity = self.compute_neighborhood_similarity(adjacency_matrix, x)\n",
    "            \n",
    "            # Graph structure scores\n",
    "            if graph_metrics.dim() == 2:\n",
    "                graph_metrics_projected = self.project_graph_metrics(graph_metrics, input_dim)\n",
    "                graph_structure_scores = graph_metrics_projected * x\n",
    "            else:\n",
    "                graph_structure_scores = torch.zeros_like(x)\n",
    "\n",
    "            # Combine DNG scores and project to d_model dimension\n",
    "            dng_scores = direct_scores + neighborhood_similarity + graph_structure_scores\n",
    "            dng_scores = self.dng_projection(dng_scores)  # Project to d_model dimension\n",
    "            \n",
    "            # Process input through transformer\n",
    "            if self.use_weights and weights is not None:\n",
    "                weighted_x = torch.zeros_like(x)\n",
    "                for i, weight in enumerate(weights.T):\n",
    "                    weighted_x += self.weight_linears[i](x) * weight.unsqueeze(1)\n",
    "                transformer_input = weighted_x\n",
    "            else:\n",
    "                transformer_input = self.input_linear(x)  # Project to d_model dimension\n",
    "\n",
    "            # Apply transformer\n",
    "            transformer_input = self.layer_norm(transformer_input)\n",
    "            transformer_output = self.transformer_encoder(transformer_input.unsqueeze(1)).squeeze(1)\n",
    "            \n",
    "            # Combine transformer output with DNG scores\n",
    "            combined = transformer_output + dng_scores\n",
    "            combined = self.dropout(combined)\n",
    "            \n",
    "            # Final output processing\n",
    "            output = self.pre_output(combined)\n",
    "            output = F.relu(output)\n",
    "            output = self.output_linear(output)\n",
    "            \n",
    "            return output.squeeze(-1)  # Return [batch_size] tensor\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            print(f\"RuntimeError during forward pass: {e}\")\n",
    "            print(f\"x shape: {x.shape}, adjacency_matrix shape: {adjacency_matrix.shape}, graph_metrics shape: {graph_metrics.shape}\")\n",
    "            raise\n",
    "\n",
    "# cropped dataset\n",
    "class MultiBehaviorDataset:\n",
    "    def __init__(self, data_path='/Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/', max_users=10000):\n",
    "        self.data_path = data_path\n",
    "        self.behaviors = ['pv', 'cart', 'buy']\n",
    "        self.trn_file = data_path + 'trn_'\n",
    "        self.tst_file = data_path + 'tst_'\n",
    "        self.max_users = max_users  # Limit number of users\n",
    "        \n",
    "        self.load_training_data()\n",
    "        self.load_test_data()\n",
    "    \n",
    "    def load_training_data(self):\n",
    "        print(\"Loading training data from:\", self.data_path)\n",
    "        self.trn_mats = []\n",
    "        for beh in self.behaviors:\n",
    "            path = self.trn_file + beh\n",
    "            print(f\"Loading behavior: {beh} from {path}\")\n",
    "            if not os.path.exists(path):\n",
    "                raise FileNotFoundError(f\"File not found: {path}\")\n",
    "            with open(path, 'rb') as fs:\n",
    "                mat = pickle.load(fs)\n",
    "                if not isinstance(mat, csr_matrix):\n",
    "                    mat = csr_matrix(mat)\n",
    "                mat = (mat != 0).astype(np.float32)\n",
    "                self.trn_mats.append(mat)\n",
    "        \n",
    "        self.trn_label = 1 * (self.trn_mats[-1] != 0)\n",
    "        self.n_users, self.n_items = self.trn_mats[0].shape\n",
    "        self.n_behaviors = len(self.behaviors)\n",
    "        print(f\"Dataset dimensions: {self.n_users} users, {self.n_items} items\")\n",
    "\n",
    "    def create_adjacency_matrix(self, users):\n",
    "        \"\"\"Optimized adjacency matrix creation\"\"\"\n",
    "        batch_size = len(users)\n",
    "        adj_matrix = torch.zeros(batch_size, batch_size, device=device)\n",
    "        \n",
    "        # Pre-compute user item sets\n",
    "        user_item_sets = []\n",
    "        for user in users:\n",
    "            user_items = set()\n",
    "            for mat in self.trn_mats:\n",
    "                user_items.update(mat[user].indices)\n",
    "            user_item_sets.append(user_items)\n",
    "        \n",
    "        # Compute similarities in parallel\n",
    "        for i in range(batch_size):\n",
    "            if not user_item_sets[i]:\n",
    "                continue\n",
    "            for j in range(i+1, batch_size):\n",
    "                if user_item_sets[j]:\n",
    "                    jaccard = len(user_item_sets[i] & user_item_sets[j]) / len(user_item_sets[i] | user_item_sets[j])\n",
    "                    adj_matrix[i,j] = adj_matrix[j,i] = jaccard\n",
    "        \n",
    "        return adj_matrix\n",
    "\n",
    "    def create_graph_metrics(self, users):\n",
    "        \"\"\"Optimized graph metrics creation\"\"\"\n",
    "        metrics = torch.zeros(len(users), 3, device=device)\n",
    "        \n",
    "        # Vectorized computation\n",
    "        for i, user in enumerate(users):\n",
    "            interactions = np.array([mat[user].nnz for mat in self.trn_mats])\n",
    "            metrics[i,0] = sum(interactions) / 100\n",
    "            metrics[i,1] = (interactions > 0).sum() / len(self.behaviors)\n",
    "            metrics[i,2] = interactions[-1] / max(interactions[0], 1)\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "    def prepare_train_instances(self, max_samples=5000):\n",
    "        \"\"\"Optimized training instance preparation\"\"\"\n",
    "        print(\"Preparing training instances...\")\n",
    "        train_data = []\n",
    "        \n",
    "        # Randomly select users\n",
    "        selected_users = np.random.choice(min(self.n_users, self.max_users), size=min(1000, self.max_users), replace=False)\n",
    "        \n",
    "        for user in selected_users:\n",
    "            pos_items = self.trn_label[user].indices[:2]  # Limit positive items\n",
    "            \n",
    "            if len(pos_items) > 0:\n",
    "                for item in pos_items:\n",
    "                    behaviors = [float(mat[user, item]) for mat in self.trn_mats]\n",
    "                    train_data.append([user, item, 1.0] + behaviors)\n",
    "                    \n",
    "                    # Limited negative sampling\n",
    "                    neg_items = np.random.choice(self.n_items, size=2, replace=False)\n",
    "                    for neg_item in neg_items:\n",
    "                        behaviors = [float(mat[user, neg_item]) for mat in self.trn_mats]\n",
    "                        train_data.append([user, neg_item, 0.0] + behaviors)\n",
    "                        \n",
    "                    if len(train_data) >= max_samples:\n",
    "                        break\n",
    "            \n",
    "            if len(train_data) >= max_samples:\n",
    "                break\n",
    "        \n",
    "        print(f\"Generated {len(train_data)} training instances\")\n",
    "        return np.array(train_data)\n",
    "    \n",
    "    def load_test_data(self):\n",
    "        \"\"\"Load test data\"\"\"\n",
    "        test_path = self.tst_file + 'int'\n",
    "        print(f\"Loading test data from: {test_path}\")\n",
    "        if not os.path.exists(test_path):\n",
    "            raise FileNotFoundError(f\"File not found: {test_path}\")\n",
    "        with open(test_path, 'rb') as fs:\n",
    "            self.tst_int = np.array(pickle.load(fs))\n",
    "        \n",
    "        self.tst_users = np.reshape(np.argwhere(self.tst_int != None), [-1])\n",
    "        # Limit test users for faster processing\n",
    "        self.tst_users = self.tst_users[:min(len(self.tst_users), self.max_users)]\n",
    "        print(f\"Using {len(self.tst_users)} test users\")\n",
    "\n",
    "    def get_test_instances(self, num_neg_samples=99):\n",
    "        \"\"\"Generate test instances with negative sampling\"\"\"\n",
    "        print(\"Preparing test instances...\")\n",
    "        test_instances = []\n",
    "        \n",
    "        for user in self.tst_users:\n",
    "            pos_item = self.tst_int[user]\n",
    "            if pos_item is not None:\n",
    "                # Add positive instance\n",
    "                test_instances.append([user, pos_item, 1.0])\n",
    "                \n",
    "                # Add negative instances\n",
    "                try:\n",
    "                    # Get all items and remove positive items\n",
    "                    all_items = set(range(self.n_items))\n",
    "                    pos_items_train = set(self.trn_label[user].indices)\n",
    "                    pos_items_train.add(pos_item)\n",
    "                    neg_items_pool = list(all_items - pos_items_train)\n",
    "                    \n",
    "                    # Sample negative items\n",
    "                    n_neg = min(num_neg_samples, len(neg_items_pool))\n",
    "                    if n_neg > 0:\n",
    "                        neg_items = np.random.choice(neg_items_pool, size=n_neg, replace=False)\n",
    "                        for neg_item in neg_items:\n",
    "                            test_instances.append([user, neg_item, 0.0])\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing test user {user}: {str(e)}\")\n",
    "                    continue\n",
    "                \n",
    "                # Limit the number of test instances for faster processing\n",
    "                if len(test_instances) >= self.max_users * 100:\n",
    "                    break\n",
    "        \n",
    "        if not test_instances:\n",
    "            raise ValueError(\"No test instances were generated!\")\n",
    "            \n",
    "        test_instances = np.array(test_instances)\n",
    "        print(f\"Generated {len(test_instances)} test instances\")\n",
    "        return test_instances\n",
    "\n",
    "def evaluate_model(model, dataset, test_instances, k=10):\n",
    "    \"\"\"Improved evaluation function with better metrics calculation\"\"\"\n",
    "    model.eval()\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    \n",
    "    # Process test instances in smaller chunks\n",
    "    chunk_size =100\n",
    "    test_chunks = [test_instances[i:i + chunk_size] for i in range(0, len(test_instances), chunk_size)]\n",
    "    \n",
    "    print(f\"Evaluating {len(test_instances)} instances in {len(test_chunks)} chunks...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for chunk_idx, chunk in enumerate(test_chunks):\n",
    "            if chunk_idx % 50 == 0:  # Reduced frequency of progress updates\n",
    "                print(f\"Processing chunk {chunk_idx + 1}/{len(test_chunks)}\")\n",
    "            \n",
    "            # Group by user and ensure we have both positive and negative items\n",
    "            user_items = {}\n",
    "            for inst in chunk:\n",
    "                user = int(inst[0])\n",
    "                item = int(inst[1])\n",
    "                label = float(inst[2])\n",
    "                \n",
    "                if user not in user_items:\n",
    "                    user_items[user] = {'pos': [], 'neg': [], 'all_items': [], 'all_scores': []}\n",
    "                \n",
    "                user_items[user]['all_items'].append(item)\n",
    "                if label > 0.5:\n",
    "                    user_items[user]['pos'].append(item)\n",
    "                else:\n",
    "                    user_items[user]['neg'].append(item)\n",
    "            \n",
    "            # Process each user that has both positive and negative items\n",
    "            for user, data in user_items.items():\n",
    "                if not data['pos'] or not data['neg']:\n",
    "                    continue\n",
    "                \n",
    "                items = data['all_items']\n",
    "                batch_size = len(items)\n",
    "                \n",
    "                # Create input features\n",
    "                behaviors = torch.zeros(batch_size, dataset.n_behaviors, device=device)\n",
    "                for i, item in enumerate(items):\n",
    "                    for j, mat in enumerate(dataset.trn_mats):\n",
    "                        behaviors[i, j] = float(mat[user, item])\n",
    "                \n",
    "                x = torch.cat([\n",
    "                    behaviors,\n",
    "                    torch.zeros(batch_size, model.input_dim - behaviors.size(1), device=device)\n",
    "                ], dim=1)\n",
    "                \n",
    "                # Simplified adjacency matrix for evaluation\n",
    "                adj_matrix = torch.eye(batch_size, device=device)\n",
    "                graph_metrics = dataset.create_graph_metrics([user] * batch_size)\n",
    "                \n",
    "                try:\n",
    "                    predictions = model(x, adj_matrix, graph_metrics)\n",
    "                    predictions = predictions.cpu().numpy().flatten()\n",
    "                    \n",
    "                    # Store all scores\n",
    "                    for item, score in zip(items, predictions):\n",
    "                        data['all_scores'].append((item, score))\n",
    "                    \n",
    "                    # Sort items by score\n",
    "                    sorted_items = [x[0] for x in sorted(data['all_scores'], key=lambda x: x[1], reverse=True)]\n",
    "                    recommended_items = sorted_items[:k]\n",
    "                    \n",
    "                    # Calculate HR\n",
    "                    hit = False\n",
    "                    for pos_item in data['pos']:\n",
    "                        if pos_item in recommended_items:\n",
    "                            hit = True\n",
    "                            break\n",
    "                    hits.append(hit)\n",
    "                    \n",
    "                    # Calculate NDCG\n",
    "                    dcg = 0\n",
    "                    idcg = 1  # Ideal DCG for one relevant item\n",
    "                    for i, item in enumerate(recommended_items):\n",
    "                        if item in data['pos']:\n",
    "                            dcg += 1 / np.log2(i + 2)\n",
    "                    ndcg = dcg / idcg\n",
    "                    ndcgs.append(ndcg)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error evaluating user {user}: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    hr = np.mean(hits) if hits else 0\n",
    "    ndcg = np.mean(ndcgs) if ndcgs else 0\n",
    "    \n",
    "    # Print detailed statistics\n",
    "    print(f\"\\nEvaluation Statistics:\")\n",
    "    print(f\"Total users evaluated: {len(hits)}\")\n",
    "    print(f\"Number of hits: {sum(hits)}\")\n",
    "    print(f\"Average HR@{k}: {hr:.4f}\")\n",
    "    print(f\"Average NDCG@{k}: {ndcg:.4f}\")\n",
    "    \n",
    "    return hr, ndcg\n",
    "\n",
    "def get_test_instances(self, num_neg_samples=99):\n",
    "    \"\"\"Improved test instance generation\"\"\"\n",
    "    print(\"Preparing test instances...\")\n",
    "    test_instances = []\n",
    "    max_test_users = 1000  # Limit number of test users\n",
    "    \n",
    "    # Randomly sample test users if there are too many\n",
    "    test_users = self.tst_users\n",
    "    if len(test_users) > max_test_users:\n",
    "        test_users = np.random.choice(test_users, max_test_users, replace=False)\n",
    "    \n",
    "    for user in test_users:\n",
    "        user = int(user)\n",
    "        pos_item = self.tst_int[user]\n",
    "        if pos_item is not None:\n",
    "            pos_item = int(pos_item)\n",
    "            test_instances.append([user, pos_item, 1.0])\n",
    "            \n",
    "            try:\n",
    "                # Get negative items\n",
    "                all_items = set(range(self.n_items))\n",
    "                pos_items = set(int(x) for x in self.trn_label[user].indices)\n",
    "                pos_items.add(pos_item)\n",
    "                neg_items_pool = list(all_items - pos_items)\n",
    "                \n",
    "                # Sample negative items\n",
    "                n_neg = min(num_neg_samples, len(neg_items_pool))\n",
    "                if n_neg > 0:\n",
    "                    neg_items = np.random.choice(neg_items_pool, size=n_neg, replace=False)\n",
    "                    for neg_item in neg_items:\n",
    "                        test_instances.append([user, int(neg_item), 0.0])\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing test user {user}: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    if not test_instances:\n",
    "        raise ValueError(\"No test instances were generated!\")\n",
    "    \n",
    "    test_instances = np.array(test_instances)\n",
    "    print(f\"Generated {len(test_instances)} test instances\")\n",
    "    print(f\"Number of unique users: {len(set(test_instances[:,0]))}\")\n",
    "    return test_instances\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Configuration\n",
    "    config = {\n",
    "        'd_model': 32,\n",
    "        'num_heads': 2,\n",
    "        'num_layers': 1,\n",
    "        'd_feedforward': 64,\n",
    "        'input_dim': 64,\n",
    "        'num_weights': 3,\n",
    "        'learning_rate': 0.001,\n",
    "        'weight_decay': 1e-6,\n",
    "        'dropout': 0.1,\n",
    "        'gradient_clip': 1.0,\n",
    "        'max_samples': USR,\n",
    "        'eval_k': TOP_N\n",
    "    }\n",
    "    \n",
    "    print(\"Initializing dataset...\")\n",
    "    dataset = MultiBehaviorDataset(max_users=USR)\n",
    "    train_data = dataset.prepare_train_instances(max_samples=config['max_samples'])\n",
    "    \n",
    "    print(f\"Using {len(train_data)} training instances\")\n",
    "\n",
    "    model = GraphTransformerV2(\n",
    "        num_layers=config['num_layers'],\n",
    "        d_model=config['d_model'],\n",
    "        num_heads=config['num_heads'],\n",
    "        d_feedforward=config['d_feedforward'],\n",
    "        input_dim=config['input_dim'],\n",
    "        num_weights=config['num_weights'],\n",
    "        dropout=config['dropout']\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "    print(\"Preparing training tensors...\")\n",
    "    users = torch.LongTensor(train_data[:, 0]).to(device)\n",
    "    items = torch.LongTensor(train_data[:, 1]).to(device)\n",
    "    labels = torch.FloatTensor(train_data[:, 2]).to(device)\n",
    "    behaviors = torch.FloatTensor(train_data[:, 3:]).to(device)\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    try:\n",
    "        model.train()\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        # Training\n",
    "        x = torch.cat([\n",
    "            behaviors,\n",
    "            torch.zeros(len(users), config['input_dim'] - behaviors.size(1), device=device)\n",
    "        ], dim=1)\n",
    "        \n",
    "        adj_matrix = dataset.create_adjacency_matrix(users)\n",
    "        graph_metrics = dataset.create_graph_metrics(users)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(x, adj_matrix, graph_metrics)\n",
    "        predictions = predictions.view(-1)\n",
    "        labels = labels.view(-1)\n",
    "        \n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), config['gradient_clip'])\n",
    "        optimizer.step()\n",
    "        \n",
    "        training_time = (datetime.now() - start_time).total_seconds()\n",
    "        print(f\"Training completed in {training_time:.2f}s\")\n",
    "        print(f\"Training loss: {loss.item():.4f}\")\n",
    "        \n",
    "        # Evaluation\n",
    "        print(\"\\nStarting evaluation...\")\n",
    "        eval_start_time = datetime.now()\n",
    "        \n",
    "        test_instances = dataset.get_test_instances()\n",
    "        hr, ndcg = evaluate_model(model, dataset, test_instances, k=config['eval_k'])\n",
    "        \n",
    "        eval_time = (datetime.now() - eval_start_time).total_seconds()\n",
    "        print(f\"Evaluation completed in {eval_time:.2f}s\")\n",
    "        print(f\"HR@{config['eval_k']}: {hr:.4f}\")\n",
    "        print(f\"NDCG@{config['eval_k']}: {ndcg:.4f}\")\n",
    "        \n",
    "        # Save results\n",
    "        results = {\n",
    "            'training_time': training_time,\n",
    "            'eval_time': eval_time,\n",
    "            'training_loss': loss.item(),\n",
    "            'hr': hr,\n",
    "            'ndcg': ndcg\n",
    "        }\n",
    "        \n",
    "        # Save to file\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        with open(f'results_{timestamp}.txt', 'w') as f:\n",
    "            for key, value in results.items():\n",
    "                f.write(f\"{key}: {value}\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during training: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GT with execT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing dataset...\n",
      "Loading training data from: /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/\n",
      "Loading behavior: pv from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_pv\n",
      "Loading behavior: cart from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_cart\n",
      "Loading behavior: buy from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_buy\n",
      "Dataset dimensions: 21716 users, 7977 items\n",
      "Loading test data from: /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/tst_int\n",
      "Using 10000 test users\n",
      "Preparing training instances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yf/20z1hn994jd04q4kl0gpgh740000gn/T/ipykernel_61723/3765390631.py:142: DeprecationWarning: Please import `csr_matrix` from the `scipy.sparse` namespace; the `scipy.sparse.csr` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  mat = pickle.load(fs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 6000 training instances\n",
      "Using 6000 training instances\n",
      "Preparing training tensors...\n",
      "Starting training...\n",
      "Training completed in 177.16s\n",
      "Training loss: 35.3388\n",
      "\n",
      "Starting evaluation...\n",
      "Preparing test instances...\n",
      "Generated 1000000 test instances\n",
      "Evaluating 1000000 instances in 10000 chunks...\n",
      "Processing chunk 1/10000\n",
      "Processing chunk 51/10000\n",
      "Processing chunk 101/10000\n",
      "Processing chunk 151/10000\n",
      "Processing chunk 201/10000\n",
      "Processing chunk 251/10000\n",
      "Processing chunk 301/10000\n",
      "Processing chunk 351/10000\n",
      "Processing chunk 401/10000\n",
      "Processing chunk 451/10000\n",
      "Processing chunk 501/10000\n",
      "Processing chunk 551/10000\n",
      "Processing chunk 601/10000\n",
      "Processing chunk 651/10000\n",
      "Processing chunk 701/10000\n",
      "Processing chunk 751/10000\n",
      "Processing chunk 801/10000\n",
      "Processing chunk 851/10000\n",
      "Processing chunk 901/10000\n",
      "Processing chunk 951/10000\n",
      "Processing chunk 1001/10000\n",
      "Processing chunk 1051/10000\n",
      "Processing chunk 1101/10000\n",
      "Processing chunk 1151/10000\n",
      "Processing chunk 1201/10000\n",
      "Processing chunk 1251/10000\n",
      "Processing chunk 1301/10000\n",
      "Processing chunk 1351/10000\n",
      "Processing chunk 1401/10000\n",
      "Processing chunk 1451/10000\n",
      "Processing chunk 1501/10000\n",
      "Processing chunk 1551/10000\n",
      "Processing chunk 1601/10000\n",
      "Processing chunk 1651/10000\n",
      "Processing chunk 1701/10000\n",
      "Processing chunk 1751/10000\n",
      "Processing chunk 1801/10000\n",
      "Processing chunk 1851/10000\n",
      "Processing chunk 1901/10000\n",
      "Processing chunk 1951/10000\n",
      "Processing chunk 2001/10000\n",
      "Processing chunk 2051/10000\n",
      "Processing chunk 2101/10000\n",
      "Processing chunk 2151/10000\n",
      "Processing chunk 2201/10000\n",
      "Processing chunk 2251/10000\n",
      "Processing chunk 2301/10000\n",
      "Processing chunk 2351/10000\n",
      "Processing chunk 2401/10000\n",
      "Processing chunk 2451/10000\n",
      "Processing chunk 2501/10000\n",
      "Processing chunk 2551/10000\n",
      "Processing chunk 2601/10000\n",
      "Processing chunk 2651/10000\n",
      "Processing chunk 2701/10000\n",
      "Processing chunk 2751/10000\n",
      "Processing chunk 2801/10000\n",
      "Processing chunk 2851/10000\n",
      "Processing chunk 2901/10000\n",
      "Processing chunk 2951/10000\n",
      "Processing chunk 3001/10000\n",
      "Processing chunk 3051/10000\n",
      "Processing chunk 3101/10000\n",
      "Processing chunk 3151/10000\n",
      "Processing chunk 3201/10000\n",
      "Processing chunk 3251/10000\n",
      "Processing chunk 3301/10000\n",
      "Processing chunk 3351/10000\n",
      "Processing chunk 3401/10000\n",
      "Processing chunk 3451/10000\n",
      "Processing chunk 3501/10000\n",
      "Processing chunk 3551/10000\n",
      "Processing chunk 3601/10000\n",
      "Processing chunk 3651/10000\n",
      "Processing chunk 3701/10000\n",
      "Processing chunk 3751/10000\n",
      "Processing chunk 3801/10000\n",
      "Processing chunk 3851/10000\n",
      "Processing chunk 3901/10000\n",
      "Processing chunk 3951/10000\n",
      "Processing chunk 4001/10000\n",
      "Processing chunk 4051/10000\n",
      "Processing chunk 4101/10000\n",
      "Processing chunk 4151/10000\n",
      "Processing chunk 4201/10000\n",
      "Processing chunk 4251/10000\n",
      "Processing chunk 4301/10000\n",
      "Processing chunk 4351/10000\n",
      "Processing chunk 4401/10000\n",
      "Processing chunk 4451/10000\n",
      "Processing chunk 4501/10000\n",
      "Processing chunk 4551/10000\n",
      "Processing chunk 4601/10000\n",
      "Processing chunk 4651/10000\n",
      "Processing chunk 4701/10000\n",
      "Processing chunk 4751/10000\n",
      "Processing chunk 4801/10000\n",
      "Processing chunk 4851/10000\n",
      "Processing chunk 4901/10000\n",
      "Processing chunk 4951/10000\n",
      "Processing chunk 5001/10000\n",
      "Processing chunk 5051/10000\n",
      "Processing chunk 5101/10000\n",
      "Processing chunk 5151/10000\n",
      "Processing chunk 5201/10000\n",
      "Processing chunk 5251/10000\n",
      "Processing chunk 5301/10000\n",
      "Processing chunk 5351/10000\n",
      "Processing chunk 5401/10000\n",
      "Processing chunk 5451/10000\n",
      "Processing chunk 5501/10000\n",
      "Processing chunk 5551/10000\n",
      "Processing chunk 5601/10000\n",
      "Processing chunk 5651/10000\n",
      "Processing chunk 5701/10000\n",
      "Processing chunk 5751/10000\n",
      "Processing chunk 5801/10000\n",
      "Processing chunk 5851/10000\n",
      "Processing chunk 5901/10000\n",
      "Processing chunk 5951/10000\n",
      "Processing chunk 6001/10000\n",
      "Processing chunk 6051/10000\n",
      "Processing chunk 6101/10000\n",
      "Processing chunk 6151/10000\n",
      "Processing chunk 6201/10000\n",
      "Processing chunk 6251/10000\n",
      "Processing chunk 6301/10000\n",
      "Processing chunk 6351/10000\n",
      "Processing chunk 6401/10000\n",
      "Processing chunk 6451/10000\n",
      "Processing chunk 6501/10000\n",
      "Processing chunk 6551/10000\n",
      "Processing chunk 6601/10000\n",
      "Processing chunk 6651/10000\n",
      "Processing chunk 6701/10000\n",
      "Processing chunk 6751/10000\n",
      "Processing chunk 6801/10000\n",
      "Processing chunk 6851/10000\n",
      "Processing chunk 6901/10000\n",
      "Processing chunk 6951/10000\n",
      "Processing chunk 7001/10000\n",
      "Processing chunk 7051/10000\n",
      "Processing chunk 7101/10000\n",
      "Processing chunk 7151/10000\n",
      "Processing chunk 7201/10000\n",
      "Processing chunk 7251/10000\n",
      "Processing chunk 7301/10000\n",
      "Processing chunk 7351/10000\n",
      "Processing chunk 7401/10000\n",
      "Processing chunk 7451/10000\n",
      "Processing chunk 7501/10000\n",
      "Processing chunk 7551/10000\n",
      "Processing chunk 7601/10000\n",
      "Processing chunk 7651/10000\n",
      "Processing chunk 7701/10000\n",
      "Processing chunk 7751/10000\n",
      "Processing chunk 7801/10000\n",
      "Processing chunk 7851/10000\n",
      "Processing chunk 7901/10000\n",
      "Processing chunk 7951/10000\n",
      "Processing chunk 8001/10000\n",
      "Processing chunk 8051/10000\n",
      "Processing chunk 8101/10000\n",
      "Processing chunk 8151/10000\n",
      "Processing chunk 8201/10000\n",
      "Processing chunk 8251/10000\n",
      "Processing chunk 8301/10000\n",
      "Processing chunk 8351/10000\n",
      "Processing chunk 8401/10000\n",
      "Processing chunk 8451/10000\n",
      "Processing chunk 8501/10000\n",
      "Processing chunk 8551/10000\n",
      "Processing chunk 8601/10000\n",
      "Processing chunk 8651/10000\n",
      "Processing chunk 8701/10000\n",
      "Processing chunk 8751/10000\n",
      "Processing chunk 8801/10000\n",
      "Processing chunk 8851/10000\n",
      "Processing chunk 8901/10000\n",
      "Processing chunk 8951/10000\n",
      "Processing chunk 9001/10000\n",
      "Processing chunk 9051/10000\n",
      "Processing chunk 9101/10000\n",
      "Processing chunk 9151/10000\n",
      "Processing chunk 9201/10000\n",
      "Processing chunk 9251/10000\n",
      "Processing chunk 9301/10000\n",
      "Processing chunk 9351/10000\n",
      "Processing chunk 9401/10000\n",
      "Processing chunk 9451/10000\n",
      "Processing chunk 9501/10000\n",
      "Processing chunk 9551/10000\n",
      "Processing chunk 9601/10000\n",
      "Processing chunk 9651/10000\n",
      "Processing chunk 9701/10000\n",
      "Processing chunk 9751/10000\n",
      "Processing chunk 9801/10000\n",
      "Processing chunk 9851/10000\n",
      "Processing chunk 9901/10000\n",
      "Processing chunk 9951/10000\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 10000\n",
      "Number of hits: 9631\n",
      "Average HR@10: 0.9631\n",
      "Average NDCG@10: 0.9395\n",
      "Evaluation completed in 126.07s\n",
      "HR@10: 0.9631\n",
      "NDCG@10: 0.9395\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import Linear, Dropout, LayerNorm\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import ModuleList\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from datetime import datetime\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Define the GraphTransformerV2 class\n",
    "class GraphTransformerV2(nn.Module):\n",
    "    def __init__(self, num_layers, d_model, num_heads, d_feedforward, input_dim, num_weights=10, use_weights=True, dropout=0.1):\n",
    "        super(GraphTransformerV2, self).__init__()\n",
    "        self.num_weights = num_weights\n",
    "        self.use_weights = use_weights\n",
    "        self.input_dim = input_dim\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # Input projection layers\n",
    "        self.input_linear = Linear(input_dim, d_model)\n",
    "        self.dng_projection = Linear(input_dim, d_model)\n",
    "        \n",
    "        self.encoder_layer = TransformerEncoderLayer(\n",
    "            d_model=d_model, \n",
    "            nhead=num_heads, \n",
    "            dim_feedforward=d_feedforward, \n",
    "            dropout=dropout, \n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Final output layers\n",
    "        self.pre_output = Linear(d_model, d_model)\n",
    "        self.output_linear = Linear(d_model, 1)\n",
    "        \n",
    "        self.dropout = Dropout(dropout)\n",
    "        self.layer_norm = LayerNorm(d_model)\n",
    "        \n",
    "        if self.use_weights:\n",
    "            self.weight_linears = ModuleList([Linear(input_dim, d_model) for _ in range(num_weights)])\n",
    "\n",
    "    def compute_neighborhood_similarity(self, adjacency_matrix, x):\n",
    "        try:\n",
    "            binary_adj = (adjacency_matrix > 0).float()\n",
    "            intersection = binary_adj @ binary_adj.T\n",
    "            row_sums = binary_adj.sum(dim=1, keepdim=True)\n",
    "            col_sums = binary_adj.sum(dim=0, keepdim=True)\n",
    "            union = row_sums + col_sums.T - intersection\n",
    "            similarity = intersection / (union + 1e-8)\n",
    "            return similarity @ x\n",
    "        except RuntimeError:\n",
    "            return torch.zeros_like(x)\n",
    "\n",
    "    def project_graph_metrics(self, graph_metrics, target_dim):\n",
    "        if graph_metrics.size(1) < target_dim:\n",
    "            repeats = (target_dim + graph_metrics.size(1) - 1) // graph_metrics.size(1)\n",
    "            graph_metrics = graph_metrics.repeat(1, repeats)[:, :target_dim]\n",
    "        elif graph_metrics.size(1) > target_dim:\n",
    "            graph_metrics = graph_metrics[:, :target_dim]\n",
    "        return graph_metrics\n",
    "\n",
    "    def forward(self, x, adjacency_matrix, graph_metrics, weights=None):\n",
    "        adjacency_matrix = adjacency_matrix.float()\n",
    "        graph_metrics = graph_metrics.float()\n",
    "        batch_size, input_dim = x.shape\n",
    "        \n",
    "        if adjacency_matrix.size(0) != batch_size or adjacency_matrix.size(1) != batch_size:\n",
    "            adjacency_matrix = torch.eye(batch_size, device=x.device)\n",
    "\n",
    "        try:\n",
    "            # Direct connections\n",
    "            direct_scores = adjacency_matrix @ x\n",
    "            \n",
    "            # Neighborhood similarity\n",
    "            neighborhood_similarity = self.compute_neighborhood_similarity(adjacency_matrix, x)\n",
    "            \n",
    "            # Graph structure scores\n",
    "            if graph_metrics.dim() == 2:\n",
    "                graph_metrics_projected = self.project_graph_metrics(graph_metrics, input_dim)\n",
    "                graph_structure_scores = graph_metrics_projected * x\n",
    "            else:\n",
    "                graph_structure_scores = torch.zeros_like(x)\n",
    "\n",
    "            # Combine DNG scores and project to d_model dimension\n",
    "            dng_scores = direct_scores + neighborhood_similarity + graph_structure_scores\n",
    "            dng_scores = self.dng_projection(dng_scores)  # Project to d_model dimension\n",
    "            \n",
    "            # Process input through transformer\n",
    "            if self.use_weights and weights is not None:\n",
    "                weighted_x = torch.zeros_like(x)\n",
    "                for i, weight in enumerate(weights.T):\n",
    "                    weighted_x += self.weight_linears[i](x) * weight.unsqueeze(1)\n",
    "                transformer_input = weighted_x\n",
    "            else:\n",
    "                transformer_input = self.input_linear(x)  # Project to d_model dimension\n",
    "\n",
    "            # Apply transformer\n",
    "            transformer_input = self.layer_norm(transformer_input)\n",
    "            transformer_output = self.transformer_encoder(transformer_input.unsqueeze(1)).squeeze(1)\n",
    "            \n",
    "            # Combine transformer output with DNG scores\n",
    "            combined = transformer_output + dng_scores\n",
    "            combined = self.dropout(combined)\n",
    "            \n",
    "            # Final output processing\n",
    "            output = self.pre_output(combined)\n",
    "            output = F.relu(output)\n",
    "            output = self.output_linear(output)\n",
    "            \n",
    "            return output.squeeze(-1)  # Return [batch_size] tensor\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            print(f\"RuntimeError during forward pass: {e}\")\n",
    "            print(f\"x shape: {x.shape}, adjacency_matrix shape: {adjacency_matrix.shape}, graph_metrics shape: {graph_metrics.shape}\")\n",
    "            raise\n",
    "\n",
    "# Define the MultiBehaviorDataset class\n",
    "class MultiBehaviorDataset:\n",
    "    def __init__(self, data_path='/Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/', max_users=10000):\n",
    "        self.data_path = data_path\n",
    "        self.behaviors = ['pv', 'cart', 'buy']\n",
    "        self.trn_file = data_path + 'trn_'\n",
    "        self.tst_file = data_path + 'tst_'\n",
    "        self.max_users = max_users  # Limit number of users\n",
    "        \n",
    "        self.load_training_data()\n",
    "        self.load_test_data()\n",
    "    \n",
    "    def load_training_data(self):\n",
    "        print(\"Loading training data from:\", self.data_path)\n",
    "        self.trn_mats = []\n",
    "        for beh in self.behaviors:\n",
    "            path = self.trn_file + beh\n",
    "            print(f\"Loading behavior: {beh} from {path}\")\n",
    "            if not os.path.exists(path):\n",
    "                raise FileNotFoundError(f\"File not found: {path}\")\n",
    "            with open(path, 'rb') as fs:\n",
    "                mat = pickle.load(fs)\n",
    "                if not isinstance(mat, csr_matrix):\n",
    "                    mat = csr_matrix(mat)\n",
    "                mat = (mat != 0).astype(np.float32)\n",
    "                self.trn_mats.append(mat)\n",
    "        \n",
    "        self.trn_label = 1 * (self.trn_mats[-1] != 0)\n",
    "        self.n_users, self.n_items = self.trn_mats[0].shape\n",
    "        self.n_behaviors = len(self.behaviors)\n",
    "        print(f\"Dataset dimensions: {self.n_users} users, {self.n_items} items\")\n",
    "\n",
    "    def create_adjacency_matrix(self, users):\n",
    "        \"\"\"Optimized adjacency matrix creation\"\"\"\n",
    "        batch_size = len(users)\n",
    "        adj_matrix = torch.zeros(batch_size, batch_size, device=device)\n",
    "        \n",
    "        # Pre-compute user item sets\n",
    "        user_item_sets = []\n",
    "        for user in users:\n",
    "            user_items = set()\n",
    "            for mat in self.trn_mats:\n",
    "                user_items.update(mat[user].indices)\n",
    "            user_item_sets.append(user_items)\n",
    "        \n",
    "        # Compute similarities in parallel\n",
    "        for i in range(batch_size):\n",
    "            if not user_item_sets[i]:\n",
    "                continue\n",
    "            for j in range(i+1, batch_size):\n",
    "                if user_item_sets[j]:\n",
    "                    jaccard = len(user_item_sets[i] & user_item_sets[j]) / len(user_item_sets[i] | user_item_sets[j])\n",
    "                    adj_matrix[i,j] = adj_matrix[j,i] = jaccard\n",
    "        \n",
    "        return adj_matrix\n",
    "\n",
    "    def create_graph_metrics(self, users):\n",
    "        \"\"\"Optimized graph metrics creation\"\"\"\n",
    "        metrics = torch.zeros(len(users), 3, device=device)\n",
    "        \n",
    "        # Vectorized computation\n",
    "        for i, user in enumerate(users):\n",
    "            interactions = np.array([mat[user].nnz for mat in self.trn_mats])\n",
    "            metrics[i,0] = sum(interactions) / 100\n",
    "            metrics[i,1] = (interactions > 0).sum() / len(self.behaviors)\n",
    "            metrics[i,2] = interactions[-1] / max(interactions[0], 1)\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "    def prepare_train_instances(self, max_samples=5000):\n",
    "        \"\"\"Optimized training instance preparation\"\"\"\n",
    "        print(\"Preparing training instances...\")\n",
    "        train_data = []\n",
    "        \n",
    "        # Randomly select users\n",
    "        selected_users = np.random.choice(min(self.n_users, self.max_users), size=min(1000, self.max_users), replace=False)\n",
    "        \n",
    "        for user in selected_users:\n",
    "            pos_items = self.trn_label[user].indices[:2]  # Limit positive items\n",
    "            \n",
    "            if len(pos_items) > 0:\n",
    "                for item in pos_items:\n",
    "                    behaviors = [float(mat[user, item]) for mat in self.trn_mats]\n",
    "                    train_data.append([user, item, 1.0] + behaviors)\n",
    "                    \n",
    "                    # Limited negative sampling\n",
    "                    neg_items = np.random.choice(self.n_items, size=2, replace=False)\n",
    "                    for neg_item in neg_items:\n",
    "                        behaviors = [float(mat[user, neg_item]) for mat in self.trn_mats]\n",
    "                        train_data.append([user, neg_item, 0.0] + behaviors)\n",
    "                        \n",
    "                    if len(train_data) >= max_samples:\n",
    "                        break\n",
    "            \n",
    "            if len(train_data) >= max_samples:\n",
    "                break\n",
    "        \n",
    "        print(f\"Generated {len(train_data)} training instances\")\n",
    "        return np.array(train_data)\n",
    "\n",
    "    def load_test_data(self):\n",
    "        \"\"\"Load test data\"\"\"\n",
    "        test_path = self.tst_file + 'int'\n",
    "        print(f\"Loading test data from: {test_path}\")\n",
    "        if not os.path.exists(test_path):\n",
    "            raise FileNotFoundError(f\"File not found: {test_path}\")\n",
    "        with open(test_path, 'rb') as fs:\n",
    "            self.tst_int = np.array(pickle.load(fs))\n",
    "        \n",
    "        self.tst_users = np.reshape(np.argwhere(self.tst_int != None), [-1])\n",
    "        # Limit test users for faster processing\n",
    "        self.tst_users = self.tst_users[:min(len(self.tst_users), self.max_users)]\n",
    "        print(f\"Using {len(self.tst_users)} test users\")\n",
    "\n",
    "    def get_test_instances(self, num_neg_samples=99):\n",
    "        \"\"\"Generate test instances with negative sampling\"\"\"\n",
    "        print(\"Preparing test instances...\")\n",
    "        test_instances = []\n",
    "        \n",
    "        for user in self.tst_users:\n",
    "            pos_item = self.tst_int[user]\n",
    "            if pos_item is not None:\n",
    "                # Add positive instance\n",
    "                test_instances.append([user, pos_item, 1.0])\n",
    "                \n",
    "                # Add negative instances\n",
    "                try:\n",
    "                    # Get all items and remove positive items\n",
    "                    all_items = set(range(self.n_items))\n",
    "                    pos_items_train = set(self.trn_label[user].indices)\n",
    "                    pos_items_train.add(pos_item)\n",
    "                    neg_items_pool = list(all_items - pos_items_train)\n",
    "                    \n",
    "                    # Sample negative items\n",
    "                    n_neg = min(num_neg_samples, len(neg_items_pool))\n",
    "                    if n_neg > 0:\n",
    "                        neg_items = np.random.choice(neg_items_pool, size=n_neg, replace=False)\n",
    "                        for neg_item in neg_items:\n",
    "                            test_instances.append([user, neg_item, 0.0])\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing test user {user}: {str(e)}\")\n",
    "                    continue\n",
    "                \n",
    "                # Limit the number of test instances for faster processing\n",
    "                if len(test_instances) >= self.max_users * 100:\n",
    "                    break\n",
    "        \n",
    "        if not test_instances:\n",
    "            raise ValueError(\"No test instances were generated!\")\n",
    "            \n",
    "        test_instances = np.array(test_instances)\n",
    "        print(f\"Generated {len(test_instances)} test instances\")\n",
    "        return test_instances\n",
    "\n",
    "# Define the corrected evaluation function\n",
    "def evaluate_model(model, dataset, test_instances, k=10):\n",
    "    \"\"\"Improved evaluation function with better metrics calculation.\"\"\"\n",
    "    model.eval()\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    \n",
    "    # Process test instances in smaller chunks\n",
    "    chunk_size = 100\n",
    "    test_chunks = [test_instances[i:i + chunk_size] for i in range(0, len(test_instances), chunk_size)]\n",
    "    \n",
    "    print(f\"Evaluating {len(test_instances)} instances in {len(test_chunks)} chunks...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for chunk_idx, chunk in enumerate(test_chunks):\n",
    "            if chunk_idx % 50 == 0:  # Reduced frequency of progress updates\n",
    "                print(f\"Processing chunk {chunk_idx + 1}/{len(test_chunks)}\")\n",
    "            \n",
    "            # Group by user and ensure we have both positive and negative items\n",
    "            user_items = {}\n",
    "            for inst in chunk:\n",
    "                user = int(inst[0])\n",
    "                item = int(inst[1])\n",
    "                label = float(inst[2])\n",
    "                \n",
    "                if user not in user_items:\n",
    "                    user_items[user] = {'pos': [], 'neg': [], 'all_items': [], 'all_scores': []}\n",
    "                \n",
    "                user_items[user]['all_items'].append(item)\n",
    "                if label > 0.5:\n",
    "                    user_items[user]['pos'].append(item)\n",
    "                else:\n",
    "                    user_items[user]['neg'].append(item)\n",
    "            \n",
    "            # Process each user that has both positive and negative items\n",
    "            for user, data in user_items.items():\n",
    "                if not data['pos'] or not data['neg']:\n",
    "                    continue\n",
    "                \n",
    "                items = data['all_items']\n",
    "                batch_size = len(items)\n",
    "                \n",
    "                # Create input features\n",
    "                behaviors = torch.zeros(batch_size, dataset.n_behaviors, device=device)\n",
    "                for i, item in enumerate(items):\n",
    "                    for j, mat in enumerate(dataset.trn_mats):\n",
    "                        behaviors[i, j] = float(mat[user, item])\n",
    "                \n",
    "                x = torch.cat([\n",
    "                    behaviors,\n",
    "                    torch.zeros(batch_size, model.input_dim - behaviors.size(1), device=device)\n",
    "                ], dim=1)\n",
    "                \n",
    "                # Simplified adjacency matrix for evaluation\n",
    "                adj_matrix = torch.eye(batch_size, device=device)\n",
    "                graph_metrics = dataset.create_graph_metrics([user] * batch_size)\n",
    "                \n",
    "                try:\n",
    "                    predictions = model(x, adj_matrix, graph_metrics)\n",
    "                    predictions = predictions.cpu().numpy().flatten()\n",
    "                    \n",
    "                    # Store all scores\n",
    "                    data['all_scores'] = [(item, score) for item, score in zip(items, predictions)]\n",
    "                    \n",
    "                    # Sort items by score\n",
    "                    sorted_items = [x[0] for x in sorted(data['all_scores'], key=lambda x: x[1], reverse=True)]\n",
    "                    recommended_items = sorted_items[:k]\n",
    "                    \n",
    "                    # Calculate HR\n",
    "                    hit = any(pos_item in recommended_items for pos_item in data['pos'])\n",
    "                    hits.append(hit)\n",
    "                    \n",
    "                    # Calculate NDCG\n",
    "                    dcg = sum(\n",
    "                        1 / np.log2(i + 2) for i, item in enumerate(recommended_items) if item in data['pos']\n",
    "                    )\n",
    "                    idcg = 1  # Ideal DCG for one relevant item\n",
    "                    ndcg = dcg / idcg\n",
    "                    ndcgs.append(ndcg)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error evaluating user {user}: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    hr = np.mean(hits) if hits else 0\n",
    "    ndcg = np.mean(ndcgs) if ndcgs else 0\n",
    "    \n",
    "    # Print detailed statistics\n",
    "    print(f\"\\nEvaluation Statistics:\")\n",
    "    print(f\"Total users evaluated: {len(hits)}\")\n",
    "    print(f\"Number of hits: {sum(hits)}\")\n",
    "    print(f\"Average HR@{k}: {hr:.4f}\")\n",
    "    print(f\"Average NDCG@{k}: {ndcg:.4f}\")\n",
    "    \n",
    "    return hr, ndcg\n",
    "\n",
    "\n",
    "# Define the main function\n",
    "def main():\n",
    "    # Configuration\n",
    "    config = {\n",
    "        'd_model': 32,\n",
    "        'num_heads': 2,\n",
    "        'num_layers': 1,\n",
    "        'd_feedforward': 64,\n",
    "        'input_dim': 64,\n",
    "        'num_weights': 3,\n",
    "        'learning_rate': 0.001,\n",
    "        'weight_decay': 1e-6,\n",
    "        'dropout': 0.1,\n",
    "        'gradient_clip': 1.0,\n",
    "        'max_samples': 500000,\n",
    "        'eval_k': 10\n",
    "    }\n",
    "    \n",
    "    print(\"Initializing dataset...\")\n",
    "    dataset = MultiBehaviorDataset(max_users=10000)\n",
    "    train_data = dataset.prepare_train_instances(max_samples=config['max_samples'])\n",
    "    \n",
    "    print(f\"Using {len(train_data)} training instances\")\n",
    "\n",
    "    model = GraphTransformerV2(\n",
    "        num_layers=config['num_layers'],\n",
    "        d_model=config['d_model'],\n",
    "        num_heads=config['num_heads'],\n",
    "        d_feedforward=config['d_feedforward'],\n",
    "        input_dim=config['input_dim'],\n",
    "        num_weights=config['num_weights'],\n",
    "        dropout=config['dropout']\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "    print(\"Preparing training tensors...\")\n",
    "    users = torch.LongTensor(train_data[:, 0]).to(device)\n",
    "    items = torch.LongTensor(train_data[:, 1]).to(device)\n",
    "    labels = torch.FloatTensor(train_data[:, 2]).to(device)\n",
    "    behaviors = torch.FloatTensor(train_data[:, 3:]).to(device)\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    try:\n",
    "        model.train()\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        # Training\n",
    "        x = torch.cat([\n",
    "            behaviors,\n",
    "            torch.zeros(len(users), config['input_dim'] - behaviors.size(1), device=device)\n",
    "        ], dim=1)\n",
    "        \n",
    "        adj_matrix = dataset.create_adjacency_matrix(users)\n",
    "        graph_metrics = dataset.create_graph_metrics(users)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(x, adj_matrix, graph_metrics)\n",
    "        predictions = predictions.view(-1)\n",
    "        labels = labels.view(-1)\n",
    "        \n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), config['gradient_clip'])\n",
    "        optimizer.step()\n",
    "        \n",
    "        training_time = (datetime.now() - start_time).total_seconds()\n",
    "        print(f\"Training completed in {training_time:.2f}s\")\n",
    "        print(f\"Training loss: {loss.item():.4f}\")\n",
    "        \n",
    "        # Evaluation\n",
    "        print(\"\\nStarting evaluation...\")\n",
    "        eval_start_time = datetime.now()\n",
    "        \n",
    "        test_instances = dataset.get_test_instances()\n",
    "        hr, ndcg = evaluate_model(model, dataset, test_instances, k=config['eval_k'])\n",
    "        \n",
    "        eval_time = (datetime.now() - eval_start_time).total_seconds()\n",
    "        print(f\"Evaluation completed in {eval_time:.2f}s\")\n",
    "        print(f\"HR@{config['eval_k']}: {hr:.4f}\")\n",
    "        print(f\"NDCG@{config['eval_k']}: {ndcg:.4f}\")\n",
    "        \n",
    "        # Save results\n",
    "        results = {\n",
    "            'training_time': training_time,\n",
    "            'eval_time': eval_time,\n",
    "            'training_loss': loss.item(),\n",
    "            'hr': hr,\n",
    "            'ndcg': ndcg\n",
    "        }\n",
    "        \n",
    "        # Save to file\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        with open(f'results_{timestamp}.txt', 'w') as f:\n",
    "            for key, value in results.items():\n",
    "                f.write(f\"{key}: {value}\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during training: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiasMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing dataset...\n",
      "Loading training data from: /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/\n",
      "Loading behavior: pv from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_pv\n",
      "Loading behavior: cart from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_cart\n",
      "Loading behavior: buy from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_buy\n",
      "Dataset dimensions: 21716 users, 7977 items\n",
      "Loading test data from: /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/tst_int\n",
      "Using 10000 test users\n",
      "Preparing training instances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yf/20z1hn994jd04q4kl0gpgh740000gn/T/ipykernel_75183/4207550206.py:22: DeprecationWarning: Please import `csr_matrix` from the `scipy.sparse` namespace; the `scipy.sparse.csr` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  mat = pickle.load(fs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 5001 training instances\n",
      "Using 5001 training instances\n",
      "Preparing training tensors...\n",
      "Starting training...\n",
      "Training completed in 0.02s\n",
      "Training loss: 0.7177\n",
      "\n",
      "Starting evaluation...\n",
      "Preparing test instances...\n",
      "Generated 1000000 test instances\n",
      "Evaluating 1000000 instances in 10000 chunks...\n",
      "Processing chunk 1/10000\n",
      "Processing chunk 51/10000\n",
      "Processing chunk 101/10000\n",
      "Processing chunk 151/10000\n",
      "Processing chunk 201/10000\n",
      "Processing chunk 251/10000\n",
      "Processing chunk 301/10000\n",
      "Processing chunk 351/10000\n",
      "Processing chunk 401/10000\n",
      "Processing chunk 451/10000\n",
      "Processing chunk 501/10000\n",
      "Processing chunk 551/10000\n",
      "Processing chunk 601/10000\n",
      "Processing chunk 651/10000\n",
      "Processing chunk 701/10000\n",
      "Processing chunk 751/10000\n",
      "Processing chunk 801/10000\n",
      "Processing chunk 851/10000\n",
      "Processing chunk 901/10000\n",
      "Processing chunk 951/10000\n",
      "Processing chunk 1001/10000\n",
      "Processing chunk 1051/10000\n",
      "Processing chunk 1101/10000\n",
      "Processing chunk 1151/10000\n",
      "Processing chunk 1201/10000\n",
      "Processing chunk 1251/10000\n",
      "Processing chunk 1301/10000\n",
      "Processing chunk 1351/10000\n",
      "Processing chunk 1401/10000\n",
      "Processing chunk 1451/10000\n",
      "Processing chunk 1501/10000\n",
      "Processing chunk 1551/10000\n",
      "Processing chunk 1601/10000\n",
      "Processing chunk 1651/10000\n",
      "Processing chunk 1701/10000\n",
      "Processing chunk 1751/10000\n",
      "Processing chunk 1801/10000\n",
      "Processing chunk 1851/10000\n",
      "Processing chunk 1901/10000\n",
      "Processing chunk 1951/10000\n",
      "Processing chunk 2001/10000\n",
      "Processing chunk 2051/10000\n",
      "Processing chunk 2101/10000\n",
      "Processing chunk 2151/10000\n",
      "Processing chunk 2201/10000\n",
      "Processing chunk 2251/10000\n",
      "Processing chunk 2301/10000\n",
      "Processing chunk 2351/10000\n",
      "Processing chunk 2401/10000\n",
      "Processing chunk 2451/10000\n",
      "Processing chunk 2501/10000\n",
      "Processing chunk 2551/10000\n",
      "Processing chunk 2601/10000\n",
      "Processing chunk 2651/10000\n",
      "Processing chunk 2701/10000\n",
      "Processing chunk 2751/10000\n",
      "Processing chunk 2801/10000\n",
      "Processing chunk 2851/10000\n",
      "Processing chunk 2901/10000\n",
      "Processing chunk 2951/10000\n",
      "Processing chunk 3001/10000\n",
      "Processing chunk 3051/10000\n",
      "Processing chunk 3101/10000\n",
      "Processing chunk 3151/10000\n",
      "Processing chunk 3201/10000\n",
      "Processing chunk 3251/10000\n",
      "Processing chunk 3301/10000\n",
      "Processing chunk 3351/10000\n",
      "Processing chunk 3401/10000\n",
      "Processing chunk 3451/10000\n",
      "Processing chunk 3501/10000\n",
      "Processing chunk 3551/10000\n",
      "Processing chunk 3601/10000\n",
      "Processing chunk 3651/10000\n",
      "Processing chunk 3701/10000\n",
      "Processing chunk 3751/10000\n",
      "Processing chunk 3801/10000\n",
      "Processing chunk 3851/10000\n",
      "Processing chunk 3901/10000\n",
      "Processing chunk 3951/10000\n",
      "Processing chunk 4001/10000\n",
      "Processing chunk 4051/10000\n",
      "Processing chunk 4101/10000\n",
      "Processing chunk 4151/10000\n",
      "Processing chunk 4201/10000\n",
      "Processing chunk 4251/10000\n",
      "Processing chunk 4301/10000\n",
      "Processing chunk 4351/10000\n",
      "Processing chunk 4401/10000\n",
      "Processing chunk 4451/10000\n",
      "Processing chunk 4501/10000\n",
      "Processing chunk 4551/10000\n",
      "Processing chunk 4601/10000\n",
      "Processing chunk 4651/10000\n",
      "Processing chunk 4701/10000\n",
      "Processing chunk 4751/10000\n",
      "Processing chunk 4801/10000\n",
      "Processing chunk 4851/10000\n",
      "Processing chunk 4901/10000\n",
      "Processing chunk 4951/10000\n",
      "Processing chunk 5001/10000\n",
      "Processing chunk 5051/10000\n",
      "Processing chunk 5101/10000\n",
      "Processing chunk 5151/10000\n",
      "Processing chunk 5201/10000\n",
      "Processing chunk 5251/10000\n",
      "Processing chunk 5301/10000\n",
      "Processing chunk 5351/10000\n",
      "Processing chunk 5401/10000\n",
      "Processing chunk 5451/10000\n",
      "Processing chunk 5501/10000\n",
      "Processing chunk 5551/10000\n",
      "Processing chunk 5601/10000\n",
      "Processing chunk 5651/10000\n",
      "Processing chunk 5701/10000\n",
      "Processing chunk 5751/10000\n",
      "Processing chunk 5801/10000\n",
      "Processing chunk 5851/10000\n",
      "Processing chunk 5901/10000\n",
      "Processing chunk 5951/10000\n",
      "Processing chunk 6001/10000\n",
      "Processing chunk 6051/10000\n",
      "Processing chunk 6101/10000\n",
      "Processing chunk 6151/10000\n",
      "Processing chunk 6201/10000\n",
      "Processing chunk 6251/10000\n",
      "Processing chunk 6301/10000\n",
      "Processing chunk 6351/10000\n",
      "Processing chunk 6401/10000\n",
      "Processing chunk 6451/10000\n",
      "Processing chunk 6501/10000\n",
      "Processing chunk 6551/10000\n",
      "Processing chunk 6601/10000\n",
      "Processing chunk 6651/10000\n",
      "Processing chunk 6701/10000\n",
      "Processing chunk 6751/10000\n",
      "Processing chunk 6801/10000\n",
      "Processing chunk 6851/10000\n",
      "Processing chunk 6901/10000\n",
      "Processing chunk 6951/10000\n",
      "Processing chunk 7001/10000\n",
      "Processing chunk 7051/10000\n",
      "Processing chunk 7101/10000\n",
      "Processing chunk 7151/10000\n",
      "Processing chunk 7201/10000\n",
      "Processing chunk 7251/10000\n",
      "Processing chunk 7301/10000\n",
      "Processing chunk 7351/10000\n",
      "Processing chunk 7401/10000\n",
      "Processing chunk 7451/10000\n",
      "Processing chunk 7501/10000\n",
      "Processing chunk 7551/10000\n",
      "Processing chunk 7601/10000\n",
      "Processing chunk 7651/10000\n",
      "Processing chunk 7701/10000\n",
      "Processing chunk 7751/10000\n",
      "Processing chunk 7801/10000\n",
      "Processing chunk 7851/10000\n",
      "Processing chunk 7901/10000\n",
      "Processing chunk 7951/10000\n",
      "Processing chunk 8001/10000\n",
      "Processing chunk 8051/10000\n",
      "Processing chunk 8101/10000\n",
      "Processing chunk 8151/10000\n",
      "Processing chunk 8201/10000\n",
      "Processing chunk 8251/10000\n",
      "Processing chunk 8301/10000\n",
      "Processing chunk 8351/10000\n",
      "Processing chunk 8401/10000\n",
      "Processing chunk 8451/10000\n",
      "Processing chunk 8501/10000\n",
      "Processing chunk 8551/10000\n",
      "Processing chunk 8601/10000\n",
      "Processing chunk 8651/10000\n",
      "Processing chunk 8701/10000\n",
      "Processing chunk 8751/10000\n",
      "Processing chunk 8801/10000\n",
      "Processing chunk 8851/10000\n",
      "Processing chunk 8901/10000\n",
      "Processing chunk 8951/10000\n",
      "Processing chunk 9001/10000\n",
      "Processing chunk 9051/10000\n",
      "Processing chunk 9101/10000\n",
      "Processing chunk 9151/10000\n",
      "Processing chunk 9201/10000\n",
      "Processing chunk 9251/10000\n",
      "Processing chunk 9301/10000\n",
      "Processing chunk 9351/10000\n",
      "Processing chunk 9401/10000\n",
      "Processing chunk 9451/10000\n",
      "Processing chunk 9501/10000\n",
      "Processing chunk 9551/10000\n",
      "Processing chunk 9601/10000\n",
      "Processing chunk 9651/10000\n",
      "Processing chunk 9701/10000\n",
      "Processing chunk 9751/10000\n",
      "Processing chunk 9801/10000\n",
      "Processing chunk 9851/10000\n",
      "Processing chunk 9901/10000\n",
      "Processing chunk 9951/10000\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 10000\n",
      "Number of hits: 7259\n",
      "Average HR@20: 0.7259\n",
      "Average NDCG@20: 0.6508\n",
      "Evaluation completed in 36.32s\n",
      "HR@20: 0.7259\n",
      "NDCG@20: 0.6508\n"
     ]
    }
   ],
   "source": [
    "# cropped dataset\n",
    "class MultiBehaviorDataset:\n",
    "    def __init__(self, data_path='/Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/', max_users=50000):\n",
    "        self.data_path = data_path\n",
    "        self.behaviors = ['pv', 'cart', 'buy']\n",
    "        self.trn_file = data_path + 'trn_'\n",
    "        self.tst_file = data_path + 'tst_'\n",
    "        self.max_users = max_users  # Limit number of users\n",
    "        \n",
    "        self.load_training_data()\n",
    "        self.load_test_data()\n",
    "    \n",
    "    def load_training_data(self):\n",
    "        print(\"Loading training data from:\", self.data_path)\n",
    "        self.trn_mats = []\n",
    "        for beh in self.behaviors:\n",
    "            path = self.trn_file + beh\n",
    "            print(f\"Loading behavior: {beh} from {path}\")\n",
    "            if not os.path.exists(path):\n",
    "                raise FileNotFoundError(f\"File not found: {path}\")\n",
    "            with open(path, 'rb') as fs:\n",
    "                mat = pickle.load(fs)\n",
    "                if not isinstance(mat, csr_matrix):\n",
    "                    mat = csr_matrix(mat)\n",
    "                mat = (mat != 0).astype(np.float32)\n",
    "                self.trn_mats.append(mat)\n",
    "        \n",
    "        self.trn_label = 1 * (self.trn_mats[-1] != 0)\n",
    "        self.n_users, self.n_items = self.trn_mats[0].shape\n",
    "        self.n_behaviors = len(self.behaviors)\n",
    "        print(f\"Dataset dimensions: {self.n_users} users, {self.n_items} items\")\n",
    "\n",
    "    def create_adjacency_matrix(self, users):\n",
    "        \"\"\"Optimized adjacency matrix creation\"\"\"\n",
    "        batch_size = len(users)\n",
    "        adj_matrix = torch.zeros(batch_size, batch_size, device=device)\n",
    "        \n",
    "        # Pre-compute user item sets\n",
    "        user_item_sets = []\n",
    "        for user in users:\n",
    "            user_items = set()\n",
    "            for mat in self.trn_mats:\n",
    "                user_items.update(mat[user].indices)\n",
    "            user_item_sets.append(user_items)\n",
    "        \n",
    "        # Compute similarities in parallel\n",
    "        for i in range(batch_size):\n",
    "            if not user_item_sets[i]:\n",
    "                continue\n",
    "            for j in range(i+1, batch_size):\n",
    "                if user_item_sets[j]:\n",
    "                    jaccard = len(user_item_sets[i] & user_item_sets[j]) / len(user_item_sets[i] | user_item_sets[j])\n",
    "                    adj_matrix[i,j] = adj_matrix[j,i] = jaccard\n",
    "        \n",
    "        return adj_matrix\n",
    "\n",
    "    def create_graph_metrics(self, users):\n",
    "        \"\"\"Optimized graph metrics creation\"\"\"\n",
    "        metrics = torch.zeros(len(users), 3, device=device)\n",
    "        \n",
    "        # Vectorized computation\n",
    "        for i, user in enumerate(users):\n",
    "            interactions = np.array([mat[user].nnz for mat in self.trn_mats])\n",
    "            metrics[i,0] = sum(interactions) / 100\n",
    "            metrics[i,1] = (interactions > 0).sum() / len(self.behaviors)\n",
    "            metrics[i,2] = interactions[-1] / max(interactions[0], 1)\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "    def prepare_train_instances(self, max_samples):\n",
    "        \"\"\"Optimized training instance preparation\"\"\"\n",
    "        print(\"Preparing training instances...\")\n",
    "        train_data = []\n",
    "        \n",
    "        # Randomly select users\n",
    "        selected_users = np.random.choice(min(self.n_users, self.max_users), size=min(1000, self.max_users), replace=False)\n",
    "        \n",
    "        for user in selected_users:\n",
    "            pos_items = self.trn_label[user].indices[:2]  # Limit positive items\n",
    "            \n",
    "            if len(pos_items) > 0:\n",
    "                for item in pos_items:\n",
    "                    behaviors = [float(mat[user, item]) for mat in self.trn_mats]\n",
    "                    train_data.append([user, item, 1.0] + behaviors)\n",
    "                    \n",
    "                    # Limited negative sampling\n",
    "                    neg_items = np.random.choice(self.n_items, size=2, replace=False)\n",
    "                    for neg_item in neg_items:\n",
    "                        behaviors = [float(mat[user, neg_item]) for mat in self.trn_mats]\n",
    "                        train_data.append([user, neg_item, 0.0] + behaviors)\n",
    "                        \n",
    "                    if len(train_data) >= max_samples:\n",
    "                        break\n",
    "            \n",
    "            if len(train_data) >= max_samples:\n",
    "                break\n",
    "        \n",
    "        print(f\"Generated {len(train_data)} training instances\")\n",
    "        return np.array(train_data)\n",
    "    \n",
    "    def load_test_data(self):\n",
    "        \"\"\"Load test data\"\"\"\n",
    "        test_path = self.tst_file + 'int'\n",
    "        print(f\"Loading test data from: {test_path}\")\n",
    "        if not os.path.exists(test_path):\n",
    "            raise FileNotFoundError(f\"File not found: {test_path}\")\n",
    "        with open(test_path, 'rb') as fs:\n",
    "            self.tst_int = np.array(pickle.load(fs))\n",
    "        \n",
    "        self.tst_users = np.reshape(np.argwhere(self.tst_int != None), [-1])\n",
    "        # Limit test users for faster processing\n",
    "        self.tst_users = self.tst_users[:min(len(self.tst_users), self.max_users)]\n",
    "        print(f\"Using {len(self.tst_users)} test users\")\n",
    "\n",
    "    def get_test_instances(self, num_neg_samples=99):\n",
    "        \"\"\"Generate test instances with negative sampling\"\"\"\n",
    "        print(\"Preparing test instances...\")\n",
    "        test_instances = []\n",
    "        \n",
    "        for user in self.tst_users:\n",
    "            pos_item = self.tst_int[user]\n",
    "            if pos_item is not None:\n",
    "                # Add positive instance\n",
    "                test_instances.append([user, pos_item, 1.0])\n",
    "                \n",
    "                # Add negative instances\n",
    "                try:\n",
    "                    # Get all items and remove positive items\n",
    "                    all_items = set(range(self.n_items))\n",
    "                    pos_items_train = set(self.trn_label[user].indices)\n",
    "                    pos_items_train.add(pos_item)\n",
    "                    neg_items_pool = list(all_items - pos_items_train)\n",
    "                    \n",
    "                    # Sample negative items\n",
    "                    n_neg = min(num_neg_samples, len(neg_items_pool))\n",
    "                    if n_neg > 0:\n",
    "                        neg_items = np.random.choice(neg_items_pool, size=n_neg, replace=False)\n",
    "                        for neg_item in neg_items:\n",
    "                            test_instances.append([user, neg_item, 0.0])\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing test user {user}: {str(e)}\")\n",
    "                    continue\n",
    "                \n",
    "                # Limit the number of test instances for faster processing\n",
    "                if len(test_instances) >= self.max_users * 100:\n",
    "                    break\n",
    "        \n",
    "        if not test_instances:\n",
    "            raise ValueError(\"No test instances were generated!\")\n",
    "            \n",
    "        test_instances = np.array(test_instances)\n",
    "        print(f\"Generated {len(test_instances)} test instances\")\n",
    "        return test_instances\n",
    "\n",
    "\n",
    "def get_test_instances(self, num_neg_samples=99):\n",
    "    \"\"\"Improved test instance generation\"\"\"\n",
    "    print(\"Preparing test instances...\")\n",
    "    test_instances = []\n",
    "    max_test_users = 1000 # Limit number of test users\n",
    "    \n",
    "    # Randomly sample test users if there are too many\n",
    "    test_users = self.tst_users\n",
    "    if len(test_users) > max_test_users:\n",
    "        test_users = np.random.choice(test_users, max_test_users, replace=False)\n",
    "    \n",
    "    for user in test_users:\n",
    "        user = int(user)\n",
    "        pos_item = self.tst_int[user]\n",
    "        if pos_item is not None:\n",
    "            pos_item = int(pos_item)\n",
    "            test_instances.append([user, pos_item, 1.0])\n",
    "            \n",
    "            try:\n",
    "                # Get negative items\n",
    "                all_items = set(range(self.n_items))\n",
    "                pos_items = set(int(x) for x in self.trn_label[user].indices)\n",
    "                pos_items.add(pos_item)\n",
    "                neg_items_pool = list(all_items - pos_items)\n",
    "                \n",
    "                # Sample negative items\n",
    "                n_neg = min(num_neg_samples, len(neg_items_pool))\n",
    "                if n_neg > 0:\n",
    "                    neg_items = np.random.choice(neg_items_pool, size=n_neg, replace=False)\n",
    "                    for neg_item in neg_items:\n",
    "                        test_instances.append([user, int(neg_item), 0.0])\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing test user {user}: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    if not test_instances:\n",
    "        raise ValueError(\"No test instances were generated!\")\n",
    "    \n",
    "    test_instances = np.array(test_instances)\n",
    "    print(f\"Generated {len(test_instances)} test instances\")\n",
    "    print(f\"Number of unique users: {len(set(test_instances[:,0]))}\")\n",
    "    return test_instances\n",
    "\n",
    "def main():\n",
    "    # Configuration\n",
    "    config = {\n",
    "        'latent_dim': 64,\n",
    "        'dropout': 0.1,\n",
    "        'learning_rate': 0.001,\n",
    "        'weight_decay': 1e-6,\n",
    "        'gradient_clip': 1.0,\n",
    "        'max_samples': 5000,\n",
    "        'eval_k': 20\n",
    "    }\n",
    "    \n",
    "    print(\"Initializing dataset...\")\n",
    "    dataset = MultiBehaviorDataset()\n",
    "    train_data = dataset.prepare_train_instances(max_samples=config['max_samples'])\n",
    "    \n",
    "    print(f\"Using {len(train_data)} training instances\")\n",
    "\n",
    "    # Initialize model with dataset dimensions\n",
    "    model = MultiBehaviorBiasMF(\n",
    "        n_users=dataset.n_users,\n",
    "        n_items=dataset.n_items,\n",
    "        n_behaviors=dataset.n_behaviors,\n",
    "        latent_dim=config['latent_dim'],\n",
    "        dropout=config['dropout']\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "    print(\"Preparing training tensors...\")\n",
    "    users = torch.LongTensor(train_data[:, 0]).to(device)\n",
    "    items = torch.LongTensor(train_data[:, 1]).to(device)\n",
    "    labels = torch.FloatTensor(train_data[:, 2]).to(device)\n",
    "    behaviors = torch.FloatTensor(train_data[:, 3:]).to(device)\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    try:\n",
    "        model.train()\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        # Training\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(users, items, behaviors)\n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), config['gradient_clip'])\n",
    "        optimizer.step()\n",
    "        \n",
    "        training_time = (datetime.now() - start_time).total_seconds()\n",
    "        print(f\"Training completed in {training_time:.2f}s\")\n",
    "        print(f\"Training loss: {loss.item():.4f}\")\n",
    "        \n",
    "        # Evaluation\n",
    "        print(\"\\nStarting evaluation...\")\n",
    "        eval_start_time = datetime.now()\n",
    "        \n",
    "        test_instances = dataset.get_test_instances()\n",
    "        hr, ndcg = evaluate_model(model, dataset, test_instances, k=config['eval_k'])\n",
    "        \n",
    "        eval_time = (datetime.now() - eval_start_time).total_seconds()\n",
    "        print(f\"Evaluation completed in {eval_time:.2f}s\")\n",
    "        print(f\"HR@{config['eval_k']}: {hr:.4f}\")\n",
    "        print(f\"NDCG@{config['eval_k']}: {ndcg:.4f}\")\n",
    "        \n",
    "        # Save results\n",
    "        results = {\n",
    "            'training_time': training_time,\n",
    "            'eval_time': eval_time,\n",
    "            'training_loss': loss.item(),\n",
    "            'hr': hr,\n",
    "            'ndcg': ndcg\n",
    "        }\n",
    "        \n",
    "        # Save to file\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        with open(f'results_{timestamp}.txt', 'w') as f:\n",
    "            for key, value in results.items():\n",
    "                f.write(f\"{key}: {value}\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during training: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "class MultiBehaviorBiasMF(nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_behaviors, latent_dim=64, dropout=0.1):\n",
    "        super(MultiBehaviorBiasMF, self).__init__()\n",
    "        \n",
    "        self.n_behaviors = n_behaviors\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # User and item embeddings\n",
    "        self.user_embedding = nn.Embedding(n_users, latent_dim)\n",
    "        self.item_embedding = nn.Embedding(n_items, latent_dim)\n",
    "        \n",
    "        # Behavior-specific embeddings\n",
    "        self.behavior_embeddings = nn.ModuleList([\n",
    "            nn.Embedding(2, latent_dim) for _ in range(n_behaviors)\n",
    "        ])\n",
    "        \n",
    "        # Bias terms\n",
    "        self.user_bias = nn.Embedding(n_users, 1)\n",
    "        self.item_bias = nn.Embedding(n_items, 1)\n",
    "        \n",
    "        # MLP for combining behavior signals\n",
    "        self.behavior_mlp = nn.Sequential(\n",
    "            nn.Linear(latent_dim * (2 + n_behaviors), latent_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(latent_dim, 1)\n",
    "        )\n",
    "        \n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.user_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.item_embedding.weight)\n",
    "        for beh_emb in self.behavior_embeddings:\n",
    "            nn.init.xavier_uniform_(beh_emb.weight)\n",
    "        nn.init.zeros_(self.user_bias.weight)\n",
    "        nn.init.zeros_(self.item_bias.weight)\n",
    "        \n",
    "    def forward(self, user_indices, item_indices, behavior_data):\n",
    "        user_emb = self.user_embedding(user_indices)\n",
    "        item_emb = self.item_embedding(item_indices)\n",
    "        \n",
    "        behavior_embs = []\n",
    "        for i in range(self.n_behaviors):\n",
    "            beh_data = behavior_data[:, i].long()\n",
    "            beh_emb = self.behavior_embeddings[i](beh_data)\n",
    "            behavior_embs.append(beh_emb)\n",
    "        \n",
    "        combined = torch.cat([user_emb, item_emb] + behavior_embs, dim=1)\n",
    "        pred = self.behavior_mlp(combined).squeeze()\n",
    "        pred = pred + self.user_bias(user_indices).squeeze()\n",
    "        pred = pred + self.item_bias(item_indices).squeeze()\n",
    "        \n",
    "        return pred\n",
    "\n",
    "def evaluate_model(model, dataset, test_instances, k=10):\n",
    "    \"\"\"Evaluation function for MultiBehaviorBiasMF\"\"\"\n",
    "    model.eval()\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    \n",
    "    chunk_size = 100\n",
    "    test_chunks = [test_instances[i:i + chunk_size] for i in range(0, len(test_instances), chunk_size)]\n",
    "    \n",
    "    print(f\"Evaluating {len(test_instances)} instances in {len(test_chunks)} chunks...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for chunk_idx, chunk in enumerate(test_chunks):\n",
    "            if chunk_idx % 50 == 0:\n",
    "                print(f\"Processing chunk {chunk_idx + 1}/{len(test_chunks)}\")\n",
    "            \n",
    "            user_items = {}\n",
    "            for inst in chunk:\n",
    "                user = int(inst[0])\n",
    "                item = int(inst[1])\n",
    "                label = float(inst[2])\n",
    "                \n",
    "                if user not in user_items:\n",
    "                    user_items[user] = {'pos': [], 'neg': [], 'all_items': [], 'all_scores': []}\n",
    "                \n",
    "                user_items[user]['all_items'].append(item)\n",
    "                if label > 0.5:\n",
    "                    user_items[user]['pos'].append(item)\n",
    "                else:\n",
    "                    user_items[user]['neg'].append(item)\n",
    "            \n",
    "            for user, data in user_items.items():\n",
    "                if not data['pos'] or not data['neg']:\n",
    "                    continue\n",
    "                \n",
    "                items = data['all_items']\n",
    "                batch_size = len(items)\n",
    "                \n",
    "                # Create input tensors\n",
    "                user_tensor = torch.LongTensor([user] * batch_size).to(device)\n",
    "                item_tensor = torch.LongTensor(items).to(device)\n",
    "                \n",
    "                # Create behavior tensor\n",
    "                behaviors = torch.zeros(batch_size, dataset.n_behaviors, device=device)\n",
    "                for i, item in enumerate(items):\n",
    "                    for j, mat in enumerate(dataset.trn_mats):\n",
    "                        behaviors[i, j] = float(mat[user, item])\n",
    "                \n",
    "                try:\n",
    "                    predictions = model(user_tensor, item_tensor, behaviors)\n",
    "                    predictions = predictions.cpu().numpy()\n",
    "                    \n",
    "                    for item, score in zip(items, predictions):\n",
    "                        data['all_scores'].append((item, score))\n",
    "                    \n",
    "                    sorted_items = [x[0] for x in sorted(data['all_scores'], key=lambda x: x[1], reverse=True)]\n",
    "                    recommended_items = sorted_items[:k]\n",
    "                    \n",
    "                    hit = False\n",
    "                    for pos_item in data['pos']:\n",
    "                        if pos_item in recommended_items:\n",
    "                            hit = True\n",
    "                            break\n",
    "                    hits.append(hit)\n",
    "                    \n",
    "                    dcg = 0\n",
    "                    idcg = 1\n",
    "                    for i, item in enumerate(recommended_items):\n",
    "                        if item in data['pos']:\n",
    "                            dcg += 1 / np.log2(i + 2)\n",
    "                    ndcg = dcg / idcg\n",
    "                    ndcgs.append(ndcg)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error evaluating user {user}: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    hr = np.mean(hits) if hits else 0\n",
    "    ndcg = np.mean(ndcgs) if ndcgs else 0\n",
    "    \n",
    "    print(f\"\\nEvaluation Statistics:\")\n",
    "    print(f\"Total users evaluated: {len(hits)}\")\n",
    "    print(f\"Number of hits: {sum(hits)}\")\n",
    "    print(f\"Average HR@{k}: {hr:.4f}\")\n",
    "    print(f\"Average NDCG@{k}: {ndcg:.4f}\")\n",
    "    \n",
    "    return hr, ndcg\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GT -replica of our above gt cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing dataset...\n",
      "Loading training data from: /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/\n",
      "Loading behavior: pv from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_pv\n",
      "Loading behavior: cart from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_cart\n",
      "Loading behavior: buy from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_buy\n",
      "Dataset dimensions: 21716 users, 7977 items\n",
      "Loading test data from: /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/tst_int\n",
      "Using 10000 test users\n",
      "Preparing training instances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yf/20z1hn994jd04q4kl0gpgh740000gn/T/ipykernel_74244/2424607899.py:128: DeprecationWarning: Please import `csr_matrix` from the `scipy.sparse` namespace; the `scipy.sparse.csr` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  mat = pickle.load(fs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 6000 training instances\n",
      "Using 6000 training instances\n",
      "Preparing training tensors...\n",
      "Starting training...\n",
      "Training completed in 135.61s\n",
      "Training loss: 8.6566\n",
      "\n",
      "Starting evaluation...\n",
      "Preparing test instances...\n",
      "Generated 1000000 test instances\n",
      "Evaluating 1000000 instances in 10000 chunks...\n",
      "Processing chunk 1/10000\n",
      "Processing chunk 51/10000\n",
      "Processing chunk 101/10000\n",
      "Processing chunk 151/10000\n",
      "Processing chunk 201/10000\n",
      "Processing chunk 251/10000\n",
      "Processing chunk 301/10000\n",
      "Processing chunk 351/10000\n",
      "Processing chunk 401/10000\n",
      "Processing chunk 451/10000\n",
      "Processing chunk 501/10000\n",
      "Processing chunk 551/10000\n",
      "Processing chunk 601/10000\n",
      "Processing chunk 651/10000\n",
      "Processing chunk 701/10000\n",
      "Processing chunk 751/10000\n",
      "Processing chunk 801/10000\n",
      "Processing chunk 851/10000\n",
      "Processing chunk 901/10000\n",
      "Processing chunk 951/10000\n",
      "Processing chunk 1001/10000\n",
      "Processing chunk 1051/10000\n",
      "Processing chunk 1101/10000\n",
      "Processing chunk 1151/10000\n",
      "Processing chunk 1201/10000\n",
      "Processing chunk 1251/10000\n",
      "Processing chunk 1301/10000\n",
      "Processing chunk 1351/10000\n",
      "Processing chunk 1401/10000\n",
      "Processing chunk 1451/10000\n",
      "Processing chunk 1501/10000\n",
      "Processing chunk 1551/10000\n",
      "Processing chunk 1601/10000\n",
      "Processing chunk 1651/10000\n",
      "Processing chunk 1701/10000\n",
      "Processing chunk 1751/10000\n",
      "Processing chunk 1801/10000\n",
      "Processing chunk 1851/10000\n",
      "Processing chunk 1901/10000\n",
      "Processing chunk 1951/10000\n",
      "Processing chunk 2001/10000\n",
      "Processing chunk 2051/10000\n",
      "Processing chunk 2101/10000\n",
      "Processing chunk 2151/10000\n",
      "Processing chunk 2201/10000\n",
      "Processing chunk 2251/10000\n",
      "Processing chunk 2301/10000\n",
      "Processing chunk 2351/10000\n",
      "Processing chunk 2401/10000\n",
      "Processing chunk 2451/10000\n",
      "Processing chunk 2501/10000\n",
      "Processing chunk 2551/10000\n",
      "Processing chunk 2601/10000\n",
      "Processing chunk 2651/10000\n",
      "Processing chunk 2701/10000\n",
      "Processing chunk 2751/10000\n",
      "Processing chunk 2801/10000\n",
      "Processing chunk 2851/10000\n",
      "Processing chunk 2901/10000\n",
      "Processing chunk 2951/10000\n",
      "Processing chunk 3001/10000\n",
      "Processing chunk 3051/10000\n",
      "Processing chunk 3101/10000\n",
      "Processing chunk 3151/10000\n",
      "Processing chunk 3201/10000\n",
      "Processing chunk 3251/10000\n",
      "Processing chunk 3301/10000\n",
      "Processing chunk 3351/10000\n",
      "Processing chunk 3401/10000\n",
      "Processing chunk 3451/10000\n",
      "Processing chunk 3501/10000\n",
      "Processing chunk 3551/10000\n",
      "Processing chunk 3601/10000\n",
      "Processing chunk 3651/10000\n",
      "Processing chunk 3701/10000\n",
      "Processing chunk 3751/10000\n",
      "Processing chunk 3801/10000\n",
      "Processing chunk 3851/10000\n",
      "Processing chunk 3901/10000\n",
      "Processing chunk 3951/10000\n",
      "Processing chunk 4001/10000\n",
      "Processing chunk 4051/10000\n",
      "Processing chunk 4101/10000\n",
      "Processing chunk 4151/10000\n",
      "Processing chunk 4201/10000\n",
      "Processing chunk 4251/10000\n",
      "Processing chunk 4301/10000\n",
      "Processing chunk 4351/10000\n",
      "Processing chunk 4401/10000\n",
      "Processing chunk 4451/10000\n",
      "Processing chunk 4501/10000\n",
      "Processing chunk 4551/10000\n",
      "Processing chunk 4601/10000\n",
      "Processing chunk 4651/10000\n",
      "Processing chunk 4701/10000\n",
      "Processing chunk 4751/10000\n",
      "Processing chunk 4801/10000\n",
      "Processing chunk 4851/10000\n",
      "Processing chunk 4901/10000\n",
      "Processing chunk 4951/10000\n",
      "Processing chunk 5001/10000\n",
      "Processing chunk 5051/10000\n",
      "Processing chunk 5101/10000\n",
      "Processing chunk 5151/10000\n",
      "Processing chunk 5201/10000\n",
      "Processing chunk 5251/10000\n",
      "Processing chunk 5301/10000\n",
      "Processing chunk 5351/10000\n",
      "Processing chunk 5401/10000\n",
      "Processing chunk 5451/10000\n",
      "Processing chunk 5501/10000\n",
      "Processing chunk 5551/10000\n",
      "Processing chunk 5601/10000\n",
      "Processing chunk 5651/10000\n",
      "Processing chunk 5701/10000\n",
      "Processing chunk 5751/10000\n",
      "Processing chunk 5801/10000\n",
      "Processing chunk 5851/10000\n",
      "Processing chunk 5901/10000\n",
      "Processing chunk 5951/10000\n",
      "Processing chunk 6001/10000\n",
      "Processing chunk 6051/10000\n",
      "Processing chunk 6101/10000\n",
      "Processing chunk 6151/10000\n",
      "Processing chunk 6201/10000\n",
      "Processing chunk 6251/10000\n",
      "Processing chunk 6301/10000\n",
      "Processing chunk 6351/10000\n",
      "Processing chunk 6401/10000\n",
      "Processing chunk 6451/10000\n",
      "Processing chunk 6501/10000\n",
      "Processing chunk 6551/10000\n",
      "Processing chunk 6601/10000\n",
      "Processing chunk 6651/10000\n",
      "Processing chunk 6701/10000\n",
      "Processing chunk 6751/10000\n",
      "Processing chunk 6801/10000\n",
      "Processing chunk 6851/10000\n",
      "Processing chunk 6901/10000\n",
      "Processing chunk 6951/10000\n",
      "Processing chunk 7001/10000\n",
      "Processing chunk 7051/10000\n",
      "Processing chunk 7101/10000\n",
      "Processing chunk 7151/10000\n",
      "Processing chunk 7201/10000\n",
      "Processing chunk 7251/10000\n",
      "Processing chunk 7301/10000\n",
      "Processing chunk 7351/10000\n",
      "Processing chunk 7401/10000\n",
      "Processing chunk 7451/10000\n",
      "Processing chunk 7501/10000\n",
      "Processing chunk 7551/10000\n",
      "Processing chunk 7601/10000\n",
      "Processing chunk 7651/10000\n",
      "Processing chunk 7701/10000\n",
      "Processing chunk 7751/10000\n",
      "Processing chunk 7801/10000\n",
      "Processing chunk 7851/10000\n",
      "Processing chunk 7901/10000\n",
      "Processing chunk 7951/10000\n",
      "Processing chunk 8001/10000\n",
      "Processing chunk 8051/10000\n",
      "Processing chunk 8101/10000\n",
      "Processing chunk 8151/10000\n",
      "Processing chunk 8201/10000\n",
      "Processing chunk 8251/10000\n",
      "Processing chunk 8301/10000\n",
      "Processing chunk 8351/10000\n",
      "Processing chunk 8401/10000\n",
      "Processing chunk 8451/10000\n",
      "Processing chunk 8501/10000\n",
      "Processing chunk 8551/10000\n",
      "Processing chunk 8601/10000\n",
      "Processing chunk 8651/10000\n",
      "Processing chunk 8701/10000\n",
      "Processing chunk 8751/10000\n",
      "Processing chunk 8801/10000\n",
      "Processing chunk 8851/10000\n",
      "Processing chunk 8901/10000\n",
      "Processing chunk 8951/10000\n",
      "Processing chunk 9001/10000\n",
      "Processing chunk 9051/10000\n",
      "Processing chunk 9101/10000\n",
      "Processing chunk 9151/10000\n",
      "Processing chunk 9201/10000\n",
      "Processing chunk 9251/10000\n",
      "Processing chunk 9301/10000\n",
      "Processing chunk 9351/10000\n",
      "Processing chunk 9401/10000\n",
      "Processing chunk 9451/10000\n",
      "Processing chunk 9501/10000\n",
      "Processing chunk 9551/10000\n",
      "Processing chunk 9601/10000\n",
      "Processing chunk 9651/10000\n",
      "Processing chunk 9701/10000\n",
      "Processing chunk 9751/10000\n",
      "Processing chunk 9801/10000\n",
      "Processing chunk 9851/10000\n",
      "Processing chunk 9901/10000\n",
      "Processing chunk 9951/10000\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 10000\n",
      "Number of hits: 3411\n",
      "Average HR@10: 0.3411\n",
      "Average NDCG@10: 0.3411\n",
      "Evaluation completed in 105.95s\n",
      "HR@10: 0.3411\n",
      "NDCG@10: 0.3411\n"
     ]
    }
   ],
   "source": [
    "class GraphTransformerV2(nn.Module):\n",
    "    def __init__(self, num_layers, d_model, num_heads, d_feedforward, input_dim, num_weights=10, use_weights=True, dropout=0.1):\n",
    "        super(GraphTransformerV2, self).__init__()\n",
    "        self.num_weights = num_weights\n",
    "        self.use_weights = use_weights\n",
    "        self.input_dim = input_dim\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # Input projection layers\n",
    "        self.input_linear = Linear(input_dim, d_model)\n",
    "        self.dng_projection = Linear(input_dim, d_model)\n",
    "        \n",
    "        self.encoder_layer = TransformerEncoderLayer(\n",
    "            d_model=d_model, \n",
    "            nhead=num_heads, \n",
    "            dim_feedforward=d_feedforward, \n",
    "            dropout=dropout, \n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Final output layers\n",
    "        self.pre_output = Linear(d_model, d_model)\n",
    "        self.output_linear = Linear(d_model, 1)\n",
    "        \n",
    "        self.dropout = Dropout(dropout)\n",
    "        self.layer_norm = LayerNorm(d_model)\n",
    "        \n",
    "        if self.use_weights:\n",
    "            self.weight_linears = ModuleList([Linear(input_dim, d_model) for _ in range(num_weights)])\n",
    "\n",
    "    def compute_neighborhood_similarity(self, adjacency_matrix, x):\n",
    "        try:\n",
    "            binary_adj = (adjacency_matrix > 0).float()\n",
    "            intersection = binary_adj @ binary_adj.T\n",
    "            row_sums = binary_adj.sum(dim=1, keepdim=True)\n",
    "            col_sums = binary_adj.sum(dim=0, keepdim=True)\n",
    "            union = row_sums + col_sums.T - intersection\n",
    "            similarity = intersection / (union + 1e-8)\n",
    "            return similarity @ x\n",
    "        except RuntimeError:\n",
    "            return torch.zeros_like(x)\n",
    "\n",
    "    def project_graph_metrics(self, graph_metrics, target_dim):\n",
    "        if graph_metrics.size(1) < target_dim:\n",
    "            repeats = (target_dim + graph_metrics.size(1) - 1) // graph_metrics.size(1)\n",
    "            graph_metrics = graph_metrics.repeat(1, repeats)[:, :target_dim]\n",
    "        elif graph_metrics.size(1) > target_dim:\n",
    "            graph_metrics = graph_metrics[:, :target_dim]\n",
    "        return graph_metrics\n",
    "\n",
    "    def forward(self, x, adjacency_matrix, graph_metrics, weights=None):\n",
    "        adjacency_matrix = adjacency_matrix.float()\n",
    "        graph_metrics = graph_metrics.float()\n",
    "        batch_size, input_dim = x.shape\n",
    "        \n",
    "        if adjacency_matrix.size(0) != batch_size or adjacency_matrix.size(1) != batch_size:\n",
    "            adjacency_matrix = torch.eye(batch_size, device=x.device)\n",
    "\n",
    "        try:\n",
    "            # Direct connections\n",
    "            direct_scores = adjacency_matrix @ x\n",
    "            \n",
    "            # Neighborhood similarity\n",
    "            neighborhood_similarity = self.compute_neighborhood_similarity(adjacency_matrix, x)\n",
    "            \n",
    "            # Graph structure scores\n",
    "            if graph_metrics.dim() == 2:\n",
    "                graph_metrics_projected = self.project_graph_metrics(graph_metrics, input_dim)\n",
    "                graph_structure_scores = graph_metrics_projected * x\n",
    "            else:\n",
    "                graph_structure_scores = torch.zeros_like(x)\n",
    "\n",
    "            # Combine DNG scores and project to d_model dimension\n",
    "            dng_scores = direct_scores + neighborhood_similarity + graph_structure_scores\n",
    "            dng_scores = self.dng_projection(dng_scores)  # Project to d_model dimension\n",
    "            \n",
    "            # Process input through transformer\n",
    "            if self.use_weights and weights is not None:\n",
    "                weighted_x = torch.zeros_like(x)\n",
    "                for i, weight in enumerate(weights.T):\n",
    "                    weighted_x += self.weight_linears[i](x) * weight.unsqueeze(1)\n",
    "                transformer_input = weighted_x\n",
    "            else:\n",
    "                transformer_input = self.input_linear(x)  # Project to d_model dimension\n",
    "\n",
    "            # Apply transformer\n",
    "            transformer_input = self.layer_norm(transformer_input)\n",
    "            transformer_output = self.transformer_encoder(transformer_input.unsqueeze(1)).squeeze(1)\n",
    "            \n",
    "            # Combine transformer output with DNG scores\n",
    "            combined = transformer_output + dng_scores\n",
    "            combined = self.dropout(combined)\n",
    "            \n",
    "            # Final output processing\n",
    "            output = self.pre_output(combined)\n",
    "            output = F.relu(output)\n",
    "            output = self.output_linear(output)\n",
    "            \n",
    "            return output.squeeze(-1)  # Return [batch_size] tensor\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            print(f\"RuntimeError during forward pass: {e}\")\n",
    "            print(f\"x shape: {x.shape}, adjacency_matrix shape: {adjacency_matrix.shape}, graph_metrics shape: {graph_metrics.shape}\")\n",
    "            raise\n",
    "\n",
    "# cropped dataset\n",
    "class MultiBehaviorDataset:\n",
    "    def __init__(self, data_path='/Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/', max_users=10000):\n",
    "        self.data_path = data_path\n",
    "        self.behaviors = ['pv', 'cart', 'buy']\n",
    "        self.trn_file = data_path + 'trn_'\n",
    "        self.tst_file = data_path + 'tst_'\n",
    "        self.max_users = max_users  # Limit number of users\n",
    "        \n",
    "        self.load_training_data()\n",
    "        self.load_test_data()\n",
    "    \n",
    "    def load_training_data(self):\n",
    "        print(\"Loading training data from:\", self.data_path)\n",
    "        self.trn_mats = []\n",
    "        for beh in self.behaviors:\n",
    "            path = self.trn_file + beh\n",
    "            print(f\"Loading behavior: {beh} from {path}\")\n",
    "            if not os.path.exists(path):\n",
    "                raise FileNotFoundError(f\"File not found: {path}\")\n",
    "            with open(path, 'rb') as fs:\n",
    "                mat = pickle.load(fs)\n",
    "                if not isinstance(mat, csr_matrix):\n",
    "                    mat = csr_matrix(mat)\n",
    "                mat = (mat != 0).astype(np.float32)\n",
    "                self.trn_mats.append(mat)\n",
    "        \n",
    "        self.trn_label = 1 * (self.trn_mats[-1] != 0)\n",
    "        self.n_users, self.n_items = self.trn_mats[0].shape\n",
    "        self.n_behaviors = len(self.behaviors)\n",
    "        print(f\"Dataset dimensions: {self.n_users} users, {self.n_items} items\")\n",
    "\n",
    "    def create_adjacency_matrix(self, users):\n",
    "        \"\"\"Optimized adjacency matrix creation\"\"\"\n",
    "        batch_size = len(users)\n",
    "        adj_matrix = torch.zeros(batch_size, batch_size, device=device)\n",
    "        \n",
    "        # Pre-compute user item sets\n",
    "        user_item_sets = []\n",
    "        for user in users:\n",
    "            user_items = set()\n",
    "            for mat in self.trn_mats:\n",
    "                user_items.update(mat[user].indices)\n",
    "            user_item_sets.append(user_items)\n",
    "        \n",
    "        # Compute similarities in parallel\n",
    "        for i in range(batch_size):\n",
    "            if not user_item_sets[i]:\n",
    "                continue\n",
    "            for j in range(i+1, batch_size):\n",
    "                if user_item_sets[j]:\n",
    "                    jaccard = len(user_item_sets[i] & user_item_sets[j]) / len(user_item_sets[i] | user_item_sets[j])\n",
    "                    adj_matrix[i,j] = adj_matrix[j,i] = jaccard\n",
    "        \n",
    "        return adj_matrix\n",
    "\n",
    "    def create_graph_metrics(self, users):\n",
    "        \"\"\"Optimized graph metrics creation\"\"\"\n",
    "        metrics = torch.zeros(len(users), 3, device=device)\n",
    "        \n",
    "        # Vectorized computation\n",
    "        for i, user in enumerate(users):\n",
    "            interactions = np.array([mat[user].nnz for mat in self.trn_mats])\n",
    "            metrics[i,0] = sum(interactions) / 100\n",
    "            metrics[i,1] = (interactions > 0).sum() / len(self.behaviors)\n",
    "            metrics[i,2] = interactions[-1] / max(interactions[0], 1)\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "    def prepare_train_instances(self, max_samples=5000):\n",
    "        \"\"\"Optimized training instance preparation\"\"\"\n",
    "        print(\"Preparing training instances...\")\n",
    "        train_data = []\n",
    "        \n",
    "        # Randomly select users\n",
    "        selected_users = np.random.choice(min(self.n_users, self.max_users), size=min(1000, self.max_users), replace=False)\n",
    "        \n",
    "        for user in selected_users:\n",
    "            pos_items = self.trn_label[user].indices[:2]  # Limit positive items\n",
    "            \n",
    "            if len(pos_items) > 0:\n",
    "                for item in pos_items:\n",
    "                    behaviors = [float(mat[user, item]) for mat in self.trn_mats]\n",
    "                    train_data.append([user, item, 1.0] + behaviors)\n",
    "                    \n",
    "                    # Limited negative sampling\n",
    "                    neg_items = np.random.choice(self.n_items, size=2, replace=False)\n",
    "                    for neg_item in neg_items:\n",
    "                        behaviors = [float(mat[user, neg_item]) for mat in self.trn_mats]\n",
    "                        train_data.append([user, neg_item, 0.0] + behaviors)\n",
    "                        \n",
    "                    if len(train_data) >= max_samples:\n",
    "                        break\n",
    "            \n",
    "            if len(train_data) >= max_samples:\n",
    "                break\n",
    "        \n",
    "        print(f\"Generated {len(train_data)} training instances\")\n",
    "        return np.array(train_data)\n",
    "    def load_test_data(self):\n",
    "        \"\"\"Load test data\"\"\"\n",
    "        test_path = self.tst_file + 'int'\n",
    "        print(f\"Loading test data from: {test_path}\")\n",
    "        if not os.path.exists(test_path):\n",
    "            raise FileNotFoundError(f\"File not found: {test_path}\")\n",
    "        with open(test_path, 'rb') as fs:\n",
    "            self.tst_int = np.array(pickle.load(fs))\n",
    "        \n",
    "        self.tst_users = np.reshape(np.argwhere(self.tst_int != None), [-1])\n",
    "        # Limit test users for faster processing\n",
    "        self.tst_users = self.tst_users[:min(len(self.tst_users), self.max_users)]\n",
    "        print(f\"Using {len(self.tst_users)} test users\")\n",
    "\n",
    "    def get_test_instances(self, num_neg_samples=99):\n",
    "        \"\"\"Generate test instances with negative sampling\"\"\"\n",
    "        print(\"Preparing test instances...\")\n",
    "        test_instances = []\n",
    "        \n",
    "        for user in self.tst_users:\n",
    "            pos_item = self.tst_int[user]\n",
    "            if pos_item is not None:\n",
    "                # Add positive instance\n",
    "                test_instances.append([user, pos_item, 1.0])\n",
    "                \n",
    "                # Add negative instances\n",
    "                try:\n",
    "                    # Get all items and remove positive items\n",
    "                    all_items = set(range(self.n_items))\n",
    "                    pos_items_train = set(self.trn_label[user].indices)\n",
    "                    pos_items_train.add(pos_item)\n",
    "                    neg_items_pool = list(all_items - pos_items_train)\n",
    "                    \n",
    "                    # Sample negative items\n",
    "                    n_neg = min(num_neg_samples, len(neg_items_pool))\n",
    "                    if n_neg > 0:\n",
    "                        neg_items = np.random.choice(neg_items_pool, size=n_neg, replace=False)\n",
    "                        for neg_item in neg_items:\n",
    "                            test_instances.append([user, neg_item, 0.0])\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing test user {user}: {str(e)}\")\n",
    "                    continue\n",
    "                \n",
    "                # Limit the number of test instances for faster processing\n",
    "                if len(test_instances) >= self.max_users * 100:\n",
    "                    break\n",
    "        \n",
    "        if not test_instances:\n",
    "            raise ValueError(\"No test instances were generated!\")\n",
    "            \n",
    "        test_instances = np.array(test_instances)\n",
    "        print(f\"Generated {len(test_instances)} test instances\")\n",
    "        return test_instances\n",
    "\n",
    "\n",
    "def evaluate_model(model, dataset, test_instances, k=10):\n",
    "    \"\"\"Improved evaluation function with better metrics calculation\"\"\"\n",
    "    model.eval()\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    \n",
    "    # Process test instances in smaller chunks\n",
    "    chunk_size = 100\n",
    "    test_chunks = [test_instances[i:i + chunk_size] for i in range(0, len(test_instances), chunk_size)]\n",
    "    \n",
    "    print(f\"Evaluating {len(test_instances)} instances in {len(test_chunks)} chunks...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for chunk_idx, chunk in enumerate(test_chunks):\n",
    "            if chunk_idx % 50 == 0:  # Reduced frequency of progress updates\n",
    "                print(f\"Processing chunk {chunk_idx + 1}/{len(test_chunks)}\")\n",
    "            \n",
    "            # Group by user and ensure we have both positive and negative items\n",
    "            user_items = {}\n",
    "            for inst in chunk:\n",
    "                user = int(inst[0])\n",
    "                item = int(inst[1])\n",
    "                label = float(inst[2])\n",
    "                \n",
    "                if user not in user_items:\n",
    "                    user_items[user] = {'pos': [], 'neg': [], 'all_items': [], 'all_scores': []}\n",
    "                \n",
    "                user_items[user]['all_items'].append(item)\n",
    "                if label > 0.5:\n",
    "                    user_items[user]['pos'].append(item)\n",
    "                else:\n",
    "                    user_items[user]['neg'].append(item)\n",
    "            \n",
    "            # Process each user that has both positive and negative items\n",
    "            for user, data in user_items.items():\n",
    "                if not data['pos'] or not data['neg']:\n",
    "                    continue\n",
    "                \n",
    "                items = data['all_items']\n",
    "                batch_size = len(items)\n",
    "                \n",
    "                # Create input features\n",
    "                behaviors = torch.zeros(batch_size, dataset.n_behaviors, device=device)\n",
    "                for i, item in enumerate(items):\n",
    "                    for j, mat in enumerate(dataset.trn_mats):\n",
    "                        behaviors[i, j] = float(mat[user, item])\n",
    "                \n",
    "                x = torch.cat([\n",
    "                    behaviors,\n",
    "                    torch.zeros(batch_size, model.input_dim - behaviors.size(1), device=device)\n",
    "                ], dim=1)\n",
    "                \n",
    "                # Simplified adjacency matrix for evaluation\n",
    "                adj_matrix = torch.eye(batch_size, device=device)\n",
    "                graph_metrics = dataset.create_graph_metrics([user] * batch_size)\n",
    "                \n",
    "                try:\n",
    "                    predictions = model(x, adj_matrix, graph_metrics)\n",
    "                    predictions = predictions.cpu().numpy().flatten()\n",
    "                    \n",
    "                    # Store all scores\n",
    "                    for item, score in zip(items, predictions):\n",
    "                        data['all_scores'].append((item, score))\n",
    "                    \n",
    "                    # Sort items by score\n",
    "                    sorted_items = [x[0] for x in sorted(data['all_scores'], key=lambda x: x[1], reverse=True)]\n",
    "                    recommended_items = sorted_items[:k]\n",
    "                    \n",
    "                    # Calculate HR\n",
    "                    hit = False\n",
    "                    for pos_item in data['pos']:\n",
    "                        if pos_item in recommended_items:\n",
    "                            hit = True\n",
    "                            break\n",
    "                    hits.append(hit)\n",
    "                    \n",
    "                    # Calculate NDCG\n",
    "                    dcg = 0\n",
    "                    idcg = 1  # Ideal DCG for one relevant item\n",
    "                    for i, item in enumerate(recommended_items):\n",
    "                        if item in data['pos']:\n",
    "                            dcg += 1 / np.log2(i + 2)\n",
    "                    ndcg = dcg / idcg\n",
    "                    ndcgs.append(ndcg)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error evaluating user {user}: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    hr = np.mean(hits) if hits else 0\n",
    "    ndcg = np.mean(ndcgs) if ndcgs else 0\n",
    "    \n",
    "    # Print detailed statistics\n",
    "    print(f\"\\nEvaluation Statistics:\")\n",
    "    print(f\"Total users evaluated: {len(hits)}\")\n",
    "    print(f\"Number of hits: {sum(hits)}\")\n",
    "    print(f\"Average HR@{k}: {hr:.4f}\")\n",
    "    print(f\"Average NDCG@{k}: {ndcg:.4f}\")\n",
    "    \n",
    "    return hr, ndcg\n",
    "\n",
    "def get_test_instances(self, num_neg_samples=99):\n",
    "    \"\"\"Improved test instance generation\"\"\"\n",
    "    print(\"Preparing test instances...\")\n",
    "    test_instances = []\n",
    "    max_test_users = 1000  # Limit number of test users\n",
    "    \n",
    "    # Randomly sample test users if there are too many\n",
    "    test_users = self.tst_users\n",
    "    if len(test_users) > max_test_users:\n",
    "        test_users = np.random.choice(test_users, max_test_users, replace=False)\n",
    "    \n",
    "    for user in test_users:\n",
    "        user = int(user)\n",
    "        pos_item = self.tst_int[user]\n",
    "        if pos_item is not None:\n",
    "            pos_item = int(pos_item)\n",
    "            test_instances.append([user, pos_item, 1.0])\n",
    "            \n",
    "            try:\n",
    "                # Get negative items\n",
    "                all_items = set(range(self.n_items))\n",
    "                pos_items = set(int(x) for x in self.trn_label[user].indices)\n",
    "                pos_items.add(pos_item)\n",
    "                neg_items_pool = list(all_items - pos_items)\n",
    "                \n",
    "                # Sample negative items\n",
    "                n_neg = min(num_neg_samples, len(neg_items_pool))\n",
    "                if n_neg > 0:\n",
    "                    neg_items = np.random.choice(neg_items_pool, size=n_neg, replace=False)\n",
    "                    for neg_item in neg_items:\n",
    "                        test_instances.append([user, int(neg_item), 0.0])\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing test user {user}: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    if not test_instances:\n",
    "        raise ValueError(\"No test instances were generated!\")\n",
    "    \n",
    "    test_instances = np.array(test_instances)\n",
    "    print(f\"Generated {len(test_instances)} test instances\")\n",
    "    print(f\"Number of unique users: {len(set(test_instances[:,0]))}\")\n",
    "    return test_instances\n",
    "\n",
    "def main():\n",
    "    # Configuration\n",
    "    config = {\n",
    "        'd_model': 32,\n",
    "        'num_heads': 2,\n",
    "        'num_layers': 1,\n",
    "        'd_feedforward': 64,\n",
    "        'input_dim': 64,\n",
    "        'num_weights': 3,\n",
    "        'learning_rate': 0.001,\n",
    "        'weight_decay': 1e-6,\n",
    "        'dropout': 0.1,\n",
    "        'gradient_clip': 1.0,\n",
    "        'max_samples': 500000,\n",
    "        'eval_k': 10\n",
    "    }\n",
    "    \n",
    "    print(\"Initializing dataset...\")\n",
    "    dataset = MultiBehaviorDataset(max_users=10000)\n",
    "    train_data = dataset.prepare_train_instances(max_samples=config['max_samples'])\n",
    "    \n",
    "    print(f\"Using {len(train_data)} training instances\")\n",
    "\n",
    "    model = GraphTransformerV2(\n",
    "        num_layers=config['num_layers'],\n",
    "        d_model=config['d_model'],\n",
    "        num_heads=config['num_heads'],\n",
    "        d_feedforward=config['d_feedforward'],\n",
    "        input_dim=config['input_dim'],\n",
    "        num_weights=config['num_weights'],\n",
    "        dropout=config['dropout']\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "    print(\"Preparing training tensors...\")\n",
    "    users = torch.LongTensor(train_data[:, 0]).to(device)\n",
    "    items = torch.LongTensor(train_data[:, 1]).to(device)\n",
    "    labels = torch.FloatTensor(train_data[:, 2]).to(device)\n",
    "    behaviors = torch.FloatTensor(train_data[:, 3:]).to(device)\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    try:\n",
    "        model.train()\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        # Training\n",
    "        x = torch.cat([\n",
    "            behaviors,\n",
    "            torch.zeros(len(users), config['input_dim'] - behaviors.size(1), device=device)\n",
    "        ], dim=1)\n",
    "        \n",
    "        adj_matrix = dataset.create_adjacency_matrix(users)\n",
    "        graph_metrics = dataset.create_graph_metrics(users)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(x, adj_matrix, graph_metrics)\n",
    "        predictions = predictions.view(-1)\n",
    "        labels = labels.view(-1)\n",
    "        \n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), config['gradient_clip'])\n",
    "        optimizer.step()\n",
    "        \n",
    "        training_time = (datetime.now() - start_time).total_seconds()\n",
    "        print(f\"Training completed in {training_time:.2f}s\")\n",
    "        print(f\"Training loss: {loss.item():.4f}\")\n",
    "        \n",
    "        # Evaluation\n",
    "        print(\"\\nStarting evaluation...\")\n",
    "        eval_start_time = datetime.now()\n",
    "        \n",
    "        test_instances = dataset.get_test_instances()\n",
    "        hr, ndcg = evaluate_model(model, dataset, test_instances, k=config['eval_k'])\n",
    "        \n",
    "        eval_time = (datetime.now() - eval_start_time).total_seconds()\n",
    "        print(f\"Evaluation completed in {eval_time:.2f}s\")\n",
    "        print(f\"HR@{config['eval_k']}: {hr:.4f}\")\n",
    "        print(f\"NDCG@{config['eval_k']}: {ndcg:.4f}\")\n",
    "        \n",
    "        # Save results\n",
    "        results = {\n",
    "            'training_time': training_time,\n",
    "            'eval_time': eval_time,\n",
    "            'training_loss': loss.item(),\n",
    "            'hr': hr,\n",
    "            'ndcg': ndcg\n",
    "        }\n",
    "        \n",
    "        # Save to file\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        with open(f'results_{timestamp}.txt', 'w') as f:\n",
    "            for key, value in results.items():\n",
    "                f.write(f\"{key}: {value}\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during training: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoRec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoRec(nn.Module):\n",
    "    def __init__(self, num_items, hidden_dim=256):\n",
    "        super(AutoRec, self).__init__()\n",
    "        self.input_dim = num_items\n",
    "        \n",
    "        # Simplified architecture\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(num_items, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, num_items),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, adjacency_matrix=None, graph_metrics=None):\n",
    "        if x.dim() > 2:\n",
    "            x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Normalize input\n",
    "        x = torch.clamp(x, 0, 1)  # Ensure input is between 0 and 1\n",
    "        \n",
    "        h = self.encoder(x)\n",
    "        out = self.decoder(h)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing dataset...\n",
      "Loading training data from: /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/\n",
      "Loading behavior: pv from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_pv\n",
      "Loading behavior: cart from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_cart\n",
      "Loading behavior: buy from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_buy\n",
      "Dataset dimensions: 21716 users, 7977 items\n",
      "Loading test data from: /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/tst_int\n",
      "Using 10000 test users\n",
      "Interaction matrix shape: (21716, 7977)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yf/20z1hn994jd04q4kl0gpgh740000gn/T/ipykernel_51372/2887790629.py:24: DeprecationWarning: Please import `csr_matrix` from the `scipy.sparse` namespace; the `scipy.sparse.csr` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  mat = pickle.load(fs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-zero elements: 282860\n",
      "Average interactions per user: 13.03\n",
      "\n",
      "Starting training...\n",
      "\n",
      "Epoch 1, Batch 0\n",
      "Loss: 0.6932\n",
      "Max prediction: 0.5348\n",
      "Min prediction: 0.4667\n",
      "Num positive targets: 1538\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 0.31s\n",
      "\n",
      "Epoch 1 completed. Average loss: 0.6809\n",
      "\n",
      "Epoch 2, Batch 0\n",
      "Loss: 0.6470\n",
      "Max prediction: 0.5626\n",
      "Min prediction: 0.2718\n",
      "Num positive targets: 1594\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 0.46s\n",
      "\n",
      "Epoch 2 completed. Average loss: 0.5904\n",
      "\n",
      "Epoch 3, Batch 0\n",
      "Loss: 0.4931\n",
      "Max prediction: 0.5074\n",
      "Min prediction: 0.0155\n",
      "Num positive targets: 1674\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 0.62s\n",
      "\n",
      "Epoch 3 completed. Average loss: 0.4123\n",
      "\n",
      "Epoch 4, Batch 0\n",
      "Loss: 0.3310\n",
      "Max prediction: 0.4717\n",
      "Min prediction: 0.0032\n",
      "Num positive targets: 1434\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 0.77s\n",
      "\n",
      "Epoch 4 completed. Average loss: 0.2324\n",
      "\n",
      "Epoch 5, Batch 0\n",
      "Loss: 0.1635\n",
      "Max prediction: 0.4309\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1643\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 1.05s\n",
      "\n",
      "Epoch 5 completed. Average loss: 0.1205\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 618\n",
      "Average HR@10: 0.6180\n",
      "Average NDCG@10: 0.3194\n",
      "Evaluation completed in 0.83s\n",
      "HR@10: 0.6180\n",
      "NDCG@10: 0.3194\n",
      "\n",
      "Epoch 6, Batch 0\n",
      "Loss: 0.0926\n",
      "Max prediction: 0.3202\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1514\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 2.07s\n",
      "\n",
      "Epoch 6 completed. Average loss: 0.0666\n",
      "\n",
      "Epoch 7, Batch 0\n",
      "Loss: 0.0542\n",
      "Max prediction: 0.3263\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1484\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 2.22s\n",
      "\n",
      "Epoch 7 completed. Average loss: 0.0430\n",
      "\n",
      "Epoch 8, Batch 0\n",
      "Loss: 0.0337\n",
      "Max prediction: 0.3604\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1572\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 2.36s\n",
      "\n",
      "Epoch 8 completed. Average loss: 0.0312\n",
      "\n",
      "Epoch 9, Batch 0\n",
      "Loss: 0.0276\n",
      "Max prediction: 0.3860\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1577\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 2.50s\n",
      "\n",
      "Epoch 9 completed. Average loss: 0.0258\n",
      "\n",
      "Epoch 10, Batch 0\n",
      "Loss: 0.0226\n",
      "Max prediction: 0.3779\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1511\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 2.64s\n",
      "\n",
      "Epoch 10 completed. Average loss: 0.0227\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 755\n",
      "Average HR@10: 0.7550\n",
      "Average NDCG@10: 0.5504\n",
      "Evaluation completed in 0.78s\n",
      "HR@10: 0.7550\n",
      "NDCG@10: 0.5504\n",
      "\n",
      "Epoch 11, Batch 0\n",
      "Loss: 0.0216\n",
      "Max prediction: 0.3549\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1637\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 3.55s\n",
      "\n",
      "Epoch 11 completed. Average loss: 0.0206\n",
      "\n",
      "Epoch 12, Batch 0\n",
      "Loss: 0.0182\n",
      "Max prediction: 0.3496\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1647\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 3.69s\n",
      "\n",
      "Epoch 12 completed. Average loss: 0.0189\n",
      "\n",
      "Epoch 13, Batch 0\n",
      "Loss: 0.0183\n",
      "Max prediction: 0.3569\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1570\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 3.83s\n",
      "\n",
      "Epoch 13 completed. Average loss: 0.0181\n",
      "\n",
      "Epoch 14, Batch 0\n",
      "Loss: 0.0176\n",
      "Max prediction: 0.3651\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1570\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 3.97s\n",
      "\n",
      "Epoch 14 completed. Average loss: 0.0172\n",
      "\n",
      "Epoch 15, Batch 0\n",
      "Loss: 0.0172\n",
      "Max prediction: 0.3486\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1618\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 4.11s\n",
      "\n",
      "Epoch 15 completed. Average loss: 0.0166\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 790\n",
      "Average HR@10: 0.7900\n",
      "Average NDCG@10: 0.5657\n",
      "Evaluation completed in 0.77s\n",
      "HR@10: 0.7900\n",
      "NDCG@10: 0.5657\n",
      "\n",
      "Epoch 16, Batch 0\n",
      "Loss: 0.0181\n",
      "Max prediction: 0.3374\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1703\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 5.02s\n",
      "\n",
      "Epoch 16 completed. Average loss: 0.0161\n",
      "\n",
      "Epoch 17, Batch 0\n",
      "Loss: 0.0160\n",
      "Max prediction: 0.3571\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1538\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 5.16s\n",
      "\n",
      "Epoch 17 completed. Average loss: 0.0158\n",
      "\n",
      "Epoch 18, Batch 0\n",
      "Loss: 0.0141\n",
      "Max prediction: 0.3700\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1516\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 5.30s\n",
      "\n",
      "Epoch 18 completed. Average loss: 0.0152\n",
      "\n",
      "Epoch 19, Batch 0\n",
      "Loss: 0.0157\n",
      "Max prediction: 0.3529\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1622\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 5.43s\n",
      "\n",
      "Epoch 19 completed. Average loss: 0.0148\n",
      "\n",
      "Epoch 20, Batch 0\n",
      "Loss: 0.0148\n",
      "Max prediction: 0.3595\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1647\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 5.58s\n",
      "\n",
      "Epoch 20 completed. Average loss: 0.0147\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 793\n",
      "Average HR@10: 0.7930\n",
      "Average NDCG@10: 0.5824\n",
      "Evaluation completed in 0.81s\n",
      "HR@10: 0.7930\n",
      "NDCG@10: 0.5824\n",
      "\n",
      "Epoch 21, Batch 0\n",
      "Loss: 0.0136\n",
      "Max prediction: 0.3607\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1611\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 6.53s\n",
      "\n",
      "Epoch 21 completed. Average loss: 0.0144\n",
      "\n",
      "Epoch 22, Batch 0\n",
      "Loss: 0.0129\n",
      "Max prediction: 0.3383\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1539\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 6.67s\n",
      "\n",
      "Epoch 22 completed. Average loss: 0.0142\n",
      "\n",
      "Epoch 23, Batch 0\n",
      "Loss: 0.0139\n",
      "Max prediction: 0.3581\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1590\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 6.81s\n",
      "\n",
      "Epoch 23 completed. Average loss: 0.0140\n",
      "\n",
      "Epoch 24, Batch 0\n",
      "Loss: 0.0147\n",
      "Max prediction: 0.3138\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1694\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 6.94s\n",
      "\n",
      "Epoch 24 completed. Average loss: 0.0139\n",
      "\n",
      "Epoch 25, Batch 0\n",
      "Loss: 0.0134\n",
      "Max prediction: 0.3542\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1567\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 7.08s\n",
      "\n",
      "Epoch 25 completed. Average loss: 0.0137\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 779\n",
      "Average HR@10: 0.7790\n",
      "Average NDCG@10: 0.5612\n",
      "Evaluation completed in 0.85s\n",
      "HR@10: 0.7790\n",
      "NDCG@10: 0.5612\n",
      "\n",
      "Epoch 26, Batch 0\n",
      "Loss: 0.0147\n",
      "Max prediction: 0.3217\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1653\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 8.07s\n",
      "\n",
      "Epoch 26 completed. Average loss: 0.0135\n",
      "\n",
      "Epoch 27, Batch 0\n",
      "Loss: 0.0133\n",
      "Max prediction: 0.3237\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1614\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 8.21s\n",
      "\n",
      "Epoch 27 completed. Average loss: 0.0133\n",
      "\n",
      "Epoch 28, Batch 0\n",
      "Loss: 0.0134\n",
      "Max prediction: 0.3388\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1596\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 8.35s\n",
      "\n",
      "Epoch 28 completed. Average loss: 0.0132\n",
      "\n",
      "Epoch 29, Batch 0\n",
      "Loss: 0.0130\n",
      "Max prediction: 0.3239\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1636\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 8.49s\n",
      "\n",
      "Epoch 29 completed. Average loss: 0.0130\n",
      "\n",
      "Epoch 30, Batch 0\n",
      "Loss: 0.0134\n",
      "Max prediction: 0.3260\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1642\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 8.63s\n",
      "\n",
      "Epoch 30 completed. Average loss: 0.0129\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 817\n",
      "Average HR@10: 0.8170\n",
      "Average NDCG@10: 0.5730\n",
      "Evaluation completed in 0.77s\n",
      "HR@10: 0.8170\n",
      "NDCG@10: 0.5730\n",
      "\n",
      "Epoch 31, Batch 0\n",
      "Loss: 0.0134\n",
      "Max prediction: 0.3498\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1652\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 9.54s\n",
      "\n",
      "Epoch 31 completed. Average loss: 0.0128\n",
      "\n",
      "Epoch 32, Batch 0\n",
      "Loss: 0.0124\n",
      "Max prediction: 0.3194\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1576\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 9.68s\n",
      "\n",
      "Epoch 32 completed. Average loss: 0.0127\n",
      "\n",
      "Epoch 33, Batch 0\n",
      "Loss: 0.0117\n",
      "Max prediction: 0.3392\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1478\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 9.82s\n",
      "\n",
      "Epoch 33 completed. Average loss: 0.0127\n",
      "\n",
      "Epoch 34, Batch 0\n",
      "Loss: 0.0124\n",
      "Max prediction: 0.3255\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1641\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 9.96s\n",
      "\n",
      "Epoch 34 completed. Average loss: 0.0125\n",
      "\n",
      "Epoch 35, Batch 0\n",
      "Loss: 0.0127\n",
      "Max prediction: 0.3187\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1699\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 10.10s\n",
      "\n",
      "Epoch 35 completed. Average loss: 0.0124\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 791\n",
      "Average HR@10: 0.7910\n",
      "Average NDCG@10: 0.5573\n",
      "Evaluation completed in 0.78s\n",
      "HR@10: 0.7910\n",
      "NDCG@10: 0.5573\n",
      "\n",
      "Epoch 36, Batch 0\n",
      "Loss: 0.0119\n",
      "Max prediction: 0.3614\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1589\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 11.11s\n",
      "\n",
      "Epoch 36 completed. Average loss: 0.0124\n",
      "\n",
      "Epoch 37, Batch 0\n",
      "Loss: 0.0143\n",
      "Max prediction: 0.3292\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1758\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 11.27s\n",
      "\n",
      "Epoch 37 completed. Average loss: 0.0123\n",
      "\n",
      "Epoch 38, Batch 0\n",
      "Loss: 0.0117\n",
      "Max prediction: 0.3128\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1601\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 11.41s\n",
      "\n",
      "Epoch 38 completed. Average loss: 0.0121\n",
      "\n",
      "Epoch 39, Batch 0\n",
      "Loss: 0.0121\n",
      "Max prediction: 0.3082\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1633\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 11.55s\n",
      "\n",
      "Epoch 39 completed. Average loss: 0.0121\n",
      "\n",
      "Epoch 40, Batch 0\n",
      "Loss: 0.0129\n",
      "Max prediction: 0.3098\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1727\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 11.69s\n",
      "\n",
      "Epoch 40 completed. Average loss: 0.0120\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 794\n",
      "Average HR@10: 0.7940\n",
      "Average NDCG@10: 0.5593\n",
      "Evaluation completed in 0.78s\n",
      "HR@10: 0.7940\n",
      "NDCG@10: 0.5593\n",
      "\n",
      "Epoch 41, Batch 0\n",
      "Loss: 0.0126\n",
      "Max prediction: 0.3163\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1675\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 12.60s\n",
      "\n",
      "Epoch 41 completed. Average loss: 0.0119\n",
      "\n",
      "Epoch 42, Batch 0\n",
      "Loss: 0.0124\n",
      "Max prediction: 0.2829\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1712\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 12.74s\n",
      "\n",
      "Epoch 42 completed. Average loss: 0.0118\n",
      "\n",
      "Epoch 43, Batch 0\n",
      "Loss: 0.0116\n",
      "Max prediction: 0.3102\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1631\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 12.89s\n",
      "\n",
      "Epoch 43 completed. Average loss: 0.0118\n",
      "\n",
      "Epoch 44, Batch 0\n",
      "Loss: 0.0123\n",
      "Max prediction: 0.3131\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1677\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 13.03s\n",
      "\n",
      "Epoch 44 completed. Average loss: 0.0117\n",
      "\n",
      "Epoch 45, Batch 0\n",
      "Loss: 0.0113\n",
      "Max prediction: 0.3504\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1563\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 13.16s\n",
      "\n",
      "Epoch 45 completed. Average loss: 0.0116\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 797\n",
      "Average HR@10: 0.7970\n",
      "Average NDCG@10: 0.5683\n",
      "Evaluation completed in 0.78s\n",
      "HR@10: 0.7970\n",
      "NDCG@10: 0.5683\n",
      "\n",
      "Epoch 46, Batch 0\n",
      "Loss: 0.0113\n",
      "Max prediction: 0.3074\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1573\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 14.08s\n",
      "\n",
      "Epoch 46 completed. Average loss: 0.0116\n",
      "\n",
      "Epoch 47, Batch 0\n",
      "Loss: 0.0118\n",
      "Max prediction: 0.6250\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1594\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 14.22s\n",
      "\n",
      "Epoch 47 completed. Average loss: 0.0114\n",
      "\n",
      "Epoch 48, Batch 0\n",
      "Loss: 0.0105\n",
      "Max prediction: 0.2990\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1460\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 14.36s\n",
      "\n",
      "Epoch 48 completed. Average loss: 0.0114\n",
      "\n",
      "Epoch 49, Batch 0\n",
      "Loss: 0.0113\n",
      "Max prediction: 0.4800\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1623\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 14.50s\n",
      "\n",
      "Epoch 49 completed. Average loss: 0.0113\n",
      "\n",
      "Epoch 50, Batch 0\n",
      "Loss: 0.0109\n",
      "Max prediction: 0.3216\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1583\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 14.64s\n",
      "\n",
      "Epoch 50 completed. Average loss: 0.0112\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 816\n",
      "Average HR@10: 0.8160\n",
      "Average NDCG@10: 0.5778\n",
      "Evaluation completed in 0.89s\n",
      "HR@10: 0.8160\n",
      "NDCG@10: 0.5778\n",
      "\n",
      "Epoch 51, Batch 0\n",
      "Loss: 0.0115\n",
      "Max prediction: 0.6177\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1691\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 15.68s\n",
      "\n",
      "Epoch 51 completed. Average loss: 0.0111\n",
      "\n",
      "Epoch 52, Batch 0\n",
      "Loss: 0.0107\n",
      "Max prediction: 0.6794\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1608\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 15.83s\n",
      "\n",
      "Epoch 52 completed. Average loss: 0.0111\n",
      "\n",
      "Epoch 53, Batch 0\n",
      "Loss: 0.0109\n",
      "Max prediction: 0.6791\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1628\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 15.98s\n",
      "\n",
      "Epoch 53 completed. Average loss: 0.0110\n",
      "\n",
      "Epoch 54, Batch 0\n",
      "Loss: 0.0104\n",
      "Max prediction: 0.2822\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1487\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 16.11s\n",
      "\n",
      "Epoch 54 completed. Average loss: 0.0109\n",
      "\n",
      "Epoch 55, Batch 0\n",
      "Loss: 0.0103\n",
      "Max prediction: 0.4098\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1432\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 16.25s\n",
      "\n",
      "Epoch 55 completed. Average loss: 0.0109\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 806\n",
      "Average HR@10: 0.8060\n",
      "Average NDCG@10: 0.5818\n",
      "Evaluation completed in 0.88s\n",
      "HR@10: 0.8060\n",
      "NDCG@10: 0.5818\n",
      "\n",
      "Epoch 56, Batch 0\n",
      "Loss: 0.0114\n",
      "Max prediction: 0.6713\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1722\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 17.29s\n",
      "\n",
      "Epoch 56 completed. Average loss: 0.0107\n",
      "\n",
      "Epoch 57, Batch 0\n",
      "Loss: 0.0111\n",
      "Max prediction: 0.9141\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1740\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 17.43s\n",
      "\n",
      "Epoch 57 completed. Average loss: 0.0107\n",
      "\n",
      "Epoch 58, Batch 0\n",
      "Loss: 0.0105\n",
      "Max prediction: 0.7100\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1561\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 17.57s\n",
      "\n",
      "Epoch 58 completed. Average loss: 0.0107\n",
      "\n",
      "Epoch 59, Batch 0\n",
      "Loss: 0.0112\n",
      "Max prediction: 0.9693\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1714\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 17.71s\n",
      "\n",
      "Epoch 59 completed. Average loss: 0.0106\n",
      "\n",
      "Epoch 60, Batch 0\n",
      "Loss: 0.0105\n",
      "Max prediction: 0.8468\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1621\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 17.85s\n",
      "\n",
      "Epoch 60 completed. Average loss: 0.0105\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 805\n",
      "Average HR@10: 0.8050\n",
      "Average NDCG@10: 0.5829\n",
      "Evaluation completed in 0.78s\n",
      "HR@10: 0.8050\n",
      "NDCG@10: 0.5829\n",
      "\n",
      "Epoch 61, Batch 0\n",
      "Loss: 0.0102\n",
      "Max prediction: 0.9506\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1658\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 18.77s\n",
      "\n",
      "Epoch 61 completed. Average loss: 0.0105\n",
      "\n",
      "Epoch 62, Batch 0\n",
      "Loss: 0.0103\n",
      "Max prediction: 0.9734\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1572\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 18.91s\n",
      "\n",
      "Epoch 62 completed. Average loss: 0.0105\n",
      "\n",
      "Epoch 63, Batch 0\n",
      "Loss: 0.0115\n",
      "Max prediction: 0.9602\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1827\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 19.05s\n",
      "\n",
      "Epoch 63 completed. Average loss: 0.0104\n",
      "\n",
      "Epoch 64, Batch 0\n",
      "Loss: 0.0105\n",
      "Max prediction: 0.7601\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1640\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 19.20s\n",
      "\n",
      "Epoch 64 completed. Average loss: 0.0104\n",
      "\n",
      "Epoch 65, Batch 0\n",
      "Loss: 0.0097\n",
      "Max prediction: 0.7613\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1520\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 19.34s\n",
      "\n",
      "Epoch 65 completed. Average loss: 0.0102\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 791\n",
      "Average HR@10: 0.7910\n",
      "Average NDCG@10: 0.5799\n",
      "Evaluation completed in 0.77s\n",
      "HR@10: 0.7910\n",
      "NDCG@10: 0.5799\n",
      "\n",
      "Epoch 66, Batch 0\n",
      "Loss: 0.0117\n",
      "Max prediction: 0.9202\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1857\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 20.25s\n",
      "\n",
      "Epoch 66 completed. Average loss: 0.0102\n",
      "\n",
      "Epoch 67, Batch 0\n",
      "Loss: 0.0105\n",
      "Max prediction: 0.5239\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1595\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 20.53s\n",
      "\n",
      "Epoch 67 completed. Average loss: 0.0102\n",
      "\n",
      "Epoch 68, Batch 0\n",
      "Loss: 0.0105\n",
      "Max prediction: 0.9242\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1611\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 20.66s\n",
      "\n",
      "Epoch 68 completed. Average loss: 0.0102\n",
      "\n",
      "Epoch 69, Batch 0\n",
      "Loss: 0.0108\n",
      "Max prediction: 0.8040\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1676\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 20.81s\n",
      "\n",
      "Epoch 69 completed. Average loss: 0.0102\n",
      "\n",
      "Epoch 70, Batch 0\n",
      "Loss: 0.0099\n",
      "Max prediction: 0.9918\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1585\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 20.95s\n",
      "\n",
      "Epoch 70 completed. Average loss: 0.0101\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 814\n",
      "Average HR@10: 0.8140\n",
      "Average NDCG@10: 0.5937\n",
      "Evaluation completed in 0.78s\n",
      "HR@10: 0.8140\n",
      "NDCG@10: 0.5937\n",
      "\n",
      "Epoch 71, Batch 0\n",
      "Loss: 0.0102\n",
      "Max prediction: 0.9325\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1608\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 21.87s\n",
      "\n",
      "Epoch 71 completed. Average loss: 0.0100\n",
      "\n",
      "Epoch 72, Batch 0\n",
      "Loss: 0.0101\n",
      "Max prediction: 0.9913\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1753\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 22.01s\n",
      "\n",
      "Epoch 72 completed. Average loss: 0.0100\n",
      "\n",
      "Epoch 73, Batch 0\n",
      "Loss: 0.0098\n",
      "Max prediction: 0.9787\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1591\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 22.15s\n",
      "\n",
      "Epoch 73 completed. Average loss: 0.0100\n",
      "\n",
      "Epoch 74, Batch 0\n",
      "Loss: 0.0099\n",
      "Max prediction: 0.7575\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1594\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 22.29s\n",
      "\n",
      "Epoch 74 completed. Average loss: 0.0100\n",
      "\n",
      "Epoch 75, Batch 0\n",
      "Loss: 0.0099\n",
      "Max prediction: 0.4747\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1510\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 22.43s\n",
      "\n",
      "Epoch 75 completed. Average loss: 0.0099\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 794\n",
      "Average HR@10: 0.7940\n",
      "Average NDCG@10: 0.5660\n",
      "Evaluation completed in 0.77s\n",
      "HR@10: 0.7940\n",
      "NDCG@10: 0.5660\n",
      "\n",
      "Epoch 76, Batch 0\n",
      "Loss: 0.0099\n",
      "Max prediction: 0.9982\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1659\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 23.33s\n",
      "\n",
      "Epoch 76 completed. Average loss: 0.0099\n",
      "\n",
      "Epoch 77, Batch 0\n",
      "Loss: 0.0099\n",
      "Max prediction: 0.9967\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1656\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 23.48s\n",
      "\n",
      "Epoch 77 completed. Average loss: 0.0098\n",
      "\n",
      "Epoch 78, Batch 0\n",
      "Loss: 0.0096\n",
      "Max prediction: 0.9952\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1604\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 23.66s\n",
      "\n",
      "Epoch 78 completed. Average loss: 0.0098\n",
      "\n",
      "Epoch 79, Batch 0\n",
      "Loss: 0.0106\n",
      "Max prediction: 0.8010\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1655\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 23.80s\n",
      "\n",
      "Epoch 79 completed. Average loss: 0.0098\n",
      "\n",
      "Epoch 80, Batch 0\n",
      "Loss: 0.0107\n",
      "Max prediction: 0.9952\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1847\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 23.95s\n",
      "\n",
      "Epoch 80 completed. Average loss: 0.0097\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 811\n",
      "Average HR@10: 0.8110\n",
      "Average NDCG@10: 0.5877\n",
      "Evaluation completed in 0.78s\n",
      "HR@10: 0.8110\n",
      "NDCG@10: 0.5877\n",
      "\n",
      "Epoch 81, Batch 0\n",
      "Loss: 0.0096\n",
      "Max prediction: 0.9656\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1596\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 24.89s\n",
      "\n",
      "Epoch 81 completed. Average loss: 0.0097\n",
      "\n",
      "Epoch 82, Batch 0\n",
      "Loss: 0.0096\n",
      "Max prediction: 0.9991\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1698\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 25.09s\n",
      "\n",
      "Epoch 82 completed. Average loss: 0.0097\n",
      "\n",
      "Epoch 83, Batch 0\n",
      "Loss: 0.0095\n",
      "Max prediction: 0.9499\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1527\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 25.24s\n",
      "\n",
      "Epoch 83 completed. Average loss: 0.0097\n",
      "\n",
      "Epoch 84, Batch 0\n",
      "Loss: 0.0101\n",
      "Max prediction: 0.9879\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1623\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 25.39s\n",
      "\n",
      "Epoch 84 completed. Average loss: 0.0096\n",
      "\n",
      "Epoch 85, Batch 0\n",
      "Loss: 0.0098\n",
      "Max prediction: 1.0000\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1693\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 25.53s\n",
      "\n",
      "Epoch 85 completed. Average loss: 0.0096\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 807\n",
      "Average HR@10: 0.8070\n",
      "Average NDCG@10: 0.5883\n",
      "Evaluation completed in 0.87s\n",
      "HR@10: 0.8070\n",
      "NDCG@10: 0.5883\n",
      "\n",
      "Epoch 86, Batch 0\n",
      "Loss: 0.0095\n",
      "Max prediction: 0.9770\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1621\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 26.56s\n",
      "\n",
      "Epoch 86 completed. Average loss: 0.0096\n",
      "\n",
      "Epoch 87, Batch 0\n",
      "Loss: 0.0100\n",
      "Max prediction: 0.9995\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1744\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 26.70s\n",
      "\n",
      "Epoch 87 completed. Average loss: 0.0095\n",
      "\n",
      "Epoch 88, Batch 0\n",
      "Loss: 0.0092\n",
      "Max prediction: 0.5714\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1467\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 26.84s\n",
      "\n",
      "Epoch 88 completed. Average loss: 0.0095\n",
      "\n",
      "Epoch 89, Batch 0\n",
      "Loss: 0.0091\n",
      "Max prediction: 0.9999\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1743\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 26.98s\n",
      "\n",
      "Epoch 89 completed. Average loss: 0.0095\n",
      "\n",
      "Epoch 90, Batch 0\n",
      "Loss: 0.0093\n",
      "Max prediction: 0.7012\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1514\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 27.12s\n",
      "\n",
      "Epoch 90 completed. Average loss: 0.0095\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 799\n",
      "Average HR@10: 0.7990\n",
      "Average NDCG@10: 0.5640\n",
      "Evaluation completed in 0.80s\n",
      "HR@10: 0.7990\n",
      "NDCG@10: 0.5640\n",
      "\n",
      "Epoch 91, Batch 0\n",
      "Loss: 0.0095\n",
      "Max prediction: 0.9979\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1675\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 28.07s\n",
      "\n",
      "Epoch 91 completed. Average loss: 0.0094\n",
      "\n",
      "Epoch 92, Batch 0\n",
      "Loss: 0.0092\n",
      "Max prediction: 0.9607\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1520\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 28.21s\n",
      "\n",
      "Epoch 92 completed. Average loss: 0.0094\n",
      "\n",
      "Epoch 93, Batch 0\n",
      "Loss: 0.0089\n",
      "Max prediction: 0.9904\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1486\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 28.35s\n",
      "\n",
      "Epoch 93 completed. Average loss: 0.0093\n",
      "\n",
      "Epoch 94, Batch 0\n",
      "Loss: 0.0093\n",
      "Max prediction: 0.9991\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1566\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 28.49s\n",
      "\n",
      "Epoch 94 completed. Average loss: 0.0093\n",
      "\n",
      "Epoch 95, Batch 0\n",
      "Loss: 0.0093\n",
      "Max prediction: 0.9886\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1652\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 28.62s\n",
      "\n",
      "Epoch 95 completed. Average loss: 0.0093\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 818\n",
      "Average HR@10: 0.8180\n",
      "Average NDCG@10: 0.5882\n",
      "Evaluation completed in 0.77s\n",
      "HR@10: 0.8180\n",
      "NDCG@10: 0.5882\n",
      "\n",
      "Epoch 96, Batch 0\n",
      "Loss: 0.0092\n",
      "Max prediction: 0.5213\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1564\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 29.54s\n",
      "\n",
      "Epoch 96 completed. Average loss: 0.0092\n",
      "\n",
      "Epoch 97, Batch 0\n",
      "Loss: 0.0091\n",
      "Max prediction: 0.9992\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1705\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 29.68s\n",
      "\n",
      "Epoch 97 completed. Average loss: 0.0092\n",
      "\n",
      "Epoch 98, Batch 0\n",
      "Loss: 0.0095\n",
      "Max prediction: 0.9994\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1695\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 29.82s\n",
      "\n",
      "Epoch 98 completed. Average loss: 0.0092\n",
      "\n",
      "Epoch 99, Batch 0\n",
      "Loss: 0.0092\n",
      "Max prediction: 0.9907\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1622\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 30.08s\n",
      "\n",
      "Epoch 99 completed. Average loss: 0.0092\n",
      "\n",
      "Epoch 100, Batch 0\n",
      "Loss: 0.0092\n",
      "Max prediction: 0.9997\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1661\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 30.23s\n",
      "\n",
      "Epoch 100 completed. Average loss: 0.0091\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 781\n",
      "Average HR@10: 0.7810\n",
      "Average NDCG@10: 0.5528\n",
      "Evaluation completed in 0.76s\n",
      "HR@10: 0.7810\n",
      "NDCG@10: 0.5528\n",
      "\n",
      "Epoch 101, Batch 0\n",
      "Loss: 0.0087\n",
      "Max prediction: 0.9804\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1559\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 31.13s\n",
      "\n",
      "Epoch 101 completed. Average loss: 0.0091\n",
      "\n",
      "Epoch 102, Batch 0\n",
      "Loss: 0.0094\n",
      "Max prediction: 1.0000\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1711\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 31.27s\n",
      "\n",
      "Epoch 102 completed. Average loss: 0.0091\n",
      "\n",
      "Epoch 103, Batch 0\n",
      "Loss: 0.0090\n",
      "Max prediction: 0.9886\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1604\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 31.42s\n",
      "\n",
      "Epoch 103 completed. Average loss: 0.0090\n",
      "\n",
      "Epoch 104, Batch 0\n",
      "Loss: 0.0094\n",
      "Max prediction: 0.9916\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1694\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 31.55s\n",
      "\n",
      "Epoch 104 completed. Average loss: 0.0090\n",
      "\n",
      "Epoch 105, Batch 0\n",
      "Loss: 0.0089\n",
      "Max prediction: 0.9768\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1578\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 31.69s\n",
      "\n",
      "Epoch 105 completed. Average loss: 0.0090\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 809\n",
      "Average HR@10: 0.8090\n",
      "Average NDCG@10: 0.6081\n",
      "Evaluation completed in 0.77s\n",
      "HR@10: 0.8090\n",
      "NDCG@10: 0.6081\n",
      "\n",
      "Epoch 106, Batch 0\n",
      "Loss: 0.0093\n",
      "Max prediction: 0.9993\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1754\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 32.61s\n",
      "\n",
      "Epoch 106 completed. Average loss: 0.0090\n",
      "\n",
      "Epoch 107, Batch 0\n",
      "Loss: 0.0086\n",
      "Max prediction: 0.9992\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1535\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 32.79s\n",
      "\n",
      "Epoch 107 completed. Average loss: 0.0090\n",
      "\n",
      "Epoch 108, Batch 0\n",
      "Loss: 0.0092\n",
      "Max prediction: 0.9909\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1635\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 32.93s\n",
      "\n",
      "Epoch 108 completed. Average loss: 0.0089\n",
      "\n",
      "Epoch 109, Batch 0\n",
      "Loss: 0.0093\n",
      "Max prediction: 0.9814\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1713\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 33.07s\n",
      "\n",
      "Epoch 109 completed. Average loss: 0.0089\n",
      "\n",
      "Epoch 110, Batch 0\n",
      "Loss: 0.0092\n",
      "Max prediction: 0.9960\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1749\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 33.21s\n",
      "\n",
      "Epoch 110 completed. Average loss: 0.0089\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 832\n",
      "Average HR@10: 0.8320\n",
      "Average NDCG@10: 0.6057\n",
      "Evaluation completed in 0.79s\n",
      "HR@10: 0.8320\n",
      "NDCG@10: 0.6057\n",
      "\n",
      "Epoch 111, Batch 0\n",
      "Loss: 0.0087\n",
      "Max prediction: 0.9955\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1577\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 34.14s\n",
      "\n",
      "Epoch 111 completed. Average loss: 0.0089\n",
      "\n",
      "Epoch 112, Batch 0\n",
      "Loss: 0.0084\n",
      "Max prediction: 0.9934\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1467\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 34.28s\n",
      "\n",
      "Epoch 112 completed. Average loss: 0.0088\n",
      "\n",
      "Epoch 113, Batch 0\n",
      "Loss: 0.0089\n",
      "Max prediction: 0.9669\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1571\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 34.42s\n",
      "\n",
      "Epoch 113 completed. Average loss: 0.0088\n",
      "\n",
      "Epoch 114, Batch 0\n",
      "Loss: 0.0089\n",
      "Max prediction: 0.9999\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1649\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 34.57s\n",
      "\n",
      "Epoch 114 completed. Average loss: 0.0088\n",
      "\n",
      "Epoch 115, Batch 0\n",
      "Loss: 0.0087\n",
      "Max prediction: 0.9998\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1652\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 34.70s\n",
      "\n",
      "Epoch 115 completed. Average loss: 0.0088\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 801\n",
      "Average HR@10: 0.8010\n",
      "Average NDCG@10: 0.5820\n",
      "Evaluation completed in 0.87s\n",
      "HR@10: 0.8010\n",
      "NDCG@10: 0.5820\n",
      "\n",
      "Epoch 116, Batch 0\n",
      "Loss: 0.0087\n",
      "Max prediction: 0.9997\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1576\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 35.72s\n",
      "\n",
      "Epoch 116 completed. Average loss: 0.0087\n",
      "\n",
      "Epoch 117, Batch 0\n",
      "Loss: 0.0091\n",
      "Max prediction: 0.9958\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1751\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 35.86s\n",
      "\n",
      "Epoch 117 completed. Average loss: 0.0087\n",
      "\n",
      "Epoch 118, Batch 0\n",
      "Loss: 0.0083\n",
      "Max prediction: 0.9759\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1499\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 36.02s\n",
      "\n",
      "Epoch 118 completed. Average loss: 0.0087\n",
      "\n",
      "Epoch 119, Batch 0\n",
      "Loss: 0.0089\n",
      "Max prediction: 0.9743\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1612\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 36.17s\n",
      "\n",
      "Epoch 119 completed. Average loss: 0.0087\n",
      "\n",
      "Epoch 120, Batch 0\n",
      "Loss: 0.0086\n",
      "Max prediction: 0.9348\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1580\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 36.33s\n",
      "\n",
      "Epoch 120 completed. Average loss: 0.0087\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 800\n",
      "Average HR@10: 0.8000\n",
      "Average NDCG@10: 0.5877\n",
      "Evaluation completed in 0.97s\n",
      "HR@10: 0.8000\n",
      "NDCG@10: 0.5877\n",
      "\n",
      "Epoch 121, Batch 0\n",
      "Loss: 0.0085\n",
      "Max prediction: 0.9999\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1659\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 37.48s\n",
      "\n",
      "Epoch 121 completed. Average loss: 0.0086\n",
      "\n",
      "Epoch 122, Batch 0\n",
      "Loss: 0.0084\n",
      "Max prediction: 0.8123\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1493\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 37.63s\n",
      "\n",
      "Epoch 122 completed. Average loss: 0.0086\n",
      "\n",
      "Epoch 123, Batch 0\n",
      "Loss: 0.0087\n",
      "Max prediction: 0.9926\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1606\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 37.78s\n",
      "\n",
      "Epoch 123 completed. Average loss: 0.0086\n",
      "\n",
      "Epoch 124, Batch 0\n",
      "Loss: 0.0087\n",
      "Max prediction: 0.9989\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1654\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 37.92s\n",
      "\n",
      "Epoch 124 completed. Average loss: 0.0085\n",
      "\n",
      "Epoch 125, Batch 0\n",
      "Loss: 0.0085\n",
      "Max prediction: 0.9945\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1617\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 38.24s\n",
      "\n",
      "Epoch 125 completed. Average loss: 0.0085\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 803\n",
      "Average HR@10: 0.8030\n",
      "Average NDCG@10: 0.5818\n",
      "Evaluation completed in 0.88s\n",
      "HR@10: 0.8030\n",
      "NDCG@10: 0.5818\n",
      "\n",
      "Epoch 126, Batch 0\n",
      "Loss: 0.0087\n",
      "Max prediction: 0.9763\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1705\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 39.33s\n",
      "\n",
      "Epoch 126 completed. Average loss: 0.0085\n",
      "\n",
      "Epoch 127, Batch 0\n",
      "Loss: 0.0082\n",
      "Max prediction: 0.9889\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1477\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 39.48s\n",
      "\n",
      "Epoch 127 completed. Average loss: 0.0085\n",
      "\n",
      "Epoch 128, Batch 0\n",
      "Loss: 0.0083\n",
      "Max prediction: 0.9999\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1706\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 39.64s\n",
      "\n",
      "Epoch 128 completed. Average loss: 0.0084\n",
      "\n",
      "Epoch 129, Batch 0\n",
      "Loss: 0.0090\n",
      "Max prediction: 0.9960\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1765\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 39.80s\n",
      "\n",
      "Epoch 129 completed. Average loss: 0.0084\n",
      "\n",
      "Epoch 130, Batch 0\n",
      "Loss: 0.0084\n",
      "Max prediction: 0.9899\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1585\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 39.95s\n",
      "\n",
      "Epoch 130 completed. Average loss: 0.0084\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 810\n",
      "Average HR@10: 0.8100\n",
      "Average NDCG@10: 0.5887\n",
      "Evaluation completed in 0.88s\n",
      "HR@10: 0.8100\n",
      "NDCG@10: 0.5887\n",
      "\n",
      "Epoch 131, Batch 0\n",
      "Loss: 0.0086\n",
      "Max prediction: 0.8338\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1555\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 40.99s\n",
      "\n",
      "Epoch 131 completed. Average loss: 0.0084\n",
      "\n",
      "Epoch 132, Batch 0\n",
      "Loss: 0.0083\n",
      "Max prediction: 1.0000\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1626\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 41.13s\n",
      "\n",
      "Epoch 132 completed. Average loss: 0.0084\n",
      "\n",
      "Epoch 133, Batch 0\n",
      "Loss: 0.0079\n",
      "Max prediction: 0.7453\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1411\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 41.29s\n",
      "\n",
      "Epoch 133 completed. Average loss: 0.0083\n",
      "\n",
      "Epoch 134, Batch 0\n",
      "Loss: 0.0085\n",
      "Max prediction: 0.9926\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1678\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 41.43s\n",
      "\n",
      "Epoch 134 completed. Average loss: 0.0083\n",
      "\n",
      "Epoch 135, Batch 0\n",
      "Loss: 0.0084\n",
      "Max prediction: 0.9996\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1600\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 41.57s\n",
      "\n",
      "Epoch 135 completed. Average loss: 0.0083\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 818\n",
      "Average HR@10: 0.8180\n",
      "Average NDCG@10: 0.5849\n",
      "Evaluation completed in 0.82s\n",
      "HR@10: 0.8180\n",
      "NDCG@10: 0.5849\n",
      "\n",
      "Epoch 136, Batch 0\n",
      "Loss: 0.0087\n",
      "Max prediction: 0.9919\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1688\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 42.59s\n",
      "\n",
      "Epoch 136 completed. Average loss: 0.0083\n",
      "\n",
      "Epoch 137, Batch 0\n",
      "Loss: 0.0080\n",
      "Max prediction: 0.9978\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1647\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 42.74s\n",
      "\n",
      "Epoch 137 completed. Average loss: 0.0082\n",
      "\n",
      "Epoch 138, Batch 0\n",
      "Loss: 0.0081\n",
      "Max prediction: 0.9999\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1631\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 42.88s\n",
      "\n",
      "Epoch 138 completed. Average loss: 0.0082\n",
      "\n",
      "Epoch 139, Batch 0\n",
      "Loss: 0.0084\n",
      "Max prediction: 0.9597\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1582\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 43.02s\n",
      "\n",
      "Epoch 139 completed. Average loss: 0.0082\n",
      "\n",
      "Epoch 140, Batch 0\n",
      "Loss: 0.0084\n",
      "Max prediction: 0.9229\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1728\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 43.16s\n",
      "\n",
      "Epoch 140 completed. Average loss: 0.0081\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 811\n",
      "Average HR@10: 0.8110\n",
      "Average NDCG@10: 0.5902\n",
      "Evaluation completed in 0.89s\n",
      "HR@10: 0.8110\n",
      "NDCG@10: 0.5902\n",
      "\n",
      "Epoch 141, Batch 0\n",
      "Loss: 0.0086\n",
      "Max prediction: 0.9606\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1708\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 44.19s\n",
      "\n",
      "Epoch 141 completed. Average loss: 0.0081\n",
      "\n",
      "Epoch 142, Batch 0\n",
      "Loss: 0.0084\n",
      "Max prediction: 0.9946\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1731\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 44.33s\n",
      "\n",
      "Epoch 142 completed. Average loss: 0.0081\n",
      "\n",
      "Epoch 143, Batch 0\n",
      "Loss: 0.0078\n",
      "Max prediction: 1.0000\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1613\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 44.47s\n",
      "\n",
      "Epoch 143 completed. Average loss: 0.0081\n",
      "\n",
      "Epoch 144, Batch 0\n",
      "Loss: 0.0080\n",
      "Max prediction: 0.9767\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1525\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 44.61s\n",
      "\n",
      "Epoch 144 completed. Average loss: 0.0081\n",
      "\n",
      "Epoch 145, Batch 0\n",
      "Loss: 0.0081\n",
      "Max prediction: 0.9997\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1672\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 44.77s\n",
      "\n",
      "Epoch 145 completed. Average loss: 0.0080\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 800\n",
      "Average HR@10: 0.8000\n",
      "Average NDCG@10: 0.5826\n",
      "Evaluation completed in 1.24s\n",
      "HR@10: 0.8000\n",
      "NDCG@10: 0.5826\n",
      "\n",
      "Epoch 146, Batch 0\n",
      "Loss: 0.0080\n",
      "Max prediction: 0.7511\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1512\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 46.32s\n",
      "\n",
      "Epoch 146 completed. Average loss: 0.0080\n",
      "\n",
      "Epoch 147, Batch 0\n",
      "Loss: 0.0079\n",
      "Max prediction: 0.9300\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1568\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 46.67s\n",
      "\n",
      "Epoch 147 completed. Average loss: 0.0080\n",
      "\n",
      "Epoch 148, Batch 0\n",
      "Loss: 0.0083\n",
      "Max prediction: 0.9893\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1680\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 46.91s\n",
      "\n",
      "Epoch 148 completed. Average loss: 0.0080\n",
      "\n",
      "Epoch 149, Batch 0\n",
      "Loss: 0.0078\n",
      "Max prediction: 0.9295\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1560\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 47.14s\n",
      "\n",
      "Epoch 149 completed. Average loss: 0.0079\n",
      "\n",
      "Epoch 150, Batch 0\n",
      "Loss: 0.0079\n",
      "Max prediction: 0.9738\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1509\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 47.29s\n",
      "\n",
      "Epoch 150 completed. Average loss: 0.0079\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 804\n",
      "Average HR@10: 0.8040\n",
      "Average NDCG@10: 0.5915\n",
      "Evaluation completed in 0.76s\n",
      "HR@10: 0.8040\n",
      "NDCG@10: 0.5915\n",
      "\n",
      "Epoch 151, Batch 0\n",
      "Loss: 0.0081\n",
      "Max prediction: 0.9508\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1611\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 48.19s\n",
      "\n",
      "Epoch 151 completed. Average loss: 0.0079\n",
      "\n",
      "Epoch 152, Batch 0\n",
      "Loss: 0.0074\n",
      "Max prediction: 0.9999\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1600\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 48.31s\n",
      "\n",
      "Epoch 152 completed. Average loss: 0.0079\n",
      "\n",
      "Epoch 153, Batch 0\n",
      "Loss: 0.0078\n",
      "Max prediction: 0.9986\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1593\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 48.47s\n",
      "\n",
      "Epoch 153 completed. Average loss: 0.0078\n",
      "\n",
      "Epoch 154, Batch 0\n",
      "Loss: 0.0079\n",
      "Max prediction: 0.9992\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1559\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 48.60s\n",
      "\n",
      "Epoch 154 completed. Average loss: 0.0078\n",
      "\n",
      "Epoch 155, Batch 0\n",
      "Loss: 0.0080\n",
      "Max prediction: 0.9964\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1623\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 48.73s\n",
      "\n",
      "Epoch 155 completed. Average loss: 0.0078\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 810\n",
      "Average HR@10: 0.8100\n",
      "Average NDCG@10: 0.5861\n",
      "Evaluation completed in 0.76s\n",
      "HR@10: 0.8100\n",
      "NDCG@10: 0.5861\n",
      "\n",
      "Epoch 156, Batch 0\n",
      "Loss: 0.0077\n",
      "Max prediction: 0.9893\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1589\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 49.63s\n",
      "\n",
      "Epoch 156 completed. Average loss: 0.0078\n",
      "\n",
      "Epoch 157, Batch 0\n",
      "Loss: 0.0078\n",
      "Max prediction: 0.9910\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1607\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 49.77s\n",
      "\n",
      "Epoch 157 completed. Average loss: 0.0077\n",
      "\n",
      "Epoch 158, Batch 0\n",
      "Loss: 0.0077\n",
      "Max prediction: 0.8316\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1493\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 49.90s\n",
      "\n",
      "Epoch 158 completed. Average loss: 0.0077\n",
      "\n",
      "Epoch 159, Batch 0\n",
      "Loss: 0.0080\n",
      "Max prediction: 0.9923\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1707\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 50.03s\n",
      "\n",
      "Epoch 159 completed. Average loss: 0.0077\n",
      "\n",
      "Epoch 160, Batch 0\n",
      "Loss: 0.0078\n",
      "Max prediction: 0.9698\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1709\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 50.18s\n",
      "\n",
      "Epoch 160 completed. Average loss: 0.0077\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 809\n",
      "Average HR@10: 0.8090\n",
      "Average NDCG@10: 0.5888\n",
      "Evaluation completed in 0.76s\n",
      "HR@10: 0.8090\n",
      "NDCG@10: 0.5888\n",
      "\n",
      "Epoch 161, Batch 0\n",
      "Loss: 0.0078\n",
      "Max prediction: 0.9782\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1712\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 51.08s\n",
      "\n",
      "Epoch 161 completed. Average loss: 0.0076\n",
      "\n",
      "Epoch 162, Batch 0\n",
      "Loss: 0.0076\n",
      "Max prediction: 0.9998\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1832\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 51.21s\n",
      "\n",
      "Epoch 162 completed. Average loss: 0.0076\n",
      "\n",
      "Epoch 163, Batch 0\n",
      "Loss: 0.0075\n",
      "Max prediction: 0.8216\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1492\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 51.35s\n",
      "\n",
      "Epoch 163 completed. Average loss: 0.0076\n",
      "\n",
      "Epoch 164, Batch 0\n",
      "Loss: 0.0077\n",
      "Max prediction: 0.9921\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1698\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 51.48s\n",
      "\n",
      "Epoch 164 completed. Average loss: 0.0076\n",
      "\n",
      "Epoch 165, Batch 0\n",
      "Loss: 0.0076\n",
      "Max prediction: 0.8244\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1519\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 51.61s\n",
      "\n",
      "Epoch 165 completed. Average loss: 0.0075\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 809\n",
      "Average HR@10: 0.8090\n",
      "Average NDCG@10: 0.6058\n",
      "Evaluation completed in 0.77s\n",
      "HR@10: 0.8090\n",
      "NDCG@10: 0.6058\n",
      "\n",
      "Epoch 166, Batch 0\n",
      "Loss: 0.0074\n",
      "Max prediction: 0.9882\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1578\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 52.51s\n",
      "\n",
      "Epoch 166 completed. Average loss: 0.0075\n",
      "\n",
      "Epoch 167, Batch 0\n",
      "Loss: 0.0077\n",
      "Max prediction: 0.8642\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1586\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 52.64s\n",
      "\n",
      "Epoch 167 completed. Average loss: 0.0075\n",
      "\n",
      "Epoch 168, Batch 0\n",
      "Loss: 0.0073\n",
      "Max prediction: 0.9995\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1548\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 52.78s\n",
      "\n",
      "Epoch 168 completed. Average loss: 0.0075\n",
      "\n",
      "Epoch 169, Batch 0\n",
      "Loss: 0.0075\n",
      "Max prediction: 0.9453\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1520\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 52.91s\n",
      "\n",
      "Epoch 169 completed. Average loss: 0.0075\n",
      "\n",
      "Epoch 170, Batch 0\n",
      "Loss: 0.0073\n",
      "Max prediction: 0.7820\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1402\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 53.04s\n",
      "\n",
      "Epoch 170 completed. Average loss: 0.0074\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 802\n",
      "Average HR@10: 0.8020\n",
      "Average NDCG@10: 0.5865\n",
      "Evaluation completed in 0.85s\n",
      "HR@10: 0.8020\n",
      "NDCG@10: 0.5865\n",
      "\n",
      "Epoch 171, Batch 0\n",
      "Loss: 0.0072\n",
      "Max prediction: 0.9999\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1640\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 54.02s\n",
      "\n",
      "Epoch 171 completed. Average loss: 0.0074\n",
      "\n",
      "Epoch 172, Batch 0\n",
      "Loss: 0.0074\n",
      "Max prediction: 0.9990\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1596\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 54.17s\n",
      "\n",
      "Epoch 172 completed. Average loss: 0.0073\n",
      "\n",
      "Epoch 173, Batch 0\n",
      "Loss: 0.0074\n",
      "Max prediction: 0.9987\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1669\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 54.42s\n",
      "\n",
      "Epoch 173 completed. Average loss: 0.0073\n",
      "\n",
      "Epoch 174, Batch 0\n",
      "Loss: 0.0075\n",
      "Max prediction: 0.9893\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1636\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 54.56s\n",
      "\n",
      "Epoch 174 completed. Average loss: 0.0073\n",
      "\n",
      "Epoch 175, Batch 0\n",
      "Loss: 0.0072\n",
      "Max prediction: 1.0000\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1692\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 54.69s\n",
      "\n",
      "Epoch 175 completed. Average loss: 0.0073\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 809\n",
      "Average HR@10: 0.8090\n",
      "Average NDCG@10: 0.5794\n",
      "Evaluation completed in 0.78s\n",
      "HR@10: 0.8090\n",
      "NDCG@10: 0.5794\n",
      "\n",
      "Epoch 176, Batch 0\n",
      "Loss: 0.0073\n",
      "Max prediction: 0.9802\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1631\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 55.62s\n",
      "\n",
      "Epoch 176 completed. Average loss: 0.0072\n",
      "\n",
      "Epoch 177, Batch 0\n",
      "Loss: 0.0075\n",
      "Max prediction: 1.0000\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1715\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 55.76s\n",
      "\n",
      "Epoch 177 completed. Average loss: 0.0072\n",
      "\n",
      "Epoch 178, Batch 0\n",
      "Loss: 0.0069\n",
      "Max prediction: 1.0000\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1653\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 55.93s\n",
      "\n",
      "Epoch 178 completed. Average loss: 0.0072\n",
      "\n",
      "Epoch 179, Batch 0\n",
      "Loss: 0.0071\n",
      "Max prediction: 0.9852\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1623\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 56.08s\n",
      "\n",
      "Epoch 179 completed. Average loss: 0.0071\n",
      "\n",
      "Epoch 180, Batch 0\n",
      "Loss: 0.0072\n",
      "Max prediction: 0.9989\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1633\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 56.21s\n",
      "\n",
      "Epoch 180 completed. Average loss: 0.0071\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 796\n",
      "Average HR@10: 0.7960\n",
      "Average NDCG@10: 0.5747\n",
      "Evaluation completed in 0.76s\n",
      "HR@10: 0.7960\n",
      "NDCG@10: 0.5747\n",
      "\n",
      "Epoch 181, Batch 0\n",
      "Loss: 0.0072\n",
      "Max prediction: 0.9955\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1668\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 57.11s\n",
      "\n",
      "Epoch 181 completed. Average loss: 0.0071\n",
      "\n",
      "Epoch 182, Batch 0\n",
      "Loss: 0.0070\n",
      "Max prediction: 0.9989\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1717\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 57.24s\n",
      "\n",
      "Epoch 182 completed. Average loss: 0.0071\n",
      "\n",
      "Epoch 183, Batch 0\n",
      "Loss: 0.0069\n",
      "Max prediction: 0.9996\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1505\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 57.39s\n",
      "\n",
      "Epoch 183 completed. Average loss: 0.0070\n",
      "\n",
      "Epoch 184, Batch 0\n",
      "Loss: 0.0070\n",
      "Max prediction: 0.9995\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1761\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 57.52s\n",
      "\n",
      "Epoch 184 completed. Average loss: 0.0070\n",
      "\n",
      "Epoch 185, Batch 0\n",
      "Loss: 0.0069\n",
      "Max prediction: 0.9999\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1601\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 57.65s\n",
      "\n",
      "Epoch 185 completed. Average loss: 0.0070\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 793\n",
      "Average HR@10: 0.7930\n",
      "Average NDCG@10: 0.5876\n",
      "Evaluation completed in 0.75s\n",
      "HR@10: 0.7930\n",
      "NDCG@10: 0.5876\n",
      "\n",
      "Epoch 186, Batch 0\n",
      "Loss: 0.0069\n",
      "Max prediction: 0.9986\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1651\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 58.54s\n",
      "\n",
      "Epoch 186 completed. Average loss: 0.0069\n",
      "\n",
      "Epoch 187, Batch 0\n",
      "Loss: 0.0066\n",
      "Max prediction: 0.9519\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1507\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 58.67s\n",
      "\n",
      "Epoch 187 completed. Average loss: 0.0069\n",
      "\n",
      "Epoch 188, Batch 0\n",
      "Loss: 0.0067\n",
      "Max prediction: 0.9998\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1640\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 58.82s\n",
      "\n",
      "Epoch 188 completed. Average loss: 0.0069\n",
      "\n",
      "Epoch 189, Batch 0\n",
      "Loss: 0.0069\n",
      "Max prediction: 0.9966\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1693\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 58.95s\n",
      "\n",
      "Epoch 189 completed. Average loss: 0.0068\n",
      "\n",
      "Epoch 190, Batch 0\n",
      "Loss: 0.0068\n",
      "Max prediction: 0.9959\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1559\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 59.08s\n",
      "\n",
      "Epoch 190 completed. Average loss: 0.0068\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 788\n",
      "Average HR@10: 0.7880\n",
      "Average NDCG@10: 0.5727\n",
      "Evaluation completed in 0.78s\n",
      "HR@10: 0.7880\n",
      "NDCG@10: 0.5727\n",
      "\n",
      "Epoch 191, Batch 0\n",
      "Loss: 0.0069\n",
      "Max prediction: 0.9789\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1612\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 59.99s\n",
      "\n",
      "Epoch 191 completed. Average loss: 0.0068\n",
      "\n",
      "Epoch 192, Batch 0\n",
      "Loss: 0.0064\n",
      "Max prediction: 0.9997\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1642\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 60.12s\n",
      "\n",
      "Epoch 192 completed. Average loss: 0.0068\n",
      "\n",
      "Epoch 193, Batch 0\n",
      "Loss: 0.0069\n",
      "Max prediction: 0.9962\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1564\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 60.27s\n",
      "\n",
      "Epoch 193 completed. Average loss: 0.0067\n",
      "\n",
      "Epoch 194, Batch 0\n",
      "Loss: 0.0065\n",
      "Max prediction: 0.9999\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1633\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 60.40s\n",
      "\n",
      "Epoch 194 completed. Average loss: 0.0067\n",
      "\n",
      "Epoch 195, Batch 0\n",
      "Loss: 0.0066\n",
      "Max prediction: 0.9998\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1615\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 60.53s\n",
      "\n",
      "Epoch 195 completed. Average loss: 0.0067\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 790\n",
      "Average HR@10: 0.7900\n",
      "Average NDCG@10: 0.5811\n",
      "Evaluation completed in 0.75s\n",
      "HR@10: 0.7900\n",
      "NDCG@10: 0.5811\n",
      "\n",
      "Epoch 196, Batch 0\n",
      "Loss: 0.0067\n",
      "Max prediction: 0.9995\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1722\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 61.41s\n",
      "\n",
      "Epoch 196 completed. Average loss: 0.0066\n",
      "\n",
      "Epoch 197, Batch 0\n",
      "Loss: 0.0064\n",
      "Max prediction: 0.9999\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1640\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 61.54s\n",
      "\n",
      "Epoch 197 completed. Average loss: 0.0066\n",
      "\n",
      "Epoch 198, Batch 0\n",
      "Loss: 0.0065\n",
      "Max prediction: 0.9988\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1619\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 61.69s\n",
      "\n",
      "Epoch 198 completed. Average loss: 0.0066\n",
      "\n",
      "Epoch 199, Batch 0\n",
      "Loss: 0.0065\n",
      "Max prediction: 0.9993\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1730\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 61.82s\n",
      "\n",
      "Epoch 199 completed. Average loss: 0.0065\n",
      "\n",
      "Epoch 200, Batch 0\n",
      "Loss: 0.0065\n",
      "Max prediction: 0.9844\n",
      "Min prediction: 0.0000\n",
      "Num positive targets: 1649\n",
      "Batch shape: torch.Size([128, 7977])\n",
      "Training completed in 61.99s\n",
      "\n",
      "Epoch 200 completed. Average loss: 0.0065\n",
      "\n",
      "Evaluating...\n",
      "Preparing test instances...\n",
      "Generated 20000 test instances\n",
      "Number of unique users: 1000\n",
      "Evaluating 20000 instances in 200 chunks...\n",
      "Processing chunk 1/200\n",
      "Processing chunk 51/200\n",
      "Processing chunk 101/200\n",
      "Processing chunk 151/200\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 1000\n",
      "Number of hits: 808\n",
      "Average HR@10: 0.8080\n",
      "Average NDCG@10: 0.5920\n",
      "Evaluation completed in 0.85s\n",
      "HR@10: 0.8080\n",
      "NDCG@10: 0.5920\n"
     ]
    }
   ],
   "source": [
    "TOP_N=10\n",
    "USR=500\n",
    "\n",
    "class MultiBehaviorDataset:\n",
    "    def __init__(self, data_path='/Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/', max_users=10000):\n",
    "        self.data_path = data_path\n",
    "        self.behaviors = ['pv', 'cart', 'buy']\n",
    "        self.trn_file = data_path + 'trn_'\n",
    "        self.tst_file = data_path + 'tst_'\n",
    "        self.max_users = max_users  # Limit number of users\n",
    "        \n",
    "        self.load_training_data()\n",
    "        self.load_test_data()\n",
    "    \n",
    "    def load_training_data(self):\n",
    "        print(\"Loading training data from:\", self.data_path)\n",
    "        self.trn_mats = []\n",
    "        for beh in self.behaviors:\n",
    "            path = self.trn_file + beh\n",
    "            print(f\"Loading behavior: {beh} from {path}\")\n",
    "            if not os.path.exists(path):\n",
    "                raise FileNotFoundError(f\"File not found: {path}\")\n",
    "            with open(path, 'rb') as fs:\n",
    "                mat = pickle.load(fs)\n",
    "                if not isinstance(mat, csr_matrix):\n",
    "                    mat = csr_matrix(mat)\n",
    "                mat = (mat != 0).astype(np.float32)\n",
    "                self.trn_mats.append(mat)\n",
    "        \n",
    "        self.trn_label = 1 * (self.trn_mats[-1] != 0)\n",
    "        self.n_users, self.n_items = self.trn_mats[0].shape\n",
    "        self.n_behaviors = len(self.behaviors)\n",
    "        print(f\"Dataset dimensions: {self.n_users} users, {self.n_items} items\")\n",
    "\n",
    "    def create_adjacency_matrix(self, users):\n",
    "        \"\"\"Optimized adjacency matrix creation\"\"\"\n",
    "        batch_size = len(users)\n",
    "        adj_matrix = torch.zeros(batch_size, batch_size, device=device)\n",
    "        \n",
    "        # Pre-compute user item sets\n",
    "        user_item_sets = []\n",
    "        for user in users:\n",
    "            user_items = set()\n",
    "            for mat in self.trn_mats:\n",
    "                user_items.update(mat[user].indices)\n",
    "            user_item_sets.append(user_items)\n",
    "        \n",
    "        # Compute similarities in parallel\n",
    "        for i in range(batch_size):\n",
    "            if not user_item_sets[i]:\n",
    "                continue\n",
    "            for j in range(i+1, batch_size):\n",
    "                if user_item_sets[j]:\n",
    "                    jaccard = len(user_item_sets[i] & user_item_sets[j]) / len(user_item_sets[i] | user_item_sets[j])\n",
    "                    adj_matrix[i,j] = adj_matrix[j,i] = jaccard\n",
    "        \n",
    "        return adj_matrix\n",
    "\n",
    "    def create_graph_metrics(self, users):\n",
    "        \"\"\"Optimized graph metrics creation\"\"\"\n",
    "        metrics = torch.zeros(len(users), 3, device=device)\n",
    "        \n",
    "        # Vectorized computation\n",
    "        for i, user in enumerate(users):\n",
    "            interactions = np.array([mat[user].nnz for mat in self.trn_mats])\n",
    "            metrics[i,0] = sum(interactions) / 100\n",
    "            metrics[i,1] = (interactions > 0).sum() / len(self.behaviors)\n",
    "            metrics[i,2] = interactions[-1] / max(interactions[0], 1)\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "    def prepare_train_instances(self, max_samples=5000):\n",
    "        \"\"\"Optimized training instance preparation\"\"\"\n",
    "        print(\"Preparing training instances...\")\n",
    "        train_data = []\n",
    "        \n",
    "        # Randomly select users\n",
    "        selected_users = np.random.choice(min(self.n_users, self.max_users), size=min(1000, self.max_users), replace=False)\n",
    "        \n",
    "        for user in selected_users:\n",
    "            pos_items = self.trn_label[user].indices[:2]  # Limit positive items\n",
    "            \n",
    "            if len(pos_items) > 0:\n",
    "                for item in pos_items:\n",
    "                    behaviors = [float(mat[user, item]) for mat in self.trn_mats]\n",
    "                    train_data.append([user, item, 1.0] + behaviors)\n",
    "                    \n",
    "                    # Limited negative sampling\n",
    "                    neg_items = np.random.choice(self.n_items, size=2, replace=False)\n",
    "                    for neg_item in neg_items:\n",
    "                        behaviors = [float(mat[user, neg_item]) for mat in self.trn_mats]\n",
    "                        train_data.append([user, neg_item, 0.0] + behaviors)\n",
    "                        \n",
    "                    if len(train_data) >= max_samples:\n",
    "                        break\n",
    "            \n",
    "            if len(train_data) >= max_samples:\n",
    "                break\n",
    "        \n",
    "        print(f\"Generated {len(train_data)} training instances\")\n",
    "        return np.array(train_data)\n",
    "    \n",
    "    def load_test_data(self):\n",
    "        \"\"\"Load test data\"\"\"\n",
    "        test_path = self.tst_file + 'int'\n",
    "        print(f\"Loading test data from: {test_path}\")\n",
    "        if not os.path.exists(test_path):\n",
    "            raise FileNotFoundError(f\"File not found: {test_path}\")\n",
    "        with open(test_path, 'rb') as fs:\n",
    "            self.tst_int = np.array(pickle.load(fs))\n",
    "        \n",
    "        self.tst_users = np.reshape(np.argwhere(self.tst_int != None), [-1])\n",
    "        # Limit test users for faster processing\n",
    "        self.tst_users = self.tst_users[:min(len(self.tst_users), self.max_users)]\n",
    "        print(f\"Using {len(self.tst_users)} test users\")\n",
    "\n",
    "    def get_test_instances(self, num_neg_samples=99, user_subset=None):\n",
    "        \"\"\"Generate test instances with negative sampling for specific users\"\"\"\n",
    "        print(\"Preparing test instances...\")\n",
    "        test_instances = []\n",
    "        \n",
    "        # Use subset of users if provided, otherwise use all test users\n",
    "        test_users = user_subset if user_subset is not None else self.tst_users\n",
    "        max_test_users = 1000  # Limit number of test users\n",
    "        \n",
    "        # Randomly sample test users if there are too many\n",
    "        if len(test_users) > max_test_users:\n",
    "            test_users = np.random.choice(test_users, max_test_users, replace=False)\n",
    "        \n",
    "        for user in test_users:\n",
    "            user = int(user)\n",
    "            pos_item = self.tst_int[user]\n",
    "            if pos_item is not None:\n",
    "                pos_item = int(pos_item)\n",
    "                test_instances.append([user, pos_item, 1.0])\n",
    "                \n",
    "                try:\n",
    "                    # Get negative items\n",
    "                    all_items = set(range(self.n_items))\n",
    "                    pos_items = set(int(x) for x in self.trn_label[user].indices)\n",
    "                    pos_items.add(pos_item)\n",
    "                    neg_items_pool = list(all_items - pos_items)\n",
    "                    \n",
    "                    # Sample negative items\n",
    "                    n_neg = min(num_neg_samples, len(neg_items_pool))\n",
    "                    if n_neg > 0:\n",
    "                        neg_items = np.random.choice(neg_items_pool, size=n_neg, replace=False)\n",
    "                        for neg_item in neg_items:\n",
    "                            test_instances.append([user, int(neg_item), 0.0])\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing test user {user}: {str(e)}\")\n",
    "                    continue\n",
    "        \n",
    "        if not test_instances:\n",
    "            raise ValueError(\"No test instances were generated!\")\n",
    "        \n",
    "        test_instances = np.array(test_instances)\n",
    "        print(f\"Generated {len(test_instances)} test instances\")\n",
    "        print(f\"Number of unique users: {len(set(test_instances[:,0]))}\")\n",
    "        return test_instances\n",
    "\n",
    "\n",
    "# def evaluate_model(model, dataset, test_instances, k=10):\n",
    "#     \"\"\"Improved evaluation function with better metrics calculation\"\"\"\n",
    "#     model.eval()\n",
    "#     hits = []\n",
    "#     ndcgs = []\n",
    "    \n",
    "#     # Process test instances in smaller chunks\n",
    "#     chunk_size = 100\n",
    "#     test_chunks = [test_instances[i:i + chunk_size] for i in range(0, len(test_instances), chunk_size)]\n",
    "    \n",
    "#     print(f\"Evaluating {len(test_instances)} instances in {len(test_chunks)} chunks...\")\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for chunk_idx, chunk in enumerate(test_chunks):\n",
    "#             if chunk_idx % 50 == 0:  # Reduced frequency of progress updates\n",
    "#                 print(f\"Processing chunk {chunk_idx + 1}/{len(test_chunks)}\")\n",
    "            \n",
    "#             # Group by user and ensure we have both positive and negative items\n",
    "#             user_items = {}\n",
    "#             for inst in chunk:\n",
    "#                 user = int(inst[0])\n",
    "#                 item = int(inst[1])\n",
    "#                 label = float(inst[2])\n",
    "                \n",
    "#                 if user not in user_items:\n",
    "#                     user_items[user] = {'pos': [], 'neg': [], 'all_items': [], 'all_scores': []}\n",
    "                \n",
    "#                 user_items[user]['all_items'].append(item)\n",
    "#                 if label > 0.5:\n",
    "#                     user_items[user]['pos'].append(item)\n",
    "#                 else:\n",
    "#                     user_items[user]['neg'].append(item)\n",
    "            \n",
    "#             # Process each user that has both positive and negative items\n",
    "#             for user, data in user_items.items():\n",
    "#                 if not data['pos'] or not data['neg']:\n",
    "#                     continue\n",
    "                \n",
    "#                 items = data['all_items']\n",
    "#                 batch_size = len(items)\n",
    "                \n",
    "#                 # Create input features\n",
    "#                 behaviors = torch.zeros(batch_size, dataset.n_behaviors, device=device)\n",
    "#                 for i, item in enumerate(items):\n",
    "#                     for j, mat in enumerate(dataset.trn_mats):\n",
    "#                         behaviors[i, j] = float(mat[user, item])\n",
    "                \n",
    "#                 x = torch.cat([\n",
    "#                     behaviors,\n",
    "#                     torch.zeros(batch_size, model.input_dim - behaviors.size(1), device=device)\n",
    "#                 ], dim=1)\n",
    "                \n",
    "#                 # Simplified adjacency matrix for evaluation\n",
    "#                 adj_matrix = torch.eye(batch_size, device=device)\n",
    "#                 graph_metrics = dataset.create_graph_metrics([user] * batch_size)\n",
    "                \n",
    "#                 try:\n",
    "#                     predictions = model(x, adj_matrix, graph_metrics)\n",
    "#                     predictions = predictions.cpu().numpy().flatten()\n",
    "                    \n",
    "#                     # Store all scores\n",
    "#                     for item, score in zip(items, predictions):\n",
    "#                         data['all_scores'].append((item, score))\n",
    "                    \n",
    "#                     # Sort items by score\n",
    "#                     sorted_items = [x[0] for x in sorted(data['all_scores'], key=lambda x: x[1], reverse=True)]\n",
    "#                     recommended_items = sorted_items[:k]\n",
    "                    \n",
    "#                     # Calculate HR\n",
    "#                     hit = False\n",
    "#                     for pos_item in data['pos']:\n",
    "#                         if pos_item in recommended_items:\n",
    "#                             hit = True\n",
    "#                             break\n",
    "#                     hits.append(hit)\n",
    "                    \n",
    "#                     # Calculate NDCG\n",
    "#                     dcg = 0\n",
    "#                     idcg = 1  # Ideal DCG for one relevant item\n",
    "#                     for i, item in enumerate(recommended_items):\n",
    "#                         if item in data['pos']:\n",
    "#                             dcg += 1 / np.log2(i + 2)\n",
    "#                     ndcg = dcg / idcg\n",
    "#                     ndcgs.append(ndcg)\n",
    "                    \n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error evaluating user {user}: {str(e)}\")\n",
    "#                     continue\n",
    "    \n",
    "#     # Calculate final metrics\n",
    "#     hr = np.mean(hits) if hits else 0\n",
    "#     ndcg = np.mean(ndcgs) if ndcgs else 0\n",
    "    \n",
    "#     # Print detailed statistics\n",
    "#     print(f\"\\nEvaluation Statistics:\")\n",
    "#     print(f\"Total users evaluated: {len(hits)}\")\n",
    "#     print(f\"Number of hits: {sum(hits)}\")\n",
    "#     print(f\"Average HR@{k}: {hr:.4f}\")\n",
    "#     print(f\"Average NDCG@{k}: {ndcg:.4f}\")\n",
    "    \n",
    "#     return hr, ndcg\n",
    "\n",
    "\n",
    "# Define the corrected evaluation function\n",
    "def evaluate_model(model, dataset, test_instances, k=10):\n",
    "    \"\"\"Improved evaluation function with better metrics calculation.\"\"\"\n",
    "    model.eval()\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    \n",
    "    # Process test instances in smaller chunks\n",
    "    chunk_size = 100\n",
    "    test_chunks = [test_instances[i:i + chunk_size] for i in range(0, len(test_instances), chunk_size)]\n",
    "    \n",
    "    print(f\"Evaluating {len(test_instances)} instances in {len(test_chunks)} chunks...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for chunk_idx, chunk in enumerate(test_chunks):\n",
    "            if chunk_idx % 50 == 0:  # Reduced frequency of progress updates\n",
    "                print(f\"Processing chunk {chunk_idx + 1}/{len(test_chunks)}\")\n",
    "            \n",
    "            # Group by user and ensure we have both positive and negative items\n",
    "            user_items = {}\n",
    "            for inst in chunk:\n",
    "                user = int(inst[0])\n",
    "                item = int(inst[1])\n",
    "                label = float(inst[2])\n",
    "                \n",
    "                if user not in user_items:\n",
    "                    user_items[user] = {'pos': [], 'neg': [], 'all_items': [], 'all_scores': []}\n",
    "                \n",
    "                user_items[user]['all_items'].append(item)\n",
    "                if label > 0.5:\n",
    "                    user_items[user]['pos'].append(item)\n",
    "                else:\n",
    "                    user_items[user]['neg'].append(item)\n",
    "            \n",
    "            # Process each user that has both positive and negative items\n",
    "            for user, data in user_items.items():\n",
    "                if not data['pos'] or not data['neg']:\n",
    "                    continue\n",
    "                \n",
    "                items = data['all_items']\n",
    "                batch_size = len(items)\n",
    "                \n",
    "                # Create input features\n",
    "                behaviors = torch.zeros(batch_size, dataset.n_behaviors, device=device)\n",
    "                for i, item in enumerate(items):\n",
    "                    for j, mat in enumerate(dataset.trn_mats):\n",
    "                        behaviors[i, j] = float(mat[user, item])\n",
    "                \n",
    "                x = torch.cat([\n",
    "                    behaviors,\n",
    "                    torch.zeros(batch_size, model.input_dim - behaviors.size(1), device=device)\n",
    "                ], dim=1)\n",
    "                \n",
    "                # Simplified adjacency matrix for evaluation\n",
    "                adj_matrix = torch.eye(batch_size, device=device)\n",
    "                graph_metrics = dataset.create_graph_metrics([user] * batch_size)\n",
    "                \n",
    "                try:\n",
    "                    predictions = model(x, adj_matrix, graph_metrics)\n",
    "                    predictions = predictions.cpu().numpy().flatten()\n",
    "                    \n",
    "                    # Store all scores\n",
    "                    data['all_scores'] = [(item, score) for item, score in zip(items, predictions)]\n",
    "                    \n",
    "                    # Sort items by score\n",
    "                    sorted_items = [x[0] for x in sorted(data['all_scores'], key=lambda x: x[1], reverse=True)]\n",
    "                    recommended_items = sorted_items[:k]\n",
    "                    \n",
    "                    # Calculate HR\n",
    "                    hit = any(pos_item in recommended_items for pos_item in data['pos'])\n",
    "                    hits.append(hit)\n",
    "                    \n",
    "                    # Calculate NDCG\n",
    "                    dcg = sum(\n",
    "                        1 / np.log2(i + 2) for i, item in enumerate(recommended_items) if item in data['pos']\n",
    "                    )\n",
    "                    idcg = 1  # Ideal DCG for one relevant item\n",
    "                    ndcg = dcg / idcg\n",
    "                    ndcgs.append(ndcg)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error evaluating user {user}: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    hr = np.mean(hits) if hits else 0\n",
    "    ndcg = np.mean(ndcgs) if ndcgs else 0\n",
    "    \n",
    "    # Print detailed statistics\n",
    "    print(f\"\\nEvaluation Statistics:\")\n",
    "    print(f\"Total users evaluated: {len(hits)}\")\n",
    "    print(f\"Number of hits: {sum(hits)}\")\n",
    "    print(f\"Average HR@{k}: {hr:.4f}\")\n",
    "    print(f\"Average NDCG@{k}: {ndcg:.4f}\")\n",
    "    \n",
    "    return hr, ndcg\n",
    "\n",
    "\n",
    "def get_test_instances(self, num_neg_samples=99):\n",
    "    \"\"\"Improved test instance generation\"\"\"\n",
    "    print(\"Preparing test instances...\")\n",
    "    test_instances = []\n",
    "    max_test_users = 1000  # Limit number of test users\n",
    "    \n",
    "    # Randomly sample test users if there are too many\n",
    "    test_users = self.tst_users\n",
    "    if len(test_users) > max_test_users:\n",
    "        test_users = np.random.choice(test_users, max_test_users, replace=False)\n",
    "    \n",
    "    for user in test_users:\n",
    "        user = int(user)\n",
    "        pos_item = self.tst_int[user]\n",
    "        if pos_item is not None:\n",
    "            pos_item = int(pos_item)\n",
    "            test_instances.append([user, pos_item, 1.0])\n",
    "            \n",
    "            try:\n",
    "                # Get negative items\n",
    "                all_items = set(range(self.n_items))\n",
    "                pos_items = set(int(x) for x in self.trn_label[user].indices)\n",
    "                pos_items.add(pos_item)\n",
    "                neg_items_pool = list(all_items - pos_items)\n",
    "                \n",
    "                # Sample negative items\n",
    "                n_neg = min(num_neg_samples, len(neg_items_pool))\n",
    "                if n_neg > 0:\n",
    "                    neg_items = np.random.choice(neg_items_pool, size=n_neg, replace=False)\n",
    "                    for neg_item in neg_items:\n",
    "                        test_instances.append([user, int(neg_item), 0.0])\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing test user {user}: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    if not test_instances:\n",
    "        raise ValueError(\"No test instances were generated!\")\n",
    "    \n",
    "    test_instances = np.array(test_instances)\n",
    "    print(f\"Generated {len(test_instances)} test instances\")\n",
    "    print(f\"Number of unique users: {len(set(test_instances[:,0]))}\")\n",
    "    return test_instances\n",
    "\n",
    "def main():\n",
    "    # Configuration\n",
    "    config = {\n",
    "        'latent_dim': 64,\n",
    "        'dropout': 0.1,\n",
    "        'learning_rate': 0.001,\n",
    "        'weight_decay': 1e-6,\n",
    "        'gradient_clip': 1.0,\n",
    "        'max_samples': USR,\n",
    "        'eval_k': TOP_N\n",
    "    }\n",
    "    \n",
    "    print(\"Initializing dataset...\")\n",
    "    dataset = MultiBehaviorDataset(max_users=USR)\n",
    "    train_data = dataset.prepare_train_instances(max_samples=config['max_samples'])\n",
    "    \n",
    "    print(f\"Using {len(train_data)} training instances\")\n",
    "\n",
    "    # Initialize model with dataset dimensions\n",
    "    model = MultiBehaviorBiasMF(\n",
    "        n_users=dataset.n_users,\n",
    "        n_items=dataset.n_items,\n",
    "        n_behaviors=dataset.n_behaviors,\n",
    "        latent_dim=config['latent_dim'],\n",
    "        dropout=config['dropout']\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "    print(\"Preparing training tensors...\")\n",
    "    users = torch.LongTensor(train_data[:, 0]).to(device)\n",
    "    items = torch.LongTensor(train_data[:, 1]).to(device)\n",
    "    labels = torch.FloatTensor(train_data[:, 2]).to(device)\n",
    "    behaviors = torch.FloatTensor(train_data[:, 3:]).to(device)\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    try:\n",
    "        model.train()\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        # Training\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(users, items, behaviors)\n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), config['gradient_clip'])\n",
    "        optimizer.step()\n",
    "        \n",
    "        training_time = (datetime.now() - start_time).total_seconds()\n",
    "        print(f\"Training completed in {training_time:.2f}s\")\n",
    "        print(f\"Training loss: {loss.item():.4f}\")\n",
    "        \n",
    "        # Evaluation\n",
    "        print(\"\\nStarting evaluation...\")\n",
    "        eval_start_time = datetime.now()\n",
    "        \n",
    "        test_instances = dataset.get_test_instances()\n",
    "        hr, ndcg = evaluate_model(model, dataset, test_instances, k=config['eval_k'])\n",
    "        \n",
    "        eval_time = (datetime.now() - eval_start_time).total_seconds()\n",
    "        print(f\"Evaluation completed in {eval_time:.2f}s\")\n",
    "        print(f\"HR@{config['eval_k']}: {hr:.4f}\")\n",
    "        print(f\"NDCG@{config['eval_k']}: {ndcg:.4f}\")\n",
    "        \n",
    "        # Save results\n",
    "        results = {\n",
    "            'training_time': training_time,\n",
    "            'eval_time': eval_time,\n",
    "            'training_loss': loss.item(),\n",
    "            'hr': hr,\n",
    "            'ndcg': ndcg\n",
    "        }\n",
    "        \n",
    "        # Save to file\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        with open(f'results_{timestamp}.txt', 'w') as f:\n",
    "            for key, value in results.items():\n",
    "                f.write(f\"{key}: {value}\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during training: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "class AutoRec(nn.Module):\n",
    "    def __init__(self, num_items, hidden_dim=256):\n",
    "        super(AutoRec, self).__init__()\n",
    "        self.input_dim = num_items\n",
    "        \n",
    "        # Simplified architecture\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(num_items, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, num_items),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, adjacency_matrix=None, graph_metrics=None):\n",
    "        if x.dim() > 2:\n",
    "            x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Normalize input\n",
    "        x = torch.clamp(x, 0, 1)  # Ensure input is between 0 and 1\n",
    "        \n",
    "        h = self.encoder(x)\n",
    "        out = self.decoder(h)\n",
    "        return out\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Simplified configuration\n",
    "    config = {\n",
    "        'batch_size': 32,\n",
    "        'num_epochs': 20,\n",
    "        'learning_rate': 0.001,\n",
    "        'hidden_dim': 256,\n",
    "        'eval_k': 10,\n",
    "        'max_samples': 10000\n",
    "    }\n",
    "    \n",
    "    print(\"Initializing dataset...\")\n",
    "    dataset = MultiBehaviorDataset(max_users=1000)\n",
    "    \n",
    "    # Create binary interaction matrix (simplify to just purchases)\n",
    "    interaction_matrix = dataset.trn_mats[-1].toarray()  # Use only purchase behavior\n",
    "    print(f\"Interaction matrix shape: {interaction_matrix.shape}\")\n",
    "    print(f\"Non-zero elements: {np.count_nonzero(interaction_matrix)}\")\n",
    "    \n",
    "    model = AutoRec(\n",
    "        num_items=dataset.n_items,\n",
    "        hidden_dim=config['hidden_dim']\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    try:\n",
    "        for epoch in range(config['num_epochs']):\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            num_batches = 0\n",
    "            \n",
    "            # Create batches of users\n",
    "            user_indices = np.random.permutation(min(1000, dataset.n_users))\n",
    "            \n",
    "            for start_idx in range(0, len(user_indices), config['batch_size']):\n",
    "                batch_users = user_indices[start_idx:start_idx + config['batch_size']]\n",
    "                batch_interactions = torch.FloatTensor(interaction_matrix[batch_users]).to(device)\n",
    "                \n",
    "                # Skip empty batches\n",
    "                if torch.sum(batch_interactions) == 0:\n",
    "                    continue\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                predictions = model(batch_interactions)\n",
    "                \n",
    "                # Calculate loss\n",
    "                loss = criterion(predictions, batch_interactions)\n",
    "                \n",
    "                if num_batches % 10 == 0:\n",
    "                    print(f\"Epoch {epoch+1}, Batch {num_batches}\")\n",
    "                    print(f\"Loss: {loss.item():.4f}\")\n",
    "                    print(f\"Max prediction: {torch.max(predictions):.4f}\")\n",
    "                    print(f\"Min prediction: {torch.min(predictions):.4f}\")\n",
    "                    print(f\"Num positive targets: {torch.sum(batch_interactions > 0).item()}\")\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                num_batches += 1\n",
    "            \n",
    "            avg_loss = total_loss / (num_batches + 1e-8)\n",
    "            print(f\"\\nEpoch {epoch+1} completed. Average loss: {avg_loss:.4f}\")\n",
    "            \n",
    "            # Evaluation\n",
    "            if (epoch + 1) % 5 == 0:\n",
    "                print(\"\\nEvaluating...\")\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    test_instances = dataset.get_test_instances(num_neg_samples=19)  # Reduced negative samples\n",
    "                    hr, ndcg = evaluate_model(model, dataset, test_instances, k=config['eval_k'])\n",
    "                    print(f\"HR@{config['eval_k']}: {hr:.4f}\")\n",
    "                    print(f\"NDCG@{config['eval_k']}: {ndcg:.4f}\")\n",
    "        \n",
    "        # Final evaluation\n",
    "        print(\"\\nFinal evaluation...\")\n",
    "        model.eval()\n",
    "        test_instances = dataset.get_test_instances(num_neg_samples=99)\n",
    "        hr, ndcg = evaluate_model(model, dataset, test_instances, k=config['eval_k'])\n",
    "        \n",
    "        print(f\"\\nFinal Results:\")\n",
    "        print(f\"HR@{config['eval_k']}: {hr:.4f}\")\n",
    "        print(f\"NDCG@{config['eval_k']}: {ndcg:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during training: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def evaluate_model(model, dataset, test_instances, k=10):\n",
    "    \"\"\"Fixed evaluation function\"\"\"\n",
    "    model.eval()\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    \n",
    "    chunk_size = 100\n",
    "    test_chunks = [test_instances[i:i + chunk_size] for i in range(0, len(test_instances), chunk_size)]\n",
    "    \n",
    "    print(f\"Evaluating {len(test_instances)} instances in {len(test_chunks)} chunks...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for chunk_idx, chunk in enumerate(test_chunks):\n",
    "            if chunk_idx % 50 == 0:\n",
    "                print(f\"Processing chunk {chunk_idx + 1}/{len(test_chunks)}\")\n",
    "            \n",
    "            user_items = {}\n",
    "            for inst in chunk:\n",
    "                user = int(inst[0])\n",
    "                item = int(inst[1])\n",
    "                label = float(inst[2])\n",
    "                \n",
    "                if user not in user_items:\n",
    "                    user_items[user] = {'pos': [], 'neg': [], 'items': [], 'scores': []}\n",
    "                \n",
    "                user_items[user]['items'].append(item)\n",
    "                if label > 0.5:\n",
    "                    user_items[user]['pos'].append(item)\n",
    "                else:\n",
    "                    user_items[user]['neg'].append(item)\n",
    "            \n",
    "            for user, data in user_items.items():\n",
    "                if not data['pos'] or not data['neg']:\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    # Get user's interaction vector (fixed broadcasting)\n",
    "                    user_vector = torch.zeros(1, dataset.n_items, device=device)\n",
    "                    for j, mat in enumerate(dataset.trn_mats):\n",
    "                        user_interactions = mat[user].toarray().reshape(1, -1)  # Ensure 2D\n",
    "                        user_vector += torch.tensor(user_interactions, device=device)\n",
    "                    \n",
    "                    # Get predictions\n",
    "                    predictions = model(user_vector)\n",
    "                    predictions = predictions.squeeze().cpu().numpy()  # Properly squeeze\n",
    "                    \n",
    "                    # Get scores for test items\n",
    "                    for item in data['items']:\n",
    "                        data['scores'].append((item, predictions[item]))\n",
    "                    \n",
    "                    # Calculate metrics\n",
    "                    sorted_items = [x[0] for x in sorted(data['scores'], key=lambda x: x[1], reverse=True)]\n",
    "                    recommended_items = sorted_items[:k]\n",
    "                    \n",
    "                    hit = len(set(recommended_items) & set(data['pos'])) > 0\n",
    "                    hits.append(hit)\n",
    "                    \n",
    "                    # Calculate NDCG\n",
    "                    dcg = 0\n",
    "                    idcg = 1\n",
    "                    for i, item in enumerate(recommended_items):\n",
    "                        if item in data['pos']:\n",
    "                            dcg += 1 / np.log2(i + 2)\n",
    "                    ndcg = dcg / idcg\n",
    "                    ndcgs.append(ndcg)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing user {user}: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    hr = np.mean(hits) if hits else 0\n",
    "    ndcg = np.mean(ndcgs) if ndcgs else 0\n",
    "    \n",
    "    print(f\"\\nEvaluation Statistics:\")\n",
    "    print(f\"Total users evaluated: {len(hits)}\")\n",
    "    print(f\"Number of hits: {sum(hits)}\")\n",
    "    print(f\"Average HR@{k}: {hr:.4f}\")\n",
    "    print(f\"Average NDCG@{k}: {ndcg:.4f}\")\n",
    "    \n",
    "    return hr, ndcg\n",
    "\n",
    "def main():\n",
    "    # Add debugging for data shapes\n",
    "    config = {\n",
    "        'batch_size': 128,\n",
    "        'num_epochs': 200,\n",
    "        'learning_rate': 0.001,\n",
    "        'hidden_dim': 256,\n",
    "        'eval_k': 10,\n",
    "        'max_samples': 10000\n",
    "    }\n",
    "    \n",
    "    print(\"Initializing dataset...\")\n",
    "    dataset = MultiBehaviorDataset(max_users=10000)\n",
    "    \n",
    "    # Create binary interaction matrix (simplify to just purchases)\n",
    "    interaction_matrix = dataset.trn_mats[-1].toarray()\n",
    "    print(f\"Interaction matrix shape: {interaction_matrix.shape}\")\n",
    "    print(f\"Non-zero elements: {np.count_nonzero(interaction_matrix)}\")\n",
    "    print(f\"Average interactions per user: {np.mean(np.sum(interaction_matrix, axis=1)):.2f}\")\n",
    "    \n",
    "    model = AutoRec(\n",
    "        num_items=dataset.n_items,\n",
    "        hidden_dim=config['hidden_dim']\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "    print(\"\\nStarting training...\")\n",
    "    try:\n",
    "        start_time = datetime.now()\n",
    "        for epoch in range(config['num_epochs']):\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            num_batches = 0\n",
    "            \n",
    "            # Create batches of users\n",
    "            user_indices = np.random.permutation(min(1000, dataset.n_users))\n",
    "            \n",
    "            for start_idx in range(0, len(user_indices), config['batch_size']):\n",
    "                batch_users = user_indices[start_idx:start_idx + config['batch_size']]\n",
    "                batch_interactions = torch.FloatTensor(interaction_matrix[batch_users]).to(device)\n",
    "                \n",
    "                # Skip empty batches\n",
    "                if torch.sum(batch_interactions) == 0:\n",
    "                    continue\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                predictions = model(batch_interactions)\n",
    "                \n",
    "                # Calculate loss\n",
    "                loss = criterion(predictions, batch_interactions)\n",
    "                \n",
    "                if num_batches % 10 == 0:\n",
    "                    print(f\"\\nEpoch {epoch+1}, Batch {num_batches}\")\n",
    "                    print(f\"Loss: {loss.item():.4f}\")\n",
    "                    print(f\"Max prediction: {torch.max(predictions):.4f}\")\n",
    "                    print(f\"Min prediction: {torch.min(predictions):.4f}\")\n",
    "                    print(f\"Num positive targets: {torch.sum(batch_interactions > 0).item()}\")\n",
    "                    print(f\"Batch shape: {batch_interactions.shape}\")\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                num_batches += 1\n",
    "            training_time = (datetime.now() - start_time).total_seconds()\n",
    "            print(f\"Training completed in {training_time:.2f}s\")\n",
    "            avg_loss = total_loss / (num_batches + 1e-8)\n",
    "            print(f\"\\nEpoch {epoch+1} completed. Average loss: {avg_loss:.4f}\")\n",
    "            \n",
    "            # Evaluation every 5 epochs\n",
    "            if (epoch + 1) % 5 == 0:\n",
    "                print(\"\\nEvaluating...\")\n",
    "                eval_start_time = datetime.now()\n",
    "                model.eval()\n",
    "                test_instances = dataset.get_test_instances(num_neg_samples=19)\n",
    "                hr, ndcg = evaluate_model(model, dataset, test_instances, k=config['eval_k'])\n",
    "                eval_time = (datetime.now() - eval_start_time).total_seconds()\n",
    "                print(f\"Evaluation completed in {eval_time:.2f}s\")\n",
    "                print(f\"HR@{config['eval_k']}: {hr:.4f}\")\n",
    "                print(f\"NDCG@{config['eval_k']}: {ndcg:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during training: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NCF --very low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pickle\n",
    "from scipy.sparse import csr_matrix\n",
    "import operator\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing dataset...\n",
      "Loading training data from: /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/\n",
      "Loading behavior: pv from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_pv\n",
      "Loading behavior: cart from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_cart\n",
      "Loading behavior: buy from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_buy\n",
      "Dataset dimensions: 21716 users, 7977 items\n",
      "Loading test data from: /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/tst_int\n",
      "Using 10000 test users\n",
      "Preparing training instances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yf/20z1hn994jd04q4kl0gpgh740000gn/T/ipykernel_51372/3378218638.py:66: DeprecationWarning: Please import `csr_matrix` from the `scipy.sparse` namespace; the `scipy.sparse.csr` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  mat = pickle.load(fs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 6000 training instances\n",
      "Using 6000 training instances\n",
      "Preparing training tensors...\n",
      "Starting training...\n",
      "Training completed in 0.01s\n",
      "Training loss: 0.6783\n",
      "\n",
      "Starting evaluation...\n",
      "Preparing test instances...\n",
      "Generated 1000000 test instances\n",
      "Evaluating 1000000 instances in 33334 chunks...\n",
      "Processing chunk 1/33334\n",
      "Processing chunk 51/33334\n",
      "Processing chunk 101/33334\n",
      "Processing chunk 151/33334\n",
      "Processing chunk 201/33334\n",
      "Processing chunk 251/33334\n",
      "Processing chunk 301/33334\n",
      "Processing chunk 351/33334\n",
      "Processing chunk 401/33334\n",
      "Processing chunk 451/33334\n",
      "Processing chunk 501/33334\n",
      "Processing chunk 551/33334\n",
      "Processing chunk 601/33334\n",
      "Processing chunk 651/33334\n",
      "Processing chunk 701/33334\n",
      "Processing chunk 751/33334\n",
      "Processing chunk 801/33334\n",
      "Processing chunk 851/33334\n",
      "Processing chunk 901/33334\n",
      "Processing chunk 951/33334\n",
      "Processing chunk 1001/33334\n",
      "Processing chunk 1051/33334\n",
      "Processing chunk 1101/33334\n",
      "Processing chunk 1151/33334\n",
      "Processing chunk 1201/33334\n",
      "Processing chunk 1251/33334\n",
      "Processing chunk 1301/33334\n",
      "Processing chunk 1351/33334\n",
      "Processing chunk 1401/33334\n",
      "Processing chunk 1451/33334\n",
      "Processing chunk 1501/33334\n",
      "Processing chunk 1551/33334\n",
      "Processing chunk 1601/33334\n",
      "Processing chunk 1651/33334\n",
      "Processing chunk 1701/33334\n",
      "Processing chunk 1751/33334\n",
      "Processing chunk 1801/33334\n",
      "Processing chunk 1851/33334\n",
      "Processing chunk 1901/33334\n",
      "Processing chunk 1951/33334\n",
      "Processing chunk 2001/33334\n",
      "Processing chunk 2051/33334\n",
      "Processing chunk 2101/33334\n",
      "Processing chunk 2151/33334\n",
      "Processing chunk 2201/33334\n",
      "Processing chunk 2251/33334\n",
      "Processing chunk 2301/33334\n",
      "Processing chunk 2351/33334\n",
      "Processing chunk 2401/33334\n",
      "Processing chunk 2451/33334\n",
      "Processing chunk 2501/33334\n",
      "Processing chunk 2551/33334\n",
      "Processing chunk 2601/33334\n",
      "Processing chunk 2651/33334\n",
      "Processing chunk 2701/33334\n",
      "Processing chunk 2751/33334\n",
      "Processing chunk 2801/33334\n",
      "Processing chunk 2851/33334\n",
      "Processing chunk 2901/33334\n",
      "Processing chunk 2951/33334\n",
      "Processing chunk 3001/33334\n",
      "Processing chunk 3051/33334\n",
      "Processing chunk 3101/33334\n",
      "Processing chunk 3151/33334\n",
      "Processing chunk 3201/33334\n",
      "Processing chunk 3251/33334\n",
      "Processing chunk 3301/33334\n",
      "Processing chunk 3351/33334\n",
      "Processing chunk 3401/33334\n",
      "Processing chunk 3451/33334\n",
      "Processing chunk 3501/33334\n",
      "Processing chunk 3551/33334\n",
      "Processing chunk 3601/33334\n",
      "Processing chunk 3651/33334\n",
      "Processing chunk 3701/33334\n",
      "Processing chunk 3751/33334\n",
      "Processing chunk 3801/33334\n",
      "Processing chunk 3851/33334\n",
      "Processing chunk 3901/33334\n",
      "Processing chunk 3951/33334\n",
      "Processing chunk 4001/33334\n",
      "Processing chunk 4051/33334\n",
      "Processing chunk 4101/33334\n",
      "Processing chunk 4151/33334\n",
      "Processing chunk 4201/33334\n",
      "Processing chunk 4251/33334\n",
      "Processing chunk 4301/33334\n",
      "Processing chunk 4351/33334\n",
      "Processing chunk 4401/33334\n",
      "Processing chunk 4451/33334\n",
      "Processing chunk 4501/33334\n",
      "Processing chunk 4551/33334\n",
      "Processing chunk 4601/33334\n",
      "Processing chunk 4651/33334\n",
      "Processing chunk 4701/33334\n",
      "Processing chunk 4751/33334\n",
      "Processing chunk 4801/33334\n",
      "Processing chunk 4851/33334\n",
      "Processing chunk 4901/33334\n",
      "Processing chunk 4951/33334\n",
      "Processing chunk 5001/33334\n",
      "Processing chunk 5051/33334\n",
      "Processing chunk 5101/33334\n",
      "Processing chunk 5151/33334\n",
      "Processing chunk 5201/33334\n",
      "Processing chunk 5251/33334\n",
      "Processing chunk 5301/33334\n",
      "Processing chunk 5351/33334\n",
      "Processing chunk 5401/33334\n",
      "Processing chunk 5451/33334\n",
      "Processing chunk 5501/33334\n",
      "Processing chunk 5551/33334\n",
      "Processing chunk 5601/33334\n",
      "Processing chunk 5651/33334\n",
      "Processing chunk 5701/33334\n",
      "Processing chunk 5751/33334\n",
      "Processing chunk 5801/33334\n",
      "Processing chunk 5851/33334\n",
      "Processing chunk 5901/33334\n",
      "Processing chunk 5951/33334\n",
      "Processing chunk 6001/33334\n",
      "Processing chunk 6051/33334\n",
      "Processing chunk 6101/33334\n",
      "Processing chunk 6151/33334\n",
      "Processing chunk 6201/33334\n",
      "Processing chunk 6251/33334\n",
      "Processing chunk 6301/33334\n",
      "Processing chunk 6351/33334\n",
      "Processing chunk 6401/33334\n",
      "Processing chunk 6451/33334\n",
      "Processing chunk 6501/33334\n",
      "Processing chunk 6551/33334\n",
      "Processing chunk 6601/33334\n",
      "Processing chunk 6651/33334\n",
      "Processing chunk 6701/33334\n",
      "Processing chunk 6751/33334\n",
      "Processing chunk 6801/33334\n",
      "Processing chunk 6851/33334\n",
      "Processing chunk 6901/33334\n",
      "Processing chunk 6951/33334\n",
      "Processing chunk 7001/33334\n",
      "Processing chunk 7051/33334\n",
      "Processing chunk 7101/33334\n",
      "Processing chunk 7151/33334\n",
      "Processing chunk 7201/33334\n",
      "Processing chunk 7251/33334\n",
      "Processing chunk 7301/33334\n",
      "Processing chunk 7351/33334\n",
      "Processing chunk 7401/33334\n",
      "Processing chunk 7451/33334\n",
      "Processing chunk 7501/33334\n",
      "Processing chunk 7551/33334\n",
      "Processing chunk 7601/33334\n",
      "Processing chunk 7651/33334\n",
      "Processing chunk 7701/33334\n",
      "Processing chunk 7751/33334\n",
      "Processing chunk 7801/33334\n",
      "Processing chunk 7851/33334\n",
      "Processing chunk 7901/33334\n",
      "Processing chunk 7951/33334\n",
      "Processing chunk 8001/33334\n",
      "Processing chunk 8051/33334\n",
      "Processing chunk 8101/33334\n",
      "Processing chunk 8151/33334\n",
      "Processing chunk 8201/33334\n",
      "Processing chunk 8251/33334\n",
      "Processing chunk 8301/33334\n",
      "Processing chunk 8351/33334\n",
      "Processing chunk 8401/33334\n",
      "Processing chunk 8451/33334\n",
      "Processing chunk 8501/33334\n",
      "Processing chunk 8551/33334\n",
      "Processing chunk 8601/33334\n",
      "Processing chunk 8651/33334\n",
      "Processing chunk 8701/33334\n",
      "Processing chunk 8751/33334\n",
      "Processing chunk 8801/33334\n",
      "Processing chunk 8851/33334\n",
      "Processing chunk 8901/33334\n",
      "Processing chunk 8951/33334\n",
      "Processing chunk 9001/33334\n",
      "Processing chunk 9051/33334\n",
      "Processing chunk 9101/33334\n",
      "Processing chunk 9151/33334\n",
      "Processing chunk 9201/33334\n",
      "Processing chunk 9251/33334\n",
      "Processing chunk 9301/33334\n",
      "Processing chunk 9351/33334\n",
      "Processing chunk 9401/33334\n",
      "Processing chunk 9451/33334\n",
      "Processing chunk 9501/33334\n",
      "Processing chunk 9551/33334\n",
      "Processing chunk 9601/33334\n",
      "Processing chunk 9651/33334\n",
      "Processing chunk 9701/33334\n",
      "Processing chunk 9751/33334\n",
      "Processing chunk 9801/33334\n",
      "Processing chunk 9851/33334\n",
      "Processing chunk 9901/33334\n",
      "Processing chunk 9951/33334\n",
      "Processing chunk 10001/33334\n",
      "Processing chunk 10051/33334\n",
      "Processing chunk 10101/33334\n",
      "Processing chunk 10151/33334\n",
      "Processing chunk 10201/33334\n",
      "Processing chunk 10251/33334\n",
      "Processing chunk 10301/33334\n",
      "Processing chunk 10351/33334\n",
      "Processing chunk 10401/33334\n",
      "Processing chunk 10451/33334\n",
      "Processing chunk 10501/33334\n",
      "Processing chunk 10551/33334\n",
      "Processing chunk 10601/33334\n",
      "Processing chunk 10651/33334\n",
      "Processing chunk 10701/33334\n",
      "Processing chunk 10751/33334\n",
      "Processing chunk 10801/33334\n",
      "Processing chunk 10851/33334\n",
      "Processing chunk 10901/33334\n",
      "Processing chunk 10951/33334\n",
      "Processing chunk 11001/33334\n",
      "Processing chunk 11051/33334\n",
      "Processing chunk 11101/33334\n",
      "Processing chunk 11151/33334\n",
      "Processing chunk 11201/33334\n",
      "Processing chunk 11251/33334\n",
      "Processing chunk 11301/33334\n",
      "Processing chunk 11351/33334\n",
      "Processing chunk 11401/33334\n",
      "Processing chunk 11451/33334\n",
      "Processing chunk 11501/33334\n",
      "Processing chunk 11551/33334\n",
      "Processing chunk 11601/33334\n",
      "Processing chunk 11651/33334\n",
      "Processing chunk 11701/33334\n",
      "Processing chunk 11751/33334\n",
      "Processing chunk 11801/33334\n",
      "Processing chunk 11851/33334\n",
      "Processing chunk 11901/33334\n",
      "Processing chunk 11951/33334\n",
      "Processing chunk 12001/33334\n",
      "Processing chunk 12051/33334\n",
      "Processing chunk 12101/33334\n",
      "Processing chunk 12151/33334\n",
      "Processing chunk 12201/33334\n",
      "Processing chunk 12251/33334\n",
      "Processing chunk 12301/33334\n",
      "Processing chunk 12351/33334\n",
      "Processing chunk 12401/33334\n",
      "Processing chunk 12451/33334\n",
      "Processing chunk 12501/33334\n",
      "Processing chunk 12551/33334\n",
      "Processing chunk 12601/33334\n",
      "Processing chunk 12651/33334\n",
      "Processing chunk 12701/33334\n",
      "Processing chunk 12751/33334\n",
      "Processing chunk 12801/33334\n",
      "Processing chunk 12851/33334\n",
      "Processing chunk 12901/33334\n",
      "Processing chunk 12951/33334\n",
      "Processing chunk 13001/33334\n",
      "Processing chunk 13051/33334\n",
      "Processing chunk 13101/33334\n",
      "Processing chunk 13151/33334\n",
      "Processing chunk 13201/33334\n",
      "Processing chunk 13251/33334\n",
      "Processing chunk 13301/33334\n",
      "Processing chunk 13351/33334\n",
      "Processing chunk 13401/33334\n",
      "Processing chunk 13451/33334\n",
      "Processing chunk 13501/33334\n",
      "Processing chunk 13551/33334\n",
      "Processing chunk 13601/33334\n",
      "Processing chunk 13651/33334\n",
      "Processing chunk 13701/33334\n",
      "Processing chunk 13751/33334\n",
      "Processing chunk 13801/33334\n",
      "Processing chunk 13851/33334\n",
      "Processing chunk 13901/33334\n",
      "Processing chunk 13951/33334\n",
      "Processing chunk 14001/33334\n",
      "Processing chunk 14051/33334\n",
      "Processing chunk 14101/33334\n",
      "Processing chunk 14151/33334\n",
      "Processing chunk 14201/33334\n",
      "Processing chunk 14251/33334\n",
      "Processing chunk 14301/33334\n",
      "Processing chunk 14351/33334\n",
      "Processing chunk 14401/33334\n",
      "Processing chunk 14451/33334\n",
      "Processing chunk 14501/33334\n",
      "Processing chunk 14551/33334\n",
      "Processing chunk 14601/33334\n",
      "Processing chunk 14651/33334\n",
      "Processing chunk 14701/33334\n",
      "Processing chunk 14751/33334\n",
      "Processing chunk 14801/33334\n",
      "Processing chunk 14851/33334\n",
      "Processing chunk 14901/33334\n",
      "Processing chunk 14951/33334\n",
      "Processing chunk 15001/33334\n",
      "Processing chunk 15051/33334\n",
      "Processing chunk 15101/33334\n",
      "Processing chunk 15151/33334\n",
      "Processing chunk 15201/33334\n",
      "Processing chunk 15251/33334\n",
      "Processing chunk 15301/33334\n",
      "Processing chunk 15351/33334\n",
      "Processing chunk 15401/33334\n",
      "Processing chunk 15451/33334\n",
      "Processing chunk 15501/33334\n",
      "Processing chunk 15551/33334\n",
      "Processing chunk 15601/33334\n",
      "Processing chunk 15651/33334\n",
      "Processing chunk 15701/33334\n",
      "Processing chunk 15751/33334\n",
      "Processing chunk 15801/33334\n",
      "Processing chunk 15851/33334\n",
      "Processing chunk 15901/33334\n",
      "Processing chunk 15951/33334\n",
      "Processing chunk 16001/33334\n",
      "Processing chunk 16051/33334\n",
      "Processing chunk 16101/33334\n",
      "Processing chunk 16151/33334\n",
      "Processing chunk 16201/33334\n",
      "Processing chunk 16251/33334\n",
      "Processing chunk 16301/33334\n",
      "Processing chunk 16351/33334\n",
      "Processing chunk 16401/33334\n",
      "Processing chunk 16451/33334\n",
      "Processing chunk 16501/33334\n",
      "Processing chunk 16551/33334\n",
      "Processing chunk 16601/33334\n",
      "Processing chunk 16651/33334\n",
      "Processing chunk 16701/33334\n",
      "Processing chunk 16751/33334\n",
      "Processing chunk 16801/33334\n",
      "Processing chunk 16851/33334\n",
      "Processing chunk 16901/33334\n",
      "Processing chunk 16951/33334\n",
      "Processing chunk 17001/33334\n",
      "Processing chunk 17051/33334\n",
      "Processing chunk 17101/33334\n",
      "Processing chunk 17151/33334\n",
      "Processing chunk 17201/33334\n",
      "Processing chunk 17251/33334\n",
      "Processing chunk 17301/33334\n",
      "Processing chunk 17351/33334\n",
      "Processing chunk 17401/33334\n",
      "Processing chunk 17451/33334\n",
      "Processing chunk 17501/33334\n",
      "Processing chunk 17551/33334\n",
      "Processing chunk 17601/33334\n",
      "Processing chunk 17651/33334\n",
      "Processing chunk 17701/33334\n",
      "Processing chunk 17751/33334\n",
      "Processing chunk 17801/33334\n",
      "Processing chunk 17851/33334\n",
      "Processing chunk 17901/33334\n",
      "Processing chunk 17951/33334\n",
      "Processing chunk 18001/33334\n",
      "Processing chunk 18051/33334\n",
      "Processing chunk 18101/33334\n",
      "Processing chunk 18151/33334\n",
      "Processing chunk 18201/33334\n",
      "Processing chunk 18251/33334\n",
      "Processing chunk 18301/33334\n",
      "Processing chunk 18351/33334\n",
      "Processing chunk 18401/33334\n",
      "Processing chunk 18451/33334\n",
      "Processing chunk 18501/33334\n",
      "Processing chunk 18551/33334\n",
      "Processing chunk 18601/33334\n",
      "Processing chunk 18651/33334\n",
      "Processing chunk 18701/33334\n",
      "Processing chunk 18751/33334\n",
      "Processing chunk 18801/33334\n",
      "Processing chunk 18851/33334\n",
      "Processing chunk 18901/33334\n",
      "Processing chunk 18951/33334\n",
      "Processing chunk 19001/33334\n",
      "Processing chunk 19051/33334\n",
      "Processing chunk 19101/33334\n",
      "Processing chunk 19151/33334\n",
      "Processing chunk 19201/33334\n",
      "Processing chunk 19251/33334\n",
      "Processing chunk 19301/33334\n",
      "Processing chunk 19351/33334\n",
      "Processing chunk 19401/33334\n",
      "Processing chunk 19451/33334\n",
      "Processing chunk 19501/33334\n",
      "Processing chunk 19551/33334\n",
      "Processing chunk 19601/33334\n",
      "Processing chunk 19651/33334\n",
      "Processing chunk 19701/33334\n",
      "Processing chunk 19751/33334\n",
      "Processing chunk 19801/33334\n",
      "Processing chunk 19851/33334\n",
      "Processing chunk 19901/33334\n",
      "Processing chunk 19951/33334\n",
      "Processing chunk 20001/33334\n",
      "Processing chunk 20051/33334\n",
      "Processing chunk 20101/33334\n",
      "Processing chunk 20151/33334\n",
      "Processing chunk 20201/33334\n",
      "Processing chunk 20251/33334\n",
      "Processing chunk 20301/33334\n",
      "Processing chunk 20351/33334\n",
      "Processing chunk 20401/33334\n",
      "Processing chunk 20451/33334\n",
      "Processing chunk 20501/33334\n",
      "Processing chunk 20551/33334\n",
      "Processing chunk 20601/33334\n",
      "Processing chunk 20651/33334\n",
      "Processing chunk 20701/33334\n",
      "Processing chunk 20751/33334\n",
      "Processing chunk 20801/33334\n",
      "Processing chunk 20851/33334\n",
      "Processing chunk 20901/33334\n",
      "Processing chunk 20951/33334\n",
      "Processing chunk 21001/33334\n",
      "Processing chunk 21051/33334\n",
      "Processing chunk 21101/33334\n",
      "Processing chunk 21151/33334\n",
      "Processing chunk 21201/33334\n",
      "Processing chunk 21251/33334\n",
      "Processing chunk 21301/33334\n",
      "Processing chunk 21351/33334\n",
      "Processing chunk 21401/33334\n",
      "Processing chunk 21451/33334\n",
      "Processing chunk 21501/33334\n",
      "Processing chunk 21551/33334\n",
      "Processing chunk 21601/33334\n",
      "Processing chunk 21651/33334\n",
      "Processing chunk 21701/33334\n",
      "Processing chunk 21751/33334\n",
      "Processing chunk 21801/33334\n",
      "Processing chunk 21851/33334\n",
      "Processing chunk 21901/33334\n",
      "Processing chunk 21951/33334\n",
      "Processing chunk 22001/33334\n",
      "Processing chunk 22051/33334\n",
      "Processing chunk 22101/33334\n",
      "Processing chunk 22151/33334\n",
      "Processing chunk 22201/33334\n",
      "Processing chunk 22251/33334\n",
      "Processing chunk 22301/33334\n",
      "Processing chunk 22351/33334\n",
      "Processing chunk 22401/33334\n",
      "Processing chunk 22451/33334\n",
      "Processing chunk 22501/33334\n",
      "Processing chunk 22551/33334\n",
      "Processing chunk 22601/33334\n",
      "Processing chunk 22651/33334\n",
      "Processing chunk 22701/33334\n",
      "Processing chunk 22751/33334\n",
      "Processing chunk 22801/33334\n",
      "Processing chunk 22851/33334\n",
      "Processing chunk 22901/33334\n",
      "Processing chunk 22951/33334\n",
      "Processing chunk 23001/33334\n",
      "Processing chunk 23051/33334\n",
      "Processing chunk 23101/33334\n",
      "Processing chunk 23151/33334\n",
      "Processing chunk 23201/33334\n",
      "Processing chunk 23251/33334\n",
      "Processing chunk 23301/33334\n",
      "Processing chunk 23351/33334\n",
      "Processing chunk 23401/33334\n",
      "Processing chunk 23451/33334\n",
      "Processing chunk 23501/33334\n",
      "Processing chunk 23551/33334\n",
      "Processing chunk 23601/33334\n",
      "Processing chunk 23651/33334\n",
      "Processing chunk 23701/33334\n",
      "Processing chunk 23751/33334\n",
      "Processing chunk 23801/33334\n",
      "Processing chunk 23851/33334\n",
      "Processing chunk 23901/33334\n",
      "Processing chunk 23951/33334\n",
      "Processing chunk 24001/33334\n",
      "Processing chunk 24051/33334\n",
      "Processing chunk 24101/33334\n",
      "Processing chunk 24151/33334\n",
      "Processing chunk 24201/33334\n",
      "Processing chunk 24251/33334\n",
      "Processing chunk 24301/33334\n",
      "Processing chunk 24351/33334\n",
      "Processing chunk 24401/33334\n",
      "Processing chunk 24451/33334\n",
      "Processing chunk 24501/33334\n",
      "Processing chunk 24551/33334\n",
      "Processing chunk 24601/33334\n",
      "Processing chunk 24651/33334\n",
      "Processing chunk 24701/33334\n",
      "Processing chunk 24751/33334\n",
      "Processing chunk 24801/33334\n",
      "Processing chunk 24851/33334\n",
      "Processing chunk 24901/33334\n",
      "Processing chunk 24951/33334\n",
      "Processing chunk 25001/33334\n",
      "Processing chunk 25051/33334\n",
      "Processing chunk 25101/33334\n",
      "Processing chunk 25151/33334\n",
      "Processing chunk 25201/33334\n",
      "Processing chunk 25251/33334\n",
      "Processing chunk 25301/33334\n",
      "Processing chunk 25351/33334\n",
      "Processing chunk 25401/33334\n",
      "Processing chunk 25451/33334\n",
      "Processing chunk 25501/33334\n",
      "Processing chunk 25551/33334\n",
      "Processing chunk 25601/33334\n",
      "Processing chunk 25651/33334\n",
      "Processing chunk 25701/33334\n",
      "Processing chunk 25751/33334\n",
      "Processing chunk 25801/33334\n",
      "Processing chunk 25851/33334\n",
      "Processing chunk 25901/33334\n",
      "Processing chunk 25951/33334\n",
      "Processing chunk 26001/33334\n",
      "Processing chunk 26051/33334\n",
      "Processing chunk 26101/33334\n",
      "Processing chunk 26151/33334\n",
      "Processing chunk 26201/33334\n",
      "Processing chunk 26251/33334\n",
      "Processing chunk 26301/33334\n",
      "Processing chunk 26351/33334\n",
      "Processing chunk 26401/33334\n",
      "Processing chunk 26451/33334\n",
      "Processing chunk 26501/33334\n",
      "Processing chunk 26551/33334\n",
      "Processing chunk 26601/33334\n",
      "Processing chunk 26651/33334\n",
      "Processing chunk 26701/33334\n",
      "Processing chunk 26751/33334\n",
      "Processing chunk 26801/33334\n",
      "Processing chunk 26851/33334\n",
      "Processing chunk 26901/33334\n",
      "Processing chunk 26951/33334\n",
      "Processing chunk 27001/33334\n",
      "Processing chunk 27051/33334\n",
      "Processing chunk 27101/33334\n",
      "Processing chunk 27151/33334\n",
      "Processing chunk 27201/33334\n",
      "Processing chunk 27251/33334\n",
      "Processing chunk 27301/33334\n",
      "Processing chunk 27351/33334\n",
      "Processing chunk 27401/33334\n",
      "Processing chunk 27451/33334\n",
      "Processing chunk 27501/33334\n",
      "Processing chunk 27551/33334\n",
      "Processing chunk 27601/33334\n",
      "Processing chunk 27651/33334\n",
      "Processing chunk 27701/33334\n",
      "Processing chunk 27751/33334\n",
      "Processing chunk 27801/33334\n",
      "Processing chunk 27851/33334\n",
      "Processing chunk 27901/33334\n",
      "Processing chunk 27951/33334\n",
      "Processing chunk 28001/33334\n",
      "Processing chunk 28051/33334\n",
      "Processing chunk 28101/33334\n",
      "Processing chunk 28151/33334\n",
      "Processing chunk 28201/33334\n",
      "Processing chunk 28251/33334\n",
      "Processing chunk 28301/33334\n",
      "Processing chunk 28351/33334\n",
      "Processing chunk 28401/33334\n",
      "Processing chunk 28451/33334\n",
      "Processing chunk 28501/33334\n",
      "Processing chunk 28551/33334\n",
      "Processing chunk 28601/33334\n",
      "Processing chunk 28651/33334\n",
      "Processing chunk 28701/33334\n",
      "Processing chunk 28751/33334\n",
      "Processing chunk 28801/33334\n",
      "Processing chunk 28851/33334\n",
      "Processing chunk 28901/33334\n",
      "Processing chunk 28951/33334\n",
      "Processing chunk 29001/33334\n",
      "Processing chunk 29051/33334\n",
      "Processing chunk 29101/33334\n",
      "Processing chunk 29151/33334\n",
      "Processing chunk 29201/33334\n",
      "Processing chunk 29251/33334\n",
      "Processing chunk 29301/33334\n",
      "Processing chunk 29351/33334\n",
      "Processing chunk 29401/33334\n",
      "Processing chunk 29451/33334\n",
      "Processing chunk 29501/33334\n",
      "Processing chunk 29551/33334\n",
      "Processing chunk 29601/33334\n",
      "Processing chunk 29651/33334\n",
      "Processing chunk 29701/33334\n",
      "Processing chunk 29751/33334\n",
      "Processing chunk 29801/33334\n",
      "Processing chunk 29851/33334\n",
      "Processing chunk 29901/33334\n",
      "Processing chunk 29951/33334\n",
      "Processing chunk 30001/33334\n",
      "Processing chunk 30051/33334\n",
      "Processing chunk 30101/33334\n",
      "Processing chunk 30151/33334\n",
      "Processing chunk 30201/33334\n",
      "Processing chunk 30251/33334\n",
      "Processing chunk 30301/33334\n",
      "Processing chunk 30351/33334\n",
      "Processing chunk 30401/33334\n",
      "Processing chunk 30451/33334\n",
      "Processing chunk 30501/33334\n",
      "Processing chunk 30551/33334\n",
      "Processing chunk 30601/33334\n",
      "Processing chunk 30651/33334\n",
      "Processing chunk 30701/33334\n",
      "Processing chunk 30751/33334\n",
      "Processing chunk 30801/33334\n",
      "Processing chunk 30851/33334\n",
      "Processing chunk 30901/33334\n",
      "Processing chunk 30951/33334\n",
      "Processing chunk 31001/33334\n",
      "Processing chunk 31051/33334\n",
      "Processing chunk 31101/33334\n",
      "Processing chunk 31151/33334\n",
      "Processing chunk 31201/33334\n",
      "Processing chunk 31251/33334\n",
      "Processing chunk 31301/33334\n",
      "Processing chunk 31351/33334\n",
      "Processing chunk 31401/33334\n",
      "Processing chunk 31451/33334\n",
      "Processing chunk 31501/33334\n",
      "Processing chunk 31551/33334\n",
      "Processing chunk 31601/33334\n",
      "Processing chunk 31651/33334\n",
      "Processing chunk 31701/33334\n",
      "Processing chunk 31751/33334\n",
      "Processing chunk 31801/33334\n",
      "Processing chunk 31851/33334\n",
      "Processing chunk 31901/33334\n",
      "Processing chunk 31951/33334\n",
      "Processing chunk 32001/33334\n",
      "Processing chunk 32051/33334\n",
      "Processing chunk 32101/33334\n",
      "Processing chunk 32151/33334\n",
      "Processing chunk 32201/33334\n",
      "Processing chunk 32251/33334\n",
      "Processing chunk 32301/33334\n",
      "Processing chunk 32351/33334\n",
      "Processing chunk 32401/33334\n",
      "Processing chunk 32451/33334\n",
      "Processing chunk 32501/33334\n",
      "Processing chunk 32551/33334\n",
      "Processing chunk 32601/33334\n",
      "Processing chunk 32651/33334\n",
      "Processing chunk 32701/33334\n",
      "Processing chunk 32751/33334\n",
      "Processing chunk 32801/33334\n",
      "Processing chunk 32851/33334\n",
      "Processing chunk 32901/33334\n",
      "Processing chunk 32951/33334\n",
      "Processing chunk 33001/33334\n",
      "Processing chunk 33051/33334\n",
      "Processing chunk 33101/33334\n",
      "Processing chunk 33151/33334\n",
      "Processing chunk 33201/33334\n",
      "Processing chunk 33251/33334\n",
      "Processing chunk 33301/33334\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 10000\n",
      "Number of hits: 10000\n",
      "Average HR@60: 1.0000\n",
      "Average NDCG@60: 0.3790\n",
      "Evaluation completed in 6.49s\n",
      "HR@60: 1.0000\n",
      "NDCG@60: 0.3790\n"
     ]
    }
   ],
   "source": [
    "USR=50000\n",
    "TOP_N=60\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import Linear, Dropout\n",
    "from datetime import datetime\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "class NCFModel(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim, mlp_layers, dropout=0.1):\n",
    "        super(NCFModel, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "        \n",
    "        # MLP layers\n",
    "        mlp_modules = []\n",
    "        input_dim = 2 * embedding_dim  # Concatenated user and item embeddings\n",
    "        for layer_size in mlp_layers:\n",
    "            mlp_modules.append(Linear(input_dim, layer_size))\n",
    "            mlp_modules.append(Dropout(dropout))\n",
    "            mlp_modules.append(nn.ReLU())\n",
    "            input_dim = layer_size\n",
    "        \n",
    "        self.mlp = nn.Sequential(*mlp_modules)\n",
    "        self.output_layer = Linear(mlp_layers[-1], 1)  # Final output layer\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        user_embeds = self.user_embedding(user_ids)\n",
    "        item_embeds = self.item_embedding(item_ids)\n",
    "        \n",
    "        # Concatenate user and item embeddings\n",
    "        x = torch.cat([user_embeds, item_embeds], dim=-1)\n",
    "        \n",
    "        # Pass through MLP\n",
    "        x = self.mlp(x)\n",
    "        output = self.output_layer(x)\n",
    "        \n",
    "        return output.squeeze(-1)  # Return [batch_size] tensor\n",
    "\n",
    "# cropped dataset\n",
    "class MultiBehaviorDataset:\n",
    "    def __init__(self, data_path='/Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/', max_users=10000):\n",
    "        self.data_path = data_path\n",
    "        self.behaviors = ['pv', 'cart', 'buy']\n",
    "        self.trn_file = data_path + 'trn_'\n",
    "        self.tst_file = data_path + 'tst_'\n",
    "        self.max_users = max_users  # Limit number of users\n",
    "        \n",
    "        self.load_training_data()\n",
    "        self.load_test_data()\n",
    "    \n",
    "    def load_training_data(self):\n",
    "        print(\"Loading training data from:\", self.data_path)\n",
    "        self.trn_mats = []\n",
    "        for beh in self.behaviors:\n",
    "            path = self.trn_file + beh\n",
    "            print(f\"Loading behavior: {beh} from {path}\")\n",
    "            if not os.path.exists(path):\n",
    "                raise FileNotFoundError(f\"File not found: {path}\")\n",
    "            with open(path, 'rb') as fs:\n",
    "                mat = pickle.load(fs)\n",
    "                if not isinstance(mat, csr_matrix):\n",
    "                    mat = csr_matrix(mat)\n",
    "                mat = (mat != 0).astype(np.float32)\n",
    "                self.trn_mats.append(mat)\n",
    "        \n",
    "        self.trn_label = 1 * (self.trn_mats[-1] != 0)\n",
    "        self.n_users, self.n_items = self.trn_mats[0].shape\n",
    "        self.n_behaviors = len(self.behaviors)\n",
    "        print(f\"Dataset dimensions: {self.n_users} users, {self.n_items} items\")\n",
    "\n",
    "    def create_adjacency_matrix(self, users):\n",
    "        \"\"\"Optimized adjacency matrix creation\"\"\"\n",
    "        batch_size = len(users)\n",
    "        adj_matrix = torch.zeros(batch_size, batch_size, device=device)\n",
    "        \n",
    "        # Pre-compute user item sets\n",
    "        user_item_sets = []\n",
    "        for user in users:\n",
    "            user_items = set()\n",
    "            for mat in self.trn_mats:\n",
    "                user_items.update(mat[user].indices)\n",
    "            user_item_sets.append(user_items)\n",
    "        \n",
    "        # Compute similarities in parallel\n",
    "        for i in range(batch_size):\n",
    "            if not user_item_sets[i]:\n",
    "                continue\n",
    "            for j in range(i+1, batch_size):\n",
    "                if user_item_sets[j]:\n",
    "                    jaccard = len(user_item_sets[i] & user_item_sets[j]) / len(user_item_sets[i] | user_item_sets[j])\n",
    "                    adj_matrix[i,j] = adj_matrix[j,i] = jaccard\n",
    "        \n",
    "        return adj_matrix\n",
    "\n",
    "    def create_graph_metrics(self, users):\n",
    "        \"\"\"Optimized graph metrics creation\"\"\"\n",
    "        metrics = torch.zeros(len(users), 3, device=device)\n",
    "        \n",
    "        # Vectorized computation\n",
    "        for i, user in enumerate(users):\n",
    "            interactions = np.array([mat[user].nnz for mat in self.trn_mats])\n",
    "            metrics[i,0] = sum(interactions) / 100\n",
    "            metrics[i,1] = (interactions > 0).sum() / len(self.behaviors)\n",
    "            metrics[i,2] = interactions[-1] / max(interactions[0], 1)\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "    def prepare_train_instances(self, max_samples=5000):\n",
    "        \"\"\"Optimized training instance preparation\"\"\"\n",
    "        print(\"Preparing training instances...\")\n",
    "        train_data = []\n",
    "        \n",
    "        # Randomly select users\n",
    "        selected_users = np.random.choice(min(self.n_users, self.max_users), size=min(1000, self.max_users), replace=False)\n",
    "        \n",
    "        for user in selected_users:\n",
    "            pos_items = self.trn_label[user].indices[:2]  # Limit positive items\n",
    "            \n",
    "            if len(pos_items) > 0:\n",
    "                for item in pos_items:\n",
    "                    behaviors = [float(mat[user, item]) for mat in self.trn_mats]\n",
    "                    train_data.append([user, item, 1.0] + behaviors)\n",
    "                    \n",
    "                    # Limited negative sampling\n",
    "                    neg_items = np.random.choice(self.n_items, size=2, replace=False)\n",
    "                    for neg_item in neg_items:\n",
    "                        behaviors = [float(mat[user, neg_item]) for mat in self.trn_mats]\n",
    "                        train_data.append([user, neg_item, 0.0] + behaviors)\n",
    "                        \n",
    "                    if len(train_data) >= max_samples:\n",
    "                        break\n",
    "            \n",
    "            if len(train_data) >= max_samples:\n",
    "                break\n",
    "        \n",
    "        print(f\"Generated {len(train_data)} training instances\")\n",
    "        return np.array(train_data)\n",
    "    \n",
    "    def load_test_data(self):\n",
    "        \"\"\"Load test data\"\"\"\n",
    "        test_path = self.tst_file + 'int'\n",
    "        print(f\"Loading test data from: {test_path}\")\n",
    "        if not os.path.exists(test_path):\n",
    "            raise FileNotFoundError(f\"File not found: {test_path}\")\n",
    "        with open(test_path, 'rb') as fs:\n",
    "            self.tst_int = np.array(pickle.load(fs))\n",
    "        \n",
    "        self.tst_users = np.reshape(np.argwhere(self.tst_int != None), [-1])\n",
    "        # Limit test users for faster processing\n",
    "        self.tst_users = self.tst_users[:min(len(self.tst_users), self.max_users)]\n",
    "        print(f\"Using {len(self.tst_users)} test users\")\n",
    "\n",
    "    def get_test_instances(self, num_neg_samples=99):\n",
    "        \"\"\"Generate test instances with negative sampling\"\"\"\n",
    "        print(\"Preparing test instances...\")\n",
    "        test_instances = []\n",
    "        \n",
    "        for user in self.tst_users:\n",
    "            pos_item = self.tst_int[user]\n",
    "            if pos_item is not None:\n",
    "                # Add positive instance\n",
    "                test_instances.append([user, pos_item, 1.0])\n",
    "                \n",
    "                # Add negative instances\n",
    "                try:\n",
    "                    # Get all items and remove positive items\n",
    "                    all_items = set(range(self.n_items))\n",
    "                    pos_items_train = set(self.trn_label[user].indices)\n",
    "                    pos_items_train.add(pos_item)\n",
    "                    neg_items_pool = list(all_items - pos_items_train)\n",
    "                    \n",
    "                    # Sample negative items\n",
    "                    n_neg = min(num_neg_samples, len(neg_items_pool))\n",
    "                    if n_neg > 0:\n",
    "                        neg_items = np.random.choice(neg_items_pool, size=n_neg, replace=False)\n",
    "                        for neg_item in neg_items:\n",
    "                            test_instances.append([user, neg_item, 0.0])\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing test user {user}: {str(e)}\")\n",
    "                    continue\n",
    "                \n",
    "                # Limit the number of test instances for faster processing\n",
    "                if len(test_instances) >= self.max_users * 100:\n",
    "                    break\n",
    "        \n",
    "        if not test_instances:\n",
    "            raise ValueError(\"No test instances were generated!\")\n",
    "            \n",
    "        test_instances = np.array(test_instances)\n",
    "        print(f\"Generated {len(test_instances)} test instances\")\n",
    "        return test_instances\n",
    "\n",
    "def evaluate_model(model, dataset, test_instances, k=10):\n",
    "    \"\"\"Improved evaluation function with better metrics calculation\"\"\"\n",
    "    model.eval()\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    \n",
    "    # Process test instances in smaller chunks\n",
    "    chunk_size = 30\n",
    "    test_chunks = [test_instances[i:i + chunk_size] for i in range(0, len(test_instances), chunk_size)]\n",
    "    \n",
    "    print(f\"Evaluating {len(test_instances)} instances in {len(test_chunks)} chunks...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for chunk_idx, chunk in enumerate(test_chunks):\n",
    "            if chunk_idx % 50 == 0:  # Reduced frequency of progress updates\n",
    "                print(f\"Processing chunk {chunk_idx + 1}/{len(test_chunks)}\")\n",
    "            \n",
    "            # Group by user and ensure we have both positive and negative items\n",
    "            user_items = {}\n",
    "            for inst in chunk:\n",
    "                user = int(inst[0])\n",
    "                item = int(inst[1])\n",
    "                label = float(inst[2])\n",
    "                \n",
    "                if user not in user_items:\n",
    "                    user_items[user] = {'pos': [], 'neg': [], 'all_items': [], 'all_scores': []}\n",
    "                \n",
    "                user_items[user]['all_items'].append(item)\n",
    "                if label > 0.5:\n",
    "                    user_items[user]['pos'].append(item)\n",
    "                else:\n",
    "                    user_items[user]['neg'].append(item)\n",
    "            \n",
    "            # Process each user that has both positive and negative items\n",
    "            for user, data in user_items.items():\n",
    "                if not data['pos'] or not data['neg']:\n",
    "                    continue\n",
    "                \n",
    "                items = data['all_items']\n",
    "                batch_size = len(items)\n",
    "                \n",
    "                # Create input features\n",
    "                user_ids = torch.LongTensor([user] * batch_size).to(device)\n",
    "                item_ids = torch.LongTensor(items).to(device)\n",
    "                \n",
    "                # Get predictions from the model\n",
    "                predictions = model(user_ids, item_ids)\n",
    "                predictions = predictions.cpu().numpy().flatten()\n",
    "                \n",
    "                # Store all scores\n",
    "                for item, score in zip(items, predictions):\n",
    "                    data['all_scores'].append((item, score))\n",
    "                \n",
    "                # Sort items by score\n",
    "                sorted_items = [x[0] for x in sorted(data['all_scores'], key=lambda x: x[1], reverse=True)]\n",
    "                recommended_items = sorted_items[:k]\n",
    "                \n",
    "                # Calculate HR\n",
    "                hit = False\n",
    "                for pos_item in data['pos']:\n",
    "                    if pos_item in recommended_items:\n",
    "                        hit = True\n",
    "                        break\n",
    "                hits.append(hit)\n",
    "                \n",
    "                # Calculate NDCG\n",
    "                dcg = 0\n",
    "                idcg = 1  # Ideal DCG for one relevant item\n",
    "                for i, item in enumerate(recommended_items):\n",
    "                    if item in data['pos']:\n",
    "                        dcg += 1 / np.log2(i + 2)\n",
    "                ndcg = dcg / idcg\n",
    "                ndcgs.append(ndcg)\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    hr = np.mean(hits) if hits else 0\n",
    "    ndcg = np.mean(ndcgs) if ndcgs else 0\n",
    "    \n",
    "    # Print detailed statistics\n",
    "    print(f\"\\nEvaluation Statistics:\")\n",
    "    print(f\"Total users evaluated: {len(hits)}\")\n",
    "    print(f\"Number of hits: {sum(hits)}\")\n",
    "    print(f\"Average HR@{k}: {hr:.4f}\")\n",
    "    print(f\"Average NDCG@{k}: {ndcg:.4f}\")\n",
    "    \n",
    "    return hr, ndcg\n",
    "\n",
    "def main():\n",
    "    # Configuration\n",
    "    config = {\n",
    "        'embedding_dim': 32,\n",
    "        'mlp_layers': [64, 32],  # Example MLP layer sizes\n",
    "        'learning_rate': 0.001,\n",
    "        'weight_decay': 1e-6,\n",
    "        'dropout': 0.1,\n",
    "        'max_samples': USR,\n",
    "        'eval_k': TOP_N,\n",
    "        'gradient_clip': 1.0  # Added gradient clipping\n",
    "    }\n",
    "    \n",
    "    print(\"Initializing dataset...\")\n",
    "    dataset = MultiBehaviorDataset(max_users=USR)\n",
    "    train_data = dataset.prepare_train_instances(max_samples=config['max_samples'])\n",
    "    \n",
    "    print(f\"Using {len(train_data)} training instances\")\n",
    "\n",
    "    model = NCFModel(\n",
    "        num_users=dataset.n_users,\n",
    "        num_items=dataset.n_items,\n",
    "        embedding_dim=config['embedding_dim'],\n",
    "        mlp_layers=config['mlp_layers'],\n",
    "        dropout=config['dropout']\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "    print(\"Preparing training tensors...\")\n",
    "    users = torch.LongTensor(train_data[:, 0]).to(device)\n",
    "    items = torch.LongTensor(train_data[:, 1]).to(device)\n",
    "    labels = torch.FloatTensor(train_data[:, 2]).to(device)\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    try:\n",
    "        model.train()\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        # Training\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(users, items)\n",
    "        predictions = predictions.view(-1)\n",
    "        labels = labels.view(-1)\n",
    "        \n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), config['gradient_clip'])  # Gradient clipping\n",
    "        optimizer.step()\n",
    "        \n",
    "        training_time = (datetime.now() - start_time).total_seconds()\n",
    "        print(f\"Training completed in {training_time:.2f}s\")\n",
    "        print(f\"Training loss: {loss.item():.4f}\")\n",
    "        \n",
    "        # Evaluation\n",
    "        print(\"\\nStarting evaluation...\")\n",
    "        eval_start_time = datetime.now()\n",
    "        \n",
    "        test_instances = dataset.get_test_instances()\n",
    "        hr, ndcg = evaluate_model(model, dataset, test_instances, k=config['eval_k'])\n",
    "        \n",
    "        eval_time = (datetime.now() - eval_start_time).total_seconds()\n",
    "        print(f\"Evaluation completed in {eval_time:.2f}s\")\n",
    "        print(f\"HR@{config['eval_k']}: {hr:.4f}\")\n",
    "        print(f\"NDCG@{config['eval_k']}: {ndcg:.4f}\")\n",
    "        \n",
    "        # Save results\n",
    "        results = {\n",
    "            'training_time': training_time,\n",
    "            'eval_time': eval_time,\n",
    "            'training_loss': loss.item(),\n",
    "            'hr': hr,\n",
    "            'ndcg': ndcg\n",
    "        }\n",
    "        \n",
    "        # Save to file\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        with open(f'results_{timestamp}.txt', 'w') as f:\n",
    "            for key, value in results.items():\n",
    "                f.write(f\"{key}: {value}\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during training: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DMF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing dataset...\n",
      "Loading training data from: /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/\n",
      "Loading behavior: pv from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_pv\n",
      "Loading behavior: cart from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_cart\n",
      "Loading behavior: buy from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_buy\n",
      "Dataset dimensions: 21716 users, 7977 items\n",
      "Loading test data from: /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/tst_int\n",
      "Using 10000 test users\n",
      "Preparing training instances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yf/20z1hn994jd04q4kl0gpgh740000gn/T/ipykernel_51372/741517217.py:58: DeprecationWarning: Please import `csr_matrix` from the `scipy.sparse` namespace; the `scipy.sparse.csr` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  mat = pickle.load(fs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 6000 training instances\n",
      "Using 6000 training instances\n",
      "Preparing training tensors...\n",
      "Starting training...\n",
      "Epoch 1, Loss: 0.6824\n",
      "Epoch 2, Loss: 0.6363\n",
      "Epoch 3, Loss: 0.5924\n",
      "Epoch 4, Loss: 0.5461\n",
      "Epoch 5, Loss: 0.4943\n",
      "Epoch 6, Loss: 0.4366\n",
      "Epoch 7, Loss: 0.3741\n",
      "Epoch 8, Loss: 0.3098\n",
      "Epoch 9, Loss: 0.2474\n",
      "Epoch 10, Loss: 0.1901\n",
      "Training completed in 0.33s\n",
      "\n",
      "Starting evaluation...\n",
      "Preparing test instances...\n",
      "Generated 1000000 test instances\n",
      "Evaluating 1000000 instances in 10000 chunks...\n",
      "Processing chunk 1/10000\n",
      "Processing chunk 51/10000\n",
      "Processing chunk 101/10000\n",
      "Processing chunk 151/10000\n",
      "Processing chunk 201/10000\n",
      "Processing chunk 251/10000\n",
      "Processing chunk 301/10000\n",
      "Processing chunk 351/10000\n",
      "Processing chunk 401/10000\n",
      "Processing chunk 451/10000\n",
      "Processing chunk 501/10000\n",
      "Processing chunk 551/10000\n",
      "Processing chunk 601/10000\n",
      "Processing chunk 651/10000\n",
      "Processing chunk 701/10000\n",
      "Processing chunk 751/10000\n",
      "Processing chunk 801/10000\n",
      "Processing chunk 851/10000\n",
      "Processing chunk 901/10000\n",
      "Processing chunk 951/10000\n",
      "Processing chunk 1001/10000\n",
      "Processing chunk 1051/10000\n",
      "Processing chunk 1101/10000\n",
      "Processing chunk 1151/10000\n",
      "Processing chunk 1201/10000\n",
      "Processing chunk 1251/10000\n",
      "Processing chunk 1301/10000\n",
      "Processing chunk 1351/10000\n",
      "Processing chunk 1401/10000\n",
      "Processing chunk 1451/10000\n",
      "Processing chunk 1501/10000\n",
      "Processing chunk 1551/10000\n",
      "Processing chunk 1601/10000\n",
      "Processing chunk 1651/10000\n",
      "Processing chunk 1701/10000\n",
      "Processing chunk 1751/10000\n",
      "Processing chunk 1801/10000\n",
      "Processing chunk 1851/10000\n",
      "Processing chunk 1901/10000\n",
      "Processing chunk 1951/10000\n",
      "Processing chunk 2001/10000\n",
      "Processing chunk 2051/10000\n",
      "Processing chunk 2101/10000\n",
      "Processing chunk 2151/10000\n",
      "Processing chunk 2201/10000\n",
      "Processing chunk 2251/10000\n",
      "Processing chunk 2301/10000\n",
      "Processing chunk 2351/10000\n",
      "Processing chunk 2401/10000\n",
      "Processing chunk 2451/10000\n",
      "Processing chunk 2501/10000\n",
      "Processing chunk 2551/10000\n",
      "Processing chunk 2601/10000\n",
      "Processing chunk 2651/10000\n",
      "Processing chunk 2701/10000\n",
      "Processing chunk 2751/10000\n",
      "Processing chunk 2801/10000\n",
      "Processing chunk 2851/10000\n",
      "Processing chunk 2901/10000\n",
      "Processing chunk 2951/10000\n",
      "Processing chunk 3001/10000\n",
      "Processing chunk 3051/10000\n",
      "Processing chunk 3101/10000\n",
      "Processing chunk 3151/10000\n",
      "Processing chunk 3201/10000\n",
      "Processing chunk 3251/10000\n",
      "Processing chunk 3301/10000\n",
      "Processing chunk 3351/10000\n",
      "Processing chunk 3401/10000\n",
      "Processing chunk 3451/10000\n",
      "Processing chunk 3501/10000\n",
      "Processing chunk 3551/10000\n",
      "Processing chunk 3601/10000\n",
      "Processing chunk 3651/10000\n",
      "Processing chunk 3701/10000\n",
      "Processing chunk 3751/10000\n",
      "Processing chunk 3801/10000\n",
      "Processing chunk 3851/10000\n",
      "Processing chunk 3901/10000\n",
      "Processing chunk 3951/10000\n",
      "Processing chunk 4001/10000\n",
      "Processing chunk 4051/10000\n",
      "Processing chunk 4101/10000\n",
      "Processing chunk 4151/10000\n",
      "Processing chunk 4201/10000\n",
      "Processing chunk 4251/10000\n",
      "Processing chunk 4301/10000\n",
      "Processing chunk 4351/10000\n",
      "Processing chunk 4401/10000\n",
      "Processing chunk 4451/10000\n",
      "Processing chunk 4501/10000\n",
      "Processing chunk 4551/10000\n",
      "Processing chunk 4601/10000\n",
      "Processing chunk 4651/10000\n",
      "Processing chunk 4701/10000\n",
      "Processing chunk 4751/10000\n",
      "Processing chunk 4801/10000\n",
      "Processing chunk 4851/10000\n",
      "Processing chunk 4901/10000\n",
      "Processing chunk 4951/10000\n",
      "Processing chunk 5001/10000\n",
      "Processing chunk 5051/10000\n",
      "Processing chunk 5101/10000\n",
      "Processing chunk 5151/10000\n",
      "Processing chunk 5201/10000\n",
      "Processing chunk 5251/10000\n",
      "Processing chunk 5301/10000\n",
      "Processing chunk 5351/10000\n",
      "Processing chunk 5401/10000\n",
      "Processing chunk 5451/10000\n",
      "Processing chunk 5501/10000\n",
      "Processing chunk 5551/10000\n",
      "Processing chunk 5601/10000\n",
      "Processing chunk 5651/10000\n",
      "Processing chunk 5701/10000\n",
      "Processing chunk 5751/10000\n",
      "Processing chunk 5801/10000\n",
      "Processing chunk 5851/10000\n",
      "Processing chunk 5901/10000\n",
      "Processing chunk 5951/10000\n",
      "Processing chunk 6001/10000\n",
      "Processing chunk 6051/10000\n",
      "Processing chunk 6101/10000\n",
      "Processing chunk 6151/10000\n",
      "Processing chunk 6201/10000\n",
      "Processing chunk 6251/10000\n",
      "Processing chunk 6301/10000\n",
      "Processing chunk 6351/10000\n",
      "Processing chunk 6401/10000\n",
      "Processing chunk 6451/10000\n",
      "Processing chunk 6501/10000\n",
      "Processing chunk 6551/10000\n",
      "Processing chunk 6601/10000\n",
      "Processing chunk 6651/10000\n",
      "Processing chunk 6701/10000\n",
      "Processing chunk 6751/10000\n",
      "Processing chunk 6801/10000\n",
      "Processing chunk 6851/10000\n",
      "Processing chunk 6901/10000\n",
      "Processing chunk 6951/10000\n",
      "Processing chunk 7001/10000\n",
      "Processing chunk 7051/10000\n",
      "Processing chunk 7101/10000\n",
      "Processing chunk 7151/10000\n",
      "Processing chunk 7201/10000\n",
      "Processing chunk 7251/10000\n",
      "Processing chunk 7301/10000\n",
      "Processing chunk 7351/10000\n",
      "Processing chunk 7401/10000\n",
      "Processing chunk 7451/10000\n",
      "Processing chunk 7501/10000\n",
      "Processing chunk 7551/10000\n",
      "Processing chunk 7601/10000\n",
      "Processing chunk 7651/10000\n",
      "Processing chunk 7701/10000\n",
      "Processing chunk 7751/10000\n",
      "Processing chunk 7801/10000\n",
      "Processing chunk 7851/10000\n",
      "Processing chunk 7901/10000\n",
      "Processing chunk 7951/10000\n",
      "Processing chunk 8001/10000\n",
      "Processing chunk 8051/10000\n",
      "Processing chunk 8101/10000\n",
      "Processing chunk 8151/10000\n",
      "Processing chunk 8201/10000\n",
      "Processing chunk 8251/10000\n",
      "Processing chunk 8301/10000\n",
      "Processing chunk 8351/10000\n",
      "Processing chunk 8401/10000\n",
      "Processing chunk 8451/10000\n",
      "Processing chunk 8501/10000\n",
      "Processing chunk 8551/10000\n",
      "Processing chunk 8601/10000\n",
      "Processing chunk 8651/10000\n",
      "Processing chunk 8701/10000\n",
      "Processing chunk 8751/10000\n",
      "Processing chunk 8801/10000\n",
      "Processing chunk 8851/10000\n",
      "Processing chunk 8901/10000\n",
      "Processing chunk 8951/10000\n",
      "Processing chunk 9001/10000\n",
      "Processing chunk 9051/10000\n",
      "Processing chunk 9101/10000\n",
      "Processing chunk 9151/10000\n",
      "Processing chunk 9201/10000\n",
      "Processing chunk 9251/10000\n",
      "Processing chunk 9301/10000\n",
      "Processing chunk 9351/10000\n",
      "Processing chunk 9401/10000\n",
      "Processing chunk 9451/10000\n",
      "Processing chunk 9501/10000\n",
      "Processing chunk 9551/10000\n",
      "Processing chunk 9601/10000\n",
      "Processing chunk 9651/10000\n",
      "Processing chunk 9701/10000\n",
      "Processing chunk 9751/10000\n",
      "Processing chunk 9801/10000\n",
      "Processing chunk 9851/10000\n",
      "Processing chunk 9901/10000\n",
      "Processing chunk 9951/10000\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 10000\n",
      "Number of hits: 8734\n",
      "Average HR@60: 0.8734\n",
      "Average NDCG@60: 0.6871\n",
      "Evaluation completed in 38.63s\n",
      "HR@60: 0.8734\n",
      "NDCG@60: 0.6871\n"
     ]
    }
   ],
   "source": [
    "USR=50000\n",
    "TOP_N=60\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import Linear, Dropout, LayerNorm\n",
    "from torch.nn import functional as F\n",
    "from datetime import datetime\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Define the DMFModel\n",
    "class DMFModel(nn.Module):\n",
    "    def __init__(self, n_users, n_items, embedding_dim=128, behavior_dim=3):\n",
    "        super(DMFModel, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(n_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(n_items, embedding_dim)\n",
    "        self.behavior_fc = nn.Linear(behavior_dim, embedding_dim)\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(embedding_dim * 3, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, users, items, behaviors):\n",
    "        user_embed = self.user_embedding(users)\n",
    "        item_embed = self.item_embedding(items)\n",
    "        behavior_embed = self.behavior_fc(behaviors)\n",
    "        combined = torch.cat([user_embed, item_embed, behavior_embed], dim=1)\n",
    "        return self.fc_layers(combined).squeeze()\n",
    "\n",
    "# Dataset class\n",
    "class MultiBehaviorDataset:\n",
    "    def __init__(self, data_path='/Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/', max_users=10000):\n",
    "        self.data_path = data_path\n",
    "        self.behaviors = ['pv', 'cart', 'buy']\n",
    "        self.trn_file = data_path + 'trn_'\n",
    "        self.tst_file = data_path + 'tst_'\n",
    "        self.max_users = max_users  # Limit number of users\n",
    "        \n",
    "        self.load_training_data()\n",
    "        self.load_test_data()\n",
    "    \n",
    "    def load_training_data(self):\n",
    "        print(\"Loading training data from:\", self.data_path)\n",
    "        self.trn_mats = []\n",
    "        for beh in self.behaviors:\n",
    "            path = self.trn_file + beh\n",
    "            print(f\"Loading behavior: {beh} from {path}\")\n",
    "            if not os.path.exists(path):\n",
    "                raise FileNotFoundError(f\"File not found: {path}\")\n",
    "            with open(path, 'rb') as fs:\n",
    "                mat = pickle.load(fs)\n",
    "                if not isinstance(mat, csr_matrix):\n",
    "                    mat = csr_matrix(mat)\n",
    "                mat = (mat != 0).astype(np.float32)\n",
    "                self.trn_mats.append(mat)\n",
    "        \n",
    "        self.trn_label = 1 * (self.trn_mats[-1] != 0)\n",
    "        self.n_users, self.n_items = self.trn_mats[0].shape\n",
    "        self.n_behaviors = len(self.behaviors)\n",
    "        print(f\"Dataset dimensions: {self.n_users} users, {self.n_items} items\")\n",
    "\n",
    "    def prepare_train_instances(self, max_samples=5000):\n",
    "        \"\"\"Optimized training instance preparation\"\"\"\n",
    "        print(\"Preparing training instances...\")\n",
    "        train_data = []\n",
    "        \n",
    "        # Randomly select users\n",
    "        selected_users = np.random.choice(min(self.n_users, self.max_users), size=min(1000, self.max_users), replace=False)\n",
    "        \n",
    "        for user in selected_users:\n",
    "            pos_items = self.trn_label[user].indices[:2]  # Limit positive items\n",
    "            \n",
    "            if len(pos_items) > 0:\n",
    "                for item in pos_items:\n",
    "                    behaviors = [float(mat[user, item]) for mat in self.trn_mats]\n",
    "                    train_data.append([user, item, 1.0] + behaviors)\n",
    "                    \n",
    "                    # Limited negative sampling\n",
    "                    neg_items = np.random.choice(self.n_items, size=2, replace=False)\n",
    "                    for neg_item in neg_items:\n",
    "                        behaviors = [float(mat[user, neg_item]) for mat in self.trn_mats]\n",
    "                        train_data.append([user, neg_item, 0.0] + behaviors)\n",
    "                        \n",
    "                    if len(train_data) >= max_samples:\n",
    "                        break\n",
    "            \n",
    "            if len(train_data) >= max_samples:\n",
    "                break\n",
    "        \n",
    "        print(f\"Generated {len(train_data)} training instances\")\n",
    "        return np.array(train_data)\n",
    "    \n",
    "    def load_test_data(self):\n",
    "        \"\"\"Load test data\"\"\"\n",
    "        test_path = self.tst_file + 'int'\n",
    "        print(f\"Loading test data from: {test_path}\")\n",
    "        if not os.path.exists(test_path):\n",
    "            raise FileNotFoundError(f\"File not found: {test_path}\")\n",
    "        with open(test_path, 'rb') as fs:\n",
    "            self.tst_int = np.array(pickle.load(fs))\n",
    "        \n",
    "        self.tst_users = np.reshape(np.argwhere(self.tst_int != None), [-1])\n",
    "        # Limit test users for faster processing\n",
    "        self.tst_users = self.tst_users[:min(len(self.tst_users), self.max_users)]\n",
    "        print(f\"Using {len(self.tst_users)} test users\")\n",
    "\n",
    "    def get_test_instances(self, num_neg_samples=99):\n",
    "        \"\"\"Generate test instances with negative sampling\"\"\"\n",
    "        print(\"Preparing test instances...\")\n",
    "        test_instances = []\n",
    "        \n",
    "        for user in self.tst_users:\n",
    "            pos_item = self.tst_int[user]\n",
    "            if pos_item is not None:\n",
    "                # Add positive instance\n",
    "                test_instances.append([user, pos_item, 1.0])\n",
    "                \n",
    "                # Add negative instances\n",
    "                try:\n",
    "                    # Get all items and remove positive items\n",
    "                    all_items = set(range(self.n_items))\n",
    "                    pos_items_train = set(self.trn_label[user].indices)\n",
    "                    pos_items_train.add(pos_item)\n",
    "                    neg_items_pool = list(all_items - pos_items_train)\n",
    "                    \n",
    "                    # Sample negative items\n",
    "                    n_neg = min(num_neg_samples, len(neg_items_pool))\n",
    "                    if n_neg > 0:\n",
    "                        neg_items = np.random.choice(neg_items_pool, size=n_neg, replace=False)\n",
    "                        for neg_item in neg_items:\n",
    "                            test_instances.append([user, neg_item, 0.0])\n",
    "            \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing test user {user}: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "        if not test_instances:\n",
    "            raise ValueError(\"No test instances were generated!\")\n",
    "        \n",
    "        test_instances = np.array(test_instances)\n",
    "        print(f\"Generated {len(test_instances)} test instances\")\n",
    "        return test_instances\n",
    "\n",
    "def evaluate_model(model, dataset, test_instances, k=10):\n",
    "    \"\"\"Improved evaluation function with better metrics calculation\"\"\"\n",
    "    model.eval()\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    \n",
    "    # Process test instances in smaller chunks\n",
    "    chunk_size = 100\n",
    "    test_chunks = [test_instances[i:i + chunk_size] for i in range(0, len(test_instances), chunk_size)]\n",
    "    \n",
    "    print(f\"Evaluating {len(test_instances)} instances in {len(test_chunks)} chunks...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for chunk_idx, chunk in enumerate(test_chunks):\n",
    "            if chunk_idx % 50 == 0:  # Reduced frequency of progress updates\n",
    "                print(f\"Processing chunk {chunk_idx + 1}/{len(test_chunks)}\")\n",
    "            \n",
    "            # Group by user and ensure we have both positive and negative items\n",
    "            user_items = {}\n",
    "            for inst in chunk:\n",
    "                user = int(inst[0])\n",
    "                item = int(inst[1])\n",
    "                label = float(inst[2])\n",
    "                \n",
    "                if user not in user_items:\n",
    "                    user_items[user] = {'pos': [], 'neg': [], 'all_items': [], 'all_scores': []}\n",
    "                \n",
    "                user_items[user]['all_items'].append(item)\n",
    "                if label > 0.5:\n",
    "                    user_items[user]['pos'].append(item)\n",
    "                else:\n",
    "                    user_items[user]['neg'].append(item)\n",
    "            \n",
    "            # Process each user that has both positive and negative items\n",
    "            for user, data in user_items.items():\n",
    "                if not data['pos'] or not data['neg']:\n",
    "                    continue\n",
    "                \n",
    "                items = data['all_items']\n",
    "                batch_size = len(items)\n",
    "                \n",
    "                # Create input features\n",
    "                behaviors = torch.zeros(batch_size, dataset.n_behaviors, device=device)\n",
    "                for i, item in enumerate(items):\n",
    "                    for j, mat in enumerate(dataset.trn_mats):\n",
    "                        behaviors[i, j] = float(mat[user, item])\n",
    "                \n",
    "                # Convert user and item indices to LongTensor\n",
    "                user_tensor = torch.LongTensor([user] * batch_size).to(device)\n",
    "                item_tensor = torch.LongTensor(items).to(device)\n",
    "\n",
    "                # Get predictions\n",
    "                predictions = model(user_tensor, item_tensor, behaviors)\n",
    "                predictions = torch.sigmoid(predictions).cpu().numpy().flatten()\n",
    "                \n",
    "                # Store all scores\n",
    "                for item, score in zip(items, predictions):\n",
    "                    data['all_scores'].append((item, score))\n",
    "                \n",
    "                # Sort items by score\n",
    "                sorted_items = [x[0] for x in sorted(data['all_scores'], key=lambda x: x[1], reverse=True)]\n",
    "                recommended_items = sorted_items[:k]\n",
    "                \n",
    "                # Calculate HR\n",
    "                hit = any(pos_item in recommended_items for pos_item in data['pos'])\n",
    "                hits.append(hit)\n",
    "                \n",
    "                # Calculate NDCG\n",
    "                dcg = 0\n",
    "                for i, item in enumerate(recommended_items):\n",
    "                    if item in data['pos']:\n",
    "                        dcg += 1 / np.log2(i + 2)\n",
    "                \n",
    "                idcg = sum(1 / np.log2(i + 2) for i in range(len(data['pos'])))\n",
    "                ndcg = dcg / idcg if idcg > 0 else 0\n",
    "                ndcgs.append(ndcg)\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    hr = np.mean(hits) if hits else 0\n",
    "    ndcg = np.mean(ndcgs) if ndcgs else 0\n",
    "    \n",
    "    # Print detailed statistics\n",
    "    print(f\"\\nEvaluation Statistics:\")\n",
    "    print(f\"Total users evaluated: {len(hits)}\")\n",
    "    print(f\"Number of hits: {sum(hits)}\")\n",
    "    print(f\"Average HR@{k}: {hr:.4f}\")\n",
    "    print(f\"Average NDCG@{k}: {ndcg:.4f}\")\n",
    "    \n",
    "    return hr, ndcg\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Configuration\n",
    "    config = {\n",
    "        'embedding_dim': 128,\n",
    "        'behavior_dim': 3,\n",
    "        'learning_rate': 0.001,\n",
    "        'weight_decay': 1e-6,\n",
    "        'dropout': 0.1,\n",
    "        'gradient_clip': 1.0,\n",
    "        'max_samples': USR,\n",
    "        'eval_k': TOP_N\n",
    "    }\n",
    "    \n",
    "    print(\"Initializing dataset...\")\n",
    "    dataset = MultiBehaviorDataset(max_users=USR)\n",
    "    train_data = dataset.prepare_train_instances(max_samples=config['max_samples'])\n",
    "    \n",
    "    print(f\"Using {len(train_data)} training instances\")\n",
    "\n",
    "    # Initialize DMFModel\n",
    "    model = DMFModel(\n",
    "        n_users=dataset.n_users,\n",
    "        n_items=dataset.n_items,\n",
    "        embedding_dim=config['embedding_dim'],\n",
    "        behavior_dim=config['behavior_dim']\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
    "\n",
    "    print(\"Preparing training tensors...\")\n",
    "    users = torch.LongTensor(train_data[:, 0]).to(device)\n",
    "    items = torch.LongTensor(train_data[:, 1]).to(device)\n",
    "    labels = torch.FloatTensor(train_data[:, 2]).to(device)\n",
    "    behaviors = torch.FloatTensor(train_data[:, 3:]).to(device)\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    try:\n",
    "        model.train()\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        # Training\n",
    "        for epoch in range(10):  # Adjust the number of epochs\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            predictions = model(users, items, behaviors)\n",
    "            loss = criterion(predictions, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), config['gradient_clip'])\n",
    "            optimizer.step()\n",
    "            \n",
    "            print(f\"Epoch {epoch + 1}, Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        training_time = (datetime.now() - start_time).total_seconds()\n",
    "        print(f\"Training completed in {training_time:.2f}s\")\n",
    "        \n",
    "        # Evaluation\n",
    "        print(\"\\nStarting evaluation...\")\n",
    "        eval_start_time = datetime.now()\n",
    "        \n",
    "        test_instances = dataset.get_test_instances()\n",
    "        hr, ndcg = evaluate_model(model, dataset, test_instances, k=config['eval_k'])\n",
    "        \n",
    "        eval_time = (datetime.now() - eval_start_time).total_seconds()\n",
    "        print(f\"Evaluation completed in {eval_time:.2f}s\")\n",
    "        print(f\"HR@{config['eval_k']}: {hr:.4f}\")\n",
    "        print(f\"NDCG@{config['eval_k']}: {ndcg:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during training: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CDAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing dataset...\n",
      "Loading training data from: /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/\n",
      "Loading behavior: pv from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_pv\n",
      "Loading behavior: cart from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_cart\n",
      "Loading behavior: buy from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_buy\n",
      "Dataset dimensions: 21716 users, 7977 items\n",
      "Loading test data from: /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/tst_int\n",
      "Using 10000 test users\n",
      "Preparing training instances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yf/20z1hn994jd04q4kl0gpgh740000gn/T/ipykernel_61723/4284113255.py:61: DeprecationWarning: Please import `csr_matrix` from the `scipy.sparse` namespace; the `scipy.sparse.csr` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  mat = pickle.load(fs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 6000 training instances\n",
      "Using 6000 training instances\n",
      "Preparing training tensors...\n",
      "Starting training...\n",
      "Training completed in 0.59s\n",
      "Training loss: 0.5950\n",
      "\n",
      "Starting evaluation...\n",
      "Preparing test instances...\n",
      "Generated 1000000 test instances\n",
      "Evaluating 1000000 instances in 33334 chunks...\n",
      "Processing chunk 1/33334\n",
      "Processing chunk 51/33334\n",
      "Processing chunk 101/33334\n",
      "Processing chunk 151/33334\n",
      "Processing chunk 201/33334\n",
      "Processing chunk 251/33334\n",
      "Processing chunk 301/33334\n",
      "Processing chunk 351/33334\n",
      "Processing chunk 401/33334\n",
      "Processing chunk 451/33334\n",
      "Processing chunk 501/33334\n",
      "Processing chunk 551/33334\n",
      "Processing chunk 601/33334\n",
      "Processing chunk 651/33334\n",
      "Processing chunk 701/33334\n",
      "Processing chunk 751/33334\n",
      "Processing chunk 801/33334\n",
      "Processing chunk 851/33334\n",
      "Processing chunk 901/33334\n",
      "Processing chunk 951/33334\n",
      "Processing chunk 1001/33334\n",
      "Processing chunk 1051/33334\n",
      "Processing chunk 1101/33334\n",
      "Processing chunk 1151/33334\n",
      "Processing chunk 1201/33334\n",
      "Processing chunk 1251/33334\n",
      "Processing chunk 1301/33334\n",
      "Processing chunk 1351/33334\n",
      "Processing chunk 1401/33334\n",
      "Processing chunk 1451/33334\n",
      "Processing chunk 1501/33334\n",
      "Processing chunk 1551/33334\n",
      "Processing chunk 1601/33334\n",
      "Processing chunk 1651/33334\n",
      "Processing chunk 1701/33334\n",
      "Processing chunk 1751/33334\n",
      "Processing chunk 1801/33334\n",
      "Processing chunk 1851/33334\n",
      "Processing chunk 1901/33334\n",
      "Processing chunk 1951/33334\n",
      "Processing chunk 2001/33334\n",
      "Processing chunk 2051/33334\n",
      "Processing chunk 2101/33334\n",
      "Processing chunk 2151/33334\n",
      "Processing chunk 2201/33334\n",
      "Processing chunk 2251/33334\n",
      "Processing chunk 2301/33334\n",
      "Processing chunk 2351/33334\n",
      "Processing chunk 2401/33334\n",
      "Processing chunk 2451/33334\n",
      "Processing chunk 2501/33334\n",
      "Processing chunk 2551/33334\n",
      "Processing chunk 2601/33334\n",
      "Processing chunk 2651/33334\n",
      "Processing chunk 2701/33334\n",
      "Processing chunk 2751/33334\n",
      "Processing chunk 2801/33334\n",
      "Processing chunk 2851/33334\n",
      "Processing chunk 2901/33334\n",
      "Processing chunk 2951/33334\n",
      "Processing chunk 3001/33334\n",
      "Processing chunk 3051/33334\n",
      "Processing chunk 3101/33334\n",
      "Processing chunk 3151/33334\n",
      "Processing chunk 3201/33334\n",
      "Processing chunk 3251/33334\n",
      "Processing chunk 3301/33334\n",
      "Processing chunk 3351/33334\n",
      "Processing chunk 3401/33334\n",
      "Processing chunk 3451/33334\n",
      "Processing chunk 3501/33334\n",
      "Processing chunk 3551/33334\n",
      "Processing chunk 3601/33334\n",
      "Processing chunk 3651/33334\n",
      "Processing chunk 3701/33334\n",
      "Processing chunk 3751/33334\n",
      "Processing chunk 3801/33334\n",
      "Processing chunk 3851/33334\n",
      "Processing chunk 3901/33334\n",
      "Processing chunk 3951/33334\n",
      "Processing chunk 4001/33334\n",
      "Processing chunk 4051/33334\n",
      "Processing chunk 4101/33334\n",
      "Processing chunk 4151/33334\n",
      "Processing chunk 4201/33334\n",
      "Processing chunk 4251/33334\n",
      "Processing chunk 4301/33334\n",
      "Processing chunk 4351/33334\n",
      "Processing chunk 4401/33334\n",
      "Processing chunk 4451/33334\n",
      "Processing chunk 4501/33334\n",
      "Processing chunk 4551/33334\n",
      "Processing chunk 4601/33334\n",
      "Processing chunk 4651/33334\n",
      "Processing chunk 4701/33334\n",
      "Processing chunk 4751/33334\n",
      "Processing chunk 4801/33334\n",
      "Processing chunk 4851/33334\n",
      "Processing chunk 4901/33334\n",
      "Processing chunk 4951/33334\n",
      "Processing chunk 5001/33334\n",
      "Processing chunk 5051/33334\n",
      "Processing chunk 5101/33334\n",
      "Processing chunk 5151/33334\n",
      "Processing chunk 5201/33334\n",
      "Processing chunk 5251/33334\n",
      "Processing chunk 5301/33334\n",
      "Processing chunk 5351/33334\n",
      "Processing chunk 5401/33334\n",
      "Processing chunk 5451/33334\n",
      "Processing chunk 5501/33334\n",
      "Processing chunk 5551/33334\n",
      "Processing chunk 5601/33334\n",
      "Processing chunk 5651/33334\n",
      "Processing chunk 5701/33334\n",
      "Processing chunk 5751/33334\n",
      "Processing chunk 5801/33334\n",
      "Processing chunk 5851/33334\n",
      "Processing chunk 5901/33334\n",
      "Processing chunk 5951/33334\n",
      "Processing chunk 6001/33334\n",
      "Processing chunk 6051/33334\n",
      "Processing chunk 6101/33334\n",
      "Processing chunk 6151/33334\n",
      "Processing chunk 6201/33334\n",
      "Processing chunk 6251/33334\n",
      "Processing chunk 6301/33334\n",
      "Processing chunk 6351/33334\n",
      "Processing chunk 6401/33334\n",
      "Processing chunk 6451/33334\n",
      "Processing chunk 6501/33334\n",
      "Processing chunk 6551/33334\n",
      "Processing chunk 6601/33334\n",
      "Processing chunk 6651/33334\n",
      "Processing chunk 6701/33334\n",
      "Processing chunk 6751/33334\n",
      "Processing chunk 6801/33334\n",
      "Processing chunk 6851/33334\n",
      "Processing chunk 6901/33334\n",
      "Processing chunk 6951/33334\n",
      "Processing chunk 7001/33334\n",
      "Processing chunk 7051/33334\n",
      "Processing chunk 7101/33334\n",
      "Processing chunk 7151/33334\n",
      "Processing chunk 7201/33334\n",
      "Processing chunk 7251/33334\n",
      "Processing chunk 7301/33334\n",
      "Processing chunk 7351/33334\n",
      "Processing chunk 7401/33334\n",
      "Processing chunk 7451/33334\n",
      "Processing chunk 7501/33334\n",
      "Processing chunk 7551/33334\n",
      "Processing chunk 7601/33334\n",
      "Processing chunk 7651/33334\n",
      "Processing chunk 7701/33334\n",
      "Processing chunk 7751/33334\n",
      "Processing chunk 7801/33334\n",
      "Processing chunk 7851/33334\n",
      "Processing chunk 7901/33334\n",
      "Processing chunk 7951/33334\n",
      "Processing chunk 8001/33334\n",
      "Processing chunk 8051/33334\n",
      "Processing chunk 8101/33334\n",
      "Processing chunk 8151/33334\n",
      "Processing chunk 8201/33334\n",
      "Processing chunk 8251/33334\n",
      "Processing chunk 8301/33334\n",
      "Processing chunk 8351/33334\n",
      "Processing chunk 8401/33334\n",
      "Processing chunk 8451/33334\n",
      "Processing chunk 8501/33334\n",
      "Processing chunk 8551/33334\n",
      "Processing chunk 8601/33334\n",
      "Processing chunk 8651/33334\n",
      "Processing chunk 8701/33334\n",
      "Processing chunk 8751/33334\n",
      "Processing chunk 8801/33334\n",
      "Processing chunk 8851/33334\n",
      "Processing chunk 8901/33334\n",
      "Processing chunk 8951/33334\n",
      "Processing chunk 9001/33334\n",
      "Processing chunk 9051/33334\n",
      "Processing chunk 9101/33334\n",
      "Processing chunk 9151/33334\n",
      "Processing chunk 9201/33334\n",
      "Processing chunk 9251/33334\n",
      "Processing chunk 9301/33334\n",
      "Processing chunk 9351/33334\n",
      "Processing chunk 9401/33334\n",
      "Processing chunk 9451/33334\n",
      "Processing chunk 9501/33334\n",
      "Processing chunk 9551/33334\n",
      "Processing chunk 9601/33334\n",
      "Processing chunk 9651/33334\n",
      "Processing chunk 9701/33334\n",
      "Processing chunk 9751/33334\n",
      "Processing chunk 9801/33334\n",
      "Processing chunk 9851/33334\n",
      "Processing chunk 9901/33334\n",
      "Processing chunk 9951/33334\n",
      "Processing chunk 10001/33334\n",
      "Processing chunk 10051/33334\n",
      "Processing chunk 10101/33334\n",
      "Processing chunk 10151/33334\n",
      "Processing chunk 10201/33334\n",
      "Processing chunk 10251/33334\n",
      "Processing chunk 10301/33334\n",
      "Processing chunk 10351/33334\n",
      "Processing chunk 10401/33334\n",
      "Processing chunk 10451/33334\n",
      "Processing chunk 10501/33334\n",
      "Processing chunk 10551/33334\n",
      "Processing chunk 10601/33334\n",
      "Processing chunk 10651/33334\n",
      "Processing chunk 10701/33334\n",
      "Processing chunk 10751/33334\n",
      "Processing chunk 10801/33334\n",
      "Processing chunk 10851/33334\n",
      "Processing chunk 10901/33334\n",
      "Processing chunk 10951/33334\n",
      "Processing chunk 11001/33334\n",
      "Processing chunk 11051/33334\n",
      "Processing chunk 11101/33334\n",
      "Processing chunk 11151/33334\n",
      "Processing chunk 11201/33334\n",
      "Processing chunk 11251/33334\n",
      "Processing chunk 11301/33334\n",
      "Processing chunk 11351/33334\n",
      "Processing chunk 11401/33334\n",
      "Processing chunk 11451/33334\n",
      "Processing chunk 11501/33334\n",
      "Processing chunk 11551/33334\n",
      "Processing chunk 11601/33334\n",
      "Processing chunk 11651/33334\n",
      "Processing chunk 11701/33334\n",
      "Processing chunk 11751/33334\n",
      "Processing chunk 11801/33334\n",
      "Processing chunk 11851/33334\n",
      "Processing chunk 11901/33334\n",
      "Processing chunk 11951/33334\n",
      "Processing chunk 12001/33334\n",
      "Processing chunk 12051/33334\n",
      "Processing chunk 12101/33334\n",
      "Processing chunk 12151/33334\n",
      "Processing chunk 12201/33334\n",
      "Processing chunk 12251/33334\n",
      "Processing chunk 12301/33334\n",
      "Processing chunk 12351/33334\n",
      "Processing chunk 12401/33334\n",
      "Processing chunk 12451/33334\n",
      "Processing chunk 12501/33334\n",
      "Processing chunk 12551/33334\n",
      "Processing chunk 12601/33334\n",
      "Processing chunk 12651/33334\n",
      "Processing chunk 12701/33334\n",
      "Processing chunk 12751/33334\n",
      "Processing chunk 12801/33334\n",
      "Processing chunk 12851/33334\n",
      "Processing chunk 12901/33334\n",
      "Processing chunk 12951/33334\n",
      "Processing chunk 13001/33334\n",
      "Processing chunk 13051/33334\n",
      "Processing chunk 13101/33334\n",
      "Processing chunk 13151/33334\n",
      "Processing chunk 13201/33334\n",
      "Processing chunk 13251/33334\n",
      "Processing chunk 13301/33334\n",
      "Processing chunk 13351/33334\n",
      "Processing chunk 13401/33334\n",
      "Processing chunk 13451/33334\n",
      "Processing chunk 13501/33334\n",
      "Processing chunk 13551/33334\n",
      "Processing chunk 13601/33334\n",
      "Processing chunk 13651/33334\n",
      "Processing chunk 13701/33334\n",
      "Processing chunk 13751/33334\n",
      "Processing chunk 13801/33334\n",
      "Processing chunk 13851/33334\n",
      "Processing chunk 13901/33334\n",
      "Processing chunk 13951/33334\n",
      "Processing chunk 14001/33334\n",
      "Processing chunk 14051/33334\n",
      "Processing chunk 14101/33334\n",
      "Processing chunk 14151/33334\n",
      "Processing chunk 14201/33334\n",
      "Processing chunk 14251/33334\n",
      "Processing chunk 14301/33334\n",
      "Processing chunk 14351/33334\n",
      "Processing chunk 14401/33334\n",
      "Processing chunk 14451/33334\n",
      "Processing chunk 14501/33334\n",
      "Processing chunk 14551/33334\n",
      "Processing chunk 14601/33334\n",
      "Processing chunk 14651/33334\n",
      "Processing chunk 14701/33334\n",
      "Processing chunk 14751/33334\n",
      "Processing chunk 14801/33334\n",
      "Processing chunk 14851/33334\n",
      "Processing chunk 14901/33334\n",
      "Processing chunk 14951/33334\n",
      "Processing chunk 15001/33334\n",
      "Processing chunk 15051/33334\n",
      "Processing chunk 15101/33334\n",
      "Processing chunk 15151/33334\n",
      "Processing chunk 15201/33334\n",
      "Processing chunk 15251/33334\n",
      "Processing chunk 15301/33334\n",
      "Processing chunk 15351/33334\n",
      "Processing chunk 15401/33334\n",
      "Processing chunk 15451/33334\n",
      "Processing chunk 15501/33334\n",
      "Processing chunk 15551/33334\n",
      "Processing chunk 15601/33334\n",
      "Processing chunk 15651/33334\n",
      "Processing chunk 15701/33334\n",
      "Processing chunk 15751/33334\n",
      "Processing chunk 15801/33334\n",
      "Processing chunk 15851/33334\n",
      "Processing chunk 15901/33334\n",
      "Processing chunk 15951/33334\n",
      "Processing chunk 16001/33334\n",
      "Processing chunk 16051/33334\n",
      "Processing chunk 16101/33334\n",
      "Processing chunk 16151/33334\n",
      "Processing chunk 16201/33334\n",
      "Processing chunk 16251/33334\n",
      "Processing chunk 16301/33334\n",
      "Processing chunk 16351/33334\n",
      "Processing chunk 16401/33334\n",
      "Processing chunk 16451/33334\n",
      "Processing chunk 16501/33334\n",
      "Processing chunk 16551/33334\n",
      "Processing chunk 16601/33334\n",
      "Processing chunk 16651/33334\n",
      "Processing chunk 16701/33334\n",
      "Processing chunk 16751/33334\n",
      "Processing chunk 16801/33334\n",
      "Processing chunk 16851/33334\n",
      "Processing chunk 16901/33334\n",
      "Processing chunk 16951/33334\n",
      "Processing chunk 17001/33334\n",
      "Processing chunk 17051/33334\n",
      "Processing chunk 17101/33334\n",
      "Processing chunk 17151/33334\n",
      "Processing chunk 17201/33334\n",
      "Processing chunk 17251/33334\n",
      "Processing chunk 17301/33334\n",
      "Processing chunk 17351/33334\n",
      "Processing chunk 17401/33334\n",
      "Processing chunk 17451/33334\n",
      "Processing chunk 17501/33334\n",
      "Processing chunk 17551/33334\n",
      "Processing chunk 17601/33334\n",
      "Processing chunk 17651/33334\n",
      "Processing chunk 17701/33334\n",
      "Processing chunk 17751/33334\n",
      "Processing chunk 17801/33334\n",
      "Processing chunk 17851/33334\n",
      "Processing chunk 17901/33334\n",
      "Processing chunk 17951/33334\n",
      "Processing chunk 18001/33334\n",
      "Processing chunk 18051/33334\n",
      "Processing chunk 18101/33334\n",
      "Processing chunk 18151/33334\n",
      "Processing chunk 18201/33334\n",
      "Processing chunk 18251/33334\n",
      "Processing chunk 18301/33334\n",
      "Processing chunk 18351/33334\n",
      "Processing chunk 18401/33334\n",
      "Processing chunk 18451/33334\n",
      "Processing chunk 18501/33334\n",
      "Processing chunk 18551/33334\n",
      "Processing chunk 18601/33334\n",
      "Processing chunk 18651/33334\n",
      "Processing chunk 18701/33334\n",
      "Processing chunk 18751/33334\n",
      "Processing chunk 18801/33334\n",
      "Processing chunk 18851/33334\n",
      "Processing chunk 18901/33334\n",
      "Processing chunk 18951/33334\n",
      "Processing chunk 19001/33334\n",
      "Processing chunk 19051/33334\n",
      "Processing chunk 19101/33334\n",
      "Processing chunk 19151/33334\n",
      "Processing chunk 19201/33334\n",
      "Processing chunk 19251/33334\n",
      "Processing chunk 19301/33334\n",
      "Processing chunk 19351/33334\n",
      "Processing chunk 19401/33334\n",
      "Processing chunk 19451/33334\n",
      "Processing chunk 19501/33334\n",
      "Processing chunk 19551/33334\n",
      "Processing chunk 19601/33334\n",
      "Processing chunk 19651/33334\n",
      "Processing chunk 19701/33334\n",
      "Processing chunk 19751/33334\n",
      "Processing chunk 19801/33334\n",
      "Processing chunk 19851/33334\n",
      "Processing chunk 19901/33334\n",
      "Processing chunk 19951/33334\n",
      "Processing chunk 20001/33334\n",
      "Processing chunk 20051/33334\n",
      "Processing chunk 20101/33334\n",
      "Processing chunk 20151/33334\n",
      "Processing chunk 20201/33334\n",
      "Processing chunk 20251/33334\n",
      "Processing chunk 20301/33334\n",
      "Processing chunk 20351/33334\n",
      "Processing chunk 20401/33334\n",
      "Processing chunk 20451/33334\n",
      "Processing chunk 20501/33334\n",
      "Processing chunk 20551/33334\n",
      "Processing chunk 20601/33334\n",
      "Processing chunk 20651/33334\n",
      "Processing chunk 20701/33334\n",
      "Processing chunk 20751/33334\n",
      "Processing chunk 20801/33334\n",
      "Processing chunk 20851/33334\n",
      "Processing chunk 20901/33334\n",
      "Processing chunk 20951/33334\n",
      "Processing chunk 21001/33334\n",
      "Processing chunk 21051/33334\n",
      "Processing chunk 21101/33334\n",
      "Processing chunk 21151/33334\n",
      "Processing chunk 21201/33334\n",
      "Processing chunk 21251/33334\n",
      "Processing chunk 21301/33334\n",
      "Processing chunk 21351/33334\n",
      "Processing chunk 21401/33334\n",
      "Processing chunk 21451/33334\n",
      "Processing chunk 21501/33334\n",
      "Processing chunk 21551/33334\n",
      "Processing chunk 21601/33334\n",
      "Processing chunk 21651/33334\n",
      "Processing chunk 21701/33334\n",
      "Processing chunk 21751/33334\n",
      "Processing chunk 21801/33334\n",
      "Processing chunk 21851/33334\n",
      "Processing chunk 21901/33334\n",
      "Processing chunk 21951/33334\n",
      "Processing chunk 22001/33334\n",
      "Processing chunk 22051/33334\n",
      "Processing chunk 22101/33334\n",
      "Processing chunk 22151/33334\n",
      "Processing chunk 22201/33334\n",
      "Processing chunk 22251/33334\n",
      "Processing chunk 22301/33334\n",
      "Processing chunk 22351/33334\n",
      "Processing chunk 22401/33334\n",
      "Processing chunk 22451/33334\n",
      "Processing chunk 22501/33334\n",
      "Processing chunk 22551/33334\n",
      "Processing chunk 22601/33334\n",
      "Processing chunk 22651/33334\n",
      "Processing chunk 22701/33334\n",
      "Processing chunk 22751/33334\n",
      "Processing chunk 22801/33334\n",
      "Processing chunk 22851/33334\n",
      "Processing chunk 22901/33334\n",
      "Processing chunk 22951/33334\n",
      "Processing chunk 23001/33334\n",
      "Processing chunk 23051/33334\n",
      "Processing chunk 23101/33334\n",
      "Processing chunk 23151/33334\n",
      "Processing chunk 23201/33334\n",
      "Processing chunk 23251/33334\n",
      "Processing chunk 23301/33334\n",
      "Processing chunk 23351/33334\n",
      "Processing chunk 23401/33334\n",
      "Processing chunk 23451/33334\n",
      "Processing chunk 23501/33334\n",
      "Processing chunk 23551/33334\n",
      "Processing chunk 23601/33334\n",
      "Processing chunk 23651/33334\n",
      "Processing chunk 23701/33334\n",
      "Processing chunk 23751/33334\n",
      "Processing chunk 23801/33334\n",
      "Processing chunk 23851/33334\n",
      "Processing chunk 23901/33334\n",
      "Processing chunk 23951/33334\n",
      "Processing chunk 24001/33334\n",
      "Processing chunk 24051/33334\n",
      "Processing chunk 24101/33334\n",
      "Processing chunk 24151/33334\n",
      "Processing chunk 24201/33334\n",
      "Processing chunk 24251/33334\n",
      "Processing chunk 24301/33334\n",
      "Processing chunk 24351/33334\n",
      "Processing chunk 24401/33334\n",
      "Processing chunk 24451/33334\n",
      "Processing chunk 24501/33334\n",
      "Processing chunk 24551/33334\n",
      "Processing chunk 24601/33334\n",
      "Processing chunk 24651/33334\n",
      "Processing chunk 24701/33334\n",
      "Processing chunk 24751/33334\n",
      "Processing chunk 24801/33334\n",
      "Processing chunk 24851/33334\n",
      "Processing chunk 24901/33334\n",
      "Processing chunk 24951/33334\n",
      "Processing chunk 25001/33334\n",
      "Processing chunk 25051/33334\n",
      "Processing chunk 25101/33334\n",
      "Processing chunk 25151/33334\n",
      "Processing chunk 25201/33334\n",
      "Processing chunk 25251/33334\n",
      "Processing chunk 25301/33334\n",
      "Processing chunk 25351/33334\n",
      "Processing chunk 25401/33334\n",
      "Processing chunk 25451/33334\n",
      "Processing chunk 25501/33334\n",
      "Processing chunk 25551/33334\n",
      "Processing chunk 25601/33334\n",
      "Processing chunk 25651/33334\n",
      "Processing chunk 25701/33334\n",
      "Processing chunk 25751/33334\n",
      "Processing chunk 25801/33334\n",
      "Processing chunk 25851/33334\n",
      "Processing chunk 25901/33334\n",
      "Processing chunk 25951/33334\n",
      "Processing chunk 26001/33334\n",
      "Processing chunk 26051/33334\n",
      "Processing chunk 26101/33334\n",
      "Processing chunk 26151/33334\n",
      "Processing chunk 26201/33334\n",
      "Processing chunk 26251/33334\n",
      "Processing chunk 26301/33334\n",
      "Processing chunk 26351/33334\n",
      "Processing chunk 26401/33334\n",
      "Processing chunk 26451/33334\n",
      "Processing chunk 26501/33334\n",
      "Processing chunk 26551/33334\n",
      "Processing chunk 26601/33334\n",
      "Processing chunk 26651/33334\n",
      "Processing chunk 26701/33334\n",
      "Processing chunk 26751/33334\n",
      "Processing chunk 26801/33334\n",
      "Processing chunk 26851/33334\n",
      "Processing chunk 26901/33334\n",
      "Processing chunk 26951/33334\n",
      "Processing chunk 27001/33334\n",
      "Processing chunk 27051/33334\n",
      "Processing chunk 27101/33334\n",
      "Processing chunk 27151/33334\n",
      "Processing chunk 27201/33334\n",
      "Processing chunk 27251/33334\n",
      "Processing chunk 27301/33334\n",
      "Processing chunk 27351/33334\n",
      "Processing chunk 27401/33334\n",
      "Processing chunk 27451/33334\n",
      "Processing chunk 27501/33334\n",
      "Processing chunk 27551/33334\n",
      "Processing chunk 27601/33334\n",
      "Processing chunk 27651/33334\n",
      "Processing chunk 27701/33334\n",
      "Processing chunk 27751/33334\n",
      "Processing chunk 27801/33334\n",
      "Processing chunk 27851/33334\n",
      "Processing chunk 27901/33334\n",
      "Processing chunk 27951/33334\n",
      "Processing chunk 28001/33334\n",
      "Processing chunk 28051/33334\n",
      "Processing chunk 28101/33334\n",
      "Processing chunk 28151/33334\n",
      "Processing chunk 28201/33334\n",
      "Processing chunk 28251/33334\n",
      "Processing chunk 28301/33334\n",
      "Processing chunk 28351/33334\n",
      "Processing chunk 28401/33334\n",
      "Processing chunk 28451/33334\n",
      "Processing chunk 28501/33334\n",
      "Processing chunk 28551/33334\n",
      "Processing chunk 28601/33334\n",
      "Processing chunk 28651/33334\n",
      "Processing chunk 28701/33334\n",
      "Processing chunk 28751/33334\n",
      "Processing chunk 28801/33334\n",
      "Processing chunk 28851/33334\n",
      "Processing chunk 28901/33334\n",
      "Processing chunk 28951/33334\n",
      "Processing chunk 29001/33334\n",
      "Processing chunk 29051/33334\n",
      "Processing chunk 29101/33334\n",
      "Processing chunk 29151/33334\n",
      "Processing chunk 29201/33334\n",
      "Processing chunk 29251/33334\n",
      "Processing chunk 29301/33334\n",
      "Processing chunk 29351/33334\n",
      "Processing chunk 29401/33334\n",
      "Processing chunk 29451/33334\n",
      "Processing chunk 29501/33334\n",
      "Processing chunk 29551/33334\n",
      "Processing chunk 29601/33334\n",
      "Processing chunk 29651/33334\n",
      "Processing chunk 29701/33334\n",
      "Processing chunk 29751/33334\n",
      "Processing chunk 29801/33334\n",
      "Processing chunk 29851/33334\n",
      "Processing chunk 29901/33334\n",
      "Processing chunk 29951/33334\n",
      "Processing chunk 30001/33334\n",
      "Processing chunk 30051/33334\n",
      "Processing chunk 30101/33334\n",
      "Processing chunk 30151/33334\n",
      "Processing chunk 30201/33334\n",
      "Processing chunk 30251/33334\n",
      "Processing chunk 30301/33334\n",
      "Processing chunk 30351/33334\n",
      "Processing chunk 30401/33334\n",
      "Processing chunk 30451/33334\n",
      "Processing chunk 30501/33334\n",
      "Processing chunk 30551/33334\n",
      "Processing chunk 30601/33334\n",
      "Processing chunk 30651/33334\n",
      "Processing chunk 30701/33334\n",
      "Processing chunk 30751/33334\n",
      "Processing chunk 30801/33334\n",
      "Processing chunk 30851/33334\n",
      "Processing chunk 30901/33334\n",
      "Processing chunk 30951/33334\n",
      "Processing chunk 31001/33334\n",
      "Processing chunk 31051/33334\n",
      "Processing chunk 31101/33334\n",
      "Processing chunk 31151/33334\n",
      "Processing chunk 31201/33334\n",
      "Processing chunk 31251/33334\n",
      "Processing chunk 31301/33334\n",
      "Processing chunk 31351/33334\n",
      "Processing chunk 31401/33334\n",
      "Processing chunk 31451/33334\n",
      "Processing chunk 31501/33334\n",
      "Processing chunk 31551/33334\n",
      "Processing chunk 31601/33334\n",
      "Processing chunk 31651/33334\n",
      "Processing chunk 31701/33334\n",
      "Processing chunk 31751/33334\n",
      "Processing chunk 31801/33334\n",
      "Processing chunk 31851/33334\n",
      "Processing chunk 31901/33334\n",
      "Processing chunk 31951/33334\n",
      "Processing chunk 32001/33334\n",
      "Processing chunk 32051/33334\n",
      "Processing chunk 32101/33334\n",
      "Processing chunk 32151/33334\n",
      "Processing chunk 32201/33334\n",
      "Processing chunk 32251/33334\n",
      "Processing chunk 32301/33334\n",
      "Processing chunk 32351/33334\n",
      "Processing chunk 32401/33334\n",
      "Processing chunk 32451/33334\n",
      "Processing chunk 32501/33334\n",
      "Processing chunk 32551/33334\n",
      "Processing chunk 32601/33334\n",
      "Processing chunk 32651/33334\n",
      "Processing chunk 32701/33334\n",
      "Processing chunk 32751/33334\n",
      "Processing chunk 32801/33334\n",
      "Processing chunk 32851/33334\n",
      "Processing chunk 32901/33334\n",
      "Processing chunk 32951/33334\n",
      "Processing chunk 33001/33334\n",
      "Processing chunk 33051/33334\n",
      "Processing chunk 33101/33334\n",
      "Processing chunk 33151/33334\n",
      "Processing chunk 33201/33334\n",
      "Processing chunk 33251/33334\n",
      "Processing chunk 33301/33334\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 10000\n",
      "Number of hits: 6153\n",
      "Average HR@10: 0.6153\n",
      "Average NDCG@10: 0.2795\n",
      "Evaluation completed in 28.50s\n",
      "HR@10: 0.6153\n",
      "NDCG@10: 0.2795\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# CDAE Model Definition\n",
    "class CDAE(nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_behaviors, embedding_dim=128):\n",
    "        super(CDAE, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(n_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(n_items, embedding_dim)\n",
    "        self.fc1 = nn.Linear(embedding_dim, 64)  # Hidden layer\n",
    "        self.fc2 = nn.Linear(64, 1)  # Output layer\n",
    "        self.input_dim = n_behaviors  # Set input_dim based on the number of behaviors\n",
    "\n",
    "    def forward(self, user, item, adj_matrix=None, graph_metrics=None):\n",
    "        user_emb = self.user_embedding(user)\n",
    "        item_emb = self.item_embedding(item)\n",
    "        combined = user_emb * item_emb  # Element-wise multiplication\n",
    "        hidden = F.relu(self.fc1(combined))  # Activation function\n",
    "        output = self.fc2(hidden)  # A scalar value per pair\n",
    "        return output.squeeze()\n",
    "\n",
    "# Dataset Class\n",
    "class MultiBehaviorDataset:\n",
    "    def __init__(self, data_path='/Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/', max_users=10000):\n",
    "        self.data_path = data_path\n",
    "        self.behaviors = ['pv', 'cart', 'buy']\n",
    "        self.trn_file = data_path + 'trn_'\n",
    "        self.tst_file = data_path + 'tst_'\n",
    "        self.max_users = max_users\n",
    "        \n",
    "        self.load_training_data()\n",
    "        self.load_test_data()\n",
    "\n",
    "    def create_graph_metrics(self, users):\n",
    "        \"\"\"Create graph metrics for the given users.\"\"\"\n",
    "        metrics = torch.zeros(len(users), 3, device=device)\n",
    "        \n",
    "        for i, user in enumerate(users):\n",
    "            interactions = np.array([mat[user].nnz for mat in self.trn_mats])\n",
    "            metrics[i, 0] = sum(interactions) / 100  # Example metric: average interactions\n",
    "            metrics[i, 1] = (interactions > 0).sum() / len(self.behaviors)  # Proportion of behaviors interacted with\n",
    "            metrics[i, 2] = interactions[-1] / max(interactions[0], 1)  # Example metric: last behavior interaction ratio\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "    def load_training_data(self):\n",
    "        print(\"Loading training data from:\", self.data_path)\n",
    "        self.trn_mats = []\n",
    "        for beh in self.behaviors:\n",
    "            path = self.trn_file + beh\n",
    "            print(f\"Loading behavior: {beh} from {path}\")\n",
    "            if not os.path.exists(path):\n",
    "                raise FileNotFoundError(f\"File not found: {path}\")\n",
    "            with open(path, 'rb') as fs:\n",
    "                mat = pickle.load(fs)\n",
    "                if not isinstance(mat, csr_matrix):\n",
    "                    mat = csr_matrix(mat)\n",
    "                mat = (mat != 0).astype(np.float32)\n",
    "                self.trn_mats.append(mat)\n",
    "        \n",
    "        self.trn_label = 1 * (self.trn_mats[-1] != 0)\n",
    "        self.n_users, self.n_items = self.trn_mats[0].shape\n",
    "        self.n_behaviors = len(self.behaviors)\n",
    "        print(f\"Dataset dimensions: {self.n_users} users, {self.n_items} items\")\n",
    "\n",
    "    def prepare_train_instances(self, max_samples=5000):\n",
    "        print(\"Preparing training instances...\")\n",
    "        train_data = []\n",
    "        \n",
    "        selected_users = np.random.choice(min(self.n_users, self.max_users), size=min(1000, self.max_users), replace=False)\n",
    "        \n",
    "        for user in selected_users:\n",
    "            pos_items = self.trn_label[user].indices[:2]  # Limit positive items\n",
    "            \n",
    "            if len(pos_items) > 0:\n",
    "                for item in pos_items:\n",
    "                    train_data.append([user, item, 1.0])\n",
    "                    \n",
    "                    # Limited negative sampling\n",
    "                    neg_items = np.random.choice(self.n_items, size=2, replace=False)\n",
    "                    for neg_item in neg_items:\n",
    "                        train_data.append([user, neg_item, 0.0])\n",
    "                        \n",
    "                    if len(train_data) >= max_samples:\n",
    "                        break\n",
    "            \n",
    "            if len(train_data) >= max_samples:\n",
    "                break\n",
    "        \n",
    "        print(f\"Generated {len(train_data)} training instances\")\n",
    "        return np.array(train_data)\n",
    "\n",
    "    def load_test_data(self):\n",
    "        test_path = self.tst_file + 'int'\n",
    "        print(f\"Loading test data from: {test_path}\")\n",
    "        if not os.path.exists(test_path):\n",
    "            raise FileNotFoundError(f\"File not found: {test_path}\")\n",
    "        with open(test_path, 'rb') as fs:\n",
    "            self.tst_int = np.array(pickle.load(fs))\n",
    "        \n",
    "        self.tst_users = np.reshape(np.argwhere(self.tst_int != None), [-1])\n",
    "        self.tst_users = self.tst_users[:min(len(self.tst_users), self.max_users)]\n",
    "        print(f\"Using {len(self.tst_users)} test users\")\n",
    "\n",
    "    def get_test_instances(self, num_neg_samples=99):\n",
    "        print(\"Preparing test instances...\")\n",
    "        test_instances = []\n",
    "        \n",
    "        for user in self.tst_users:\n",
    "            pos_item = self.tst_int[user]\n",
    "            if pos_item is not None:\n",
    "                test_instances.append([user, pos_item, 1.0])\n",
    "                \n",
    "                all_items = set(range(self.n_items))\n",
    "                pos_items_train = set(self.trn_label[user].indices)\n",
    "                pos_items_train.add(pos_item)\n",
    "                neg_items_pool = list(all_items - pos_items_train)\n",
    "                \n",
    "                n_neg = min(num_neg_samples, len(neg_items_pool))\n",
    "                if n_neg > 0:\n",
    "                    neg_items = np.random.choice(neg_items_pool, size=n_neg, replace=False)\n",
    "                    for neg_item in neg_items:\n",
    "                        test_instances.append([user, neg_item, 0.0])\n",
    "        \n",
    "        if not test_instances:\n",
    "            raise ValueError(\"No test instances were generated!\")\n",
    "            \n",
    "        test_instances = np.array(test_instances)\n",
    "        print(f\"Generated {len(test_instances)} test instances\")\n",
    "        return test_instances\n",
    "\n",
    "def evaluate_model(model, dataset, test_instances, k=10):\n",
    "    model.eval()\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    \n",
    "    chunk_size = 30\n",
    "    test_chunks = [test_instances[i:i + chunk_size] for i in range(0, len(test_instances), chunk_size)]\n",
    "    \n",
    "    print(f\"Evaluating {len(test_instances)} instances in {len(test_chunks)} chunks...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for chunk_idx, chunk in enumerate(test_chunks):\n",
    "            if chunk_idx % 50 == 0:\n",
    "                print(f\"Processing chunk {chunk_idx + 1}/{len(test_chunks)}\")\n",
    "            \n",
    "            user_items = {}\n",
    "            for inst in chunk:\n",
    "                user = int(inst[0])\n",
    "                item = int(inst[1])\n",
    "                label = float(inst[2])\n",
    "                \n",
    "                if user not in user_items:\n",
    "                    user_items[user] = {'pos': [], 'neg': [], 'all_items': [], 'all_scores': []}\n",
    "                \n",
    "                user_items[user]['all_items'].append(item)\n",
    "                if label > 0.5:\n",
    "                    user_items[user]['pos'].append(item)\n",
    "                else:\n",
    "                    user_items[user]['neg'].append(item)\n",
    "            \n",
    "            for user, data in user_items.items():\n",
    "                if not data['pos'] or not data['neg']:\n",
    "                    continue\n",
    "                \n",
    "                items = data['all_items']\n",
    "                batch_size = len(items)\n",
    "                \n",
    "                behaviors = torch.zeros(batch_size, dataset.n_behaviors, device=device)\n",
    "                for i, item in enumerate(items):\n",
    "                    for j, mat in enumerate(dataset.trn_mats):\n",
    "                        behaviors[i, j] = float(mat[user, item])\n",
    "                \n",
    "                x = torch.cat([\n",
    "                    behaviors,\n",
    "                    torch.zeros(batch_size, model.input_dim - behaviors.size(1), device=device)\n",
    "                ], dim=1)\n",
    "                \n",
    "                # Simplified adjacency matrix for evaluation\n",
    "                adj_matrix = torch.eye(batch_size, device=device)\n",
    "                graph_metrics = dataset.create_graph_metrics([user] * batch_size)\n",
    "                \n",
    "                # Call the model with user and item tensors\n",
    "                user_tensor = torch.LongTensor([user] * batch_size).to(device)\n",
    "                item_tensor = torch.LongTensor(items).to(device)\n",
    "                predictions = model(user_tensor, item_tensor)  # Call with user and item tensors\n",
    "                predictions = predictions.cpu().numpy().flatten()\n",
    "                \n",
    "                for item, score in zip(items, predictions):\n",
    "                    data['all_scores'].append((item, score))\n",
    "                \n",
    "                sorted_items = [x[0] for x in sorted(data['all_scores'], key=lambda x: x[1], reverse=True)]\n",
    "                recommended_items = sorted_items[:k]\n",
    "                \n",
    "                hit = any(pos_item in recommended_items for pos_item in data['pos'])\n",
    "                hits.append(hit)\n",
    "                \n",
    "                dcg = sum(1 / np.log2(i + 2) for i, item in enumerate(recommended_items) if item in data['pos'])\n",
    "                idcg = 1  # Ideal DCG for one relevant item\n",
    "                ndcg = dcg / idcg\n",
    "                ndcgs.append(ndcg)\n",
    "    \n",
    "    hr = np.mean(hits) if hits else 0\n",
    "    ndcg = np.mean(ndcgs) if ndcgs else 0\n",
    "    \n",
    "    print(f\"\\nEvaluation Statistics:\")\n",
    "    print(f\"Total users evaluated: {len(hits)}\")\n",
    "    print(f\"Number of hits: {sum(hits)}\")\n",
    "    print(f\"Average HR@{k}: {hr:.4f}\")\n",
    "    print(f\"Average NDCG@{k}: {ndcg:.4f}\")\n",
    "    \n",
    "    return hr, ndcg\n",
    "\n",
    "def main():\n",
    "    # Configuration\n",
    "    config = {\n",
    "        'embedding_dim': 512,\n",
    "        'learning_rate': 0.001,\n",
    "        'max_samples': 500000,\n",
    "        'eval_k': 10\n",
    "    }\n",
    "    \n",
    "    print(\"Initializing dataset...\")\n",
    "    dataset = MultiBehaviorDataset(max_users=10000)\n",
    "    train_data = dataset.prepare_train_instances(max_samples=config['max_samples'])\n",
    "    \n",
    "    print(f\"Using {len(train_data)} training instances\")\n",
    "\n",
    "    # Pass n_behaviors to the CDAE model\n",
    "    model = CDAE(dataset.n_users, dataset.n_items, dataset.n_behaviors, embedding_dim=config['embedding_dim']).to(device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "    print(\"Preparing training tensors...\")\n",
    "    users = torch.LongTensor(train_data[:, 0]).to(device)\n",
    "    items = torch.LongTensor(train_data[:, 1]).to(device)\n",
    "    labels = torch.FloatTensor(train_data[:, 2]).to(device)\n",
    "    behaviors = torch.FloatTensor(train_data[:, 3:]).to(device)\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    try:\n",
    "        model.train()\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        # Training\n",
    "        for epoch in range(10):  # Number of epochs\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(users, items)  # Call forward with user and item\n",
    "            loss = criterion(predictions, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        training_time = (datetime.now() - start_time).total_seconds()\n",
    "        print(f\"Training completed in {training_time:.2f}s\")\n",
    "        print(f\"Training loss: {loss.item():.4f}\")\n",
    "        \n",
    "        # Evaluation\n",
    "        print(\"\\nStarting evaluation...\")\n",
    "        eval_start_time = datetime.now()\n",
    "        \n",
    "        test_instances = dataset.get_test_instances()\n",
    "        hr, ndcg = evaluate_model(model, dataset, test_instances, k=config['eval_k'])\n",
    "        \n",
    "        eval_time = (datetime.now() - eval_start_time).total_seconds()\n",
    "        print(f\"Evaluation completed in {eval_time:.2f}s\")\n",
    "        print(f\"HR@{config['eval_k']}: {hr:.4f}\")\n",
    "        print(f\"NDCG@{config['eval_k']}: {ndcg:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during training: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing dataset...\n",
      "Loading training data from: /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/\n",
      "Loading behavior: pv from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_pv\n",
      "Loading behavior: cart from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_cart\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yf/20z1hn994jd04q4kl0gpgh740000gn/T/ipykernel_61723/2664878744.py:57: DeprecationWarning: Please import `csr_matrix` from the `scipy.sparse` namespace; the `scipy.sparse.csr` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  mat = pickle.load(fs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading behavior: buy from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_buy\n",
      "Dataset dimensions: 21716 users, 7977 items\n",
      "Loading test data from: /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/tst_int\n",
      "Using 10000 test users\n",
      "Preparing training instances...\n",
      "Generated 6000 training instances\n",
      "Using 6000 training instances\n",
      "Preparing training tensors...\n",
      "Starting training...\n",
      "Epoch 1, Loss: 0.7016\n",
      "Epoch 2, Loss: 0.6903\n",
      "Epoch 3, Loss: 0.6827\n",
      "Epoch 4, Loss: 0.6767\n",
      "Epoch 5, Loss: 0.6708\n",
      "Epoch 6, Loss: 0.6630\n",
      "Epoch 7, Loss: 0.6587\n",
      "Epoch 8, Loss: 0.6560\n",
      "Epoch 9, Loss: 0.6497\n",
      "Epoch 10, Loss: 0.6446\n",
      "Training completed in 0.30s\n",
      "\n",
      "Starting evaluation...\n",
      "Preparing test instances...\n",
      "Generated 1000000 test instances\n",
      "Evaluating 1000000 instances in 10000 chunks...\n",
      "Processing chunk 1/10000\n",
      "Processing chunk 51/10000\n",
      "Processing chunk 101/10000\n",
      "Processing chunk 151/10000\n",
      "Processing chunk 201/10000\n",
      "Processing chunk 251/10000\n",
      "Processing chunk 301/10000\n",
      "Processing chunk 351/10000\n",
      "Processing chunk 401/10000\n",
      "Processing chunk 451/10000\n",
      "Processing chunk 501/10000\n",
      "Processing chunk 551/10000\n",
      "Processing chunk 601/10000\n",
      "Processing chunk 651/10000\n",
      "Processing chunk 701/10000\n",
      "Processing chunk 751/10000\n",
      "Processing chunk 801/10000\n",
      "Processing chunk 851/10000\n",
      "Processing chunk 901/10000\n",
      "Processing chunk 951/10000\n",
      "Processing chunk 1001/10000\n",
      "Processing chunk 1051/10000\n",
      "Processing chunk 1101/10000\n",
      "Processing chunk 1151/10000\n",
      "Processing chunk 1201/10000\n",
      "Processing chunk 1251/10000\n",
      "Processing chunk 1301/10000\n",
      "Processing chunk 1351/10000\n",
      "Processing chunk 1401/10000\n",
      "Processing chunk 1451/10000\n",
      "Processing chunk 1501/10000\n",
      "Processing chunk 1551/10000\n",
      "Processing chunk 1601/10000\n",
      "Processing chunk 1651/10000\n",
      "Processing chunk 1701/10000\n",
      "Processing chunk 1751/10000\n",
      "Processing chunk 1801/10000\n",
      "Processing chunk 1851/10000\n",
      "Processing chunk 1901/10000\n",
      "Processing chunk 1951/10000\n",
      "Processing chunk 2001/10000\n",
      "Processing chunk 2051/10000\n",
      "Processing chunk 2101/10000\n",
      "Processing chunk 2151/10000\n",
      "Processing chunk 2201/10000\n",
      "Processing chunk 2251/10000\n",
      "Processing chunk 2301/10000\n",
      "Processing chunk 2351/10000\n",
      "Processing chunk 2401/10000\n",
      "Processing chunk 2451/10000\n",
      "Processing chunk 2501/10000\n",
      "Processing chunk 2551/10000\n",
      "Processing chunk 2601/10000\n",
      "Processing chunk 2651/10000\n",
      "Processing chunk 2701/10000\n",
      "Processing chunk 2751/10000\n",
      "Processing chunk 2801/10000\n",
      "Processing chunk 2851/10000\n",
      "Processing chunk 2901/10000\n",
      "Processing chunk 2951/10000\n",
      "Processing chunk 3001/10000\n",
      "Processing chunk 3051/10000\n",
      "Processing chunk 3101/10000\n",
      "Processing chunk 3151/10000\n",
      "Processing chunk 3201/10000\n",
      "Processing chunk 3251/10000\n",
      "Processing chunk 3301/10000\n",
      "Processing chunk 3351/10000\n",
      "Processing chunk 3401/10000\n",
      "Processing chunk 3451/10000\n",
      "Processing chunk 3501/10000\n",
      "Processing chunk 3551/10000\n",
      "Processing chunk 3601/10000\n",
      "Processing chunk 3651/10000\n",
      "Processing chunk 3701/10000\n",
      "Processing chunk 3751/10000\n",
      "Processing chunk 3801/10000\n",
      "Processing chunk 3851/10000\n",
      "Processing chunk 3901/10000\n",
      "Processing chunk 3951/10000\n",
      "Processing chunk 4001/10000\n",
      "Processing chunk 4051/10000\n",
      "Processing chunk 4101/10000\n",
      "Processing chunk 4151/10000\n",
      "Processing chunk 4201/10000\n",
      "Processing chunk 4251/10000\n",
      "Processing chunk 4301/10000\n",
      "Processing chunk 4351/10000\n",
      "Processing chunk 4401/10000\n",
      "Processing chunk 4451/10000\n",
      "Processing chunk 4501/10000\n",
      "Processing chunk 4551/10000\n",
      "Processing chunk 4601/10000\n",
      "Processing chunk 4651/10000\n",
      "Processing chunk 4701/10000\n",
      "Processing chunk 4751/10000\n",
      "Processing chunk 4801/10000\n",
      "Processing chunk 4851/10000\n",
      "Processing chunk 4901/10000\n",
      "Processing chunk 4951/10000\n",
      "Processing chunk 5001/10000\n",
      "Processing chunk 5051/10000\n",
      "Processing chunk 5101/10000\n",
      "Processing chunk 5151/10000\n",
      "Processing chunk 5201/10000\n",
      "Processing chunk 5251/10000\n",
      "Processing chunk 5301/10000\n",
      "Processing chunk 5351/10000\n",
      "Processing chunk 5401/10000\n",
      "Processing chunk 5451/10000\n",
      "Processing chunk 5501/10000\n",
      "Processing chunk 5551/10000\n",
      "Processing chunk 5601/10000\n",
      "Processing chunk 5651/10000\n",
      "Processing chunk 5701/10000\n",
      "Processing chunk 5751/10000\n",
      "Processing chunk 5801/10000\n",
      "Processing chunk 5851/10000\n",
      "Processing chunk 5901/10000\n",
      "Processing chunk 5951/10000\n",
      "Processing chunk 6001/10000\n",
      "Processing chunk 6051/10000\n",
      "Processing chunk 6101/10000\n",
      "Processing chunk 6151/10000\n",
      "Processing chunk 6201/10000\n",
      "Processing chunk 6251/10000\n",
      "Processing chunk 6301/10000\n",
      "Processing chunk 6351/10000\n",
      "Processing chunk 6401/10000\n",
      "Processing chunk 6451/10000\n",
      "Processing chunk 6501/10000\n",
      "Processing chunk 6551/10000\n",
      "Processing chunk 6601/10000\n",
      "Processing chunk 6651/10000\n",
      "Processing chunk 6701/10000\n",
      "Processing chunk 6751/10000\n",
      "Processing chunk 6801/10000\n",
      "Processing chunk 6851/10000\n",
      "Processing chunk 6901/10000\n",
      "Processing chunk 6951/10000\n",
      "Processing chunk 7001/10000\n",
      "Processing chunk 7051/10000\n",
      "Processing chunk 7101/10000\n",
      "Processing chunk 7151/10000\n",
      "Processing chunk 7201/10000\n",
      "Processing chunk 7251/10000\n",
      "Processing chunk 7301/10000\n",
      "Processing chunk 7351/10000\n",
      "Processing chunk 7401/10000\n",
      "Processing chunk 7451/10000\n",
      "Processing chunk 7501/10000\n",
      "Processing chunk 7551/10000\n",
      "Processing chunk 7601/10000\n",
      "Processing chunk 7651/10000\n",
      "Processing chunk 7701/10000\n",
      "Processing chunk 7751/10000\n",
      "Processing chunk 7801/10000\n",
      "Processing chunk 7851/10000\n",
      "Processing chunk 7901/10000\n",
      "Processing chunk 7951/10000\n",
      "Processing chunk 8001/10000\n",
      "Processing chunk 8051/10000\n",
      "Processing chunk 8101/10000\n",
      "Processing chunk 8151/10000\n",
      "Processing chunk 8201/10000\n",
      "Processing chunk 8251/10000\n",
      "Processing chunk 8301/10000\n",
      "Processing chunk 8351/10000\n",
      "Processing chunk 8401/10000\n",
      "Processing chunk 8451/10000\n",
      "Processing chunk 8501/10000\n",
      "Processing chunk 8551/10000\n",
      "Processing chunk 8601/10000\n",
      "Processing chunk 8651/10000\n",
      "Processing chunk 8701/10000\n",
      "Processing chunk 8751/10000\n",
      "Processing chunk 8801/10000\n",
      "Processing chunk 8851/10000\n",
      "Processing chunk 8901/10000\n",
      "Processing chunk 8951/10000\n",
      "Processing chunk 9001/10000\n",
      "Processing chunk 9051/10000\n",
      "Processing chunk 9101/10000\n",
      "Processing chunk 9151/10000\n",
      "Processing chunk 9201/10000\n",
      "Processing chunk 9251/10000\n",
      "Processing chunk 9301/10000\n",
      "Processing chunk 9351/10000\n",
      "Processing chunk 9401/10000\n",
      "Processing chunk 9451/10000\n",
      "Processing chunk 9501/10000\n",
      "Processing chunk 9551/10000\n",
      "Processing chunk 9601/10000\n",
      "Processing chunk 9651/10000\n",
      "Processing chunk 9701/10000\n",
      "Processing chunk 9751/10000\n",
      "Processing chunk 9801/10000\n",
      "Processing chunk 9851/10000\n",
      "Processing chunk 9901/10000\n",
      "Processing chunk 9951/10000\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 10000\n",
      "Number of hits: 1009\n",
      "Average HR@10: 0.1009\n",
      "Average NDCG@10: 0.0452\n",
      "Evaluation completed in 47.94s\n",
      "HR@10: 0.1009\n",
      "NDCG@10: 0.0452\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import Linear, Dropout, BatchNorm1d\n",
    "from torch.nn import functional as F\n",
    "from datetime import datetime\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# CDAE Model Definition\n",
    "class CDAE(nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_behaviors, embedding_dim=128):\n",
    "        super(CDAE, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(n_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(n_items, embedding_dim)\n",
    "        self.fc1 = nn.Linear(embedding_dim, 128)  # Hidden layer\n",
    "        self.bn1 = BatchNorm1d(128)  # Batch normalization\n",
    "        self.fc2 = nn.Linear(128, 32)  # Additional hidden layer\n",
    "        self.fc3 = nn.Linear(32, 1)  # Output layer\n",
    "        self.dropout = Dropout(0.5)  # Dropout layer\n",
    "        self.input_dim = n_behaviors  # Set input_dim based on the number of behaviors\n",
    "\n",
    "    def forward(self, user, item, adj_matrix=None, graph_metrics=None):\n",
    "        user_emb = self.user_embedding(user)\n",
    "        item_emb = self.item_embedding(item)\n",
    "        combined = user_emb * item_emb  # Element-wise multiplication\n",
    "        hidden = F.relu(self.fc1(combined))  # Activation function\n",
    "        hidden = self.bn1(hidden)  # Apply batch normalization\n",
    "        hidden = self.dropout(hidden)  # Apply dropout\n",
    "        output = self.fc3(F.relu(self.fc2(hidden)))  # A scalar value per pair\n",
    "        return output.squeeze()\n",
    "\n",
    "\n",
    "# MultiBehaviorDataset and other classes remain unchanged Dataset class\n",
    "class MultiBehaviorDataset:\n",
    "    def __init__(self, data_path='/Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/', max_users=10000):\n",
    "        self.data_path = data_path\n",
    "        self.behaviors = ['pv', 'cart', 'buy']\n",
    "        self.trn_file = data_path + 'trn_'\n",
    "        self.tst_file = data_path + 'tst_'\n",
    "        self.max_users = max_users  # Limit number of users\n",
    "        \n",
    "        self.load_training_data()\n",
    "        self.load_test_data()\n",
    "    \n",
    "    def load_training_data(self):\n",
    "        print(\"Loading training data from:\", self.data_path)\n",
    "        self.trn_mats = []\n",
    "        for beh in self.behaviors:\n",
    "            path = self.trn_file + beh\n",
    "            print(f\"Loading behavior: {beh} from {path}\")\n",
    "            if not os.path.exists(path):\n",
    "                raise FileNotFoundError(f\"File not found: {path}\")\n",
    "            with open(path, 'rb') as fs:\n",
    "                mat = pickle.load(fs)\n",
    "                if not isinstance(mat, csr_matrix):\n",
    "                    mat = csr_matrix(mat)\n",
    "                mat = (mat != 0).astype(np.float32)\n",
    "                self.trn_mats.append(mat)\n",
    "        \n",
    "        self.trn_label = 1 * (self.trn_mats[-1] != 0)\n",
    "        self.n_users, self.n_items = self.trn_mats[0].shape\n",
    "        self.n_behaviors = len(self.behaviors)\n",
    "        print(f\"Dataset dimensions: {self.n_users} users, {self.n_items} items\")\n",
    "\n",
    "    def prepare_train_instances(self, max_samples=5000):\n",
    "        \"\"\"Optimized training instance preparation\"\"\"\n",
    "        print(\"Preparing training instances...\")\n",
    "        train_data = []\n",
    "        \n",
    "        # Randomly select users\n",
    "        selected_users = np.random.choice(min(self.n_users, self.max_users), size=min(1000, self.max_users), replace=False)\n",
    "        \n",
    "        for user in selected_users:\n",
    "            pos_items = self.trn_label[user].indices[:2]  # Limit positive items\n",
    "            \n",
    "            if len(pos_items) > 0:\n",
    "                for item in pos_items:\n",
    "                    behaviors = [float(mat[user, item]) for mat in self.trn_mats]\n",
    "                    train_data.append([user, item, 1.0] + behaviors)\n",
    "                    \n",
    "                    # Limited negative sampling\n",
    "                    neg_items = np.random.choice(self.n_items, size=2, replace=False)\n",
    "                    for neg_item in neg_items:\n",
    "                        behaviors = [float(mat[user, neg_item]) for mat in self.trn_mats]\n",
    "                        train_data.append([user, neg_item, 0.0] + behaviors)\n",
    "                        \n",
    "                    if len(train_data) >= max_samples:\n",
    "                        break\n",
    "            \n",
    "            if len(train_data) >= max_samples:\n",
    "                break\n",
    "        \n",
    "        print(f\"Generated {len(train_data)} training instances\")\n",
    "        return np.array(train_data)\n",
    "    \n",
    "    def load_test_data(self):\n",
    "        \"\"\"Load test data\"\"\"\n",
    "        test_path = self.tst_file + 'int'\n",
    "        print(f\"Loading test data from: {test_path}\")\n",
    "        if not os.path.exists(test_path):\n",
    "            raise FileNotFoundError(f\"File not found: {test_path}\")\n",
    "        with open(test_path, 'rb') as fs:\n",
    "            self.tst_int = np.array(pickle.load(fs))\n",
    "        \n",
    "        self.tst_users = np.reshape(np.argwhere(self.tst_int != None), [-1])\n",
    "        # Limit test users for faster processing\n",
    "        self.tst_users = self.tst_users[:min(len(self.tst_users), self.max_users)]\n",
    "        print(f\"Using {len(self.tst_users)} test users\")\n",
    "\n",
    "    def get_test_instances(self, num_neg_samples=99):\n",
    "        \"\"\"Generate test instances with negative sampling\"\"\"\n",
    "        print(\"Preparing test instances...\")\n",
    "        test_instances = []\n",
    "        \n",
    "        for user in self.tst_users:\n",
    "            pos_item = self.tst_int[user]\n",
    "            if pos_item is not None:\n",
    "                # Add positive instance\n",
    "                test_instances.append([user, pos_item, 1.0])\n",
    "                \n",
    "                # Add negative instances\n",
    "                try:\n",
    "                    # Get all items and remove positive items\n",
    "                    all_items = set(range(self.n_items))\n",
    "                    pos_items_train = set(self.trn_label[user].indices)\n",
    "                    pos_items_train.add(pos_item)\n",
    "                    neg_items_pool = list(all_items - pos_items_train)\n",
    "                    \n",
    "                    # Sample negative items\n",
    "                    n_neg = min(num_neg_samples, len(neg_items_pool))\n",
    "                    if n_neg > 0:\n",
    "                        neg_items = np.random.choice(neg_items_pool, size=n_neg, replace=False)\n",
    "                        for neg_item in neg_items:\n",
    "                            test_instances.append([user, neg_item, 0.0])\n",
    "            \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing test user {user}: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "        if not test_instances:\n",
    "            raise ValueError(\"No test instances were generated!\")\n",
    "        \n",
    "        test_instances = np.array(test_instances)\n",
    "        print(f\"Generated {len(test_instances)} test instances\")\n",
    "        return test_instances\n",
    "\n",
    "# def train_and_evaluate_cdae(dataset):\n",
    "#     # Prepare training and test instances\n",
    "#     train_data = dataset.prepare_train_instances()\n",
    "#     test_data = dataset.get_test_instances()\n",
    "\n",
    "#     # Prepare the PyTorch data\n",
    "#     train_users = torch.LongTensor(train_data[:, 0]).to(device)\n",
    "#     train_items = torch.LongTensor(train_data[:, 1]).to(device)\n",
    "#     train_labels = torch.FloatTensor(train_data[:, 2]).to(device)\n",
    "\n",
    "#     # Model, Loss, and Optimizer\n",
    "#     model = CDAE(dataset.n_users, dataset.n_items, dataset.n_behaviors, embedding_dim=128).to(device)\n",
    "#     criterion = nn.BCEWithLogitsLoss()  # Loss for binary classification\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "#     # Learning Rate Scheduler\n",
    "#     scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)  # Example scheduler\n",
    "\n",
    "#     # Training\n",
    "#     start_time = datetime.now()\n",
    "#     num_epochs = 20\n",
    "#     for epoch in range(num_epochs):\n",
    "#         model.train()\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(train_users, train_items)  # Predict for each user-item pair\n",
    "#         loss = criterion(output, train_labels)  # Compute loss for each pair\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         scheduler.step()  # Step the scheduler\n",
    "#         print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "#     # Evaluation using the new evaluate_model function\n",
    "#     model.eval()\n",
    "#     hr, ndcg = evaluate_model(model, dataset, test_data)  # Call the new evaluation function\n",
    "\n",
    "#     exec_time = (datetime.now() - start_time).total_seconds()\n",
    "#     print(f\"HR: {hr:.4f}, NDCG: {ndcg:.4f}, Execution Time: {exec_time:.4f} seconds\")\n",
    "\n",
    "def evaluate_model(model, dataset, test_instances, k=10):\n",
    "    \"\"\"Improved evaluation function with better metrics calculation\"\"\"\n",
    "    model.eval()\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    \n",
    "    # Process test instances in smaller chunks\n",
    "    chunk_size = 100\n",
    "    test_chunks = [test_instances[i:i + chunk_size] for i in range(0, len(test_instances), chunk_size)]\n",
    "    \n",
    "    print(f\"Evaluating {len(test_instances)} instances in {len(test_chunks)} chunks...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for chunk_idx, chunk in enumerate(test_chunks):\n",
    "            if chunk_idx % 50 == 0:  # Reduced frequency of progress updates\n",
    "                print(f\"Processing chunk {chunk_idx + 1}/{len(test_chunks)}\")\n",
    "            \n",
    "            # Group by user and ensure we have both positive and negative items\n",
    "            user_items = {}\n",
    "            for inst in chunk:\n",
    "                user = int(inst[0])\n",
    "                item = int(inst[1])\n",
    "                label = float(inst[2])\n",
    "                \n",
    "                if user not in user_items:\n",
    "                    user_items[user] = {'pos': [], 'neg': [], 'all_items': [], 'all_scores': []}\n",
    "                \n",
    "                user_items[user]['all_items'].append(item)\n",
    "                if label > 0.5:\n",
    "                    user_items[user]['pos'].append(item)\n",
    "                else:\n",
    "                    user_items[user]['neg'].append(item)\n",
    "            \n",
    "            # Process each user that has both positive and negative items\n",
    "            for user, data in user_items.items():\n",
    "                if not data['pos'] or not data['neg']:\n",
    "                    continue\n",
    "                \n",
    "                items = data['all_items']\n",
    "                batch_size = len(items)\n",
    "                \n",
    "                # Create input features\n",
    "                behaviors = torch.zeros(batch_size, dataset.n_behaviors, device=device)\n",
    "                for i, item in enumerate(items):\n",
    "                    for j, mat in enumerate(dataset.trn_mats):\n",
    "                        behaviors[i, j] = float(mat[user, item])\n",
    "                \n",
    "                # Convert user and item indices to LongTensor\n",
    "                user_tensor = torch.LongTensor([user] * batch_size).to(device)\n",
    "                item_tensor = torch.LongTensor(items).to(device)\n",
    "\n",
    "                # Get predictions\n",
    "                predictions = model(user_tensor, item_tensor, behaviors)\n",
    "                predictions = torch.sigmoid(predictions).cpu().numpy().flatten()\n",
    "                \n",
    "                # Store all scores\n",
    "                for item, score in zip(items, predictions):\n",
    "                    data['all_scores'].append((item, score))\n",
    "                \n",
    "                # Sort items by score\n",
    "                sorted_items = [x[0] for x in sorted(data['all_scores'], key=lambda x: x[1], reverse=True)]\n",
    "                recommended_items = sorted_items[:k]\n",
    "                \n",
    "                # Calculate HR\n",
    "                hit = any(pos_item in recommended_items for pos_item in data['pos'])\n",
    "                hits.append(hit)\n",
    "                \n",
    "                # Calculate NDCG\n",
    "                dcg = 0\n",
    "                for i, item in enumerate(recommended_items):\n",
    "                    if item in data['pos']:\n",
    "                        dcg += 1 / np.log2(i + 2)\n",
    "                \n",
    "                idcg = sum(1 / np.log2(i + 2) for i in range(len(data['pos'])))\n",
    "                ndcg = dcg / idcg if idcg > 0 else 0\n",
    "                ndcgs.append(ndcg)\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    hr = np.mean(hits) if hits else 0\n",
    "    ndcg = np.mean(ndcgs) if ndcgs else 0\n",
    "    \n",
    "    # Print detailed statistics\n",
    "    print(f\"\\nEvaluation Statistics:\")\n",
    "    print(f\"Total users evaluated: {len(hits)}\")\n",
    "    print(f\"Number of hits: {sum(hits)}\")\n",
    "    print(f\"Average HR@{k}: {hr:.4f}\")\n",
    "    print(f\"Average NDCG@{k}: {ndcg:.4f}\")\n",
    "    \n",
    "    return hr, ndcg\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Configuration\n",
    "    config = {\n",
    "        'max_users': 10000,\n",
    "        'max_samples': 500000,\n",
    "        'eval_k': 10,\n",
    "        'embedding_dim': 128,\n",
    "        'behavior_dim': 3,\n",
    "        'learning_rate': 0.001,\n",
    "        'weight_decay': 1e-6,\n",
    "        'dropout': 0.1,\n",
    "        'gradient_clip': 1.0,\n",
    "        'max_samples': 500000,\n",
    "        'eval_k': 10\n",
    "    }\n",
    "\n",
    "    print(\"Initializing dataset...\")\n",
    "    dataset = MultiBehaviorDataset(max_users=config['max_users'])\n",
    "    train_data=dataset.prepare_train_instances(max_samples=config['max_samples'])\n",
    "\n",
    "    print(f\"Using {len(train_data)} training instances\")\n",
    "\n",
    "    model = CDAE(dataset.n_users, dataset.n_items, dataset.n_behaviors, embedding_dim=128).to(device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
    "\n",
    "    print(\"Preparing training tensors...\")\n",
    "    users = torch.LongTensor(train_data[:, 0]).to(device)\n",
    "    items = torch.LongTensor(train_data[:, 1]).to(device)\n",
    "    labels = torch.FloatTensor(train_data[:, 2]).to(device)\n",
    "    behaviors = torch.FloatTensor(train_data[:, 3:]).to(device)\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    try:\n",
    "        model.train()\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        # Training\n",
    "        for epoch in range(10):  # Adjust the number of epochs\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            predictions = model(users, items, behaviors)\n",
    "            loss = criterion(predictions, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), config['gradient_clip'])\n",
    "            optimizer.step()\n",
    "            \n",
    "            print(f\"Epoch {epoch + 1}, Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        training_time = (datetime.now() - start_time).total_seconds()\n",
    "        print(f\"Training completed in {training_time:.2f}s\")\n",
    "        \n",
    "        # Evaluation\n",
    "        print(\"\\nStarting evaluation...\")\n",
    "        eval_start_time = datetime.now()\n",
    "        \n",
    "        test_instances = dataset.get_test_instances()\n",
    "        hr, ndcg = evaluate_model(model, dataset, test_instances, k=config['eval_k'])\n",
    "        \n",
    "        eval_time = (datetime.now() - eval_start_time).total_seconds()\n",
    "        print(f\"Evaluation completed in {eval_time:.2f}s\")\n",
    "        print(f\"HR@{config['eval_k']}: {hr:.4f}\")\n",
    "        print(f\"NDCG@{config['eval_k']}: {ndcg:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during training: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing dataset...\n",
      "Loading training data from: /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/\n",
      "Loading behavior: pv from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_pv\n",
      "Loading behavior: cart from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_cart\n",
      "Loading behavior: buy from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_buy\n",
      "Dataset dimensions: 21716 users, 7977 items\n",
      "Loading test data from: /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/tst_int\n",
      "Using 10000 test users\n",
      "Preparing training instances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yf/20z1hn994jd04q4kl0gpgh740000gn/T/ipykernel_51372/3406085589.py:77: DeprecationWarning: Please import `csr_matrix` from the `scipy.sparse` namespace; the `scipy.sparse.csr` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  mat = pickle.load(fs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 6000 training instances\n",
      "Using 6000 training instances\n",
      "Preparing training tensors...\n",
      "Starting training...\n",
      "Training completed in 0.03s\n",
      "Training loss: 0.6904\n",
      "\n",
      "Starting evaluation...\n",
      "Preparing test instances...\n",
      "Generated 1000000 test instances\n",
      "Evaluating 1000000 instances in 33334 chunks...\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 10000\n",
      "Number of hits: 10000\n",
      "Average HR@10: 1.0000\n",
      "Average NDCG@10: 0.9331\n",
      "Evaluation completed in 27.03s\n",
      "HR@10: 1.0000\n",
      "NDCG@10: 0.9331\n"
     ]
    }
   ],
   "source": [
    "USR=50000\n",
    "TOP_N=10\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import Linear, Dropout, LayerNorm\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import ModuleList\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from datetime import datetime\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# CDAE Model Definition\n",
    "class CDAE(nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_behaviors, embedding_dim=128):\n",
    "        super(CDAE, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(n_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(n_items, embedding_dim)\n",
    "        self.fc1 = nn.Linear(embedding_dim, 64)  # Hidden layer\n",
    "        self.fc2 = nn.Linear(64, 1)  # Output layer\n",
    "        self.input_dim = n_behaviors  # Set input_dim based on the number of behaviors\n",
    "\n",
    "    def forward(self, user, item, adj_matrix=None, graph_metrics=None):\n",
    "        user_emb = self.user_embedding(user)\n",
    "        item_emb = self.item_embedding(item)\n",
    "        combined = user_emb * item_emb  # Element-wise multiplication\n",
    "        hidden = F.relu(self.fc1(combined))  # Activation function\n",
    "        output = self.fc2(hidden)  # A scalar value per pair\n",
    "        return output.squeeze()\n",
    "\n",
    "# NADE Model Definition\n",
    "class NADE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(NADE, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        # Define layers\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through the network\n",
    "        hidden = F.relu(self.fc1(x))\n",
    "        output = self.fc2(hidden)\n",
    "        return output\n",
    "\n",
    "# Dataset Class\n",
    "class MultiBehaviorDataset:\n",
    "    def __init__(self, data_path='/Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/', max_users=10000):\n",
    "        self.data_path = data_path\n",
    "        self.behaviors = ['pv', 'cart', 'buy']\n",
    "        self.trn_file = data_path + 'trn_'\n",
    "        self.tst_file = data_path + 'tst_'\n",
    "        self.max_users = max_users  # Limit number of users\n",
    "        \n",
    "        self.load_training_data()\n",
    "        self.load_test_data()\n",
    "    \n",
    "    def load_training_data(self):\n",
    "        print(\"Loading training data from:\", self.data_path)\n",
    "        self.trn_mats = []\n",
    "        for beh in self.behaviors:\n",
    "            path = self.trn_file + beh\n",
    "            print(f\"Loading behavior: {beh} from {path}\")\n",
    "            if not os.path.exists(path):\n",
    "                raise FileNotFoundError(f\"File not found: {path}\")\n",
    "            with open(path, 'rb') as fs:\n",
    "                mat = pickle.load(fs)\n",
    "                if not isinstance(mat, csr_matrix):\n",
    "                    mat = csr_matrix(mat)\n",
    "                mat = (mat != 0).astype(np.float32)\n",
    "                self.trn_mats.append(mat)\n",
    "        \n",
    "        self.trn_label = 1 * (self.trn_mats[-1] != 0)\n",
    "        self.n_users, self.n_items = self.trn_mats[0].shape\n",
    "        self.n_behaviors = len(self.behaviors)\n",
    "        print(f\"Dataset dimensions: {self.n_users} users, {self.n_items} items\")\n",
    "\n",
    "    def create_adjacency_matrix(self, users):\n",
    "        \"\"\"Optimized adjacency matrix creation\"\"\"\n",
    "        batch_size = len(users)\n",
    "        adj_matrix = torch.zeros(batch_size, batch_size, device=device)\n",
    "        \n",
    "        # Pre-compute user item sets\n",
    "        user_item_sets = []\n",
    "        for user in users:\n",
    "            user_items = set()\n",
    "            for mat in self.trn_mats:\n",
    "                user_items.update(mat[user].indices)\n",
    "            user_item_sets.append(user_items)\n",
    "        \n",
    "        # Compute similarities in parallel\n",
    "        for i in range(batch_size):\n",
    "            if not user_item_sets[i]:\n",
    "                continue\n",
    "            for j in range(i+1, batch_size):\n",
    "                if user_item_sets[j]:\n",
    "                    jaccard = len(user_item_sets[i] & user_item_sets[j]) / len(user_item_sets[i] | user_item_sets[j])\n",
    "                    adj_matrix[i,j] = adj_matrix[j,i] = jaccard\n",
    "        \n",
    "        return adj_matrix\n",
    "\n",
    "    def create_graph_metrics(self, users):\n",
    "        \"\"\"Optimized graph metrics creation\"\"\"\n",
    "        metrics = torch.zeros(len(users), 3, device=device)\n",
    "        \n",
    "        # Vectorized computation\n",
    "        for i, user in enumerate(users):\n",
    "            interactions = np.array([mat[user].nnz for mat in self.trn_mats])\n",
    "            metrics[i,0] = sum(interactions) / 100\n",
    "            metrics[i,1] = (interactions > 0).sum() / len(self.behaviors)\n",
    "            metrics[i,2] = interactions[-1] / max(interactions[0], 1)\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "    def prepare_train_instances(self, max_samples=5000):\n",
    "        \"\"\"Optimized training instance preparation\"\"\"\n",
    "        print(\"Preparing training instances...\")\n",
    "        train_data = []\n",
    "        \n",
    "        # Randomly select users\n",
    "        selected_users = np.random.choice(min(self.n_users, self.max_users), size=min(1000, self.max_users), replace=False)\n",
    "        \n",
    "        for user in selected_users:\n",
    "            pos_items = self.trn_label[user].indices[:2]  # Limit positive items\n",
    "            \n",
    "            if len(pos_items) > 0:\n",
    "                for item in pos_items:\n",
    "                    behaviors = [float(mat[user, item]) for mat in self.trn_mats]\n",
    "                    train_data.append([user, item, 1.0] + behaviors)\n",
    "                    \n",
    "                    # Limited negative sampling\n",
    "                    neg_items = np.random.choice(self.n_items, size=2, replace=False)\n",
    "                    for neg_item in neg_items:\n",
    "                        behaviors = [float(mat[user, neg_item]) for mat in self.trn_mats]\n",
    "                        train_data.append([user, neg_item, 0.0] + behaviors)\n",
    "                        \n",
    "                    if len(train_data) >= max_samples:\n",
    "                        break\n",
    "            \n",
    "            if len(train_data) >= max_samples:\n",
    "                break\n",
    "        \n",
    "        print(f\"Generated {len(train_data)} training instances\")\n",
    "        return np.array(train_data)\n",
    "    \n",
    "    def load_test_data(self):\n",
    "        \"\"\"Load test data\"\"\"\n",
    "        test_path = self.tst_file + 'int'\n",
    "        print(f\"Loading test data from: {test_path}\")\n",
    "        if not os.path.exists(test_path):\n",
    "            raise FileNotFoundError(f\"File not found: {test_path}\")\n",
    "        with open(test_path, 'rb') as fs:\n",
    "            self.tst_int = np.array(pickle.load(fs))\n",
    "        \n",
    "        self.tst_users = np.reshape(np.argwhere(self.tst_int != None), [-1])\n",
    "        # Limit test users for faster processing\n",
    "        self.tst_users = self.tst_users[:min(len(self.tst_users), self.max_users)]\n",
    "        print(f\"Using {len(self.tst_users)} test users\")\n",
    "\n",
    "    def get_test_instances(self, num_neg_samples=99):\n",
    "        \"\"\"Generate test instances with negative sampling\"\"\"\n",
    "        print(\"Preparing test instances...\")\n",
    "        test_instances = []\n",
    "        \n",
    "        for user in self.tst_users:\n",
    "            pos_item = self.tst_int[user]\n",
    "            if pos_item is not None:\n",
    "                # Add positive instance\n",
    "                test_instances.append([user, pos_item, 1.0])\n",
    "                \n",
    "                # Add negative instances\n",
    "                try:\n",
    "                    # Get all items and remove positive items\n",
    "                    all_items = set(range(self.n_items))\n",
    "                    pos_items_train = set(self.trn_label[user].indices)\n",
    "                    pos_items_train.add(pos_item)\n",
    "                    neg_items_pool = list(all_items - pos_items_train)\n",
    "                    \n",
    "                    # Sample negative items\n",
    "                    n_neg = min(num_neg_samples, len(neg_items_pool))\n",
    "                    if n_neg > 0:\n",
    "                        neg_items = np.random.choice(neg_items_pool, size=n_neg, replace=False)\n",
    "                        for neg_item in neg_items:\n",
    "                            test_instances.append([user, neg_item, 0.0])\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing test user {user}: {str(e)}\")\n",
    "                    continue\n",
    "                \n",
    "                # Limit the number of test instances for faster processing\n",
    "                if len(test_instances) >= self.max_users * 100:\n",
    "                    break\n",
    "        \n",
    "        if not test_instances:\n",
    "            raise ValueError(\"No test instances were generated!\")\n",
    "            \n",
    "        test_instances = np.array(test_instances)\n",
    "        print(f\"Generated {len(test_instances)} test instances\")\n",
    "        return test_instances\n",
    "\n",
    "\n",
    "def evaluate_model(model, dataset, test_instances, k=10):\n",
    "    \"\"\"Improved evaluation function with better metrics calculation\"\"\"\n",
    "    model.eval()\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    \n",
    "    # Process test instances in smaller chunks\n",
    "    chunk_size = 30\n",
    "    test_chunks = [test_instances[i:i + chunk_size] for i in range(0, len(test_instances), chunk_size)]\n",
    "    \n",
    "    print(f\"Evaluating {len(test_instances)} instances in {len(test_chunks)} chunks...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for chunk_idx, chunk in enumerate(test_chunks):\n",
    "            # if chunk_idx % 50 == 0:  # Reduced frequency of progress updates\n",
    "            #     print(f\"Processing chunk {chunk_idx + 1}/{len(test_chunks)}\")\n",
    "            \n",
    "            # Group by user and ensure we have both positive and negative items\n",
    "            user_items = {}\n",
    "            for inst in chunk:\n",
    "                user = int(inst[0])\n",
    "                item = int(inst[1])\n",
    "                label = float(inst[2])\n",
    "                \n",
    "                if user not in user_items:\n",
    "                    user_items[user] = {'pos': [], 'neg': [], 'all_items': [], 'all_scores': []}\n",
    "                \n",
    "                user_items[user]['all_items'].append(item)\n",
    "                if label > 0.5:\n",
    "                    user_items[user]['pos'].append(item)\n",
    "                else:\n",
    "                    user_items[user]['neg'].append(item)\n",
    "            \n",
    "            # Process each user that has both positive and negative items\n",
    "            for user, data in user_items.items():\n",
    "                if not data['pos'] or not data['neg']:\n",
    "                    continue\n",
    "                \n",
    "                items = data['all_items']\n",
    "                batch_size = len(items)\n",
    "                \n",
    "                # Create input features\n",
    "                behaviors = torch.zeros(batch_size, dataset.n_behaviors, device=device)\n",
    "                for i, item in enumerate(items):\n",
    "                    for j, mat in enumerate(dataset.trn_mats):\n",
    "                        behaviors[i, j] = float(mat[user, item])\n",
    "                \n",
    "                x = torch.cat([\n",
    "                    behaviors,\n",
    "                    torch.zeros(batch_size, model.input_dim - behaviors.size(1), device=device)\n",
    "                ], dim=1)\n",
    "                \n",
    "                # Simplified adjacency matrix for evaluation\n",
    "                adj_matrix = torch.eye(batch_size, device=device)\n",
    "                graph_metrics = dataset.create_graph_metrics([user] * batch_size)\n",
    "                \n",
    "                try:\n",
    "                    predictions = model(x)\n",
    "                    predictions = predictions.cpu().numpy().flatten()\n",
    "                    \n",
    "                    # Store all scores\n",
    "                    for item, score in zip(items, predictions):\n",
    "                        data['all_scores'].append((item, score))\n",
    "                    \n",
    "                    # Sort items by score\n",
    "                    sorted_items = [x[0] for x in sorted(data['all_scores'], key=lambda x: x[1], reverse=True)]\n",
    "                    recommended_items = sorted_items[:k]\n",
    "                    \n",
    "                    # Calculate HR\n",
    "                    hit = any(pos_item in recommended_items for pos_item in data['pos'])\n",
    "                    hits.append(hit)\n",
    "                    \n",
    "                    # Calculate NDCG\n",
    "                    dcg = 0\n",
    "                    for i, item in enumerate(recommended_items):\n",
    "                        if item in data['pos']:\n",
    "                            dcg += 1 / np.log2(i + 2)\n",
    "                    idcg = sum(1 / np.log2(i + 2) for i in range(len(data['pos'])))  # Ideal DCG\n",
    "                    ndcg = dcg / (idcg if idcg > 0 else 0)  # Avoid division by zero\n",
    "                    ndcgs.append(ndcg)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error evaluating user {user}: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    hr = np.mean(hits) if hits else 0\n",
    "    ndcg = np.mean(ndcgs) if ndcgs else 0\n",
    "    \n",
    "    # Print detailed statistics\n",
    "    print(f\"\\nEvaluation Statistics:\")\n",
    "    print(f\"Total users evaluated: {len(hits)}\")\n",
    "    print(f\"Number of hits: {sum(hits)}\")\n",
    "    print(f\"Average HR@{k}: {hr:.4f}\")\n",
    "    print(f\"Average NDCG@{k}: {ndcg:.4f}\")\n",
    "    \n",
    "    return hr, ndcg\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Configuration\n",
    "    config = {\n",
    "        'hidden_dim': 64,\n",
    "        'input_dim': 64,  # Adjust based on your dataset\n",
    "        'output_dim': 1,  # For binary classification\n",
    "        'learning_rate': 0.001,\n",
    "        'weight_decay': 1e-6,\n",
    "        'dropout': 0.1,\n",
    "        'gradient_clip': 1.0,\n",
    "        'max_samples': USR,\n",
    "        'eval_k': TOP_N\n",
    "    }\n",
    "    \n",
    "    print(\"Initializing dataset...\")\n",
    "    dataset = MultiBehaviorDataset(max_users=USR)\n",
    "    train_data = dataset.prepare_train_instances(max_samples=config['max_samples'])\n",
    "    \n",
    "    print(f\"Using {len(train_data)} training instances\")\n",
    "\n",
    "    # Initialize NADE model\n",
    "    model = NADE(\n",
    "        input_dim=config['input_dim'],\n",
    "        hidden_dim=config['hidden_dim'],\n",
    "        output_dim=config['output_dim']\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "    print(\"Preparing training tensors...\")\n",
    "    users = torch.LongTensor(train_data[:, 0]).to(device)\n",
    "    items = torch.LongTensor(train_data[:, 1]).to(device)\n",
    "    labels = torch.FloatTensor(train_data[:, 2]).to(device)\n",
    "    behaviors = torch.FloatTensor(train_data[:, 3:]).to(device)\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    try:\n",
    "        model.train()\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        # Training\n",
    "        x = torch.cat([\n",
    "            behaviors,\n",
    "            torch.zeros(len(users), config['input_dim'] - behaviors.size(1), device=device)\n",
    "        ], dim=1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(x)\n",
    "        predictions = predictions.view(-1)\n",
    "        labels = labels.view(-1)\n",
    "        \n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), config['gradient_clip'])\n",
    "        optimizer.step()\n",
    "        \n",
    "        training_time = (datetime.now() - start_time).total_seconds()\n",
    "        print(f\"Training completed in {training_time:.2f}s\")\n",
    "        print(f\"Training loss: {loss.item():.4f}\")\n",
    "        \n",
    "        # Evaluation\n",
    "        print(\"\\nStarting evaluation...\")\n",
    "        eval_start_time = datetime.now()\n",
    "        \n",
    "        test_instances = dataset.get_test_instances()\n",
    "        hr, ndcg = evaluate_model(model, dataset, test_instances, k=config['eval_k'])\n",
    "        \n",
    "        eval_time = (datetime.now() - eval_start_time).total_seconds()\n",
    "        print(f\"Evaluation completed in {eval_time:.2f}s\")\n",
    "        print(f\"HR@{config['eval_k']}: {hr:.4f}\")\n",
    "        print(f\"NDCG@{config['eval_k']}: {ndcg:.4f}\")\n",
    "        \n",
    "        # Save results\n",
    "        results = {\n",
    "            'training_time': training_time,\n",
    "            'eval_time': eval_time,\n",
    "            'training_loss': loss.item(),\n",
    "            'hr': hr,\n",
    "            'ndcg': ndcg\n",
    "        }\n",
    "        \n",
    "        # Save to file\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        with open(f'results_{timestamp}.txt', 'w') as f:\n",
    "            for key, value in results.items():\n",
    "                f.write(f\"{key}: {value}\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during training: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # wholesome metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data for plotting\n",
    "models = [\n",
    "    \"GraphTransformer\", \"CF-UIcA\", \"ST-GCN\", \"NGCF\", \"NMTR\", \n",
    "    \"DIPN\", \"NGCF+M\", \"MBGCN\", \"MATN\", \"GNMR\", \n",
    "    \"GraphSAGE\", \"MFBias\", \"AutoRec\", \"NCF\", \"DMF\", \n",
    "    \"CDAE\", \"NADE\"\n",
    "]\n",
    "hr_values = [\n",
    "    0.9998, 0.5880, 0.6240, 0.6140, 0.6060, \n",
    "    0.6140, 0.6060, 0.6060, 0.6540, 0.6220, \n",
    "    0.6124, 0.6824, 0.8000, 0.6288, 0.6896, \n",
    "    0.6153, 0.5591\n",
    "]\n",
    "ndcg_values = [\n",
    "    0.8975, 0.2704, 0.2934, 0.2824, 0.2854, \n",
    "    0.2712, 0.2833, 0.2824, 0.2957, 0.2911, \n",
    "    0.2911, 0.5902, 0.5736, 0.2891, 0.6381, \n",
    "    0.2795, 0.4044\n",
    "]\n",
    "\n",
    "# Set up the bar chart\n",
    "x = np.arange(len(models))  # the label locations\n",
    "width = 0.25  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))  # Increase figure size\n",
    "bars1 = ax.bar(x - width/2, hr_values, width, label='HR@10', color='skyblue')\n",
    "bars2 = ax.bar(x + width/2, ndcg_values, width, label='NDCG@10', color='orange')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('HR@10 and NDCG@10 by Model')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)  # Add gridlines\n",
    "\n",
    "# Add value labels on top of the bars\n",
    "for bar in bars1 + bars2:\n",
    "    yval = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 4), ha='center', va='bottom')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data for plotting\n",
    "models = [\n",
    "    \"GraphTransformer\", \"CF-UIcA\", \"ST-GCN\", \"NGCF\", \"NMTR\", \n",
    "    \"DIPN\", \"NGCF+M\", \"MBGCN\", \"MATN\", \"GNMR\", \n",
    "    \"GraphSAGE\", \"MFBias\", \"AutoRec\", \"NCF\", \"DMF\", \n",
    "    \"CDAE\", \"NADE\"\n",
    "]\n",
    "hr_values = [\n",
    "    0.9988, 0.5880, 0.6240, 0.6140, 0.6060, \n",
    "    0.6140, 0.6060, 0.6060, 0.6540, 0.6220, \n",
    "    0.6124, 0.6824, 0.8000, 0.6288, 0.6896, \n",
    "    0.6153, 0.5591\n",
    "]\n",
    "ndcg_values = [\n",
    "   0.8959, 0.2704, 0.2934, 0.2824, 0.2854, \n",
    "    0.2712, 0.2833, 0.2824, 0.2957, 0.2911, \n",
    "    0.2911, 0.5902, 0.5736, 0.2891, 0.6381, \n",
    "    0.2795, 0.4044\n",
    "]\n",
    "\n",
    "# Set up the bar chart\n",
    "x = np.arange(len(models))  # the label locations\n",
    "width = 0.25  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))  # Increase figure size\n",
    "bars1 = ax.bar(x - width/2, hr_values, width, label='HR@10', color='skyblue')\n",
    "bars2 = ax.bar(x + width/2, ndcg_values, width, label='NDCG@10', color='orange')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('HR@10 and NDCG@10 by Model')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)  # Add gridlines\n",
    "\n",
    "# Add value labels on top of the bars\n",
    "for bar in bars1 + bars2:\n",
    "    yval = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 4), ha='center', va='bottom')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data for plotting\n",
    "models = [\n",
    "    \"GraphTransformer\", \"CF-UIcA\", \"ST-GCN\", \"NGCF\", \"NMTR\", \n",
    "    \"DIPN\", \"NGCF+M\", \"MBGCN\", \"MATN\", \"GNMR\", \n",
    "    \"GraphSAGE\", \"MFBias\", \"AutoRec\", \"NCF\", \"DMF\", \n",
    "    \"CDAE\", \"NADE\"\n",
    "]\n",
    "training_times = [\n",
    "    107.07, 1.35, 2.63, 2.37, 1.00, \n",
    "    0.97, 2.14, 2.47, 1.19, 1.74, \n",
    "    1.34, 0.77, 1.34, 6.86, 42.65, \n",
    "    28.50, 27.34\n",
    "]\n",
    "\n",
    "# Set up the bar chart\n",
    "x = np.arange(len(models))  # the label locations\n",
    "width = 0.4  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))  # Increase figure size\n",
    "bars = ax.bar(x, training_times, width, color='lightgreen')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Training Time (seconds)')\n",
    "ax.set_title('Training Time by Model')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models, rotation=45, ha='right')\n",
    "\n",
    "# Add value labels on top of the bars\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try bulk "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing dataset...\n",
      "Loading training data from: /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/\n",
      "Loading behavior: pv from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_pv\n",
      "Loading behavior: cart from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_cart\n",
      "Loading behavior: buy from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_buy\n",
      "Dataset dimensions: 21716 users, 7977 items\n",
      "Loading test data from: /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/tst_int\n",
      "Using 5000 test users\n",
      "Preparing training instances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yf/20z1hn994jd04q4kl0gpgh740000gn/T/ipykernel_34291/1679634088.py:38: DeprecationWarning: Please import `csr_matrix` from the `scipy.sparse` namespace; the `scipy.sparse.csr` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  mat = pickle.load(fs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 6000 training instances\n",
      "Using 6000 training instances\n",
      "\n",
      "Training and evaluating CF-UIcA...\n",
      "Epoch 1, Loss: 0.7255\n",
      "Epoch 2, Loss: 0.7031\n",
      "Epoch 3, Loss: 0.6825\n",
      "Epoch 4, Loss: 0.6633\n",
      "Epoch 5, Loss: 0.6456\n",
      "Epoch 6, Loss: 0.6290\n",
      "Epoch 7, Loss: 0.6133\n",
      "Epoch 8, Loss: 0.5985\n",
      "Epoch 9, Loss: 0.5845\n",
      "Epoch 10, Loss: 0.5710\n",
      "Training completed in 1.25s\n",
      "Preparing test instances...\n",
      "Generated 500000 test instances\n",
      "Evaluating 500000 instances in 16667 chunks...\n",
      "Processing chunk 1/16667\n",
      "Processing chunk 51/16667\n",
      "Processing chunk 101/16667\n",
      "Processing chunk 151/16667\n",
      "Processing chunk 201/16667\n",
      "Processing chunk 251/16667\n",
      "Processing chunk 301/16667\n",
      "Processing chunk 351/16667\n",
      "Processing chunk 401/16667\n",
      "Processing chunk 451/16667\n",
      "Processing chunk 501/16667\n",
      "Processing chunk 551/16667\n",
      "Processing chunk 601/16667\n",
      "Processing chunk 651/16667\n",
      "Processing chunk 701/16667\n",
      "Processing chunk 751/16667\n",
      "Processing chunk 801/16667\n",
      "Processing chunk 851/16667\n",
      "Processing chunk 901/16667\n",
      "Processing chunk 951/16667\n",
      "Processing chunk 1001/16667\n",
      "Processing chunk 1051/16667\n",
      "Processing chunk 1101/16667\n",
      "Processing chunk 1151/16667\n",
      "Processing chunk 1201/16667\n",
      "Processing chunk 1251/16667\n",
      "Processing chunk 1301/16667\n",
      "Processing chunk 1351/16667\n",
      "Processing chunk 1401/16667\n",
      "Processing chunk 1451/16667\n",
      "Processing chunk 1501/16667\n",
      "Processing chunk 1551/16667\n",
      "Processing chunk 1601/16667\n",
      "Processing chunk 1651/16667\n",
      "Processing chunk 1701/16667\n",
      "Processing chunk 1751/16667\n",
      "Processing chunk 1801/16667\n",
      "Processing chunk 1851/16667\n",
      "Processing chunk 1901/16667\n",
      "Processing chunk 1951/16667\n",
      "Processing chunk 2001/16667\n",
      "Processing chunk 2051/16667\n",
      "Processing chunk 2101/16667\n",
      "Processing chunk 2151/16667\n",
      "Processing chunk 2201/16667\n",
      "Processing chunk 2251/16667\n",
      "Processing chunk 2301/16667\n",
      "Processing chunk 2351/16667\n",
      "Processing chunk 2401/16667\n",
      "Processing chunk 2451/16667\n",
      "Processing chunk 2501/16667\n",
      "Processing chunk 2551/16667\n",
      "Processing chunk 2601/16667\n",
      "Processing chunk 2651/16667\n",
      "Processing chunk 2701/16667\n",
      "Processing chunk 2751/16667\n",
      "Processing chunk 2801/16667\n",
      "Processing chunk 2851/16667\n",
      "Processing chunk 2901/16667\n",
      "Processing chunk 2951/16667\n",
      "Processing chunk 3001/16667\n",
      "Processing chunk 3051/16667\n",
      "Processing chunk 3101/16667\n",
      "Processing chunk 3151/16667\n",
      "Processing chunk 3201/16667\n",
      "Processing chunk 3251/16667\n",
      "Processing chunk 3301/16667\n",
      "Processing chunk 3351/16667\n",
      "Processing chunk 3401/16667\n",
      "Processing chunk 3451/16667\n",
      "Processing chunk 3501/16667\n",
      "Processing chunk 3551/16667\n",
      "Processing chunk 3601/16667\n",
      "Processing chunk 3651/16667\n",
      "Processing chunk 3701/16667\n",
      "Processing chunk 3751/16667\n",
      "Processing chunk 3801/16667\n",
      "Processing chunk 3851/16667\n",
      "Processing chunk 3901/16667\n",
      "Processing chunk 3951/16667\n",
      "Processing chunk 4001/16667\n",
      "Processing chunk 4051/16667\n",
      "Processing chunk 4101/16667\n",
      "Processing chunk 4151/16667\n",
      "Processing chunk 4201/16667\n",
      "Processing chunk 4251/16667\n",
      "Processing chunk 4301/16667\n",
      "Processing chunk 4351/16667\n",
      "Processing chunk 4401/16667\n",
      "Processing chunk 4451/16667\n",
      "Processing chunk 4501/16667\n",
      "Processing chunk 4551/16667\n",
      "Processing chunk 4601/16667\n",
      "Processing chunk 4651/16667\n",
      "Processing chunk 4701/16667\n",
      "Processing chunk 4751/16667\n",
      "Processing chunk 4801/16667\n",
      "Processing chunk 4851/16667\n",
      "Processing chunk 4901/16667\n",
      "Processing chunk 4951/16667\n",
      "Processing chunk 5001/16667\n",
      "Processing chunk 5051/16667\n",
      "Processing chunk 5101/16667\n",
      "Processing chunk 5151/16667\n",
      "Processing chunk 5201/16667\n",
      "Processing chunk 5251/16667\n",
      "Processing chunk 5301/16667\n",
      "Processing chunk 5351/16667\n",
      "Processing chunk 5401/16667\n",
      "Processing chunk 5451/16667\n",
      "Processing chunk 5501/16667\n",
      "Processing chunk 5551/16667\n",
      "Processing chunk 5601/16667\n",
      "Processing chunk 5651/16667\n",
      "Processing chunk 5701/16667\n",
      "Processing chunk 5751/16667\n",
      "Processing chunk 5801/16667\n",
      "Processing chunk 5851/16667\n",
      "Processing chunk 5901/16667\n",
      "Processing chunk 5951/16667\n",
      "Processing chunk 6001/16667\n",
      "Processing chunk 6051/16667\n",
      "Processing chunk 6101/16667\n",
      "Processing chunk 6151/16667\n",
      "Processing chunk 6201/16667\n",
      "Processing chunk 6251/16667\n",
      "Processing chunk 6301/16667\n",
      "Processing chunk 6351/16667\n",
      "Processing chunk 6401/16667\n",
      "Processing chunk 6451/16667\n",
      "Processing chunk 6501/16667\n",
      "Processing chunk 6551/16667\n",
      "Processing chunk 6601/16667\n",
      "Processing chunk 6651/16667\n",
      "Processing chunk 6701/16667\n",
      "Processing chunk 6751/16667\n",
      "Processing chunk 6801/16667\n",
      "Processing chunk 6851/16667\n",
      "Processing chunk 6901/16667\n",
      "Processing chunk 6951/16667\n",
      "Processing chunk 7001/16667\n",
      "Processing chunk 7051/16667\n",
      "Processing chunk 7101/16667\n",
      "Processing chunk 7151/16667\n",
      "Processing chunk 7201/16667\n",
      "Processing chunk 7251/16667\n",
      "Processing chunk 7301/16667\n",
      "Processing chunk 7351/16667\n",
      "Processing chunk 7401/16667\n",
      "Processing chunk 7451/16667\n",
      "Processing chunk 7501/16667\n",
      "Processing chunk 7551/16667\n",
      "Processing chunk 7601/16667\n",
      "Processing chunk 7651/16667\n",
      "Processing chunk 7701/16667\n",
      "Processing chunk 7751/16667\n",
      "Processing chunk 7801/16667\n",
      "Processing chunk 7851/16667\n",
      "Processing chunk 7901/16667\n",
      "Processing chunk 7951/16667\n",
      "Processing chunk 8001/16667\n",
      "Processing chunk 8051/16667\n",
      "Processing chunk 8101/16667\n",
      "Processing chunk 8151/16667\n",
      "Processing chunk 8201/16667\n",
      "Processing chunk 8251/16667\n",
      "Processing chunk 8301/16667\n",
      "Processing chunk 8351/16667\n",
      "Processing chunk 8401/16667\n",
      "Processing chunk 8451/16667\n",
      "Processing chunk 8501/16667\n",
      "Processing chunk 8551/16667\n",
      "Processing chunk 8601/16667\n",
      "Processing chunk 8651/16667\n",
      "Processing chunk 8701/16667\n",
      "Processing chunk 8751/16667\n",
      "Processing chunk 8801/16667\n",
      "Processing chunk 8851/16667\n",
      "Processing chunk 8901/16667\n",
      "Processing chunk 8951/16667\n",
      "Processing chunk 9001/16667\n",
      "Processing chunk 9051/16667\n",
      "Processing chunk 9101/16667\n",
      "Processing chunk 9151/16667\n",
      "Processing chunk 9201/16667\n",
      "Processing chunk 9251/16667\n",
      "Processing chunk 9301/16667\n",
      "Processing chunk 9351/16667\n",
      "Processing chunk 9401/16667\n",
      "Processing chunk 9451/16667\n",
      "Processing chunk 9501/16667\n",
      "Processing chunk 9551/16667\n",
      "Processing chunk 9601/16667\n",
      "Processing chunk 9651/16667\n",
      "Processing chunk 9701/16667\n",
      "Processing chunk 9751/16667\n",
      "Processing chunk 9801/16667\n",
      "Processing chunk 9851/16667\n",
      "Processing chunk 9901/16667\n",
      "Processing chunk 9951/16667\n",
      "Processing chunk 10001/16667\n",
      "Processing chunk 10051/16667\n",
      "Processing chunk 10101/16667\n",
      "Processing chunk 10151/16667\n",
      "Processing chunk 10201/16667\n",
      "Processing chunk 10251/16667\n",
      "Processing chunk 10301/16667\n",
      "Processing chunk 10351/16667\n",
      "Processing chunk 10401/16667\n",
      "Processing chunk 10451/16667\n",
      "Processing chunk 10501/16667\n",
      "Processing chunk 10551/16667\n",
      "Processing chunk 10601/16667\n",
      "Processing chunk 10651/16667\n",
      "Processing chunk 10701/16667\n",
      "Processing chunk 10751/16667\n",
      "Processing chunk 10801/16667\n",
      "Processing chunk 10851/16667\n",
      "Processing chunk 10901/16667\n",
      "Processing chunk 10951/16667\n",
      "Processing chunk 11001/16667\n",
      "Processing chunk 11051/16667\n",
      "Processing chunk 11101/16667\n",
      "Processing chunk 11151/16667\n",
      "Processing chunk 11201/16667\n",
      "Processing chunk 11251/16667\n",
      "Processing chunk 11301/16667\n",
      "Processing chunk 11351/16667\n",
      "Processing chunk 11401/16667\n",
      "Processing chunk 11451/16667\n",
      "Processing chunk 11501/16667\n",
      "Processing chunk 11551/16667\n",
      "Processing chunk 11601/16667\n",
      "Processing chunk 11651/16667\n",
      "Processing chunk 11701/16667\n",
      "Processing chunk 11751/16667\n",
      "Processing chunk 11801/16667\n",
      "Processing chunk 11851/16667\n",
      "Processing chunk 11901/16667\n",
      "Processing chunk 11951/16667\n",
      "Processing chunk 12001/16667\n",
      "Processing chunk 12051/16667\n",
      "Processing chunk 12101/16667\n",
      "Processing chunk 12151/16667\n",
      "Processing chunk 12201/16667\n",
      "Processing chunk 12251/16667\n",
      "Processing chunk 12301/16667\n",
      "Processing chunk 12351/16667\n",
      "Processing chunk 12401/16667\n",
      "Processing chunk 12451/16667\n",
      "Processing chunk 12501/16667\n",
      "Processing chunk 12551/16667\n",
      "Processing chunk 12601/16667\n",
      "Processing chunk 12651/16667\n",
      "Processing chunk 12701/16667\n",
      "Processing chunk 12751/16667\n",
      "Processing chunk 12801/16667\n",
      "Processing chunk 12851/16667\n",
      "Processing chunk 12901/16667\n",
      "Processing chunk 12951/16667\n",
      "Processing chunk 13001/16667\n",
      "Processing chunk 13051/16667\n",
      "Processing chunk 13101/16667\n",
      "Processing chunk 13151/16667\n",
      "Processing chunk 13201/16667\n",
      "Processing chunk 13251/16667\n",
      "Processing chunk 13301/16667\n",
      "Processing chunk 13351/16667\n",
      "Processing chunk 13401/16667\n",
      "Processing chunk 13451/16667\n",
      "Processing chunk 13501/16667\n",
      "Processing chunk 13551/16667\n",
      "Processing chunk 13601/16667\n",
      "Processing chunk 13651/16667\n",
      "Processing chunk 13701/16667\n",
      "Processing chunk 13751/16667\n",
      "Processing chunk 13801/16667\n",
      "Processing chunk 13851/16667\n",
      "Processing chunk 13901/16667\n",
      "Processing chunk 13951/16667\n",
      "Processing chunk 14001/16667\n",
      "Processing chunk 14051/16667\n",
      "Processing chunk 14101/16667\n",
      "Processing chunk 14151/16667\n",
      "Processing chunk 14201/16667\n",
      "Processing chunk 14251/16667\n",
      "Processing chunk 14301/16667\n",
      "Processing chunk 14351/16667\n",
      "Processing chunk 14401/16667\n",
      "Processing chunk 14451/16667\n",
      "Processing chunk 14501/16667\n",
      "Processing chunk 14551/16667\n",
      "Processing chunk 14601/16667\n",
      "Processing chunk 14651/16667\n",
      "Processing chunk 14701/16667\n",
      "Processing chunk 14751/16667\n",
      "Processing chunk 14801/16667\n",
      "Processing chunk 14851/16667\n",
      "Processing chunk 14901/16667\n",
      "Processing chunk 14951/16667\n",
      "Processing chunk 15001/16667\n",
      "Processing chunk 15051/16667\n",
      "Processing chunk 15101/16667\n",
      "Processing chunk 15151/16667\n",
      "Processing chunk 15201/16667\n",
      "Processing chunk 15251/16667\n",
      "Processing chunk 15301/16667\n",
      "Processing chunk 15351/16667\n",
      "Processing chunk 15401/16667\n",
      "Processing chunk 15451/16667\n",
      "Processing chunk 15501/16667\n",
      "Processing chunk 15551/16667\n",
      "Processing chunk 15601/16667\n",
      "Processing chunk 15651/16667\n",
      "Processing chunk 15701/16667\n",
      "Processing chunk 15751/16667\n",
      "Processing chunk 15801/16667\n",
      "Processing chunk 15851/16667\n",
      "Processing chunk 15901/16667\n",
      "Processing chunk 15951/16667\n",
      "Processing chunk 16001/16667\n",
      "Processing chunk 16051/16667\n",
      "Processing chunk 16101/16667\n",
      "Processing chunk 16151/16667\n",
      "Processing chunk 16201/16667\n",
      "Processing chunk 16251/16667\n",
      "Processing chunk 16301/16667\n",
      "Processing chunk 16351/16667\n",
      "Processing chunk 16401/16667\n",
      "Processing chunk 16451/16667\n",
      "Processing chunk 16501/16667\n",
      "Processing chunk 16551/16667\n",
      "Processing chunk 16601/16667\n",
      "Processing chunk 16651/16667\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 5000\n",
      "Number of hits: 4484\n",
      "Average HR@20: 0.8968\n",
      "Average NDCG@20: 0.3429\n",
      "\n",
      "Training and evaluating ST-GCN...\n",
      "Epoch 1, Loss: 0.6772\n",
      "Epoch 2, Loss: 0.5347\n",
      "Epoch 3, Loss: 0.4552\n",
      "Epoch 4, Loss: 0.3991\n",
      "Epoch 5, Loss: 0.3508\n",
      "Epoch 6, Loss: 0.3074\n",
      "Epoch 7, Loss: 0.2691\n",
      "Epoch 8, Loss: 0.2356\n",
      "Epoch 9, Loss: 0.2058\n",
      "Epoch 10, Loss: 0.1787\n",
      "Training completed in 2.02s\n",
      "Preparing test instances...\n",
      "Generated 500000 test instances\n",
      "Evaluating 500000 instances in 16667 chunks...\n",
      "Processing chunk 1/16667\n",
      "Processing chunk 51/16667\n",
      "Processing chunk 101/16667\n",
      "Processing chunk 151/16667\n",
      "Processing chunk 201/16667\n",
      "Processing chunk 251/16667\n",
      "Processing chunk 301/16667\n",
      "Processing chunk 351/16667\n",
      "Processing chunk 401/16667\n",
      "Processing chunk 451/16667\n",
      "Processing chunk 501/16667\n",
      "Processing chunk 551/16667\n",
      "Processing chunk 601/16667\n",
      "Processing chunk 651/16667\n",
      "Processing chunk 701/16667\n",
      "Processing chunk 751/16667\n",
      "Processing chunk 801/16667\n",
      "Processing chunk 851/16667\n",
      "Processing chunk 901/16667\n",
      "Processing chunk 951/16667\n",
      "Processing chunk 1001/16667\n",
      "Processing chunk 1051/16667\n",
      "Processing chunk 1101/16667\n",
      "Processing chunk 1151/16667\n",
      "Processing chunk 1201/16667\n",
      "Processing chunk 1251/16667\n",
      "Processing chunk 1301/16667\n",
      "Processing chunk 1351/16667\n",
      "Processing chunk 1401/16667\n",
      "Processing chunk 1451/16667\n",
      "Processing chunk 1501/16667\n",
      "Processing chunk 1551/16667\n",
      "Processing chunk 1601/16667\n",
      "Processing chunk 1651/16667\n",
      "Processing chunk 1701/16667\n",
      "Processing chunk 1751/16667\n",
      "Processing chunk 1801/16667\n",
      "Processing chunk 1851/16667\n",
      "Processing chunk 1901/16667\n",
      "Processing chunk 1951/16667\n",
      "Processing chunk 2001/16667\n",
      "Processing chunk 2051/16667\n",
      "Processing chunk 2101/16667\n",
      "Processing chunk 2151/16667\n",
      "Processing chunk 2201/16667\n",
      "Processing chunk 2251/16667\n",
      "Processing chunk 2301/16667\n",
      "Processing chunk 2351/16667\n",
      "Processing chunk 2401/16667\n",
      "Processing chunk 2451/16667\n",
      "Processing chunk 2501/16667\n",
      "Processing chunk 2551/16667\n",
      "Processing chunk 2601/16667\n",
      "Processing chunk 2651/16667\n",
      "Processing chunk 2701/16667\n",
      "Processing chunk 2751/16667\n",
      "Processing chunk 2801/16667\n",
      "Processing chunk 2851/16667\n",
      "Processing chunk 2901/16667\n",
      "Processing chunk 2951/16667\n",
      "Processing chunk 3001/16667\n",
      "Processing chunk 3051/16667\n",
      "Processing chunk 3101/16667\n",
      "Processing chunk 3151/16667\n",
      "Processing chunk 3201/16667\n",
      "Processing chunk 3251/16667\n",
      "Processing chunk 3301/16667\n",
      "Processing chunk 3351/16667\n",
      "Processing chunk 3401/16667\n",
      "Processing chunk 3451/16667\n",
      "Processing chunk 3501/16667\n",
      "Processing chunk 3551/16667\n",
      "Processing chunk 3601/16667\n",
      "Processing chunk 3651/16667\n",
      "Processing chunk 3701/16667\n",
      "Processing chunk 3751/16667\n",
      "Processing chunk 3801/16667\n",
      "Processing chunk 3851/16667\n",
      "Processing chunk 3901/16667\n",
      "Processing chunk 3951/16667\n",
      "Processing chunk 4001/16667\n",
      "Processing chunk 4051/16667\n",
      "Processing chunk 4101/16667\n",
      "Processing chunk 4151/16667\n",
      "Processing chunk 4201/16667\n",
      "Processing chunk 4251/16667\n",
      "Processing chunk 4301/16667\n",
      "Processing chunk 4351/16667\n",
      "Processing chunk 4401/16667\n",
      "Processing chunk 4451/16667\n",
      "Processing chunk 4501/16667\n",
      "Processing chunk 4551/16667\n",
      "Processing chunk 4601/16667\n",
      "Processing chunk 4651/16667\n",
      "Processing chunk 4701/16667\n",
      "Processing chunk 4751/16667\n",
      "Processing chunk 4801/16667\n",
      "Processing chunk 4851/16667\n",
      "Processing chunk 4901/16667\n",
      "Processing chunk 4951/16667\n",
      "Processing chunk 5001/16667\n",
      "Processing chunk 5051/16667\n",
      "Processing chunk 5101/16667\n",
      "Processing chunk 5151/16667\n",
      "Processing chunk 5201/16667\n",
      "Processing chunk 5251/16667\n",
      "Processing chunk 5301/16667\n",
      "Processing chunk 5351/16667\n",
      "Processing chunk 5401/16667\n",
      "Processing chunk 5451/16667\n",
      "Processing chunk 5501/16667\n",
      "Processing chunk 5551/16667\n",
      "Processing chunk 5601/16667\n",
      "Processing chunk 5651/16667\n",
      "Processing chunk 5701/16667\n",
      "Processing chunk 5751/16667\n",
      "Processing chunk 5801/16667\n",
      "Processing chunk 5851/16667\n",
      "Processing chunk 5901/16667\n",
      "Processing chunk 5951/16667\n",
      "Processing chunk 6001/16667\n",
      "Processing chunk 6051/16667\n",
      "Processing chunk 6101/16667\n",
      "Processing chunk 6151/16667\n",
      "Processing chunk 6201/16667\n",
      "Processing chunk 6251/16667\n",
      "Processing chunk 6301/16667\n",
      "Processing chunk 6351/16667\n",
      "Processing chunk 6401/16667\n",
      "Processing chunk 6451/16667\n",
      "Processing chunk 6501/16667\n",
      "Processing chunk 6551/16667\n",
      "Processing chunk 6601/16667\n",
      "Processing chunk 6651/16667\n",
      "Processing chunk 6701/16667\n",
      "Processing chunk 6751/16667\n",
      "Processing chunk 6801/16667\n",
      "Processing chunk 6851/16667\n",
      "Processing chunk 6901/16667\n",
      "Processing chunk 6951/16667\n",
      "Processing chunk 7001/16667\n",
      "Processing chunk 7051/16667\n",
      "Processing chunk 7101/16667\n",
      "Processing chunk 7151/16667\n",
      "Processing chunk 7201/16667\n",
      "Processing chunk 7251/16667\n",
      "Processing chunk 7301/16667\n",
      "Processing chunk 7351/16667\n",
      "Processing chunk 7401/16667\n",
      "Processing chunk 7451/16667\n",
      "Processing chunk 7501/16667\n",
      "Processing chunk 7551/16667\n",
      "Processing chunk 7601/16667\n",
      "Processing chunk 7651/16667\n",
      "Processing chunk 7701/16667\n",
      "Processing chunk 7751/16667\n",
      "Processing chunk 7801/16667\n",
      "Processing chunk 7851/16667\n",
      "Processing chunk 7901/16667\n",
      "Processing chunk 7951/16667\n",
      "Processing chunk 8001/16667\n",
      "Processing chunk 8051/16667\n",
      "Processing chunk 8101/16667\n",
      "Processing chunk 8151/16667\n",
      "Processing chunk 8201/16667\n",
      "Processing chunk 8251/16667\n",
      "Processing chunk 8301/16667\n",
      "Processing chunk 8351/16667\n",
      "Processing chunk 8401/16667\n",
      "Processing chunk 8451/16667\n",
      "Processing chunk 8501/16667\n",
      "Processing chunk 8551/16667\n",
      "Processing chunk 8601/16667\n",
      "Processing chunk 8651/16667\n",
      "Processing chunk 8701/16667\n",
      "Processing chunk 8751/16667\n",
      "Processing chunk 8801/16667\n",
      "Processing chunk 8851/16667\n",
      "Processing chunk 8901/16667\n",
      "Processing chunk 8951/16667\n",
      "Processing chunk 9001/16667\n",
      "Processing chunk 9051/16667\n",
      "Processing chunk 9101/16667\n",
      "Processing chunk 9151/16667\n",
      "Processing chunk 9201/16667\n",
      "Processing chunk 9251/16667\n",
      "Processing chunk 9301/16667\n",
      "Processing chunk 9351/16667\n",
      "Processing chunk 9401/16667\n",
      "Processing chunk 9451/16667\n",
      "Processing chunk 9501/16667\n",
      "Processing chunk 9551/16667\n",
      "Processing chunk 9601/16667\n",
      "Processing chunk 9651/16667\n",
      "Processing chunk 9701/16667\n",
      "Processing chunk 9751/16667\n",
      "Processing chunk 9801/16667\n",
      "Processing chunk 9851/16667\n",
      "Processing chunk 9901/16667\n",
      "Processing chunk 9951/16667\n",
      "Processing chunk 10001/16667\n",
      "Processing chunk 10051/16667\n",
      "Processing chunk 10101/16667\n",
      "Processing chunk 10151/16667\n",
      "Processing chunk 10201/16667\n",
      "Processing chunk 10251/16667\n",
      "Processing chunk 10301/16667\n",
      "Processing chunk 10351/16667\n",
      "Processing chunk 10401/16667\n",
      "Processing chunk 10451/16667\n",
      "Processing chunk 10501/16667\n",
      "Processing chunk 10551/16667\n",
      "Processing chunk 10601/16667\n",
      "Processing chunk 10651/16667\n",
      "Processing chunk 10701/16667\n",
      "Processing chunk 10751/16667\n",
      "Processing chunk 10801/16667\n",
      "Processing chunk 10851/16667\n",
      "Processing chunk 10901/16667\n",
      "Processing chunk 10951/16667\n",
      "Processing chunk 11001/16667\n",
      "Processing chunk 11051/16667\n",
      "Processing chunk 11101/16667\n",
      "Processing chunk 11151/16667\n",
      "Processing chunk 11201/16667\n",
      "Processing chunk 11251/16667\n",
      "Processing chunk 11301/16667\n",
      "Processing chunk 11351/16667\n",
      "Processing chunk 11401/16667\n",
      "Processing chunk 11451/16667\n",
      "Processing chunk 11501/16667\n",
      "Processing chunk 11551/16667\n",
      "Processing chunk 11601/16667\n",
      "Processing chunk 11651/16667\n",
      "Processing chunk 11701/16667\n",
      "Processing chunk 11751/16667\n",
      "Processing chunk 11801/16667\n",
      "Processing chunk 11851/16667\n",
      "Processing chunk 11901/16667\n",
      "Processing chunk 11951/16667\n",
      "Processing chunk 12001/16667\n",
      "Processing chunk 12051/16667\n",
      "Processing chunk 12101/16667\n",
      "Processing chunk 12151/16667\n",
      "Processing chunk 12201/16667\n",
      "Processing chunk 12251/16667\n",
      "Processing chunk 12301/16667\n",
      "Processing chunk 12351/16667\n",
      "Processing chunk 12401/16667\n",
      "Processing chunk 12451/16667\n",
      "Processing chunk 12501/16667\n",
      "Processing chunk 12551/16667\n",
      "Processing chunk 12601/16667\n",
      "Processing chunk 12651/16667\n",
      "Processing chunk 12701/16667\n",
      "Processing chunk 12751/16667\n",
      "Processing chunk 12801/16667\n",
      "Processing chunk 12851/16667\n",
      "Processing chunk 12901/16667\n",
      "Processing chunk 12951/16667\n",
      "Processing chunk 13001/16667\n",
      "Processing chunk 13051/16667\n",
      "Processing chunk 13101/16667\n",
      "Processing chunk 13151/16667\n",
      "Processing chunk 13201/16667\n",
      "Processing chunk 13251/16667\n",
      "Processing chunk 13301/16667\n",
      "Processing chunk 13351/16667\n",
      "Processing chunk 13401/16667\n",
      "Processing chunk 13451/16667\n",
      "Processing chunk 13501/16667\n",
      "Processing chunk 13551/16667\n",
      "Processing chunk 13601/16667\n",
      "Processing chunk 13651/16667\n",
      "Processing chunk 13701/16667\n",
      "Processing chunk 13751/16667\n",
      "Processing chunk 13801/16667\n",
      "Processing chunk 13851/16667\n",
      "Processing chunk 13901/16667\n",
      "Processing chunk 13951/16667\n",
      "Processing chunk 14001/16667\n",
      "Processing chunk 14051/16667\n",
      "Processing chunk 14101/16667\n",
      "Processing chunk 14151/16667\n",
      "Processing chunk 14201/16667\n",
      "Processing chunk 14251/16667\n",
      "Processing chunk 14301/16667\n",
      "Processing chunk 14351/16667\n",
      "Processing chunk 14401/16667\n",
      "Processing chunk 14451/16667\n",
      "Processing chunk 14501/16667\n",
      "Processing chunk 14551/16667\n",
      "Processing chunk 14601/16667\n",
      "Processing chunk 14651/16667\n",
      "Processing chunk 14701/16667\n",
      "Processing chunk 14751/16667\n",
      "Processing chunk 14801/16667\n",
      "Processing chunk 14851/16667\n",
      "Processing chunk 14901/16667\n",
      "Processing chunk 14951/16667\n",
      "Processing chunk 15001/16667\n",
      "Processing chunk 15051/16667\n",
      "Processing chunk 15101/16667\n",
      "Processing chunk 15151/16667\n",
      "Processing chunk 15201/16667\n",
      "Processing chunk 15251/16667\n",
      "Processing chunk 15301/16667\n",
      "Processing chunk 15351/16667\n",
      "Processing chunk 15401/16667\n",
      "Processing chunk 15451/16667\n",
      "Processing chunk 15501/16667\n",
      "Processing chunk 15551/16667\n",
      "Processing chunk 15601/16667\n",
      "Processing chunk 15651/16667\n",
      "Processing chunk 15701/16667\n",
      "Processing chunk 15751/16667\n",
      "Processing chunk 15801/16667\n",
      "Processing chunk 15851/16667\n",
      "Processing chunk 15901/16667\n",
      "Processing chunk 15951/16667\n",
      "Processing chunk 16001/16667\n",
      "Processing chunk 16051/16667\n",
      "Processing chunk 16101/16667\n",
      "Processing chunk 16151/16667\n",
      "Processing chunk 16201/16667\n",
      "Processing chunk 16251/16667\n",
      "Processing chunk 16301/16667\n",
      "Processing chunk 16351/16667\n",
      "Processing chunk 16401/16667\n",
      "Processing chunk 16451/16667\n",
      "Processing chunk 16501/16667\n",
      "Processing chunk 16551/16667\n",
      "Processing chunk 16601/16667\n",
      "Processing chunk 16651/16667\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 5000\n",
      "Number of hits: 4414\n",
      "Average HR@20: 0.8828\n",
      "Average NDCG@20: 0.3528\n",
      "\n",
      "Training and evaluating NGCF...\n",
      "Epoch 1, Loss: 0.7055\n",
      "Epoch 2, Loss: 0.5481\n",
      "Epoch 3, Loss: 0.4607\n",
      "Epoch 4, Loss: 0.4026\n",
      "Epoch 5, Loss: 0.3535\n",
      "Epoch 6, Loss: 0.3090\n",
      "Epoch 7, Loss: 0.2694\n",
      "Epoch 8, Loss: 0.2350\n",
      "Epoch 9, Loss: 0.2048\n",
      "Epoch 10, Loss: 0.1777\n",
      "Training completed in 1.85s\n",
      "Preparing test instances...\n",
      "Generated 500000 test instances\n",
      "Evaluating 500000 instances in 16667 chunks...\n",
      "Processing chunk 1/16667\n",
      "Processing chunk 51/16667\n",
      "Processing chunk 101/16667\n",
      "Processing chunk 151/16667\n",
      "Processing chunk 201/16667\n",
      "Processing chunk 251/16667\n",
      "Processing chunk 301/16667\n",
      "Processing chunk 351/16667\n",
      "Processing chunk 401/16667\n",
      "Processing chunk 451/16667\n",
      "Processing chunk 501/16667\n",
      "Processing chunk 551/16667\n",
      "Processing chunk 601/16667\n",
      "Processing chunk 651/16667\n",
      "Processing chunk 701/16667\n",
      "Processing chunk 751/16667\n",
      "Processing chunk 801/16667\n",
      "Processing chunk 851/16667\n",
      "Processing chunk 901/16667\n",
      "Processing chunk 951/16667\n",
      "Processing chunk 1001/16667\n",
      "Processing chunk 1051/16667\n",
      "Processing chunk 1101/16667\n",
      "Processing chunk 1151/16667\n",
      "Processing chunk 1201/16667\n",
      "Processing chunk 1251/16667\n",
      "Processing chunk 1301/16667\n",
      "Processing chunk 1351/16667\n",
      "Processing chunk 1401/16667\n",
      "Processing chunk 1451/16667\n",
      "Processing chunk 1501/16667\n",
      "Processing chunk 1551/16667\n",
      "Processing chunk 1601/16667\n",
      "Processing chunk 1651/16667\n",
      "Processing chunk 1701/16667\n",
      "Processing chunk 1751/16667\n",
      "Processing chunk 1801/16667\n",
      "Processing chunk 1851/16667\n",
      "Processing chunk 1901/16667\n",
      "Processing chunk 1951/16667\n",
      "Processing chunk 2001/16667\n",
      "Processing chunk 2051/16667\n",
      "Processing chunk 2101/16667\n",
      "Processing chunk 2151/16667\n",
      "Processing chunk 2201/16667\n",
      "Processing chunk 2251/16667\n",
      "Processing chunk 2301/16667\n",
      "Processing chunk 2351/16667\n",
      "Processing chunk 2401/16667\n",
      "Processing chunk 2451/16667\n",
      "Processing chunk 2501/16667\n",
      "Processing chunk 2551/16667\n",
      "Processing chunk 2601/16667\n",
      "Processing chunk 2651/16667\n",
      "Processing chunk 2701/16667\n",
      "Processing chunk 2751/16667\n",
      "Processing chunk 2801/16667\n",
      "Processing chunk 2851/16667\n",
      "Processing chunk 2901/16667\n",
      "Processing chunk 2951/16667\n",
      "Processing chunk 3001/16667\n",
      "Processing chunk 3051/16667\n",
      "Processing chunk 3101/16667\n",
      "Processing chunk 3151/16667\n",
      "Processing chunk 3201/16667\n",
      "Processing chunk 3251/16667\n",
      "Processing chunk 3301/16667\n",
      "Processing chunk 3351/16667\n",
      "Processing chunk 3401/16667\n",
      "Processing chunk 3451/16667\n",
      "Processing chunk 3501/16667\n",
      "Processing chunk 3551/16667\n",
      "Processing chunk 3601/16667\n",
      "Processing chunk 3651/16667\n",
      "Processing chunk 3701/16667\n",
      "Processing chunk 3751/16667\n",
      "Processing chunk 3801/16667\n",
      "Processing chunk 3851/16667\n",
      "Processing chunk 3901/16667\n",
      "Processing chunk 3951/16667\n",
      "Processing chunk 4001/16667\n",
      "Processing chunk 4051/16667\n",
      "Processing chunk 4101/16667\n",
      "Processing chunk 4151/16667\n",
      "Processing chunk 4201/16667\n",
      "Processing chunk 4251/16667\n",
      "Processing chunk 4301/16667\n",
      "Processing chunk 4351/16667\n",
      "Processing chunk 4401/16667\n",
      "Processing chunk 4451/16667\n",
      "Processing chunk 4501/16667\n",
      "Processing chunk 4551/16667\n",
      "Processing chunk 4601/16667\n",
      "Processing chunk 4651/16667\n",
      "Processing chunk 4701/16667\n",
      "Processing chunk 4751/16667\n",
      "Processing chunk 4801/16667\n",
      "Processing chunk 4851/16667\n",
      "Processing chunk 4901/16667\n",
      "Processing chunk 4951/16667\n",
      "Processing chunk 5001/16667\n",
      "Processing chunk 5051/16667\n",
      "Processing chunk 5101/16667\n",
      "Processing chunk 5151/16667\n",
      "Processing chunk 5201/16667\n",
      "Processing chunk 5251/16667\n",
      "Processing chunk 5301/16667\n",
      "Processing chunk 5351/16667\n",
      "Processing chunk 5401/16667\n",
      "Processing chunk 5451/16667\n",
      "Processing chunk 5501/16667\n",
      "Processing chunk 5551/16667\n",
      "Processing chunk 5601/16667\n",
      "Processing chunk 5651/16667\n",
      "Processing chunk 5701/16667\n",
      "Processing chunk 5751/16667\n",
      "Processing chunk 5801/16667\n",
      "Processing chunk 5851/16667\n",
      "Processing chunk 5901/16667\n",
      "Processing chunk 5951/16667\n",
      "Processing chunk 6001/16667\n",
      "Processing chunk 6051/16667\n",
      "Processing chunk 6101/16667\n",
      "Processing chunk 6151/16667\n",
      "Processing chunk 6201/16667\n",
      "Processing chunk 6251/16667\n",
      "Processing chunk 6301/16667\n",
      "Processing chunk 6351/16667\n",
      "Processing chunk 6401/16667\n",
      "Processing chunk 6451/16667\n",
      "Processing chunk 6501/16667\n",
      "Processing chunk 6551/16667\n",
      "Processing chunk 6601/16667\n",
      "Processing chunk 6651/16667\n",
      "Processing chunk 6701/16667\n",
      "Processing chunk 6751/16667\n",
      "Processing chunk 6801/16667\n",
      "Processing chunk 6851/16667\n",
      "Processing chunk 6901/16667\n",
      "Processing chunk 6951/16667\n",
      "Processing chunk 7001/16667\n",
      "Processing chunk 7051/16667\n",
      "Processing chunk 7101/16667\n",
      "Processing chunk 7151/16667\n",
      "Processing chunk 7201/16667\n",
      "Processing chunk 7251/16667\n",
      "Processing chunk 7301/16667\n",
      "Processing chunk 7351/16667\n",
      "Processing chunk 7401/16667\n",
      "Processing chunk 7451/16667\n",
      "Processing chunk 7501/16667\n",
      "Processing chunk 7551/16667\n",
      "Processing chunk 7601/16667\n",
      "Processing chunk 7651/16667\n",
      "Processing chunk 7701/16667\n",
      "Processing chunk 7751/16667\n",
      "Processing chunk 7801/16667\n",
      "Processing chunk 7851/16667\n",
      "Processing chunk 7901/16667\n",
      "Processing chunk 7951/16667\n",
      "Processing chunk 8001/16667\n",
      "Processing chunk 8051/16667\n",
      "Processing chunk 8101/16667\n",
      "Processing chunk 8151/16667\n",
      "Processing chunk 8201/16667\n",
      "Processing chunk 8251/16667\n",
      "Processing chunk 8301/16667\n",
      "Processing chunk 8351/16667\n",
      "Processing chunk 8401/16667\n",
      "Processing chunk 8451/16667\n",
      "Processing chunk 8501/16667\n",
      "Processing chunk 8551/16667\n",
      "Processing chunk 8601/16667\n",
      "Processing chunk 8651/16667\n",
      "Processing chunk 8701/16667\n",
      "Processing chunk 8751/16667\n",
      "Processing chunk 8801/16667\n",
      "Processing chunk 8851/16667\n",
      "Processing chunk 8901/16667\n",
      "Processing chunk 8951/16667\n",
      "Processing chunk 9001/16667\n",
      "Processing chunk 9051/16667\n",
      "Processing chunk 9101/16667\n",
      "Processing chunk 9151/16667\n",
      "Processing chunk 9201/16667\n",
      "Processing chunk 9251/16667\n",
      "Processing chunk 9301/16667\n",
      "Processing chunk 9351/16667\n",
      "Processing chunk 9401/16667\n",
      "Processing chunk 9451/16667\n",
      "Processing chunk 9501/16667\n",
      "Processing chunk 9551/16667\n",
      "Processing chunk 9601/16667\n",
      "Processing chunk 9651/16667\n",
      "Processing chunk 9701/16667\n",
      "Processing chunk 9751/16667\n",
      "Processing chunk 9801/16667\n",
      "Processing chunk 9851/16667\n",
      "Processing chunk 9901/16667\n",
      "Processing chunk 9951/16667\n",
      "Processing chunk 10001/16667\n",
      "Processing chunk 10051/16667\n",
      "Processing chunk 10101/16667\n",
      "Processing chunk 10151/16667\n",
      "Processing chunk 10201/16667\n",
      "Processing chunk 10251/16667\n",
      "Processing chunk 10301/16667\n",
      "Processing chunk 10351/16667\n",
      "Processing chunk 10401/16667\n",
      "Processing chunk 10451/16667\n",
      "Processing chunk 10501/16667\n",
      "Processing chunk 10551/16667\n",
      "Processing chunk 10601/16667\n",
      "Processing chunk 10651/16667\n",
      "Processing chunk 10701/16667\n",
      "Processing chunk 10751/16667\n",
      "Processing chunk 10801/16667\n",
      "Processing chunk 10851/16667\n",
      "Processing chunk 10901/16667\n",
      "Processing chunk 10951/16667\n",
      "Processing chunk 11001/16667\n",
      "Processing chunk 11051/16667\n",
      "Processing chunk 11101/16667\n",
      "Processing chunk 11151/16667\n",
      "Processing chunk 11201/16667\n",
      "Processing chunk 11251/16667\n",
      "Processing chunk 11301/16667\n",
      "Processing chunk 11351/16667\n",
      "Processing chunk 11401/16667\n",
      "Processing chunk 11451/16667\n",
      "Processing chunk 11501/16667\n",
      "Processing chunk 11551/16667\n",
      "Processing chunk 11601/16667\n",
      "Processing chunk 11651/16667\n",
      "Processing chunk 11701/16667\n",
      "Processing chunk 11751/16667\n",
      "Processing chunk 11801/16667\n",
      "Processing chunk 11851/16667\n",
      "Processing chunk 11901/16667\n",
      "Processing chunk 11951/16667\n",
      "Processing chunk 12001/16667\n",
      "Processing chunk 12051/16667\n",
      "Processing chunk 12101/16667\n",
      "Processing chunk 12151/16667\n",
      "Processing chunk 12201/16667\n",
      "Processing chunk 12251/16667\n",
      "Processing chunk 12301/16667\n",
      "Processing chunk 12351/16667\n",
      "Processing chunk 12401/16667\n",
      "Processing chunk 12451/16667\n",
      "Processing chunk 12501/16667\n",
      "Processing chunk 12551/16667\n",
      "Processing chunk 12601/16667\n",
      "Processing chunk 12651/16667\n",
      "Processing chunk 12701/16667\n",
      "Processing chunk 12751/16667\n",
      "Processing chunk 12801/16667\n",
      "Processing chunk 12851/16667\n",
      "Processing chunk 12901/16667\n",
      "Processing chunk 12951/16667\n",
      "Processing chunk 13001/16667\n",
      "Processing chunk 13051/16667\n",
      "Processing chunk 13101/16667\n",
      "Processing chunk 13151/16667\n",
      "Processing chunk 13201/16667\n",
      "Processing chunk 13251/16667\n",
      "Processing chunk 13301/16667\n",
      "Processing chunk 13351/16667\n",
      "Processing chunk 13401/16667\n",
      "Processing chunk 13451/16667\n",
      "Processing chunk 13501/16667\n",
      "Processing chunk 13551/16667\n",
      "Processing chunk 13601/16667\n",
      "Processing chunk 13651/16667\n",
      "Processing chunk 13701/16667\n",
      "Processing chunk 13751/16667\n",
      "Processing chunk 13801/16667\n",
      "Processing chunk 13851/16667\n",
      "Processing chunk 13901/16667\n",
      "Processing chunk 13951/16667\n",
      "Processing chunk 14001/16667\n",
      "Processing chunk 14051/16667\n",
      "Processing chunk 14101/16667\n",
      "Processing chunk 14151/16667\n",
      "Processing chunk 14201/16667\n",
      "Processing chunk 14251/16667\n",
      "Processing chunk 14301/16667\n",
      "Processing chunk 14351/16667\n",
      "Processing chunk 14401/16667\n",
      "Processing chunk 14451/16667\n",
      "Processing chunk 14501/16667\n",
      "Processing chunk 14551/16667\n",
      "Processing chunk 14601/16667\n",
      "Processing chunk 14651/16667\n",
      "Processing chunk 14701/16667\n",
      "Processing chunk 14751/16667\n",
      "Processing chunk 14801/16667\n",
      "Processing chunk 14851/16667\n",
      "Processing chunk 14901/16667\n",
      "Processing chunk 14951/16667\n",
      "Processing chunk 15001/16667\n",
      "Processing chunk 15051/16667\n",
      "Processing chunk 15101/16667\n",
      "Processing chunk 15151/16667\n",
      "Processing chunk 15201/16667\n",
      "Processing chunk 15251/16667\n",
      "Processing chunk 15301/16667\n",
      "Processing chunk 15351/16667\n",
      "Processing chunk 15401/16667\n",
      "Processing chunk 15451/16667\n",
      "Processing chunk 15501/16667\n",
      "Processing chunk 15551/16667\n",
      "Processing chunk 15601/16667\n",
      "Processing chunk 15651/16667\n",
      "Processing chunk 15701/16667\n",
      "Processing chunk 15751/16667\n",
      "Processing chunk 15801/16667\n",
      "Processing chunk 15851/16667\n",
      "Processing chunk 15901/16667\n",
      "Processing chunk 15951/16667\n",
      "Processing chunk 16001/16667\n",
      "Processing chunk 16051/16667\n",
      "Processing chunk 16101/16667\n",
      "Processing chunk 16151/16667\n",
      "Processing chunk 16201/16667\n",
      "Processing chunk 16251/16667\n",
      "Processing chunk 16301/16667\n",
      "Processing chunk 16351/16667\n",
      "Processing chunk 16401/16667\n",
      "Processing chunk 16451/16667\n",
      "Processing chunk 16501/16667\n",
      "Processing chunk 16551/16667\n",
      "Processing chunk 16601/16667\n",
      "Processing chunk 16651/16667\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 5000\n",
      "Number of hits: 4472\n",
      "Average HR@20: 0.8944\n",
      "Average NDCG@20: 0.3617\n",
      "\n",
      "Training and evaluating NMTR...\n",
      "Epoch 1, Loss: 0.7374\n",
      "Epoch 2, Loss: 0.7147\n",
      "Epoch 3, Loss: 0.6937\n",
      "Epoch 4, Loss: 0.6743\n",
      "Epoch 5, Loss: 0.6563\n",
      "Epoch 6, Loss: 0.6394\n",
      "Epoch 7, Loss: 0.6236\n",
      "Epoch 8, Loss: 0.6087\n",
      "Epoch 9, Loss: 0.5946\n",
      "Epoch 10, Loss: 0.5812\n",
      "Training completed in 0.89s\n",
      "Preparing test instances...\n",
      "Generated 500000 test instances\n",
      "Evaluating 500000 instances in 16667 chunks...\n",
      "Processing chunk 1/16667\n",
      "Processing chunk 51/16667\n",
      "Processing chunk 101/16667\n",
      "Processing chunk 151/16667\n",
      "Processing chunk 201/16667\n",
      "Processing chunk 251/16667\n",
      "Processing chunk 301/16667\n",
      "Processing chunk 351/16667\n",
      "Processing chunk 401/16667\n",
      "Processing chunk 451/16667\n",
      "Processing chunk 501/16667\n",
      "Processing chunk 551/16667\n",
      "Processing chunk 601/16667\n",
      "Processing chunk 651/16667\n",
      "Processing chunk 701/16667\n",
      "Processing chunk 751/16667\n",
      "Processing chunk 801/16667\n",
      "Processing chunk 851/16667\n",
      "Processing chunk 901/16667\n",
      "Processing chunk 951/16667\n",
      "Processing chunk 1001/16667\n",
      "Processing chunk 1051/16667\n",
      "Processing chunk 1101/16667\n",
      "Processing chunk 1151/16667\n",
      "Processing chunk 1201/16667\n",
      "Processing chunk 1251/16667\n",
      "Processing chunk 1301/16667\n",
      "Processing chunk 1351/16667\n",
      "Processing chunk 1401/16667\n",
      "Processing chunk 1451/16667\n",
      "Processing chunk 1501/16667\n",
      "Processing chunk 1551/16667\n",
      "Processing chunk 1601/16667\n",
      "Processing chunk 1651/16667\n",
      "Processing chunk 1701/16667\n",
      "Processing chunk 1751/16667\n",
      "Processing chunk 1801/16667\n",
      "Processing chunk 1851/16667\n",
      "Processing chunk 1901/16667\n",
      "Processing chunk 1951/16667\n",
      "Processing chunk 2001/16667\n",
      "Processing chunk 2051/16667\n",
      "Processing chunk 2101/16667\n",
      "Processing chunk 2151/16667\n",
      "Processing chunk 2201/16667\n",
      "Processing chunk 2251/16667\n",
      "Processing chunk 2301/16667\n",
      "Processing chunk 2351/16667\n",
      "Processing chunk 2401/16667\n",
      "Processing chunk 2451/16667\n",
      "Processing chunk 2501/16667\n",
      "Processing chunk 2551/16667\n",
      "Processing chunk 2601/16667\n",
      "Processing chunk 2651/16667\n",
      "Processing chunk 2701/16667\n",
      "Processing chunk 2751/16667\n",
      "Processing chunk 2801/16667\n",
      "Processing chunk 2851/16667\n",
      "Processing chunk 2901/16667\n",
      "Processing chunk 2951/16667\n",
      "Processing chunk 3001/16667\n",
      "Processing chunk 3051/16667\n",
      "Processing chunk 3101/16667\n",
      "Processing chunk 3151/16667\n",
      "Processing chunk 3201/16667\n",
      "Processing chunk 3251/16667\n",
      "Processing chunk 3301/16667\n",
      "Processing chunk 3351/16667\n",
      "Processing chunk 3401/16667\n",
      "Processing chunk 3451/16667\n",
      "Processing chunk 3501/16667\n",
      "Processing chunk 3551/16667\n",
      "Processing chunk 3601/16667\n",
      "Processing chunk 3651/16667\n",
      "Processing chunk 3701/16667\n",
      "Processing chunk 3751/16667\n",
      "Processing chunk 3801/16667\n",
      "Processing chunk 3851/16667\n",
      "Processing chunk 3901/16667\n",
      "Processing chunk 3951/16667\n",
      "Processing chunk 4001/16667\n",
      "Processing chunk 4051/16667\n",
      "Processing chunk 4101/16667\n",
      "Processing chunk 4151/16667\n",
      "Processing chunk 4201/16667\n",
      "Processing chunk 4251/16667\n",
      "Processing chunk 4301/16667\n",
      "Processing chunk 4351/16667\n",
      "Processing chunk 4401/16667\n",
      "Processing chunk 4451/16667\n",
      "Processing chunk 4501/16667\n",
      "Processing chunk 4551/16667\n",
      "Processing chunk 4601/16667\n",
      "Processing chunk 4651/16667\n",
      "Processing chunk 4701/16667\n",
      "Processing chunk 4751/16667\n",
      "Processing chunk 4801/16667\n",
      "Processing chunk 4851/16667\n",
      "Processing chunk 4901/16667\n",
      "Processing chunk 4951/16667\n",
      "Processing chunk 5001/16667\n",
      "Processing chunk 5051/16667\n",
      "Processing chunk 5101/16667\n",
      "Processing chunk 5151/16667\n",
      "Processing chunk 5201/16667\n",
      "Processing chunk 5251/16667\n",
      "Processing chunk 5301/16667\n",
      "Processing chunk 5351/16667\n",
      "Processing chunk 5401/16667\n",
      "Processing chunk 5451/16667\n",
      "Processing chunk 5501/16667\n",
      "Processing chunk 5551/16667\n",
      "Processing chunk 5601/16667\n",
      "Processing chunk 5651/16667\n",
      "Processing chunk 5701/16667\n",
      "Processing chunk 5751/16667\n",
      "Processing chunk 5801/16667\n",
      "Processing chunk 5851/16667\n",
      "Processing chunk 5901/16667\n",
      "Processing chunk 5951/16667\n",
      "Processing chunk 6001/16667\n",
      "Processing chunk 6051/16667\n",
      "Processing chunk 6101/16667\n",
      "Processing chunk 6151/16667\n",
      "Processing chunk 6201/16667\n",
      "Processing chunk 6251/16667\n",
      "Processing chunk 6301/16667\n",
      "Processing chunk 6351/16667\n",
      "Processing chunk 6401/16667\n",
      "Processing chunk 6451/16667\n",
      "Processing chunk 6501/16667\n",
      "Processing chunk 6551/16667\n",
      "Processing chunk 6601/16667\n",
      "Processing chunk 6651/16667\n",
      "Processing chunk 6701/16667\n",
      "Processing chunk 6751/16667\n",
      "Processing chunk 6801/16667\n",
      "Processing chunk 6851/16667\n",
      "Processing chunk 6901/16667\n",
      "Processing chunk 6951/16667\n",
      "Processing chunk 7001/16667\n",
      "Processing chunk 7051/16667\n",
      "Processing chunk 7101/16667\n",
      "Processing chunk 7151/16667\n",
      "Processing chunk 7201/16667\n",
      "Processing chunk 7251/16667\n",
      "Processing chunk 7301/16667\n",
      "Processing chunk 7351/16667\n",
      "Processing chunk 7401/16667\n",
      "Processing chunk 7451/16667\n",
      "Processing chunk 7501/16667\n",
      "Processing chunk 7551/16667\n",
      "Processing chunk 7601/16667\n",
      "Processing chunk 7651/16667\n",
      "Processing chunk 7701/16667\n",
      "Processing chunk 7751/16667\n",
      "Processing chunk 7801/16667\n",
      "Processing chunk 7851/16667\n",
      "Processing chunk 7901/16667\n",
      "Processing chunk 7951/16667\n",
      "Processing chunk 8001/16667\n",
      "Processing chunk 8051/16667\n",
      "Processing chunk 8101/16667\n",
      "Processing chunk 8151/16667\n",
      "Processing chunk 8201/16667\n",
      "Processing chunk 8251/16667\n",
      "Processing chunk 8301/16667\n",
      "Processing chunk 8351/16667\n",
      "Processing chunk 8401/16667\n",
      "Processing chunk 8451/16667\n",
      "Processing chunk 8501/16667\n",
      "Processing chunk 8551/16667\n",
      "Processing chunk 8601/16667\n",
      "Processing chunk 8651/16667\n",
      "Processing chunk 8701/16667\n",
      "Processing chunk 8751/16667\n",
      "Processing chunk 8801/16667\n",
      "Processing chunk 8851/16667\n",
      "Processing chunk 8901/16667\n",
      "Processing chunk 8951/16667\n",
      "Processing chunk 9001/16667\n",
      "Processing chunk 9051/16667\n",
      "Processing chunk 9101/16667\n",
      "Processing chunk 9151/16667\n",
      "Processing chunk 9201/16667\n",
      "Processing chunk 9251/16667\n",
      "Processing chunk 9301/16667\n",
      "Processing chunk 9351/16667\n",
      "Processing chunk 9401/16667\n",
      "Processing chunk 9451/16667\n",
      "Processing chunk 9501/16667\n",
      "Processing chunk 9551/16667\n",
      "Processing chunk 9601/16667\n",
      "Processing chunk 9651/16667\n",
      "Processing chunk 9701/16667\n",
      "Processing chunk 9751/16667\n",
      "Processing chunk 9801/16667\n",
      "Processing chunk 9851/16667\n",
      "Processing chunk 9901/16667\n",
      "Processing chunk 9951/16667\n",
      "Processing chunk 10001/16667\n",
      "Processing chunk 10051/16667\n",
      "Processing chunk 10101/16667\n",
      "Processing chunk 10151/16667\n",
      "Processing chunk 10201/16667\n",
      "Processing chunk 10251/16667\n",
      "Processing chunk 10301/16667\n",
      "Processing chunk 10351/16667\n",
      "Processing chunk 10401/16667\n",
      "Processing chunk 10451/16667\n",
      "Processing chunk 10501/16667\n",
      "Processing chunk 10551/16667\n",
      "Processing chunk 10601/16667\n",
      "Processing chunk 10651/16667\n",
      "Processing chunk 10701/16667\n",
      "Processing chunk 10751/16667\n",
      "Processing chunk 10801/16667\n",
      "Processing chunk 10851/16667\n",
      "Processing chunk 10901/16667\n",
      "Processing chunk 10951/16667\n",
      "Processing chunk 11001/16667\n",
      "Processing chunk 11051/16667\n",
      "Processing chunk 11101/16667\n",
      "Processing chunk 11151/16667\n",
      "Processing chunk 11201/16667\n",
      "Processing chunk 11251/16667\n",
      "Processing chunk 11301/16667\n",
      "Processing chunk 11351/16667\n",
      "Processing chunk 11401/16667\n",
      "Processing chunk 11451/16667\n",
      "Processing chunk 11501/16667\n",
      "Processing chunk 11551/16667\n",
      "Processing chunk 11601/16667\n",
      "Processing chunk 11651/16667\n",
      "Processing chunk 11701/16667\n",
      "Processing chunk 11751/16667\n",
      "Processing chunk 11801/16667\n",
      "Processing chunk 11851/16667\n",
      "Processing chunk 11901/16667\n",
      "Processing chunk 11951/16667\n",
      "Processing chunk 12001/16667\n",
      "Processing chunk 12051/16667\n",
      "Processing chunk 12101/16667\n",
      "Processing chunk 12151/16667\n",
      "Processing chunk 12201/16667\n",
      "Processing chunk 12251/16667\n",
      "Processing chunk 12301/16667\n",
      "Processing chunk 12351/16667\n",
      "Processing chunk 12401/16667\n",
      "Processing chunk 12451/16667\n",
      "Processing chunk 12501/16667\n",
      "Processing chunk 12551/16667\n",
      "Processing chunk 12601/16667\n",
      "Processing chunk 12651/16667\n",
      "Processing chunk 12701/16667\n",
      "Processing chunk 12751/16667\n",
      "Processing chunk 12801/16667\n",
      "Processing chunk 12851/16667\n",
      "Processing chunk 12901/16667\n",
      "Processing chunk 12951/16667\n",
      "Processing chunk 13001/16667\n",
      "Processing chunk 13051/16667\n",
      "Processing chunk 13101/16667\n",
      "Processing chunk 13151/16667\n",
      "Processing chunk 13201/16667\n",
      "Processing chunk 13251/16667\n",
      "Processing chunk 13301/16667\n",
      "Processing chunk 13351/16667\n",
      "Processing chunk 13401/16667\n",
      "Processing chunk 13451/16667\n",
      "Processing chunk 13501/16667\n",
      "Processing chunk 13551/16667\n",
      "Processing chunk 13601/16667\n",
      "Processing chunk 13651/16667\n",
      "Processing chunk 13701/16667\n",
      "Processing chunk 13751/16667\n",
      "Processing chunk 13801/16667\n",
      "Processing chunk 13851/16667\n",
      "Processing chunk 13901/16667\n",
      "Processing chunk 13951/16667\n",
      "Processing chunk 14001/16667\n",
      "Processing chunk 14051/16667\n",
      "Processing chunk 14101/16667\n",
      "Processing chunk 14151/16667\n",
      "Processing chunk 14201/16667\n",
      "Processing chunk 14251/16667\n",
      "Processing chunk 14301/16667\n",
      "Processing chunk 14351/16667\n",
      "Processing chunk 14401/16667\n",
      "Processing chunk 14451/16667\n",
      "Processing chunk 14501/16667\n",
      "Processing chunk 14551/16667\n",
      "Processing chunk 14601/16667\n",
      "Processing chunk 14651/16667\n",
      "Processing chunk 14701/16667\n",
      "Processing chunk 14751/16667\n",
      "Processing chunk 14801/16667\n",
      "Processing chunk 14851/16667\n",
      "Processing chunk 14901/16667\n",
      "Processing chunk 14951/16667\n",
      "Processing chunk 15001/16667\n",
      "Processing chunk 15051/16667\n",
      "Processing chunk 15101/16667\n",
      "Processing chunk 15151/16667\n",
      "Processing chunk 15201/16667\n",
      "Processing chunk 15251/16667\n",
      "Processing chunk 15301/16667\n",
      "Processing chunk 15351/16667\n",
      "Processing chunk 15401/16667\n",
      "Processing chunk 15451/16667\n",
      "Processing chunk 15501/16667\n",
      "Processing chunk 15551/16667\n",
      "Processing chunk 15601/16667\n",
      "Processing chunk 15651/16667\n",
      "Processing chunk 15701/16667\n",
      "Processing chunk 15751/16667\n",
      "Processing chunk 15801/16667\n",
      "Processing chunk 15851/16667\n",
      "Processing chunk 15901/16667\n",
      "Processing chunk 15951/16667\n",
      "Processing chunk 16001/16667\n",
      "Processing chunk 16051/16667\n",
      "Processing chunk 16101/16667\n",
      "Processing chunk 16151/16667\n",
      "Processing chunk 16201/16667\n",
      "Processing chunk 16251/16667\n",
      "Processing chunk 16301/16667\n",
      "Processing chunk 16351/16667\n",
      "Processing chunk 16401/16667\n",
      "Processing chunk 16451/16667\n",
      "Processing chunk 16501/16667\n",
      "Processing chunk 16551/16667\n",
      "Processing chunk 16601/16667\n",
      "Processing chunk 16651/16667\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 5000\n",
      "Number of hits: 4500\n",
      "Average HR@20: 0.9000\n",
      "Average NDCG@20: 0.3462\n",
      "\n",
      "Training and evaluating DIPN...\n",
      "Epoch 1, Loss: 0.7241\n",
      "Epoch 2, Loss: 0.7020\n",
      "Epoch 3, Loss: 0.6815\n",
      "Epoch 4, Loss: 0.6626\n",
      "Epoch 5, Loss: 0.6449\n",
      "Epoch 6, Loss: 0.6284\n",
      "Epoch 7, Loss: 0.6129\n",
      "Epoch 8, Loss: 0.5982\n",
      "Epoch 9, Loss: 0.5842\n",
      "Epoch 10, Loss: 0.5708\n",
      "Training completed in 0.88s\n",
      "Preparing test instances...\n",
      "Generated 500000 test instances\n",
      "Evaluating 500000 instances in 16667 chunks...\n",
      "Processing chunk 1/16667\n",
      "Processing chunk 51/16667\n",
      "Processing chunk 101/16667\n",
      "Processing chunk 151/16667\n",
      "Processing chunk 201/16667\n",
      "Processing chunk 251/16667\n",
      "Processing chunk 301/16667\n",
      "Processing chunk 351/16667\n",
      "Processing chunk 401/16667\n",
      "Processing chunk 451/16667\n",
      "Processing chunk 501/16667\n",
      "Processing chunk 551/16667\n",
      "Processing chunk 601/16667\n",
      "Processing chunk 651/16667\n",
      "Processing chunk 701/16667\n",
      "Processing chunk 751/16667\n",
      "Processing chunk 801/16667\n",
      "Processing chunk 851/16667\n",
      "Processing chunk 901/16667\n",
      "Processing chunk 951/16667\n",
      "Processing chunk 1001/16667\n",
      "Processing chunk 1051/16667\n",
      "Processing chunk 1101/16667\n",
      "Processing chunk 1151/16667\n",
      "Processing chunk 1201/16667\n",
      "Processing chunk 1251/16667\n",
      "Processing chunk 1301/16667\n",
      "Processing chunk 1351/16667\n",
      "Processing chunk 1401/16667\n",
      "Processing chunk 1451/16667\n",
      "Processing chunk 1501/16667\n",
      "Processing chunk 1551/16667\n",
      "Processing chunk 1601/16667\n",
      "Processing chunk 1651/16667\n",
      "Processing chunk 1701/16667\n",
      "Processing chunk 1751/16667\n",
      "Processing chunk 1801/16667\n",
      "Processing chunk 1851/16667\n",
      "Processing chunk 1901/16667\n",
      "Processing chunk 1951/16667\n",
      "Processing chunk 2001/16667\n",
      "Processing chunk 2051/16667\n",
      "Processing chunk 2101/16667\n",
      "Processing chunk 2151/16667\n",
      "Processing chunk 2201/16667\n",
      "Processing chunk 2251/16667\n",
      "Processing chunk 2301/16667\n",
      "Processing chunk 2351/16667\n",
      "Processing chunk 2401/16667\n",
      "Processing chunk 2451/16667\n",
      "Processing chunk 2501/16667\n",
      "Processing chunk 2551/16667\n",
      "Processing chunk 2601/16667\n",
      "Processing chunk 2651/16667\n",
      "Processing chunk 2701/16667\n",
      "Processing chunk 2751/16667\n",
      "Processing chunk 2801/16667\n",
      "Processing chunk 2851/16667\n",
      "Processing chunk 2901/16667\n",
      "Processing chunk 2951/16667\n",
      "Processing chunk 3001/16667\n",
      "Processing chunk 3051/16667\n",
      "Processing chunk 3101/16667\n",
      "Processing chunk 3151/16667\n",
      "Processing chunk 3201/16667\n",
      "Processing chunk 3251/16667\n",
      "Processing chunk 3301/16667\n",
      "Processing chunk 3351/16667\n",
      "Processing chunk 3401/16667\n",
      "Processing chunk 3451/16667\n",
      "Processing chunk 3501/16667\n",
      "Processing chunk 3551/16667\n",
      "Processing chunk 3601/16667\n",
      "Processing chunk 3651/16667\n",
      "Processing chunk 3701/16667\n",
      "Processing chunk 3751/16667\n",
      "Processing chunk 3801/16667\n",
      "Processing chunk 3851/16667\n",
      "Processing chunk 3901/16667\n",
      "Processing chunk 3951/16667\n",
      "Processing chunk 4001/16667\n",
      "Processing chunk 4051/16667\n",
      "Processing chunk 4101/16667\n",
      "Processing chunk 4151/16667\n",
      "Processing chunk 4201/16667\n",
      "Processing chunk 4251/16667\n",
      "Processing chunk 4301/16667\n",
      "Processing chunk 4351/16667\n",
      "Processing chunk 4401/16667\n",
      "Processing chunk 4451/16667\n",
      "Processing chunk 4501/16667\n",
      "Processing chunk 4551/16667\n",
      "Processing chunk 4601/16667\n",
      "Processing chunk 4651/16667\n",
      "Processing chunk 4701/16667\n",
      "Processing chunk 4751/16667\n",
      "Processing chunk 4801/16667\n",
      "Processing chunk 4851/16667\n",
      "Processing chunk 4901/16667\n",
      "Processing chunk 4951/16667\n",
      "Processing chunk 5001/16667\n",
      "Processing chunk 5051/16667\n",
      "Processing chunk 5101/16667\n",
      "Processing chunk 5151/16667\n",
      "Processing chunk 5201/16667\n",
      "Processing chunk 5251/16667\n",
      "Processing chunk 5301/16667\n",
      "Processing chunk 5351/16667\n",
      "Processing chunk 5401/16667\n",
      "Processing chunk 5451/16667\n",
      "Processing chunk 5501/16667\n",
      "Processing chunk 5551/16667\n",
      "Processing chunk 5601/16667\n",
      "Processing chunk 5651/16667\n",
      "Processing chunk 5701/16667\n",
      "Processing chunk 5751/16667\n",
      "Processing chunk 5801/16667\n",
      "Processing chunk 5851/16667\n",
      "Processing chunk 5901/16667\n",
      "Processing chunk 5951/16667\n",
      "Processing chunk 6001/16667\n",
      "Processing chunk 6051/16667\n",
      "Processing chunk 6101/16667\n",
      "Processing chunk 6151/16667\n",
      "Processing chunk 6201/16667\n",
      "Processing chunk 6251/16667\n",
      "Processing chunk 6301/16667\n",
      "Processing chunk 6351/16667\n",
      "Processing chunk 6401/16667\n",
      "Processing chunk 6451/16667\n",
      "Processing chunk 6501/16667\n",
      "Processing chunk 6551/16667\n",
      "Processing chunk 6601/16667\n",
      "Processing chunk 6651/16667\n",
      "Processing chunk 6701/16667\n",
      "Processing chunk 6751/16667\n",
      "Processing chunk 6801/16667\n",
      "Processing chunk 6851/16667\n",
      "Processing chunk 6901/16667\n",
      "Processing chunk 6951/16667\n",
      "Processing chunk 7001/16667\n",
      "Processing chunk 7051/16667\n",
      "Processing chunk 7101/16667\n",
      "Processing chunk 7151/16667\n",
      "Processing chunk 7201/16667\n",
      "Processing chunk 7251/16667\n",
      "Processing chunk 7301/16667\n",
      "Processing chunk 7351/16667\n",
      "Processing chunk 7401/16667\n",
      "Processing chunk 7451/16667\n",
      "Processing chunk 7501/16667\n",
      "Processing chunk 7551/16667\n",
      "Processing chunk 7601/16667\n",
      "Processing chunk 7651/16667\n",
      "Processing chunk 7701/16667\n",
      "Processing chunk 7751/16667\n",
      "Processing chunk 7801/16667\n",
      "Processing chunk 7851/16667\n",
      "Processing chunk 7901/16667\n",
      "Processing chunk 7951/16667\n",
      "Processing chunk 8001/16667\n",
      "Processing chunk 8051/16667\n",
      "Processing chunk 8101/16667\n",
      "Processing chunk 8151/16667\n",
      "Processing chunk 8201/16667\n",
      "Processing chunk 8251/16667\n",
      "Processing chunk 8301/16667\n",
      "Processing chunk 8351/16667\n",
      "Processing chunk 8401/16667\n",
      "Processing chunk 8451/16667\n",
      "Processing chunk 8501/16667\n",
      "Processing chunk 8551/16667\n",
      "Processing chunk 8601/16667\n",
      "Processing chunk 8651/16667\n",
      "Processing chunk 8701/16667\n",
      "Processing chunk 8751/16667\n",
      "Processing chunk 8801/16667\n",
      "Processing chunk 8851/16667\n",
      "Processing chunk 8901/16667\n",
      "Processing chunk 8951/16667\n",
      "Processing chunk 9001/16667\n",
      "Processing chunk 9051/16667\n",
      "Processing chunk 9101/16667\n",
      "Processing chunk 9151/16667\n",
      "Processing chunk 9201/16667\n",
      "Processing chunk 9251/16667\n",
      "Processing chunk 9301/16667\n",
      "Processing chunk 9351/16667\n",
      "Processing chunk 9401/16667\n",
      "Processing chunk 9451/16667\n",
      "Processing chunk 9501/16667\n",
      "Processing chunk 9551/16667\n",
      "Processing chunk 9601/16667\n",
      "Processing chunk 9651/16667\n",
      "Processing chunk 9701/16667\n",
      "Processing chunk 9751/16667\n",
      "Processing chunk 9801/16667\n",
      "Processing chunk 9851/16667\n",
      "Processing chunk 9901/16667\n",
      "Processing chunk 9951/16667\n",
      "Processing chunk 10001/16667\n",
      "Processing chunk 10051/16667\n",
      "Processing chunk 10101/16667\n",
      "Processing chunk 10151/16667\n",
      "Processing chunk 10201/16667\n",
      "Processing chunk 10251/16667\n",
      "Processing chunk 10301/16667\n",
      "Processing chunk 10351/16667\n",
      "Processing chunk 10401/16667\n",
      "Processing chunk 10451/16667\n",
      "Processing chunk 10501/16667\n",
      "Processing chunk 10551/16667\n",
      "Processing chunk 10601/16667\n",
      "Processing chunk 10651/16667\n",
      "Processing chunk 10701/16667\n",
      "Processing chunk 10751/16667\n",
      "Processing chunk 10801/16667\n",
      "Processing chunk 10851/16667\n",
      "Processing chunk 10901/16667\n",
      "Processing chunk 10951/16667\n",
      "Processing chunk 11001/16667\n",
      "Processing chunk 11051/16667\n",
      "Processing chunk 11101/16667\n",
      "Processing chunk 11151/16667\n",
      "Processing chunk 11201/16667\n",
      "Processing chunk 11251/16667\n",
      "Processing chunk 11301/16667\n",
      "Processing chunk 11351/16667\n",
      "Processing chunk 11401/16667\n",
      "Processing chunk 11451/16667\n",
      "Processing chunk 11501/16667\n",
      "Processing chunk 11551/16667\n",
      "Processing chunk 11601/16667\n",
      "Processing chunk 11651/16667\n",
      "Processing chunk 11701/16667\n",
      "Processing chunk 11751/16667\n",
      "Processing chunk 11801/16667\n",
      "Processing chunk 11851/16667\n",
      "Processing chunk 11901/16667\n",
      "Processing chunk 11951/16667\n",
      "Processing chunk 12001/16667\n",
      "Processing chunk 12051/16667\n",
      "Processing chunk 12101/16667\n",
      "Processing chunk 12151/16667\n",
      "Processing chunk 12201/16667\n",
      "Processing chunk 12251/16667\n",
      "Processing chunk 12301/16667\n",
      "Processing chunk 12351/16667\n",
      "Processing chunk 12401/16667\n",
      "Processing chunk 12451/16667\n",
      "Processing chunk 12501/16667\n",
      "Processing chunk 12551/16667\n",
      "Processing chunk 12601/16667\n",
      "Processing chunk 12651/16667\n",
      "Processing chunk 12701/16667\n",
      "Processing chunk 12751/16667\n",
      "Processing chunk 12801/16667\n",
      "Processing chunk 12851/16667\n",
      "Processing chunk 12901/16667\n",
      "Processing chunk 12951/16667\n",
      "Processing chunk 13001/16667\n",
      "Processing chunk 13051/16667\n",
      "Processing chunk 13101/16667\n",
      "Processing chunk 13151/16667\n",
      "Processing chunk 13201/16667\n",
      "Processing chunk 13251/16667\n",
      "Processing chunk 13301/16667\n",
      "Processing chunk 13351/16667\n",
      "Processing chunk 13401/16667\n",
      "Processing chunk 13451/16667\n",
      "Processing chunk 13501/16667\n",
      "Processing chunk 13551/16667\n",
      "Processing chunk 13601/16667\n",
      "Processing chunk 13651/16667\n",
      "Processing chunk 13701/16667\n",
      "Processing chunk 13751/16667\n",
      "Processing chunk 13801/16667\n",
      "Processing chunk 13851/16667\n",
      "Processing chunk 13901/16667\n",
      "Processing chunk 13951/16667\n",
      "Processing chunk 14001/16667\n",
      "Processing chunk 14051/16667\n",
      "Processing chunk 14101/16667\n",
      "Processing chunk 14151/16667\n",
      "Processing chunk 14201/16667\n",
      "Processing chunk 14251/16667\n",
      "Processing chunk 14301/16667\n",
      "Processing chunk 14351/16667\n",
      "Processing chunk 14401/16667\n",
      "Processing chunk 14451/16667\n",
      "Processing chunk 14501/16667\n",
      "Processing chunk 14551/16667\n",
      "Processing chunk 14601/16667\n",
      "Processing chunk 14651/16667\n",
      "Processing chunk 14701/16667\n",
      "Processing chunk 14751/16667\n",
      "Processing chunk 14801/16667\n",
      "Processing chunk 14851/16667\n",
      "Processing chunk 14901/16667\n",
      "Processing chunk 14951/16667\n",
      "Processing chunk 15001/16667\n",
      "Processing chunk 15051/16667\n",
      "Processing chunk 15101/16667\n",
      "Processing chunk 15151/16667\n",
      "Processing chunk 15201/16667\n",
      "Processing chunk 15251/16667\n",
      "Processing chunk 15301/16667\n",
      "Processing chunk 15351/16667\n",
      "Processing chunk 15401/16667\n",
      "Processing chunk 15451/16667\n",
      "Processing chunk 15501/16667\n",
      "Processing chunk 15551/16667\n",
      "Processing chunk 15601/16667\n",
      "Processing chunk 15651/16667\n",
      "Processing chunk 15701/16667\n",
      "Processing chunk 15751/16667\n",
      "Processing chunk 15801/16667\n",
      "Processing chunk 15851/16667\n",
      "Processing chunk 15901/16667\n",
      "Processing chunk 15951/16667\n",
      "Processing chunk 16001/16667\n",
      "Processing chunk 16051/16667\n",
      "Processing chunk 16101/16667\n",
      "Processing chunk 16151/16667\n",
      "Processing chunk 16201/16667\n",
      "Processing chunk 16251/16667\n",
      "Processing chunk 16301/16667\n",
      "Processing chunk 16351/16667\n",
      "Processing chunk 16401/16667\n",
      "Processing chunk 16451/16667\n",
      "Processing chunk 16501/16667\n",
      "Processing chunk 16551/16667\n",
      "Processing chunk 16601/16667\n",
      "Processing chunk 16651/16667\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 5000\n",
      "Number of hits: 4431\n",
      "Average HR@20: 0.8862\n",
      "Average NDCG@20: 0.3471\n",
      "\n",
      "Training and evaluating NGCF+M...\n",
      "Epoch 1, Loss: 0.6880\n",
      "Epoch 2, Loss: 0.5408\n",
      "Epoch 3, Loss: 0.4589\n",
      "Epoch 4, Loss: 0.3997\n",
      "Epoch 5, Loss: 0.3482\n",
      "Epoch 6, Loss: 0.3027\n",
      "Epoch 7, Loss: 0.2633\n",
      "Epoch 8, Loss: 0.2293\n",
      "Epoch 9, Loss: 0.1992\n",
      "Epoch 10, Loss: 0.1718\n",
      "Training completed in 1.73s\n",
      "Preparing test instances...\n",
      "Generated 500000 test instances\n",
      "Evaluating 500000 instances in 16667 chunks...\n",
      "Processing chunk 1/16667\n",
      "Processing chunk 51/16667\n",
      "Processing chunk 101/16667\n",
      "Processing chunk 151/16667\n",
      "Processing chunk 201/16667\n",
      "Processing chunk 251/16667\n",
      "Processing chunk 301/16667\n",
      "Processing chunk 351/16667\n",
      "Processing chunk 401/16667\n",
      "Processing chunk 451/16667\n",
      "Processing chunk 501/16667\n",
      "Processing chunk 551/16667\n",
      "Processing chunk 601/16667\n",
      "Processing chunk 651/16667\n",
      "Processing chunk 701/16667\n",
      "Processing chunk 751/16667\n",
      "Processing chunk 801/16667\n",
      "Processing chunk 851/16667\n",
      "Processing chunk 901/16667\n",
      "Processing chunk 951/16667\n",
      "Processing chunk 1001/16667\n",
      "Processing chunk 1051/16667\n",
      "Processing chunk 1101/16667\n",
      "Processing chunk 1151/16667\n",
      "Processing chunk 1201/16667\n",
      "Processing chunk 1251/16667\n",
      "Processing chunk 1301/16667\n",
      "Processing chunk 1351/16667\n",
      "Processing chunk 1401/16667\n",
      "Processing chunk 1451/16667\n",
      "Processing chunk 1501/16667\n",
      "Processing chunk 1551/16667\n",
      "Processing chunk 1601/16667\n",
      "Processing chunk 1651/16667\n",
      "Processing chunk 1701/16667\n",
      "Processing chunk 1751/16667\n",
      "Processing chunk 1801/16667\n",
      "Processing chunk 1851/16667\n",
      "Processing chunk 1901/16667\n",
      "Processing chunk 1951/16667\n",
      "Processing chunk 2001/16667\n",
      "Processing chunk 2051/16667\n",
      "Processing chunk 2101/16667\n",
      "Processing chunk 2151/16667\n",
      "Processing chunk 2201/16667\n",
      "Processing chunk 2251/16667\n",
      "Processing chunk 2301/16667\n",
      "Processing chunk 2351/16667\n",
      "Processing chunk 2401/16667\n",
      "Processing chunk 2451/16667\n",
      "Processing chunk 2501/16667\n",
      "Processing chunk 2551/16667\n",
      "Processing chunk 2601/16667\n",
      "Processing chunk 2651/16667\n",
      "Processing chunk 2701/16667\n",
      "Processing chunk 2751/16667\n",
      "Processing chunk 2801/16667\n",
      "Processing chunk 2851/16667\n",
      "Processing chunk 2901/16667\n",
      "Processing chunk 2951/16667\n",
      "Processing chunk 3001/16667\n",
      "Processing chunk 3051/16667\n",
      "Processing chunk 3101/16667\n",
      "Processing chunk 3151/16667\n",
      "Processing chunk 3201/16667\n",
      "Processing chunk 3251/16667\n",
      "Processing chunk 3301/16667\n",
      "Processing chunk 3351/16667\n",
      "Processing chunk 3401/16667\n",
      "Processing chunk 3451/16667\n",
      "Processing chunk 3501/16667\n",
      "Processing chunk 3551/16667\n",
      "Processing chunk 3601/16667\n",
      "Processing chunk 3651/16667\n",
      "Processing chunk 3701/16667\n",
      "Processing chunk 3751/16667\n",
      "Processing chunk 3801/16667\n",
      "Processing chunk 3851/16667\n",
      "Processing chunk 3901/16667\n",
      "Processing chunk 3951/16667\n",
      "Processing chunk 4001/16667\n",
      "Processing chunk 4051/16667\n",
      "Processing chunk 4101/16667\n",
      "Processing chunk 4151/16667\n",
      "Processing chunk 4201/16667\n",
      "Processing chunk 4251/16667\n",
      "Processing chunk 4301/16667\n",
      "Processing chunk 4351/16667\n",
      "Processing chunk 4401/16667\n",
      "Processing chunk 4451/16667\n",
      "Processing chunk 4501/16667\n",
      "Processing chunk 4551/16667\n",
      "Processing chunk 4601/16667\n",
      "Processing chunk 4651/16667\n",
      "Processing chunk 4701/16667\n",
      "Processing chunk 4751/16667\n",
      "Processing chunk 4801/16667\n",
      "Processing chunk 4851/16667\n",
      "Processing chunk 4901/16667\n",
      "Processing chunk 4951/16667\n",
      "Processing chunk 5001/16667\n",
      "Processing chunk 5051/16667\n",
      "Processing chunk 5101/16667\n",
      "Processing chunk 5151/16667\n",
      "Processing chunk 5201/16667\n",
      "Processing chunk 5251/16667\n",
      "Processing chunk 5301/16667\n",
      "Processing chunk 5351/16667\n",
      "Processing chunk 5401/16667\n",
      "Processing chunk 5451/16667\n",
      "Processing chunk 5501/16667\n",
      "Processing chunk 5551/16667\n",
      "Processing chunk 5601/16667\n",
      "Processing chunk 5651/16667\n",
      "Processing chunk 5701/16667\n",
      "Processing chunk 5751/16667\n",
      "Processing chunk 5801/16667\n",
      "Processing chunk 5851/16667\n",
      "Processing chunk 5901/16667\n",
      "Processing chunk 5951/16667\n",
      "Processing chunk 6001/16667\n",
      "Processing chunk 6051/16667\n",
      "Processing chunk 6101/16667\n",
      "Processing chunk 6151/16667\n",
      "Processing chunk 6201/16667\n",
      "Processing chunk 6251/16667\n",
      "Processing chunk 6301/16667\n",
      "Processing chunk 6351/16667\n",
      "Processing chunk 6401/16667\n",
      "Processing chunk 6451/16667\n",
      "Processing chunk 6501/16667\n",
      "Processing chunk 6551/16667\n",
      "Processing chunk 6601/16667\n",
      "Processing chunk 6651/16667\n",
      "Processing chunk 6701/16667\n",
      "Processing chunk 6751/16667\n",
      "Processing chunk 6801/16667\n",
      "Processing chunk 6851/16667\n",
      "Processing chunk 6901/16667\n",
      "Processing chunk 6951/16667\n",
      "Processing chunk 7001/16667\n",
      "Processing chunk 7051/16667\n",
      "Processing chunk 7101/16667\n",
      "Processing chunk 7151/16667\n",
      "Processing chunk 7201/16667\n",
      "Processing chunk 7251/16667\n",
      "Processing chunk 7301/16667\n",
      "Processing chunk 7351/16667\n",
      "Processing chunk 7401/16667\n",
      "Processing chunk 7451/16667\n",
      "Processing chunk 7501/16667\n",
      "Processing chunk 7551/16667\n",
      "Processing chunk 7601/16667\n",
      "Processing chunk 7651/16667\n",
      "Processing chunk 7701/16667\n",
      "Processing chunk 7751/16667\n",
      "Processing chunk 7801/16667\n",
      "Processing chunk 7851/16667\n",
      "Processing chunk 7901/16667\n",
      "Processing chunk 7951/16667\n",
      "Processing chunk 8001/16667\n",
      "Processing chunk 8051/16667\n",
      "Processing chunk 8101/16667\n",
      "Processing chunk 8151/16667\n",
      "Processing chunk 8201/16667\n",
      "Processing chunk 8251/16667\n",
      "Processing chunk 8301/16667\n",
      "Processing chunk 8351/16667\n",
      "Processing chunk 8401/16667\n",
      "Processing chunk 8451/16667\n",
      "Processing chunk 8501/16667\n",
      "Processing chunk 8551/16667\n",
      "Processing chunk 8601/16667\n",
      "Processing chunk 8651/16667\n",
      "Processing chunk 8701/16667\n",
      "Processing chunk 8751/16667\n",
      "Processing chunk 8801/16667\n",
      "Processing chunk 8851/16667\n",
      "Processing chunk 8901/16667\n",
      "Processing chunk 8951/16667\n",
      "Processing chunk 9001/16667\n",
      "Processing chunk 9051/16667\n",
      "Processing chunk 9101/16667\n",
      "Processing chunk 9151/16667\n",
      "Processing chunk 9201/16667\n",
      "Processing chunk 9251/16667\n",
      "Processing chunk 9301/16667\n",
      "Processing chunk 9351/16667\n",
      "Processing chunk 9401/16667\n",
      "Processing chunk 9451/16667\n",
      "Processing chunk 9501/16667\n",
      "Processing chunk 9551/16667\n",
      "Processing chunk 9601/16667\n",
      "Processing chunk 9651/16667\n",
      "Processing chunk 9701/16667\n",
      "Processing chunk 9751/16667\n",
      "Processing chunk 9801/16667\n",
      "Processing chunk 9851/16667\n",
      "Processing chunk 9901/16667\n",
      "Processing chunk 9951/16667\n",
      "Processing chunk 10001/16667\n",
      "Processing chunk 10051/16667\n",
      "Processing chunk 10101/16667\n",
      "Processing chunk 10151/16667\n",
      "Processing chunk 10201/16667\n",
      "Processing chunk 10251/16667\n",
      "Processing chunk 10301/16667\n",
      "Processing chunk 10351/16667\n",
      "Processing chunk 10401/16667\n",
      "Processing chunk 10451/16667\n",
      "Processing chunk 10501/16667\n",
      "Processing chunk 10551/16667\n",
      "Processing chunk 10601/16667\n",
      "Processing chunk 10651/16667\n",
      "Processing chunk 10701/16667\n",
      "Processing chunk 10751/16667\n",
      "Processing chunk 10801/16667\n",
      "Processing chunk 10851/16667\n",
      "Processing chunk 10901/16667\n",
      "Processing chunk 10951/16667\n",
      "Processing chunk 11001/16667\n",
      "Processing chunk 11051/16667\n",
      "Processing chunk 11101/16667\n",
      "Processing chunk 11151/16667\n",
      "Processing chunk 11201/16667\n",
      "Processing chunk 11251/16667\n",
      "Processing chunk 11301/16667\n",
      "Processing chunk 11351/16667\n",
      "Processing chunk 11401/16667\n",
      "Processing chunk 11451/16667\n",
      "Processing chunk 11501/16667\n",
      "Processing chunk 11551/16667\n",
      "Processing chunk 11601/16667\n",
      "Processing chunk 11651/16667\n",
      "Processing chunk 11701/16667\n",
      "Processing chunk 11751/16667\n",
      "Processing chunk 11801/16667\n",
      "Processing chunk 11851/16667\n",
      "Processing chunk 11901/16667\n",
      "Processing chunk 11951/16667\n",
      "Processing chunk 12001/16667\n",
      "Processing chunk 12051/16667\n",
      "Processing chunk 12101/16667\n",
      "Processing chunk 12151/16667\n",
      "Processing chunk 12201/16667\n",
      "Processing chunk 12251/16667\n",
      "Processing chunk 12301/16667\n",
      "Processing chunk 12351/16667\n",
      "Processing chunk 12401/16667\n",
      "Processing chunk 12451/16667\n",
      "Processing chunk 12501/16667\n",
      "Processing chunk 12551/16667\n",
      "Processing chunk 12601/16667\n",
      "Processing chunk 12651/16667\n",
      "Processing chunk 12701/16667\n",
      "Processing chunk 12751/16667\n",
      "Processing chunk 12801/16667\n",
      "Processing chunk 12851/16667\n",
      "Processing chunk 12901/16667\n",
      "Processing chunk 12951/16667\n",
      "Processing chunk 13001/16667\n",
      "Processing chunk 13051/16667\n",
      "Processing chunk 13101/16667\n",
      "Processing chunk 13151/16667\n",
      "Processing chunk 13201/16667\n",
      "Processing chunk 13251/16667\n",
      "Processing chunk 13301/16667\n",
      "Processing chunk 13351/16667\n",
      "Processing chunk 13401/16667\n",
      "Processing chunk 13451/16667\n",
      "Processing chunk 13501/16667\n",
      "Processing chunk 13551/16667\n",
      "Processing chunk 13601/16667\n",
      "Processing chunk 13651/16667\n",
      "Processing chunk 13701/16667\n",
      "Processing chunk 13751/16667\n",
      "Processing chunk 13801/16667\n",
      "Processing chunk 13851/16667\n",
      "Processing chunk 13901/16667\n",
      "Processing chunk 13951/16667\n",
      "Processing chunk 14001/16667\n",
      "Processing chunk 14051/16667\n",
      "Processing chunk 14101/16667\n",
      "Processing chunk 14151/16667\n",
      "Processing chunk 14201/16667\n",
      "Processing chunk 14251/16667\n",
      "Processing chunk 14301/16667\n",
      "Processing chunk 14351/16667\n",
      "Processing chunk 14401/16667\n",
      "Processing chunk 14451/16667\n",
      "Processing chunk 14501/16667\n",
      "Processing chunk 14551/16667\n",
      "Processing chunk 14601/16667\n",
      "Processing chunk 14651/16667\n",
      "Processing chunk 14701/16667\n",
      "Processing chunk 14751/16667\n",
      "Processing chunk 14801/16667\n",
      "Processing chunk 14851/16667\n",
      "Processing chunk 14901/16667\n",
      "Processing chunk 14951/16667\n",
      "Processing chunk 15001/16667\n",
      "Processing chunk 15051/16667\n",
      "Processing chunk 15101/16667\n",
      "Processing chunk 15151/16667\n",
      "Processing chunk 15201/16667\n",
      "Processing chunk 15251/16667\n",
      "Processing chunk 15301/16667\n",
      "Processing chunk 15351/16667\n",
      "Processing chunk 15401/16667\n",
      "Processing chunk 15451/16667\n",
      "Processing chunk 15501/16667\n",
      "Processing chunk 15551/16667\n",
      "Processing chunk 15601/16667\n",
      "Processing chunk 15651/16667\n",
      "Processing chunk 15701/16667\n",
      "Processing chunk 15751/16667\n",
      "Processing chunk 15801/16667\n",
      "Processing chunk 15851/16667\n",
      "Processing chunk 15901/16667\n",
      "Processing chunk 15951/16667\n",
      "Processing chunk 16001/16667\n",
      "Processing chunk 16051/16667\n",
      "Processing chunk 16101/16667\n",
      "Processing chunk 16151/16667\n",
      "Processing chunk 16201/16667\n",
      "Processing chunk 16251/16667\n",
      "Processing chunk 16301/16667\n",
      "Processing chunk 16351/16667\n",
      "Processing chunk 16401/16667\n",
      "Processing chunk 16451/16667\n",
      "Processing chunk 16501/16667\n",
      "Processing chunk 16551/16667\n",
      "Processing chunk 16601/16667\n",
      "Processing chunk 16651/16667\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 5000\n",
      "Number of hits: 4425\n",
      "Average HR@20: 0.8850\n",
      "Average NDCG@20: 0.3461\n",
      "\n",
      "Training and evaluating MBGCN...\n",
      "Epoch 1, Loss: 0.7384\n",
      "Epoch 2, Loss: 0.5684\n",
      "Epoch 3, Loss: 0.4745\n",
      "Epoch 4, Loss: 0.4161\n",
      "Epoch 5, Loss: 0.3681\n",
      "Epoch 6, Loss: 0.3233\n",
      "Epoch 7, Loss: 0.2824\n",
      "Epoch 8, Loss: 0.2466\n",
      "Epoch 9, Loss: 0.2156\n",
      "Epoch 10, Loss: 0.1881\n",
      "Training completed in 1.88s\n",
      "Preparing test instances...\n",
      "Generated 500000 test instances\n",
      "Evaluating 500000 instances in 16667 chunks...\n",
      "Processing chunk 1/16667\n",
      "Processing chunk 51/16667\n",
      "Processing chunk 101/16667\n",
      "Processing chunk 151/16667\n",
      "Processing chunk 201/16667\n",
      "Processing chunk 251/16667\n",
      "Processing chunk 301/16667\n",
      "Processing chunk 351/16667\n",
      "Processing chunk 401/16667\n",
      "Processing chunk 451/16667\n",
      "Processing chunk 501/16667\n",
      "Processing chunk 551/16667\n",
      "Processing chunk 601/16667\n",
      "Processing chunk 651/16667\n",
      "Processing chunk 701/16667\n",
      "Processing chunk 751/16667\n",
      "Processing chunk 801/16667\n",
      "Processing chunk 851/16667\n",
      "Processing chunk 901/16667\n",
      "Processing chunk 951/16667\n",
      "Processing chunk 1001/16667\n",
      "Processing chunk 1051/16667\n",
      "Processing chunk 1101/16667\n",
      "Processing chunk 1151/16667\n",
      "Processing chunk 1201/16667\n",
      "Processing chunk 1251/16667\n",
      "Processing chunk 1301/16667\n",
      "Processing chunk 1351/16667\n",
      "Processing chunk 1401/16667\n",
      "Processing chunk 1451/16667\n",
      "Processing chunk 1501/16667\n",
      "Processing chunk 1551/16667\n",
      "Processing chunk 1601/16667\n",
      "Processing chunk 1651/16667\n",
      "Processing chunk 1701/16667\n",
      "Processing chunk 1751/16667\n",
      "Processing chunk 1801/16667\n",
      "Processing chunk 1851/16667\n",
      "Processing chunk 1901/16667\n",
      "Processing chunk 1951/16667\n",
      "Processing chunk 2001/16667\n",
      "Processing chunk 2051/16667\n",
      "Processing chunk 2101/16667\n",
      "Processing chunk 2151/16667\n",
      "Processing chunk 2201/16667\n",
      "Processing chunk 2251/16667\n",
      "Processing chunk 2301/16667\n",
      "Processing chunk 2351/16667\n",
      "Processing chunk 2401/16667\n",
      "Processing chunk 2451/16667\n",
      "Processing chunk 2501/16667\n",
      "Processing chunk 2551/16667\n",
      "Processing chunk 2601/16667\n",
      "Processing chunk 2651/16667\n",
      "Processing chunk 2701/16667\n",
      "Processing chunk 2751/16667\n",
      "Processing chunk 2801/16667\n",
      "Processing chunk 2851/16667\n",
      "Processing chunk 2901/16667\n",
      "Processing chunk 2951/16667\n",
      "Processing chunk 3001/16667\n",
      "Processing chunk 3051/16667\n",
      "Processing chunk 3101/16667\n",
      "Processing chunk 3151/16667\n",
      "Processing chunk 3201/16667\n",
      "Processing chunk 3251/16667\n",
      "Processing chunk 3301/16667\n",
      "Processing chunk 3351/16667\n",
      "Processing chunk 3401/16667\n",
      "Processing chunk 3451/16667\n",
      "Processing chunk 3501/16667\n",
      "Processing chunk 3551/16667\n",
      "Processing chunk 3601/16667\n",
      "Processing chunk 3651/16667\n",
      "Processing chunk 3701/16667\n",
      "Processing chunk 3751/16667\n",
      "Processing chunk 3801/16667\n",
      "Processing chunk 3851/16667\n",
      "Processing chunk 3901/16667\n",
      "Processing chunk 3951/16667\n",
      "Processing chunk 4001/16667\n",
      "Processing chunk 4051/16667\n",
      "Processing chunk 4101/16667\n",
      "Processing chunk 4151/16667\n",
      "Processing chunk 4201/16667\n",
      "Processing chunk 4251/16667\n",
      "Processing chunk 4301/16667\n",
      "Processing chunk 4351/16667\n",
      "Processing chunk 4401/16667\n",
      "Processing chunk 4451/16667\n",
      "Processing chunk 4501/16667\n",
      "Processing chunk 4551/16667\n",
      "Processing chunk 4601/16667\n",
      "Processing chunk 4651/16667\n",
      "Processing chunk 4701/16667\n",
      "Processing chunk 4751/16667\n",
      "Processing chunk 4801/16667\n",
      "Processing chunk 4851/16667\n",
      "Processing chunk 4901/16667\n",
      "Processing chunk 4951/16667\n",
      "Processing chunk 5001/16667\n",
      "Processing chunk 5051/16667\n",
      "Processing chunk 5101/16667\n",
      "Processing chunk 5151/16667\n",
      "Processing chunk 5201/16667\n",
      "Processing chunk 5251/16667\n",
      "Processing chunk 5301/16667\n",
      "Processing chunk 5351/16667\n",
      "Processing chunk 5401/16667\n",
      "Processing chunk 5451/16667\n",
      "Processing chunk 5501/16667\n",
      "Processing chunk 5551/16667\n",
      "Processing chunk 5601/16667\n",
      "Processing chunk 5651/16667\n",
      "Processing chunk 5701/16667\n",
      "Processing chunk 5751/16667\n",
      "Processing chunk 5801/16667\n",
      "Processing chunk 5851/16667\n",
      "Processing chunk 5901/16667\n",
      "Processing chunk 5951/16667\n",
      "Processing chunk 6001/16667\n",
      "Processing chunk 6051/16667\n",
      "Processing chunk 6101/16667\n",
      "Processing chunk 6151/16667\n",
      "Processing chunk 6201/16667\n",
      "Processing chunk 6251/16667\n",
      "Processing chunk 6301/16667\n",
      "Processing chunk 6351/16667\n",
      "Processing chunk 6401/16667\n",
      "Processing chunk 6451/16667\n",
      "Processing chunk 6501/16667\n",
      "Processing chunk 6551/16667\n",
      "Processing chunk 6601/16667\n",
      "Processing chunk 6651/16667\n",
      "Processing chunk 6701/16667\n",
      "Processing chunk 6751/16667\n",
      "Processing chunk 6801/16667\n",
      "Processing chunk 6851/16667\n",
      "Processing chunk 6901/16667\n",
      "Processing chunk 6951/16667\n",
      "Processing chunk 7001/16667\n",
      "Processing chunk 7051/16667\n",
      "Processing chunk 7101/16667\n",
      "Processing chunk 7151/16667\n",
      "Processing chunk 7201/16667\n",
      "Processing chunk 7251/16667\n",
      "Processing chunk 7301/16667\n",
      "Processing chunk 7351/16667\n",
      "Processing chunk 7401/16667\n",
      "Processing chunk 7451/16667\n",
      "Processing chunk 7501/16667\n",
      "Processing chunk 7551/16667\n",
      "Processing chunk 7601/16667\n",
      "Processing chunk 7651/16667\n",
      "Processing chunk 7701/16667\n",
      "Processing chunk 7751/16667\n",
      "Processing chunk 7801/16667\n",
      "Processing chunk 7851/16667\n",
      "Processing chunk 7901/16667\n",
      "Processing chunk 7951/16667\n",
      "Processing chunk 8001/16667\n",
      "Processing chunk 8051/16667\n",
      "Processing chunk 8101/16667\n",
      "Processing chunk 8151/16667\n",
      "Processing chunk 8201/16667\n",
      "Processing chunk 8251/16667\n",
      "Processing chunk 8301/16667\n",
      "Processing chunk 8351/16667\n",
      "Processing chunk 8401/16667\n",
      "Processing chunk 8451/16667\n",
      "Processing chunk 8501/16667\n",
      "Processing chunk 8551/16667\n",
      "Processing chunk 8601/16667\n",
      "Processing chunk 8651/16667\n",
      "Processing chunk 8701/16667\n",
      "Processing chunk 8751/16667\n",
      "Processing chunk 8801/16667\n",
      "Processing chunk 8851/16667\n",
      "Processing chunk 8901/16667\n",
      "Processing chunk 8951/16667\n",
      "Processing chunk 9001/16667\n",
      "Processing chunk 9051/16667\n",
      "Processing chunk 9101/16667\n",
      "Processing chunk 9151/16667\n",
      "Processing chunk 9201/16667\n",
      "Processing chunk 9251/16667\n",
      "Processing chunk 9301/16667\n",
      "Processing chunk 9351/16667\n",
      "Processing chunk 9401/16667\n",
      "Processing chunk 9451/16667\n",
      "Processing chunk 9501/16667\n",
      "Processing chunk 9551/16667\n",
      "Processing chunk 9601/16667\n",
      "Processing chunk 9651/16667\n",
      "Processing chunk 9701/16667\n",
      "Processing chunk 9751/16667\n",
      "Processing chunk 9801/16667\n",
      "Processing chunk 9851/16667\n",
      "Processing chunk 9901/16667\n",
      "Processing chunk 9951/16667\n",
      "Processing chunk 10001/16667\n",
      "Processing chunk 10051/16667\n",
      "Processing chunk 10101/16667\n",
      "Processing chunk 10151/16667\n",
      "Processing chunk 10201/16667\n",
      "Processing chunk 10251/16667\n",
      "Processing chunk 10301/16667\n",
      "Processing chunk 10351/16667\n",
      "Processing chunk 10401/16667\n",
      "Processing chunk 10451/16667\n",
      "Processing chunk 10501/16667\n",
      "Processing chunk 10551/16667\n",
      "Processing chunk 10601/16667\n",
      "Processing chunk 10651/16667\n",
      "Processing chunk 10701/16667\n",
      "Processing chunk 10751/16667\n",
      "Processing chunk 10801/16667\n",
      "Processing chunk 10851/16667\n",
      "Processing chunk 10901/16667\n",
      "Processing chunk 10951/16667\n",
      "Processing chunk 11001/16667\n",
      "Processing chunk 11051/16667\n",
      "Processing chunk 11101/16667\n",
      "Processing chunk 11151/16667\n",
      "Processing chunk 11201/16667\n",
      "Processing chunk 11251/16667\n",
      "Processing chunk 11301/16667\n",
      "Processing chunk 11351/16667\n",
      "Processing chunk 11401/16667\n",
      "Processing chunk 11451/16667\n",
      "Processing chunk 11501/16667\n",
      "Processing chunk 11551/16667\n",
      "Processing chunk 11601/16667\n",
      "Processing chunk 11651/16667\n",
      "Processing chunk 11701/16667\n",
      "Processing chunk 11751/16667\n",
      "Processing chunk 11801/16667\n",
      "Processing chunk 11851/16667\n",
      "Processing chunk 11901/16667\n",
      "Processing chunk 11951/16667\n",
      "Processing chunk 12001/16667\n",
      "Processing chunk 12051/16667\n",
      "Processing chunk 12101/16667\n",
      "Processing chunk 12151/16667\n",
      "Processing chunk 12201/16667\n",
      "Processing chunk 12251/16667\n",
      "Processing chunk 12301/16667\n",
      "Processing chunk 12351/16667\n",
      "Processing chunk 12401/16667\n",
      "Processing chunk 12451/16667\n",
      "Processing chunk 12501/16667\n",
      "Processing chunk 12551/16667\n",
      "Processing chunk 12601/16667\n",
      "Processing chunk 12651/16667\n",
      "Processing chunk 12701/16667\n",
      "Processing chunk 12751/16667\n",
      "Processing chunk 12801/16667\n",
      "Processing chunk 12851/16667\n",
      "Processing chunk 12901/16667\n",
      "Processing chunk 12951/16667\n",
      "Processing chunk 13001/16667\n",
      "Processing chunk 13051/16667\n",
      "Processing chunk 13101/16667\n",
      "Processing chunk 13151/16667\n",
      "Processing chunk 13201/16667\n",
      "Processing chunk 13251/16667\n",
      "Processing chunk 13301/16667\n",
      "Processing chunk 13351/16667\n",
      "Processing chunk 13401/16667\n",
      "Processing chunk 13451/16667\n",
      "Processing chunk 13501/16667\n",
      "Processing chunk 13551/16667\n",
      "Processing chunk 13601/16667\n",
      "Processing chunk 13651/16667\n",
      "Processing chunk 13701/16667\n",
      "Processing chunk 13751/16667\n",
      "Processing chunk 13801/16667\n",
      "Processing chunk 13851/16667\n",
      "Processing chunk 13901/16667\n",
      "Processing chunk 13951/16667\n",
      "Processing chunk 14001/16667\n",
      "Processing chunk 14051/16667\n",
      "Processing chunk 14101/16667\n",
      "Processing chunk 14151/16667\n",
      "Processing chunk 14201/16667\n",
      "Processing chunk 14251/16667\n",
      "Processing chunk 14301/16667\n",
      "Processing chunk 14351/16667\n",
      "Processing chunk 14401/16667\n",
      "Processing chunk 14451/16667\n",
      "Processing chunk 14501/16667\n",
      "Processing chunk 14551/16667\n",
      "Processing chunk 14601/16667\n",
      "Processing chunk 14651/16667\n",
      "Processing chunk 14701/16667\n",
      "Processing chunk 14751/16667\n",
      "Processing chunk 14801/16667\n",
      "Processing chunk 14851/16667\n",
      "Processing chunk 14901/16667\n",
      "Processing chunk 14951/16667\n",
      "Processing chunk 15001/16667\n",
      "Processing chunk 15051/16667\n",
      "Processing chunk 15101/16667\n",
      "Processing chunk 15151/16667\n",
      "Processing chunk 15201/16667\n",
      "Processing chunk 15251/16667\n",
      "Processing chunk 15301/16667\n",
      "Processing chunk 15351/16667\n",
      "Processing chunk 15401/16667\n",
      "Processing chunk 15451/16667\n",
      "Processing chunk 15501/16667\n",
      "Processing chunk 15551/16667\n",
      "Processing chunk 15601/16667\n",
      "Processing chunk 15651/16667\n",
      "Processing chunk 15701/16667\n",
      "Processing chunk 15751/16667\n",
      "Processing chunk 15801/16667\n",
      "Processing chunk 15851/16667\n",
      "Processing chunk 15901/16667\n",
      "Processing chunk 15951/16667\n",
      "Processing chunk 16001/16667\n",
      "Processing chunk 16051/16667\n",
      "Processing chunk 16101/16667\n",
      "Processing chunk 16151/16667\n",
      "Processing chunk 16201/16667\n",
      "Processing chunk 16251/16667\n",
      "Processing chunk 16301/16667\n",
      "Processing chunk 16351/16667\n",
      "Processing chunk 16401/16667\n",
      "Processing chunk 16451/16667\n",
      "Processing chunk 16501/16667\n",
      "Processing chunk 16551/16667\n",
      "Processing chunk 16601/16667\n",
      "Processing chunk 16651/16667\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 5000\n",
      "Number of hits: 4507\n",
      "Average HR@20: 0.9014\n",
      "Average NDCG@20: 0.3519\n",
      "\n",
      "Training and evaluating MATN...\n",
      "Epoch 1, Loss: 0.7332\n",
      "Epoch 2, Loss: 0.7104\n",
      "Epoch 3, Loss: 0.6893\n",
      "Epoch 4, Loss: 0.6697\n",
      "Epoch 5, Loss: 0.6514\n",
      "Epoch 6, Loss: 0.6344\n",
      "Epoch 7, Loss: 0.6184\n",
      "Epoch 8, Loss: 0.6034\n",
      "Epoch 9, Loss: 0.5891\n",
      "Epoch 10, Loss: 0.5754\n",
      "Training completed in 0.91s\n",
      "Preparing test instances...\n",
      "Generated 500000 test instances\n",
      "Evaluating 500000 instances in 16667 chunks...\n",
      "Processing chunk 1/16667\n",
      "Processing chunk 51/16667\n",
      "Processing chunk 101/16667\n",
      "Processing chunk 151/16667\n",
      "Processing chunk 201/16667\n",
      "Processing chunk 251/16667\n",
      "Processing chunk 301/16667\n",
      "Processing chunk 351/16667\n",
      "Processing chunk 401/16667\n",
      "Processing chunk 451/16667\n",
      "Processing chunk 501/16667\n",
      "Processing chunk 551/16667\n",
      "Processing chunk 601/16667\n",
      "Processing chunk 651/16667\n",
      "Processing chunk 701/16667\n",
      "Processing chunk 751/16667\n",
      "Processing chunk 801/16667\n",
      "Processing chunk 851/16667\n",
      "Processing chunk 901/16667\n",
      "Processing chunk 951/16667\n",
      "Processing chunk 1001/16667\n",
      "Processing chunk 1051/16667\n",
      "Processing chunk 1101/16667\n",
      "Processing chunk 1151/16667\n",
      "Processing chunk 1201/16667\n",
      "Processing chunk 1251/16667\n",
      "Processing chunk 1301/16667\n",
      "Processing chunk 1351/16667\n",
      "Processing chunk 1401/16667\n",
      "Processing chunk 1451/16667\n",
      "Processing chunk 1501/16667\n",
      "Processing chunk 1551/16667\n",
      "Processing chunk 1601/16667\n",
      "Processing chunk 1651/16667\n",
      "Processing chunk 1701/16667\n",
      "Processing chunk 1751/16667\n",
      "Processing chunk 1801/16667\n",
      "Processing chunk 1851/16667\n",
      "Processing chunk 1901/16667\n",
      "Processing chunk 1951/16667\n",
      "Processing chunk 2001/16667\n",
      "Processing chunk 2051/16667\n",
      "Processing chunk 2101/16667\n",
      "Processing chunk 2151/16667\n",
      "Processing chunk 2201/16667\n",
      "Processing chunk 2251/16667\n",
      "Processing chunk 2301/16667\n",
      "Processing chunk 2351/16667\n",
      "Processing chunk 2401/16667\n",
      "Processing chunk 2451/16667\n",
      "Processing chunk 2501/16667\n",
      "Processing chunk 2551/16667\n",
      "Processing chunk 2601/16667\n",
      "Processing chunk 2651/16667\n",
      "Processing chunk 2701/16667\n",
      "Processing chunk 2751/16667\n",
      "Processing chunk 2801/16667\n",
      "Processing chunk 2851/16667\n",
      "Processing chunk 2901/16667\n",
      "Processing chunk 2951/16667\n",
      "Processing chunk 3001/16667\n",
      "Processing chunk 3051/16667\n",
      "Processing chunk 3101/16667\n",
      "Processing chunk 3151/16667\n",
      "Processing chunk 3201/16667\n",
      "Processing chunk 3251/16667\n",
      "Processing chunk 3301/16667\n",
      "Processing chunk 3351/16667\n",
      "Processing chunk 3401/16667\n",
      "Processing chunk 3451/16667\n",
      "Processing chunk 3501/16667\n",
      "Processing chunk 3551/16667\n",
      "Processing chunk 3601/16667\n",
      "Processing chunk 3651/16667\n",
      "Processing chunk 3701/16667\n",
      "Processing chunk 3751/16667\n",
      "Processing chunk 3801/16667\n",
      "Processing chunk 3851/16667\n",
      "Processing chunk 3901/16667\n",
      "Processing chunk 3951/16667\n",
      "Processing chunk 4001/16667\n",
      "Processing chunk 4051/16667\n",
      "Processing chunk 4101/16667\n",
      "Processing chunk 4151/16667\n",
      "Processing chunk 4201/16667\n",
      "Processing chunk 4251/16667\n",
      "Processing chunk 4301/16667\n",
      "Processing chunk 4351/16667\n",
      "Processing chunk 4401/16667\n",
      "Processing chunk 4451/16667\n",
      "Processing chunk 4501/16667\n",
      "Processing chunk 4551/16667\n",
      "Processing chunk 4601/16667\n",
      "Processing chunk 4651/16667\n",
      "Processing chunk 4701/16667\n",
      "Processing chunk 4751/16667\n",
      "Processing chunk 4801/16667\n",
      "Processing chunk 4851/16667\n",
      "Processing chunk 4901/16667\n",
      "Processing chunk 4951/16667\n",
      "Processing chunk 5001/16667\n",
      "Processing chunk 5051/16667\n",
      "Processing chunk 5101/16667\n",
      "Processing chunk 5151/16667\n",
      "Processing chunk 5201/16667\n",
      "Processing chunk 5251/16667\n",
      "Processing chunk 5301/16667\n",
      "Processing chunk 5351/16667\n",
      "Processing chunk 5401/16667\n",
      "Processing chunk 5451/16667\n",
      "Processing chunk 5501/16667\n",
      "Processing chunk 5551/16667\n",
      "Processing chunk 5601/16667\n",
      "Processing chunk 5651/16667\n",
      "Processing chunk 5701/16667\n",
      "Processing chunk 5751/16667\n",
      "Processing chunk 5801/16667\n",
      "Processing chunk 5851/16667\n",
      "Processing chunk 5901/16667\n",
      "Processing chunk 5951/16667\n",
      "Processing chunk 6001/16667\n",
      "Processing chunk 6051/16667\n",
      "Processing chunk 6101/16667\n",
      "Processing chunk 6151/16667\n",
      "Processing chunk 6201/16667\n",
      "Processing chunk 6251/16667\n",
      "Processing chunk 6301/16667\n",
      "Processing chunk 6351/16667\n",
      "Processing chunk 6401/16667\n",
      "Processing chunk 6451/16667\n",
      "Processing chunk 6501/16667\n",
      "Processing chunk 6551/16667\n",
      "Processing chunk 6601/16667\n",
      "Processing chunk 6651/16667\n",
      "Processing chunk 6701/16667\n",
      "Processing chunk 6751/16667\n",
      "Processing chunk 6801/16667\n",
      "Processing chunk 6851/16667\n",
      "Processing chunk 6901/16667\n",
      "Processing chunk 6951/16667\n",
      "Processing chunk 7001/16667\n",
      "Processing chunk 7051/16667\n",
      "Processing chunk 7101/16667\n",
      "Processing chunk 7151/16667\n",
      "Processing chunk 7201/16667\n",
      "Processing chunk 7251/16667\n",
      "Processing chunk 7301/16667\n",
      "Processing chunk 7351/16667\n",
      "Processing chunk 7401/16667\n",
      "Processing chunk 7451/16667\n",
      "Processing chunk 7501/16667\n",
      "Processing chunk 7551/16667\n",
      "Processing chunk 7601/16667\n",
      "Processing chunk 7651/16667\n",
      "Processing chunk 7701/16667\n",
      "Processing chunk 7751/16667\n",
      "Processing chunk 7801/16667\n",
      "Processing chunk 7851/16667\n",
      "Processing chunk 7901/16667\n",
      "Processing chunk 7951/16667\n",
      "Processing chunk 8001/16667\n",
      "Processing chunk 8051/16667\n",
      "Processing chunk 8101/16667\n",
      "Processing chunk 8151/16667\n",
      "Processing chunk 8201/16667\n",
      "Processing chunk 8251/16667\n",
      "Processing chunk 8301/16667\n",
      "Processing chunk 8351/16667\n",
      "Processing chunk 8401/16667\n",
      "Processing chunk 8451/16667\n",
      "Processing chunk 8501/16667\n",
      "Processing chunk 8551/16667\n",
      "Processing chunk 8601/16667\n",
      "Processing chunk 8651/16667\n",
      "Processing chunk 8701/16667\n",
      "Processing chunk 8751/16667\n",
      "Processing chunk 8801/16667\n",
      "Processing chunk 8851/16667\n",
      "Processing chunk 8901/16667\n",
      "Processing chunk 8951/16667\n",
      "Processing chunk 9001/16667\n",
      "Processing chunk 9051/16667\n",
      "Processing chunk 9101/16667\n",
      "Processing chunk 9151/16667\n",
      "Processing chunk 9201/16667\n",
      "Processing chunk 9251/16667\n",
      "Processing chunk 9301/16667\n",
      "Processing chunk 9351/16667\n",
      "Processing chunk 9401/16667\n",
      "Processing chunk 9451/16667\n",
      "Processing chunk 9501/16667\n",
      "Processing chunk 9551/16667\n",
      "Processing chunk 9601/16667\n",
      "Processing chunk 9651/16667\n",
      "Processing chunk 9701/16667\n",
      "Processing chunk 9751/16667\n",
      "Processing chunk 9801/16667\n",
      "Processing chunk 9851/16667\n",
      "Processing chunk 9901/16667\n",
      "Processing chunk 9951/16667\n",
      "Processing chunk 10001/16667\n",
      "Processing chunk 10051/16667\n",
      "Processing chunk 10101/16667\n",
      "Processing chunk 10151/16667\n",
      "Processing chunk 10201/16667\n",
      "Processing chunk 10251/16667\n",
      "Processing chunk 10301/16667\n",
      "Processing chunk 10351/16667\n",
      "Processing chunk 10401/16667\n",
      "Processing chunk 10451/16667\n",
      "Processing chunk 10501/16667\n",
      "Processing chunk 10551/16667\n",
      "Processing chunk 10601/16667\n",
      "Processing chunk 10651/16667\n",
      "Processing chunk 10701/16667\n",
      "Processing chunk 10751/16667\n",
      "Processing chunk 10801/16667\n",
      "Processing chunk 10851/16667\n",
      "Processing chunk 10901/16667\n",
      "Processing chunk 10951/16667\n",
      "Processing chunk 11001/16667\n",
      "Processing chunk 11051/16667\n",
      "Processing chunk 11101/16667\n",
      "Processing chunk 11151/16667\n",
      "Processing chunk 11201/16667\n",
      "Processing chunk 11251/16667\n",
      "Processing chunk 11301/16667\n",
      "Processing chunk 11351/16667\n",
      "Processing chunk 11401/16667\n",
      "Processing chunk 11451/16667\n",
      "Processing chunk 11501/16667\n",
      "Processing chunk 11551/16667\n",
      "Processing chunk 11601/16667\n",
      "Processing chunk 11651/16667\n",
      "Processing chunk 11701/16667\n",
      "Processing chunk 11751/16667\n",
      "Processing chunk 11801/16667\n",
      "Processing chunk 11851/16667\n",
      "Processing chunk 11901/16667\n",
      "Processing chunk 11951/16667\n",
      "Processing chunk 12001/16667\n",
      "Processing chunk 12051/16667\n",
      "Processing chunk 12101/16667\n",
      "Processing chunk 12151/16667\n",
      "Processing chunk 12201/16667\n",
      "Processing chunk 12251/16667\n",
      "Processing chunk 12301/16667\n",
      "Processing chunk 12351/16667\n",
      "Processing chunk 12401/16667\n",
      "Processing chunk 12451/16667\n",
      "Processing chunk 12501/16667\n",
      "Processing chunk 12551/16667\n",
      "Processing chunk 12601/16667\n",
      "Processing chunk 12651/16667\n",
      "Processing chunk 12701/16667\n",
      "Processing chunk 12751/16667\n",
      "Processing chunk 12801/16667\n",
      "Processing chunk 12851/16667\n",
      "Processing chunk 12901/16667\n",
      "Processing chunk 12951/16667\n",
      "Processing chunk 13001/16667\n",
      "Processing chunk 13051/16667\n",
      "Processing chunk 13101/16667\n",
      "Processing chunk 13151/16667\n",
      "Processing chunk 13201/16667\n",
      "Processing chunk 13251/16667\n",
      "Processing chunk 13301/16667\n",
      "Processing chunk 13351/16667\n",
      "Processing chunk 13401/16667\n",
      "Processing chunk 13451/16667\n",
      "Processing chunk 13501/16667\n",
      "Processing chunk 13551/16667\n",
      "Processing chunk 13601/16667\n",
      "Processing chunk 13651/16667\n",
      "Processing chunk 13701/16667\n",
      "Processing chunk 13751/16667\n",
      "Processing chunk 13801/16667\n",
      "Processing chunk 13851/16667\n",
      "Processing chunk 13901/16667\n",
      "Processing chunk 13951/16667\n",
      "Processing chunk 14001/16667\n",
      "Processing chunk 14051/16667\n",
      "Processing chunk 14101/16667\n",
      "Processing chunk 14151/16667\n",
      "Processing chunk 14201/16667\n",
      "Processing chunk 14251/16667\n",
      "Processing chunk 14301/16667\n",
      "Processing chunk 14351/16667\n",
      "Processing chunk 14401/16667\n",
      "Processing chunk 14451/16667\n",
      "Processing chunk 14501/16667\n",
      "Processing chunk 14551/16667\n",
      "Processing chunk 14601/16667\n",
      "Processing chunk 14651/16667\n",
      "Processing chunk 14701/16667\n",
      "Processing chunk 14751/16667\n",
      "Processing chunk 14801/16667\n",
      "Processing chunk 14851/16667\n",
      "Processing chunk 14901/16667\n",
      "Processing chunk 14951/16667\n",
      "Processing chunk 15001/16667\n",
      "Processing chunk 15051/16667\n",
      "Processing chunk 15101/16667\n",
      "Processing chunk 15151/16667\n",
      "Processing chunk 15201/16667\n",
      "Processing chunk 15251/16667\n",
      "Processing chunk 15301/16667\n",
      "Processing chunk 15351/16667\n",
      "Processing chunk 15401/16667\n",
      "Processing chunk 15451/16667\n",
      "Processing chunk 15501/16667\n",
      "Processing chunk 15551/16667\n",
      "Processing chunk 15601/16667\n",
      "Processing chunk 15651/16667\n",
      "Processing chunk 15701/16667\n",
      "Processing chunk 15751/16667\n",
      "Processing chunk 15801/16667\n",
      "Processing chunk 15851/16667\n",
      "Processing chunk 15901/16667\n",
      "Processing chunk 15951/16667\n",
      "Processing chunk 16001/16667\n",
      "Processing chunk 16051/16667\n",
      "Processing chunk 16101/16667\n",
      "Processing chunk 16151/16667\n",
      "Processing chunk 16201/16667\n",
      "Processing chunk 16251/16667\n",
      "Processing chunk 16301/16667\n",
      "Processing chunk 16351/16667\n",
      "Processing chunk 16401/16667\n",
      "Processing chunk 16451/16667\n",
      "Processing chunk 16501/16667\n",
      "Processing chunk 16551/16667\n",
      "Processing chunk 16601/16667\n",
      "Processing chunk 16651/16667\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 5000\n",
      "Number of hits: 4552\n",
      "Average HR@20: 0.9104\n",
      "Average NDCG@20: 0.3514\n",
      "\n",
      "Training and evaluating GNMR...\n",
      "Epoch 1, Loss: 0.7360\n",
      "Epoch 2, Loss: 0.7132\n",
      "Epoch 3, Loss: 0.6921\n",
      "Epoch 4, Loss: 0.6724\n",
      "Epoch 5, Loss: 0.6541\n",
      "Epoch 6, Loss: 0.6371\n",
      "Epoch 7, Loss: 0.6210\n",
      "Epoch 8, Loss: 0.6059\n",
      "Epoch 9, Loss: 0.5915\n",
      "Epoch 10, Loss: 0.5778\n",
      "Training completed in 0.92s\n",
      "Preparing test instances...\n",
      "Generated 500000 test instances\n",
      "Evaluating 500000 instances in 16667 chunks...\n",
      "Processing chunk 1/16667\n",
      "Processing chunk 51/16667\n",
      "Processing chunk 101/16667\n",
      "Processing chunk 151/16667\n",
      "Processing chunk 201/16667\n",
      "Processing chunk 251/16667\n",
      "Processing chunk 301/16667\n",
      "Processing chunk 351/16667\n",
      "Processing chunk 401/16667\n",
      "Processing chunk 451/16667\n",
      "Processing chunk 501/16667\n",
      "Processing chunk 551/16667\n",
      "Processing chunk 601/16667\n",
      "Processing chunk 651/16667\n",
      "Processing chunk 701/16667\n",
      "Processing chunk 751/16667\n",
      "Processing chunk 801/16667\n",
      "Processing chunk 851/16667\n",
      "Processing chunk 901/16667\n",
      "Processing chunk 951/16667\n",
      "Processing chunk 1001/16667\n",
      "Processing chunk 1051/16667\n",
      "Processing chunk 1101/16667\n",
      "Processing chunk 1151/16667\n",
      "Processing chunk 1201/16667\n",
      "Processing chunk 1251/16667\n",
      "Processing chunk 1301/16667\n",
      "Processing chunk 1351/16667\n",
      "Processing chunk 1401/16667\n",
      "Processing chunk 1451/16667\n",
      "Processing chunk 1501/16667\n",
      "Processing chunk 1551/16667\n",
      "Processing chunk 1601/16667\n",
      "Processing chunk 1651/16667\n",
      "Processing chunk 1701/16667\n",
      "Processing chunk 1751/16667\n",
      "Processing chunk 1801/16667\n",
      "Processing chunk 1851/16667\n",
      "Processing chunk 1901/16667\n",
      "Processing chunk 1951/16667\n",
      "Processing chunk 2001/16667\n",
      "Processing chunk 2051/16667\n",
      "Processing chunk 2101/16667\n",
      "Processing chunk 2151/16667\n",
      "Processing chunk 2201/16667\n",
      "Processing chunk 2251/16667\n",
      "Processing chunk 2301/16667\n",
      "Processing chunk 2351/16667\n",
      "Processing chunk 2401/16667\n",
      "Processing chunk 2451/16667\n",
      "Processing chunk 2501/16667\n",
      "Processing chunk 2551/16667\n",
      "Processing chunk 2601/16667\n",
      "Processing chunk 2651/16667\n",
      "Processing chunk 2701/16667\n",
      "Processing chunk 2751/16667\n",
      "Processing chunk 2801/16667\n",
      "Processing chunk 2851/16667\n",
      "Processing chunk 2901/16667\n",
      "Processing chunk 2951/16667\n",
      "Processing chunk 3001/16667\n",
      "Processing chunk 3051/16667\n",
      "Processing chunk 3101/16667\n",
      "Processing chunk 3151/16667\n",
      "Processing chunk 3201/16667\n",
      "Processing chunk 3251/16667\n",
      "Processing chunk 3301/16667\n",
      "Processing chunk 3351/16667\n",
      "Processing chunk 3401/16667\n",
      "Processing chunk 3451/16667\n",
      "Processing chunk 3501/16667\n",
      "Processing chunk 3551/16667\n",
      "Processing chunk 3601/16667\n",
      "Processing chunk 3651/16667\n",
      "Processing chunk 3701/16667\n",
      "Processing chunk 3751/16667\n",
      "Processing chunk 3801/16667\n",
      "Processing chunk 3851/16667\n",
      "Processing chunk 3901/16667\n",
      "Processing chunk 3951/16667\n",
      "Processing chunk 4001/16667\n",
      "Processing chunk 4051/16667\n",
      "Processing chunk 4101/16667\n",
      "Processing chunk 4151/16667\n",
      "Processing chunk 4201/16667\n",
      "Processing chunk 4251/16667\n",
      "Processing chunk 4301/16667\n",
      "Processing chunk 4351/16667\n",
      "Processing chunk 4401/16667\n",
      "Processing chunk 4451/16667\n",
      "Processing chunk 4501/16667\n",
      "Processing chunk 4551/16667\n",
      "Processing chunk 4601/16667\n",
      "Processing chunk 4651/16667\n",
      "Processing chunk 4701/16667\n",
      "Processing chunk 4751/16667\n",
      "Processing chunk 4801/16667\n",
      "Processing chunk 4851/16667\n",
      "Processing chunk 4901/16667\n",
      "Processing chunk 4951/16667\n",
      "Processing chunk 5001/16667\n",
      "Processing chunk 5051/16667\n",
      "Processing chunk 5101/16667\n",
      "Processing chunk 5151/16667\n",
      "Processing chunk 5201/16667\n",
      "Processing chunk 5251/16667\n",
      "Processing chunk 5301/16667\n",
      "Processing chunk 5351/16667\n",
      "Processing chunk 5401/16667\n",
      "Processing chunk 5451/16667\n",
      "Processing chunk 5501/16667\n",
      "Processing chunk 5551/16667\n",
      "Processing chunk 5601/16667\n",
      "Processing chunk 5651/16667\n",
      "Processing chunk 5701/16667\n",
      "Processing chunk 5751/16667\n",
      "Processing chunk 5801/16667\n",
      "Processing chunk 5851/16667\n",
      "Processing chunk 5901/16667\n",
      "Processing chunk 5951/16667\n",
      "Processing chunk 6001/16667\n",
      "Processing chunk 6051/16667\n",
      "Processing chunk 6101/16667\n",
      "Processing chunk 6151/16667\n",
      "Processing chunk 6201/16667\n",
      "Processing chunk 6251/16667\n",
      "Processing chunk 6301/16667\n",
      "Processing chunk 6351/16667\n",
      "Processing chunk 6401/16667\n",
      "Processing chunk 6451/16667\n",
      "Processing chunk 6501/16667\n",
      "Processing chunk 6551/16667\n",
      "Processing chunk 6601/16667\n",
      "Processing chunk 6651/16667\n",
      "Processing chunk 6701/16667\n",
      "Processing chunk 6751/16667\n",
      "Processing chunk 6801/16667\n",
      "Processing chunk 6851/16667\n",
      "Processing chunk 6901/16667\n",
      "Processing chunk 6951/16667\n",
      "Processing chunk 7001/16667\n",
      "Processing chunk 7051/16667\n",
      "Processing chunk 7101/16667\n",
      "Processing chunk 7151/16667\n",
      "Processing chunk 7201/16667\n",
      "Processing chunk 7251/16667\n",
      "Processing chunk 7301/16667\n",
      "Processing chunk 7351/16667\n",
      "Processing chunk 7401/16667\n",
      "Processing chunk 7451/16667\n",
      "Processing chunk 7501/16667\n",
      "Processing chunk 7551/16667\n",
      "Processing chunk 7601/16667\n",
      "Processing chunk 7651/16667\n",
      "Processing chunk 7701/16667\n",
      "Processing chunk 7751/16667\n",
      "Processing chunk 7801/16667\n",
      "Processing chunk 7851/16667\n",
      "Processing chunk 7901/16667\n",
      "Processing chunk 7951/16667\n",
      "Processing chunk 8001/16667\n",
      "Processing chunk 8051/16667\n",
      "Processing chunk 8101/16667\n",
      "Processing chunk 8151/16667\n",
      "Processing chunk 8201/16667\n",
      "Processing chunk 8251/16667\n",
      "Processing chunk 8301/16667\n",
      "Processing chunk 8351/16667\n",
      "Processing chunk 8401/16667\n",
      "Processing chunk 8451/16667\n",
      "Processing chunk 8501/16667\n",
      "Processing chunk 8551/16667\n",
      "Processing chunk 8601/16667\n",
      "Processing chunk 8651/16667\n",
      "Processing chunk 8701/16667\n",
      "Processing chunk 8751/16667\n",
      "Processing chunk 8801/16667\n",
      "Processing chunk 8851/16667\n",
      "Processing chunk 8901/16667\n",
      "Processing chunk 8951/16667\n",
      "Processing chunk 9001/16667\n",
      "Processing chunk 9051/16667\n",
      "Processing chunk 9101/16667\n",
      "Processing chunk 9151/16667\n",
      "Processing chunk 9201/16667\n",
      "Processing chunk 9251/16667\n",
      "Processing chunk 9301/16667\n",
      "Processing chunk 9351/16667\n",
      "Processing chunk 9401/16667\n",
      "Processing chunk 9451/16667\n",
      "Processing chunk 9501/16667\n",
      "Processing chunk 9551/16667\n",
      "Processing chunk 9601/16667\n",
      "Processing chunk 9651/16667\n",
      "Processing chunk 9701/16667\n",
      "Processing chunk 9751/16667\n",
      "Processing chunk 9801/16667\n",
      "Processing chunk 9851/16667\n",
      "Processing chunk 9901/16667\n",
      "Processing chunk 9951/16667\n",
      "Processing chunk 10001/16667\n",
      "Processing chunk 10051/16667\n",
      "Processing chunk 10101/16667\n",
      "Processing chunk 10151/16667\n",
      "Processing chunk 10201/16667\n",
      "Processing chunk 10251/16667\n",
      "Processing chunk 10301/16667\n",
      "Processing chunk 10351/16667\n",
      "Processing chunk 10401/16667\n",
      "Processing chunk 10451/16667\n",
      "Processing chunk 10501/16667\n",
      "Processing chunk 10551/16667\n",
      "Processing chunk 10601/16667\n",
      "Processing chunk 10651/16667\n",
      "Processing chunk 10701/16667\n",
      "Processing chunk 10751/16667\n",
      "Processing chunk 10801/16667\n",
      "Processing chunk 10851/16667\n",
      "Processing chunk 10901/16667\n",
      "Processing chunk 10951/16667\n",
      "Processing chunk 11001/16667\n",
      "Processing chunk 11051/16667\n",
      "Processing chunk 11101/16667\n",
      "Processing chunk 11151/16667\n",
      "Processing chunk 11201/16667\n",
      "Processing chunk 11251/16667\n",
      "Processing chunk 11301/16667\n",
      "Processing chunk 11351/16667\n",
      "Processing chunk 11401/16667\n",
      "Processing chunk 11451/16667\n",
      "Processing chunk 11501/16667\n",
      "Processing chunk 11551/16667\n",
      "Processing chunk 11601/16667\n",
      "Processing chunk 11651/16667\n",
      "Processing chunk 11701/16667\n",
      "Processing chunk 11751/16667\n",
      "Processing chunk 11801/16667\n",
      "Processing chunk 11851/16667\n",
      "Processing chunk 11901/16667\n",
      "Processing chunk 11951/16667\n",
      "Processing chunk 12001/16667\n",
      "Processing chunk 12051/16667\n",
      "Processing chunk 12101/16667\n",
      "Processing chunk 12151/16667\n",
      "Processing chunk 12201/16667\n",
      "Processing chunk 12251/16667\n",
      "Processing chunk 12301/16667\n",
      "Processing chunk 12351/16667\n",
      "Processing chunk 12401/16667\n",
      "Processing chunk 12451/16667\n",
      "Processing chunk 12501/16667\n",
      "Processing chunk 12551/16667\n",
      "Processing chunk 12601/16667\n",
      "Processing chunk 12651/16667\n",
      "Processing chunk 12701/16667\n",
      "Processing chunk 12751/16667\n",
      "Processing chunk 12801/16667\n",
      "Processing chunk 12851/16667\n",
      "Processing chunk 12901/16667\n",
      "Processing chunk 12951/16667\n",
      "Processing chunk 13001/16667\n",
      "Processing chunk 13051/16667\n",
      "Processing chunk 13101/16667\n",
      "Processing chunk 13151/16667\n",
      "Processing chunk 13201/16667\n",
      "Processing chunk 13251/16667\n",
      "Processing chunk 13301/16667\n",
      "Processing chunk 13351/16667\n",
      "Processing chunk 13401/16667\n",
      "Processing chunk 13451/16667\n",
      "Processing chunk 13501/16667\n",
      "Processing chunk 13551/16667\n",
      "Processing chunk 13601/16667\n",
      "Processing chunk 13651/16667\n",
      "Processing chunk 13701/16667\n",
      "Processing chunk 13751/16667\n",
      "Processing chunk 13801/16667\n",
      "Processing chunk 13851/16667\n",
      "Processing chunk 13901/16667\n",
      "Processing chunk 13951/16667\n",
      "Processing chunk 14001/16667\n",
      "Processing chunk 14051/16667\n",
      "Processing chunk 14101/16667\n",
      "Processing chunk 14151/16667\n",
      "Processing chunk 14201/16667\n",
      "Processing chunk 14251/16667\n",
      "Processing chunk 14301/16667\n",
      "Processing chunk 14351/16667\n",
      "Processing chunk 14401/16667\n",
      "Processing chunk 14451/16667\n",
      "Processing chunk 14501/16667\n",
      "Processing chunk 14551/16667\n",
      "Processing chunk 14601/16667\n",
      "Processing chunk 14651/16667\n",
      "Processing chunk 14701/16667\n",
      "Processing chunk 14751/16667\n",
      "Processing chunk 14801/16667\n",
      "Processing chunk 14851/16667\n",
      "Processing chunk 14901/16667\n",
      "Processing chunk 14951/16667\n",
      "Processing chunk 15001/16667\n",
      "Processing chunk 15051/16667\n",
      "Processing chunk 15101/16667\n",
      "Processing chunk 15151/16667\n",
      "Processing chunk 15201/16667\n",
      "Processing chunk 15251/16667\n",
      "Processing chunk 15301/16667\n",
      "Processing chunk 15351/16667\n",
      "Processing chunk 15401/16667\n",
      "Processing chunk 15451/16667\n",
      "Processing chunk 15501/16667\n",
      "Processing chunk 15551/16667\n",
      "Processing chunk 15601/16667\n",
      "Processing chunk 15651/16667\n",
      "Processing chunk 15701/16667\n",
      "Processing chunk 15751/16667\n",
      "Processing chunk 15801/16667\n",
      "Processing chunk 15851/16667\n",
      "Processing chunk 15901/16667\n",
      "Processing chunk 15951/16667\n",
      "Processing chunk 16001/16667\n",
      "Processing chunk 16051/16667\n",
      "Processing chunk 16101/16667\n",
      "Processing chunk 16151/16667\n",
      "Processing chunk 16201/16667\n",
      "Processing chunk 16251/16667\n",
      "Processing chunk 16301/16667\n",
      "Processing chunk 16351/16667\n",
      "Processing chunk 16401/16667\n",
      "Processing chunk 16451/16667\n",
      "Processing chunk 16501/16667\n",
      "Processing chunk 16551/16667\n",
      "Processing chunk 16601/16667\n",
      "Processing chunk 16651/16667\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 5000\n",
      "Number of hits: 4419\n",
      "Average HR@20: 0.8838\n",
      "Average NDCG@20: 0.3373\n",
      "\n",
      "Final Results:\n",
      "CF-UIcA: HR@20 = 0.8968, NDCG@20 = 0.3429, Training Time = 1.25s\n",
      "ST-GCN: HR@20 = 0.8828, NDCG@20 = 0.3528, Training Time = 2.02s\n",
      "NGCF: HR@20 = 0.8944, NDCG@20 = 0.3617, Training Time = 1.85s\n",
      "NMTR: HR@20 = 0.9000, NDCG@20 = 0.3462, Training Time = 0.89s\n",
      "DIPN: HR@20 = 0.8862, NDCG@20 = 0.3471, Training Time = 0.88s\n",
      "NGCF+M: HR@20 = 0.8850, NDCG@20 = 0.3461, Training Time = 1.73s\n",
      "MBGCN: HR@20 = 0.9014, NDCG@20 = 0.3519, Training Time = 1.88s\n",
      "MATN: HR@20 = 0.9104, NDCG@20 = 0.3514, Training Time = 0.91s\n",
      "GNMR: HR@20 = 0.8838, NDCG@20 = 0.3373, Training Time = 0.92s\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import pickle\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.nn import Linear, Dropout, LayerNorm\n",
    "# from torch.nn import functional as F\n",
    "# from torch.nn import ModuleList\n",
    "# from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "# from datetime import datetime\n",
    "# from scipy.sparse import csr_matrix\n",
    "\n",
    "# # Device configuration\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# # cropped dataset\n",
    "# class MultiBehaviorDataset:\n",
    "#     def __init__(self, data_path='/Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/', max_users=10000):\n",
    "#         self.data_path = data_path\n",
    "#         self.behaviors = ['pv', 'cart', 'buy']\n",
    "#         self.trn_file = data_path + 'trn_'\n",
    "#         self.tst_file = data_path + 'tst_'\n",
    "#         self.max_users = max_users  # Limit number of users\n",
    "        \n",
    "#         self.load_training_data()\n",
    "#         self.load_test_data()\n",
    "    \n",
    "#     def load_training_data(self):\n",
    "#         print(\"Loading training data from:\", self.data_path)\n",
    "#         self.trn_mats = []\n",
    "#         for beh in self.behaviors:\n",
    "#             path = self.trn_file + beh\n",
    "#             print(f\"Loading behavior: {beh} from {path}\")\n",
    "#             if not os.path.exists(path):\n",
    "#                 raise FileNotFoundError(f\"File not found: {path}\")\n",
    "#             with open(path, 'rb') as fs:\n",
    "#                 mat = pickle.load(fs)\n",
    "#                 if not isinstance(mat, csr_matrix):\n",
    "#                     mat = csr_matrix(mat)\n",
    "#                 mat = (mat != 0).astype(np.float32)\n",
    "#                 self.trn_mats.append(mat)\n",
    "        \n",
    "#         self.trn_label = 1 * (self.trn_mats[-1] != 0)\n",
    "#         self.n_users, self.n_items = self.trn_mats[0].shape\n",
    "#         self.n_behaviors = len(self.behaviors)\n",
    "#         print(f\"Dataset dimensions: {self.n_users} users, {self.n_items} items\")\n",
    "\n",
    "#     def create_adjacency_matrix(self, users):\n",
    "#         \"\"\"Optimized adjacency matrix creation\"\"\"\n",
    "#         batch_size = len(users)\n",
    "#         adj_matrix = torch.zeros(batch_size, batch_size, device=device)\n",
    "        \n",
    "#         # Pre-compute user item sets\n",
    "#         user_item_sets = []\n",
    "#         for user in users:\n",
    "#             user_items = set()\n",
    "#             for mat in self.trn_mats:\n",
    "#                 user_items.update(mat[user].indices)\n",
    "#             user_item_sets.append(user_items)\n",
    "        \n",
    "#         # Compute similarities in parallel\n",
    "#         for i in range(batch_size):\n",
    "#             if not user_item_sets[i]:\n",
    "#                 continue\n",
    "#             for j in range(i+1, batch_size):\n",
    "#                 if user_item_sets[j]:\n",
    "#                     jaccard = len(user_item_sets[i] & user_item_sets[j]) / len(user_item_sets[i] | user_item_sets[j])\n",
    "#                     adj_matrix[i,j] = adj_matrix[j,i] = jaccard\n",
    "        \n",
    "#         return adj_matrix\n",
    "\n",
    "#     def create_graph_metrics(self, users):\n",
    "#         \"\"\"Optimized graph metrics creation\"\"\"\n",
    "#         metrics = torch.zeros(len(users), 3, device=device)\n",
    "        \n",
    "#         # Vectorized computation\n",
    "#         for i, user in enumerate(users):\n",
    "#             interactions = np.array([mat[user].nnz for mat in self.trn_mats])\n",
    "#             metrics[i,0] = sum(interactions) / 100\n",
    "#             metrics[i,1] = (interactions > 0).sum() / len(self.behaviors)\n",
    "#             metrics[i,2] = interactions[-1] / max(interactions[0], 1)\n",
    "        \n",
    "#         return metrics\n",
    "\n",
    "#     def prepare_train_instances(self, max_samples=5000):\n",
    "#         \"\"\"Optimized training instance preparation\"\"\"\n",
    "#         print(\"Preparing training instances...\")\n",
    "#         train_data = []\n",
    "        \n",
    "#         # Randomly select users\n",
    "#         selected_users = np.random.choice(min(self.n_users, self.max_users), size=min(1000, self.max_users), replace=False)\n",
    "        \n",
    "#         for user in selected_users:\n",
    "#             pos_items = self.trn_label[user].indices[:2]  # Limit positive items\n",
    "            \n",
    "#             if len(pos_items) > 0:\n",
    "#                 for item in pos_items:\n",
    "#                     behaviors = [float(mat[user, item]) for mat in self.trn_mats]\n",
    "#                     train_data.append([user, item, 1.0] + behaviors)\n",
    "                    \n",
    "#                     # Limited negative sampling\n",
    "#                     neg_items = np.random.choice(self.n_items, size=2, replace=False)\n",
    "#                     for neg_item in neg_items:\n",
    "#                         behaviors = [float(mat[user, neg_item]) for mat in self.trn_mats]\n",
    "#                         train_data.append([user, neg_item, 0.0] + behaviors)\n",
    "                        \n",
    "#                     if len(train_data) >= max_samples:\n",
    "#                         break\n",
    "            \n",
    "#             if len(train_data) >= max_samples:\n",
    "#                 break\n",
    "        \n",
    "#         print(f\"Generated {len(train_data)} training instances\")\n",
    "#         return np.array(train_data)\n",
    "    \n",
    "#     def load_test_data(self):\n",
    "#         \"\"\"Load test data\"\"\"\n",
    "#         test_path = self.tst_file + 'int'\n",
    "#         print(f\"Loading test data from: {test_path}\")\n",
    "#         if not os.path.exists(test_path):\n",
    "#             raise FileNotFoundError(f\"File not found: {test_path}\")\n",
    "#         with open(test_path, 'rb') as fs:\n",
    "#             self.tst_int = np.array(pickle.load(fs))\n",
    "        \n",
    "#         self.tst_users = np.reshape(np.argwhere(self.tst_int != None), [-1])\n",
    "#         # Limit test users for faster processing\n",
    "#         self.tst_users = self.tst_users[:min(len(self.tst_users), self.max_users)]\n",
    "#         print(f\"Using {len(self.tst_users)} test users\")\n",
    "\n",
    "#     def get_test_instances(self, num_neg_samples=99):\n",
    "#         \"\"\"Generate test instances with negative sampling\"\"\"\n",
    "#         print(\"Preparing test instances...\")\n",
    "#         test_instances = []\n",
    "        \n",
    "#         for user in self.tst_users:\n",
    "#             pos_item = self.tst_int[user]\n",
    "#             if pos_item is not None:\n",
    "#                 # Add positive instance\n",
    "#                 test_instances.append([user, pos_item, 1.0])\n",
    "                \n",
    "#                 # Add negative instances\n",
    "#                 try:\n",
    "#                     # Get all items and remove positive items\n",
    "#                     all_items = set(range(self.n_items))\n",
    "#                     pos_items_train = set(self.trn_label[user].indices)\n",
    "#                     pos_items_train.add(pos_item)\n",
    "#                     neg_items_pool = list(all_items - pos_items_train)\n",
    "                    \n",
    "#                     # Sample negative items\n",
    "#                     n_neg = min(num_neg_samples, len(neg_items_pool))\n",
    "#                     if n_neg > 0:\n",
    "#                         neg_items = np.random.choice(neg_items_pool, size=n_neg, replace=False)\n",
    "#                         for neg_item in neg_items:\n",
    "#                             test_instances.append([user, neg_item, 0.0])\n",
    "                \n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error processing test user {user}: {str(e)}\")\n",
    "#                     continue\n",
    "                \n",
    "#                 # Limit the number of test instances for faster processing\n",
    "#                 if len(test_instances) >= self.max_users * 100:\n",
    "#                     break\n",
    "        \n",
    "#         if not test_instances:\n",
    "#             raise ValueError(\"No test instances were generated!\")\n",
    "            \n",
    "#         test_instances = np.array(test_instances)\n",
    "#         print(f\"Generated {len(test_instances)} test instances\")\n",
    "#         return test_instances\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def evaluate_model(model, dataset, test_instances, k=10):\n",
    "#     \"\"\"Improved evaluation function with better metrics calculation\"\"\"\n",
    "#     model.eval()\n",
    "#     hits = []\n",
    "#     ndcgs = []\n",
    "    \n",
    "#     # Process test instances in smaller chunks\n",
    "#     chunk_size = 30\n",
    "#     test_chunks = [test_instances[i:i + chunk_size] for i in range(0, len(test_instances), chunk_size)]\n",
    "    \n",
    "#     print(f\"Evaluating {len(test_instances)} instances in {len(test_chunks)} chunks...\")\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for chunk_idx, chunk in enumerate(test_chunks):\n",
    "#             if chunk_idx % 50 == 0:  # Reduced frequency of progress updates\n",
    "#                 print(f\"Processing chunk {chunk_idx + 1}/{len(test_chunks)}\")\n",
    "            \n",
    "#             # Group by user and ensure we have both positive and negative items\n",
    "#             user_items = {}\n",
    "#             for inst in chunk:\n",
    "#                 user = int(inst[0])\n",
    "#                 item = int(inst[1])\n",
    "#                 label = float(inst[2])\n",
    "                \n",
    "#                 if user not in user_items:\n",
    "#                     user_items[user] = {'pos': [], 'neg': [], 'all_items': [], 'all_scores': []}\n",
    "                \n",
    "#                 user_items[user]['all_items'].append(item)\n",
    "#                 if label > 0.5:\n",
    "#                     user_items[user]['pos'].append(item)\n",
    "#                 else:\n",
    "#                     user_items[user]['neg'].append(item)\n",
    "            \n",
    "#             # Process each user that has both positive and negative items\n",
    "#             for user, data in user_items.items():\n",
    "#                 if not data['pos'] or not data['neg']:\n",
    "#                     continue\n",
    "                \n",
    "#                 items = data['all_items']\n",
    "#                 batch_size = len(items)\n",
    "                \n",
    "#                 # Create input features\n",
    "#                 user_tensor = torch.LongTensor([user] * batch_size).to(device)\n",
    "#                 item_tensor = torch.LongTensor(items).to(device)\n",
    "                \n",
    "#                 # Forward pass\n",
    "#                 predictions = model(user_tensor, item_tensor)  # Pass both user and item\n",
    "#                 predictions = predictions.cpu().numpy().flatten()\n",
    "                \n",
    "#                 # Store all scores\n",
    "#                 for item, score in zip(items, predictions):\n",
    "#                     data['all_scores'].append((item, score))\n",
    "                \n",
    "#                 # Sort items by score\n",
    "#                 sorted_items = [x[0] for x in sorted(data['all_scores'], key=lambda x: x[1], reverse=True)]\n",
    "#                 recommended_items = sorted_items[:k]\n",
    "                \n",
    "#                 # Calculate HR\n",
    "#                 hit = any(pos_item in recommended_items for pos_item in data['pos'])\n",
    "#                 hits.append(hit)\n",
    "                \n",
    "#                 # Calculate NDCG\n",
    "#                 dcg = 0\n",
    "#                 for i, item in enumerate(recommended_items):\n",
    "#                     if item in data['pos']:\n",
    "#                         dcg += 1 / np.log2(i + 2)\n",
    "#                 idcg = sum(1 / np.log2(i + 2) for i in range(len(data['pos'])))  # Ideal DCG\n",
    "#                 ndcg = dcg / (idcg if idcg > 0 else 1)  # Avoid division by zero\n",
    "#                 ndcgs.append(ndcg)\n",
    "    \n",
    "#     # Calculate final metrics\n",
    "#     hr = np.mean(hits) if hits else 0\n",
    "#     ndcg = np.mean(ndcgs) if ndcgs else 0\n",
    "    \n",
    "#     # Print detailed statistics\n",
    "#     print(f\"\\nEvaluation Statistics:\")\n",
    "#     print(f\"Total users evaluated: {len(hits)}\")\n",
    "#     print(f\"Number of hits: {sum(hits)}\")\n",
    "#     print(f\"Average HR@{k}: {hr:.4f}\")\n",
    "#     print(f\"Average NDCG@{k}: {ndcg:.4f}\")\n",
    "    \n",
    "#     return hr, ndcg\n",
    "\n",
    "# # Define and Implement Each Algorithm\n",
    "# class CF_UIcA(nn.Module):\n",
    "#     def __init__(self, n_users, n_items, embedding_dim=128):\n",
    "#         super(CF_UIcA, self).__init__()\n",
    "#         self.user_embedding = nn.Embedding(n_users, embedding_dim)\n",
    "#         self.item_embedding = nn.Embedding(n_items, embedding_dim)\n",
    "#         self.fc = nn.Linear(embedding_dim * 2, 1)\n",
    "#         self.input_dim = embedding_dim * 2\n",
    "\n",
    "#     def forward(self, users, items):\n",
    "#         user_emb = self.user_embedding(users)\n",
    "#         item_emb = self.item_embedding(items)\n",
    "#         combined = torch.cat([user_emb, item_emb], dim=1)\n",
    "#         return self.fc(combined).squeeze()\n",
    "\n",
    "# class ST_GCN(nn.Module):\n",
    "#     def __init__(self, n_users, n_items, embedding_dim=128):\n",
    "#         super(ST_GCN, self).__init__()\n",
    "#         self.user_embedding = nn.Embedding(n_users, embedding_dim)\n",
    "#         self.item_embedding = nn.Embedding(n_items, embedding_dim)\n",
    "#         self.gcn_layer = nn.Linear(embedding_dim * 2, embedding_dim)\n",
    "#         self.fc = nn.Linear(embedding_dim, 1)\n",
    "#         self.input_dim = embedding_dim * 2\n",
    "\n",
    "    \n",
    "#     def forward(self, users, items):\n",
    "#         user_emb = self.user_embedding(users)\n",
    "#         item_emb = self.item_embedding(items)\n",
    "#         combined = torch.cat([user_emb, item_emb], dim=1)\n",
    "#         gcn_output = F.relu(self.gcn_layer(combined))\n",
    "#         return self.fc(gcn_output).squeeze()\n",
    "    \n",
    "# class NGCF(nn.Module):\n",
    "#     def __init__(self, n_users, n_items, embedding_dim=128):\n",
    "#         super(NGCF, self).__init__()\n",
    "#         self.user_embedding = nn.Embedding(n_users, embedding_dim)\n",
    "#         self.item_embedding = nn.Embedding(n_items, embedding_dim)\n",
    "#         self.gcn_layer = nn.Linear(embedding_dim * 2, embedding_dim)\n",
    "#         self.fc = nn.Linear(embedding_dim, 1)\n",
    "#         self.input_dim = embedding_dim * 2\n",
    "\n",
    "    \n",
    "#     def forward(self, users, items):\n",
    "#         user_emb = self.user_embedding(users)\n",
    "#         item_emb = self.item_embedding(items)\n",
    "#         combined = torch.cat([user_emb, item_emb], dim=1)\n",
    "#         gcn_output = F.relu(self.gcn_layer(combined))\n",
    "#         return self.fc(gcn_output).squeeze()\n",
    "\n",
    "# class NMTR(nn.Module):\n",
    "#     def __init__(self, n_users, n_items, embedding_dim=128):\n",
    "#         super(NMTR, self).__init__()\n",
    "#         self.user_embedding = nn.Embedding(n_users, embedding_dim)\n",
    "#         self.item_embedding = nn.Embedding(n_items, embedding_dim)\n",
    "#         self.fc = nn.Linear(embedding_dim * 2, 1)\n",
    "#         self.input_dim = embedding_dim * 2\n",
    "\n",
    "    \n",
    "#     def forward(self, users, items):\n",
    "#         user_emb = self.user_embedding(users)\n",
    "#         item_emb = self.item_embedding(items)\n",
    "#         combined = torch.cat([user_emb, item_emb], dim=1)\n",
    "#         return self.fc(combined).squeeze()\n",
    "\n",
    "# class DIPN(nn.Module):\n",
    "#     def __init__(self, n_users, n_items, embedding_dim=128):\n",
    "#         super(DIPN, self).__init__()\n",
    "#         self.user_embedding = nn.Embedding(n_users, embedding_dim)\n",
    "#         self.item_embedding = nn.Embedding(n_items, embedding_dim)\n",
    "#         self.fc = nn.Linear(embedding_dim * 2, 1)\n",
    "#         self.input_dim = embedding_dim * 2\n",
    "\n",
    "    \n",
    "#     def forward(self, users, items):\n",
    "#         user_emb = self.user_embedding(users)\n",
    "#         item_emb = self.item_embedding(items)\n",
    "#         combined = torch.cat([user_emb, item_emb], dim=1)\n",
    "#         return self.fc(combined).squeeze()\n",
    "\n",
    "# class NGCF_M(nn.Module):\n",
    "#     def __init__(self, n_users, n_items, embedding_dim=128):\n",
    "#         super(NGCF_M, self).__init__()\n",
    "#         self.user_embedding = nn.Embedding(n_users, embedding_dim)\n",
    "#         self.item_embedding = nn.Embedding(n_items, embedding_dim)\n",
    "#         self.gcn_layer = nn.Linear(embedding_dim * 2, embedding_dim)\n",
    "#         self.fc = nn.Linear(embedding_dim, 1)\n",
    "#         self.input_dim = embedding_dim * 2\n",
    "\n",
    "    \n",
    "#     def forward(self, users, items):\n",
    "#         user_emb = self.user_embedding(users)\n",
    "#         item_emb = self.item_embedding(items)\n",
    "#         combined = torch.cat([user_emb, item_emb], dim=1)\n",
    "#         gcn_output = F.relu(self.gcn_layer(combined))\n",
    "#         return self.fc(gcn_output).squeeze()\n",
    "\n",
    "# class MBGCN(nn.Module):\n",
    "#     def __init__(self, n_users, n_items, embedding_dim=128):\n",
    "#         super(MBGCN, self).__init__()\n",
    "#         self.user_embedding = nn.Embedding(n_users, embedding_dim)\n",
    "#         self.item_embedding = nn.Embedding(n_items, embedding_dim)\n",
    "#         self.gcn_layer = nn.Linear(embedding_dim * 2, embedding_dim)\n",
    "#         self.fc = nn.Linear(embedding_dim, 1)\n",
    "#         self.input_dim = embedding_dim * 2\n",
    "\n",
    "    \n",
    "#     def forward(self, users, items):\n",
    "#         user_emb = self.user_embedding(users)\n",
    "#         item_emb = self.item_embedding(items)\n",
    "#         combined = torch.cat([user_emb, item_emb], dim=1)\n",
    "#         gcn_output = F.relu(self.gcn_layer(combined))\n",
    "#         return self.fc(gcn_output).squeeze()\n",
    "\n",
    "# class MATN(nn.Module):\n",
    "#     def __init__(self, n_users, n_items, embedding_dim=128):\n",
    "#         super(MATN, self).__init__()\n",
    "#         self.user_embedding = nn.Embedding(n_users, embedding_dim)\n",
    "#         self.item_embedding = nn.Embedding(n_items, embedding_dim)\n",
    "#         self.fc = nn.Linear(embedding_dim * 2, 1)\n",
    "#         self.input_dim = embedding_dim * 2\n",
    "\n",
    "    \n",
    "#     def forward(self, users, items):\n",
    "#         user_emb = self.user_embedding(users)\n",
    "#         item_emb = self.item_embedding(items)\n",
    "#         combined = torch.cat([user_emb, item_emb], dim=1)\n",
    "#         return self.fc(combined).squeeze()\n",
    "\n",
    "# class GNMR(nn.Module):\n",
    "#     def __init__(self, n_users, n_items, embedding_dim=128):\n",
    "#         super(GNMR, self).__init__()\n",
    "#         self.user_embedding = nn.Embedding(n_users, embedding_dim)\n",
    "#         self.item_embedding = nn.Embedding(n_items, embedding_dim)\n",
    "#         self.fc = nn.Linear(embedding_dim * 2, 1)\n",
    "#         self.input_dim = embedding_dim * 2\n",
    "\n",
    "    \n",
    "#     def forward(self, users, items):\n",
    "#         user_emb = self.user_embedding(users)\n",
    "#         item_emb = self.item_embedding(items)\n",
    "#         combined = torch.cat([user_emb, item_emb], dim=1)\n",
    "#         return self.fc(combined).squeeze()\n",
    "\n",
    "\n",
    "# # Main Function to Train and Evaluate All Models\n",
    "# def main():\n",
    "#     # Configuration\n",
    "#     config = {\n",
    "#         'embedding_dim': 1024,\n",
    "#         'learning_rate': 0.001,\n",
    "#         'weight_decay': 1e-6,\n",
    "#         'dropout': 0.001,\n",
    "#         'gradient_clip': 1.0,\n",
    "#         'max_samples': 10000,\n",
    "#         'eval_k': 20\n",
    "#     }\n",
    "    \n",
    "#     print(\"Initializing dataset...\")\n",
    "#     dataset = MultiBehaviorDataset(max_users=5000)\n",
    "#     train_data = dataset.prepare_train_instances(max_samples=config['max_samples'])\n",
    "    \n",
    "#     print(f\"Using {len(train_data)} training instances\")\n",
    "\n",
    "#     # Define all models\n",
    "#     models = {\n",
    "#         \"CF-UIcA\": CF_UIcA(dataset.n_users, dataset.n_items, config['embedding_dim']).to(device),\n",
    "#         \"ST-GCN\": ST_GCN(dataset.n_users, dataset.n_items, config['embedding_dim']).to(device),\n",
    "#         \"NGCF\": NGCF(dataset.n_users, dataset.n_items, config['embedding_dim']).to(device),\n",
    "#         \"NMTR\": NMTR(dataset.n_users, dataset.n_items, config['embedding_dim']).to(device),\n",
    "#         \"DIPN\": DIPN(dataset.n_users, dataset.n_items, config['embedding_dim']).to(device),\n",
    "#         \"NGCF+M\": NGCF_M(dataset.n_users, dataset.n_items, config['embedding_dim']).to(device),\n",
    "#         \"MBGCN\": MBGCN(dataset.n_users, dataset.n_items, config['embedding_dim']).to(device),\n",
    "#         \"MATN\": MATN(dataset.n_users, dataset.n_items, config['embedding_dim']).to(device),\n",
    "#         \"GNMR\": GNMR(dataset.n_users, dataset.n_items, config['embedding_dim']).to(device),\n",
    "#     }\n",
    "\n",
    "#     # Train and evaluate each model\n",
    "#     results = {}\n",
    "#     for model_name, model in models.items():\n",
    "#         print(f\"\\nTraining and evaluating {model_name}...\")\n",
    "#         criterion = nn.BCEWithLogitsLoss()\n",
    "#         optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
    "\n",
    "#         # Prepare training tensors\n",
    "#         users = torch.LongTensor(train_data[:, 0]).to(device)\n",
    "#         items = torch.LongTensor(train_data[:, 1]).to(device)\n",
    "#         labels = torch.FloatTensor(train_data[:, 2]).to(device)\n",
    "#         behaviors = torch.FloatTensor(train_data[:, 3:]).to(device)\n",
    "\n",
    "#         # Training\n",
    "#         model.train()\n",
    "#         start_time = datetime.now()\n",
    "#         for epoch in range(10):  # Adjust the number of epochs\n",
    "#             optimizer.zero_grad()\n",
    "#             predictions = model(users, items)\n",
    "#             loss = criterion(predictions, labels)\n",
    "#             loss.backward()\n",
    "#             torch.nn.utils.clip_grad_norm_(model.parameters(), config['gradient_clip'])\n",
    "#             optimizer.step()\n",
    "#             print(f\"Epoch {epoch + 1}, Loss: {loss.item():.4f}\")\n",
    "        \n",
    "#         training_time = (datetime.now() - start_time).total_seconds()\n",
    "#         print(f\"Training completed in {training_time:.2f}s\")\n",
    "\n",
    "#         # Evaluation\n",
    "#         test_instances = dataset.get_test_instances()\n",
    "#         hr, ndcg = evaluate_model(model, dataset, test_instances, k=config['eval_k'])\n",
    "        \n",
    "#         # Save results\n",
    "#         results[model_name] = {\n",
    "#             'training_time': training_time,\n",
    "#             'hr': hr,\n",
    "#             'ndcg': ndcg\n",
    "#         }\n",
    "    \n",
    "#     # Print final results\n",
    "#     print(\"\\nFinal Results:\")\n",
    "#     for model_name, metrics in results.items():\n",
    "#         print(f\"{model_name}: HR@{config['eval_k']} = {metrics['hr']:.4f}, NDCG@{config['eval_k']} = {metrics['ndcg']:.4f}, Training Time = {metrics['training_time']:.2f}s\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing dataset...\n",
      "Loading training data from: /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/\n",
      "Loading behavior: pv from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_pv\n",
      "Loading behavior: cart from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_cart\n",
      "Loading behavior: buy from /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/trn_buy\n",
      "Dataset dimensions: 21716 users, 7977 items\n",
      "Loading test data from: /Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/tst_int\n",
      "Using 10000 test users\n",
      "Preparing training instances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yf/20z1hn994jd04q4kl0gpgh740000gn/T/ipykernel_51372/178899499.py:44: DeprecationWarning: Please import `csr_matrix` from the `scipy.sparse` namespace; the `scipy.sparse.csr` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  mat = pickle.load(fs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 6000 training instances\n",
      "Using 6000 training instances\n",
      "\n",
      "Training and evaluating CF-UIcA...\n",
      "Epoch 1, Loss: 0.7332\n",
      "Epoch 2, Loss: 0.7105\n",
      "Epoch 3, Loss: 0.6895\n",
      "Epoch 4, Loss: 0.6700\n",
      "Epoch 5, Loss: 0.6519\n",
      "Epoch 6, Loss: 0.6350\n",
      "Epoch 7, Loss: 0.6192\n",
      "Epoch 8, Loss: 0.6043\n",
      "Epoch 9, Loss: 0.5901\n",
      "Epoch 10, Loss: 0.5766\n",
      "Training completed in 1.35s\n",
      "Preparing test instances...\n",
      "Generated 1000000 test instances\n",
      "Evaluating 1000000 instances in 45455 chunks...\n",
      "Processing chunk 1/45455\n",
      "Processing chunk 51/45455\n",
      "Processing chunk 101/45455\n",
      "Processing chunk 151/45455\n",
      "Processing chunk 201/45455\n",
      "Processing chunk 251/45455\n",
      "Processing chunk 301/45455\n",
      "Processing chunk 351/45455\n",
      "Processing chunk 401/45455\n",
      "Processing chunk 451/45455\n",
      "Processing chunk 501/45455\n",
      "Processing chunk 551/45455\n",
      "Processing chunk 601/45455\n",
      "Processing chunk 651/45455\n",
      "Processing chunk 701/45455\n",
      "Processing chunk 751/45455\n",
      "Processing chunk 801/45455\n",
      "Processing chunk 851/45455\n",
      "Processing chunk 901/45455\n",
      "Processing chunk 951/45455\n",
      "Processing chunk 1001/45455\n",
      "Processing chunk 1051/45455\n",
      "Processing chunk 1101/45455\n",
      "Processing chunk 1151/45455\n",
      "Processing chunk 1201/45455\n",
      "Processing chunk 1251/45455\n",
      "Processing chunk 1301/45455\n",
      "Processing chunk 1351/45455\n",
      "Processing chunk 1401/45455\n",
      "Processing chunk 1451/45455\n",
      "Processing chunk 1501/45455\n",
      "Processing chunk 1551/45455\n",
      "Processing chunk 1601/45455\n",
      "Processing chunk 1651/45455\n",
      "Processing chunk 1701/45455\n",
      "Processing chunk 1751/45455\n",
      "Processing chunk 1801/45455\n",
      "Processing chunk 1851/45455\n",
      "Processing chunk 1901/45455\n",
      "Processing chunk 1951/45455\n",
      "Processing chunk 2001/45455\n",
      "Processing chunk 2051/45455\n",
      "Processing chunk 2101/45455\n",
      "Processing chunk 2151/45455\n",
      "Processing chunk 2201/45455\n",
      "Processing chunk 2251/45455\n",
      "Processing chunk 2301/45455\n",
      "Processing chunk 2351/45455\n",
      "Processing chunk 2401/45455\n",
      "Processing chunk 2451/45455\n",
      "Processing chunk 2501/45455\n",
      "Processing chunk 2551/45455\n",
      "Processing chunk 2601/45455\n",
      "Processing chunk 2651/45455\n",
      "Processing chunk 2701/45455\n",
      "Processing chunk 2751/45455\n",
      "Processing chunk 2801/45455\n",
      "Processing chunk 2851/45455\n",
      "Processing chunk 2901/45455\n",
      "Processing chunk 2951/45455\n",
      "Processing chunk 3001/45455\n",
      "Processing chunk 3051/45455\n",
      "Processing chunk 3101/45455\n",
      "Processing chunk 3151/45455\n",
      "Processing chunk 3201/45455\n",
      "Processing chunk 3251/45455\n",
      "Processing chunk 3301/45455\n",
      "Processing chunk 3351/45455\n",
      "Processing chunk 3401/45455\n",
      "Processing chunk 3451/45455\n",
      "Processing chunk 3501/45455\n",
      "Processing chunk 3551/45455\n",
      "Processing chunk 3601/45455\n",
      "Processing chunk 3651/45455\n",
      "Processing chunk 3701/45455\n",
      "Processing chunk 3751/45455\n",
      "Processing chunk 3801/45455\n",
      "Processing chunk 3851/45455\n",
      "Processing chunk 3901/45455\n",
      "Processing chunk 3951/45455\n",
      "Processing chunk 4001/45455\n",
      "Processing chunk 4051/45455\n",
      "Processing chunk 4101/45455\n",
      "Processing chunk 4151/45455\n",
      "Processing chunk 4201/45455\n",
      "Processing chunk 4251/45455\n",
      "Processing chunk 4301/45455\n",
      "Processing chunk 4351/45455\n",
      "Processing chunk 4401/45455\n",
      "Processing chunk 4451/45455\n",
      "Processing chunk 4501/45455\n",
      "Processing chunk 4551/45455\n",
      "Processing chunk 4601/45455\n",
      "Processing chunk 4651/45455\n",
      "Processing chunk 4701/45455\n",
      "Processing chunk 4751/45455\n",
      "Processing chunk 4801/45455\n",
      "Processing chunk 4851/45455\n",
      "Processing chunk 4901/45455\n",
      "Processing chunk 4951/45455\n",
      "Processing chunk 5001/45455\n",
      "Processing chunk 5051/45455\n",
      "Processing chunk 5101/45455\n",
      "Processing chunk 5151/45455\n",
      "Processing chunk 5201/45455\n",
      "Processing chunk 5251/45455\n",
      "Processing chunk 5301/45455\n",
      "Processing chunk 5351/45455\n",
      "Processing chunk 5401/45455\n",
      "Processing chunk 5451/45455\n",
      "Processing chunk 5501/45455\n",
      "Processing chunk 5551/45455\n",
      "Processing chunk 5601/45455\n",
      "Processing chunk 5651/45455\n",
      "Processing chunk 5701/45455\n",
      "Processing chunk 5751/45455\n",
      "Processing chunk 5801/45455\n",
      "Processing chunk 5851/45455\n",
      "Processing chunk 5901/45455\n",
      "Processing chunk 5951/45455\n",
      "Processing chunk 6001/45455\n",
      "Processing chunk 6051/45455\n",
      "Processing chunk 6101/45455\n",
      "Processing chunk 6151/45455\n",
      "Processing chunk 6201/45455\n",
      "Processing chunk 6251/45455\n",
      "Processing chunk 6301/45455\n",
      "Processing chunk 6351/45455\n",
      "Processing chunk 6401/45455\n",
      "Processing chunk 6451/45455\n",
      "Processing chunk 6501/45455\n",
      "Processing chunk 6551/45455\n",
      "Processing chunk 6601/45455\n",
      "Processing chunk 6651/45455\n",
      "Processing chunk 6701/45455\n",
      "Processing chunk 6751/45455\n",
      "Processing chunk 6801/45455\n",
      "Processing chunk 6851/45455\n",
      "Processing chunk 6901/45455\n",
      "Processing chunk 6951/45455\n",
      "Processing chunk 7001/45455\n",
      "Processing chunk 7051/45455\n",
      "Processing chunk 7101/45455\n",
      "Processing chunk 7151/45455\n",
      "Processing chunk 7201/45455\n",
      "Processing chunk 7251/45455\n",
      "Processing chunk 7301/45455\n",
      "Processing chunk 7351/45455\n",
      "Processing chunk 7401/45455\n",
      "Processing chunk 7451/45455\n",
      "Processing chunk 7501/45455\n",
      "Processing chunk 7551/45455\n",
      "Processing chunk 7601/45455\n",
      "Processing chunk 7651/45455\n",
      "Processing chunk 7701/45455\n",
      "Processing chunk 7751/45455\n",
      "Processing chunk 7801/45455\n",
      "Processing chunk 7851/45455\n",
      "Processing chunk 7901/45455\n",
      "Processing chunk 7951/45455\n",
      "Processing chunk 8001/45455\n",
      "Processing chunk 8051/45455\n",
      "Processing chunk 8101/45455\n",
      "Processing chunk 8151/45455\n",
      "Processing chunk 8201/45455\n",
      "Processing chunk 8251/45455\n",
      "Processing chunk 8301/45455\n",
      "Processing chunk 8351/45455\n",
      "Processing chunk 8401/45455\n",
      "Processing chunk 8451/45455\n",
      "Processing chunk 8501/45455\n",
      "Processing chunk 8551/45455\n",
      "Processing chunk 8601/45455\n",
      "Processing chunk 8651/45455\n",
      "Processing chunk 8701/45455\n",
      "Processing chunk 8751/45455\n",
      "Processing chunk 8801/45455\n",
      "Processing chunk 8851/45455\n",
      "Processing chunk 8901/45455\n",
      "Processing chunk 8951/45455\n",
      "Processing chunk 9001/45455\n",
      "Processing chunk 9051/45455\n",
      "Processing chunk 9101/45455\n",
      "Processing chunk 9151/45455\n",
      "Processing chunk 9201/45455\n",
      "Processing chunk 9251/45455\n",
      "Processing chunk 9301/45455\n",
      "Processing chunk 9351/45455\n",
      "Processing chunk 9401/45455\n",
      "Processing chunk 9451/45455\n",
      "Processing chunk 9501/45455\n",
      "Processing chunk 9551/45455\n",
      "Processing chunk 9601/45455\n",
      "Processing chunk 9651/45455\n",
      "Processing chunk 9701/45455\n",
      "Processing chunk 9751/45455\n",
      "Processing chunk 9801/45455\n",
      "Processing chunk 9851/45455\n",
      "Processing chunk 9901/45455\n",
      "Processing chunk 9951/45455\n",
      "Processing chunk 10001/45455\n",
      "Processing chunk 10051/45455\n",
      "Processing chunk 10101/45455\n",
      "Processing chunk 10151/45455\n",
      "Processing chunk 10201/45455\n",
      "Processing chunk 10251/45455\n",
      "Processing chunk 10301/45455\n",
      "Processing chunk 10351/45455\n",
      "Processing chunk 10401/45455\n",
      "Processing chunk 10451/45455\n",
      "Processing chunk 10501/45455\n",
      "Processing chunk 10551/45455\n",
      "Processing chunk 10601/45455\n",
      "Processing chunk 10651/45455\n",
      "Processing chunk 10701/45455\n",
      "Processing chunk 10751/45455\n",
      "Processing chunk 10801/45455\n",
      "Processing chunk 10851/45455\n",
      "Processing chunk 10901/45455\n",
      "Processing chunk 10951/45455\n",
      "Processing chunk 11001/45455\n",
      "Processing chunk 11051/45455\n",
      "Processing chunk 11101/45455\n",
      "Processing chunk 11151/45455\n",
      "Processing chunk 11201/45455\n",
      "Processing chunk 11251/45455\n",
      "Processing chunk 11301/45455\n",
      "Processing chunk 11351/45455\n",
      "Processing chunk 11401/45455\n",
      "Processing chunk 11451/45455\n",
      "Processing chunk 11501/45455\n",
      "Processing chunk 11551/45455\n",
      "Processing chunk 11601/45455\n",
      "Processing chunk 11651/45455\n",
      "Processing chunk 11701/45455\n",
      "Processing chunk 11751/45455\n",
      "Processing chunk 11801/45455\n",
      "Processing chunk 11851/45455\n",
      "Processing chunk 11901/45455\n",
      "Processing chunk 11951/45455\n",
      "Processing chunk 12001/45455\n",
      "Processing chunk 12051/45455\n",
      "Processing chunk 12101/45455\n",
      "Processing chunk 12151/45455\n",
      "Processing chunk 12201/45455\n",
      "Processing chunk 12251/45455\n",
      "Processing chunk 12301/45455\n",
      "Processing chunk 12351/45455\n",
      "Processing chunk 12401/45455\n",
      "Processing chunk 12451/45455\n",
      "Processing chunk 12501/45455\n",
      "Processing chunk 12551/45455\n",
      "Processing chunk 12601/45455\n",
      "Processing chunk 12651/45455\n",
      "Processing chunk 12701/45455\n",
      "Processing chunk 12751/45455\n",
      "Processing chunk 12801/45455\n",
      "Processing chunk 12851/45455\n",
      "Processing chunk 12901/45455\n",
      "Processing chunk 12951/45455\n",
      "Processing chunk 13001/45455\n",
      "Processing chunk 13051/45455\n",
      "Processing chunk 13101/45455\n",
      "Processing chunk 13151/45455\n",
      "Processing chunk 13201/45455\n",
      "Processing chunk 13251/45455\n",
      "Processing chunk 13301/45455\n",
      "Processing chunk 13351/45455\n",
      "Processing chunk 13401/45455\n",
      "Processing chunk 13451/45455\n",
      "Processing chunk 13501/45455\n",
      "Processing chunk 13551/45455\n",
      "Processing chunk 13601/45455\n",
      "Processing chunk 13651/45455\n",
      "Processing chunk 13701/45455\n",
      "Processing chunk 13751/45455\n",
      "Processing chunk 13801/45455\n",
      "Processing chunk 13851/45455\n",
      "Processing chunk 13901/45455\n",
      "Processing chunk 13951/45455\n",
      "Processing chunk 14001/45455\n",
      "Processing chunk 14051/45455\n",
      "Processing chunk 14101/45455\n",
      "Processing chunk 14151/45455\n",
      "Processing chunk 14201/45455\n",
      "Processing chunk 14251/45455\n",
      "Processing chunk 14301/45455\n",
      "Processing chunk 14351/45455\n",
      "Processing chunk 14401/45455\n",
      "Processing chunk 14451/45455\n",
      "Processing chunk 14501/45455\n",
      "Processing chunk 14551/45455\n",
      "Processing chunk 14601/45455\n",
      "Processing chunk 14651/45455\n",
      "Processing chunk 14701/45455\n",
      "Processing chunk 14751/45455\n",
      "Processing chunk 14801/45455\n",
      "Processing chunk 14851/45455\n",
      "Processing chunk 14901/45455\n",
      "Processing chunk 14951/45455\n",
      "Processing chunk 15001/45455\n",
      "Processing chunk 15051/45455\n",
      "Processing chunk 15101/45455\n",
      "Processing chunk 15151/45455\n",
      "Processing chunk 15201/45455\n",
      "Processing chunk 15251/45455\n",
      "Processing chunk 15301/45455\n",
      "Processing chunk 15351/45455\n",
      "Processing chunk 15401/45455\n",
      "Processing chunk 15451/45455\n",
      "Processing chunk 15501/45455\n",
      "Processing chunk 15551/45455\n",
      "Processing chunk 15601/45455\n",
      "Processing chunk 15651/45455\n",
      "Processing chunk 15701/45455\n",
      "Processing chunk 15751/45455\n",
      "Processing chunk 15801/45455\n",
      "Processing chunk 15851/45455\n",
      "Processing chunk 15901/45455\n",
      "Processing chunk 15951/45455\n",
      "Processing chunk 16001/45455\n",
      "Processing chunk 16051/45455\n",
      "Processing chunk 16101/45455\n",
      "Processing chunk 16151/45455\n",
      "Processing chunk 16201/45455\n",
      "Processing chunk 16251/45455\n",
      "Processing chunk 16301/45455\n",
      "Processing chunk 16351/45455\n",
      "Processing chunk 16401/45455\n",
      "Processing chunk 16451/45455\n",
      "Processing chunk 16501/45455\n",
      "Processing chunk 16551/45455\n",
      "Processing chunk 16601/45455\n",
      "Processing chunk 16651/45455\n",
      "Processing chunk 16701/45455\n",
      "Processing chunk 16751/45455\n",
      "Processing chunk 16801/45455\n",
      "Processing chunk 16851/45455\n",
      "Processing chunk 16901/45455\n",
      "Processing chunk 16951/45455\n",
      "Processing chunk 17001/45455\n",
      "Processing chunk 17051/45455\n",
      "Processing chunk 17101/45455\n",
      "Processing chunk 17151/45455\n",
      "Processing chunk 17201/45455\n",
      "Processing chunk 17251/45455\n",
      "Processing chunk 17301/45455\n",
      "Processing chunk 17351/45455\n",
      "Processing chunk 17401/45455\n",
      "Processing chunk 17451/45455\n",
      "Processing chunk 17501/45455\n",
      "Processing chunk 17551/45455\n",
      "Processing chunk 17601/45455\n",
      "Processing chunk 17651/45455\n",
      "Processing chunk 17701/45455\n",
      "Processing chunk 17751/45455\n",
      "Processing chunk 17801/45455\n",
      "Processing chunk 17851/45455\n",
      "Processing chunk 17901/45455\n",
      "Processing chunk 17951/45455\n",
      "Processing chunk 18001/45455\n",
      "Processing chunk 18051/45455\n",
      "Processing chunk 18101/45455\n",
      "Processing chunk 18151/45455\n",
      "Processing chunk 18201/45455\n",
      "Processing chunk 18251/45455\n",
      "Processing chunk 18301/45455\n",
      "Processing chunk 18351/45455\n",
      "Processing chunk 18401/45455\n",
      "Processing chunk 18451/45455\n",
      "Processing chunk 18501/45455\n",
      "Processing chunk 18551/45455\n",
      "Processing chunk 18601/45455\n",
      "Processing chunk 18651/45455\n",
      "Processing chunk 18701/45455\n",
      "Processing chunk 18751/45455\n",
      "Processing chunk 18801/45455\n",
      "Processing chunk 18851/45455\n",
      "Processing chunk 18901/45455\n",
      "Processing chunk 18951/45455\n",
      "Processing chunk 19001/45455\n",
      "Processing chunk 19051/45455\n",
      "Processing chunk 19101/45455\n",
      "Processing chunk 19151/45455\n",
      "Processing chunk 19201/45455\n",
      "Processing chunk 19251/45455\n",
      "Processing chunk 19301/45455\n",
      "Processing chunk 19351/45455\n",
      "Processing chunk 19401/45455\n",
      "Processing chunk 19451/45455\n",
      "Processing chunk 19501/45455\n",
      "Processing chunk 19551/45455\n",
      "Processing chunk 19601/45455\n",
      "Processing chunk 19651/45455\n",
      "Processing chunk 19701/45455\n",
      "Processing chunk 19751/45455\n",
      "Processing chunk 19801/45455\n",
      "Processing chunk 19851/45455\n",
      "Processing chunk 19901/45455\n",
      "Processing chunk 19951/45455\n",
      "Processing chunk 20001/45455\n",
      "Processing chunk 20051/45455\n",
      "Processing chunk 20101/45455\n",
      "Processing chunk 20151/45455\n",
      "Processing chunk 20201/45455\n",
      "Processing chunk 20251/45455\n",
      "Processing chunk 20301/45455\n",
      "Processing chunk 20351/45455\n",
      "Processing chunk 20401/45455\n",
      "Processing chunk 20451/45455\n",
      "Processing chunk 20501/45455\n",
      "Processing chunk 20551/45455\n",
      "Processing chunk 20601/45455\n",
      "Processing chunk 20651/45455\n",
      "Processing chunk 20701/45455\n",
      "Processing chunk 20751/45455\n",
      "Processing chunk 20801/45455\n",
      "Processing chunk 20851/45455\n",
      "Processing chunk 20901/45455\n",
      "Processing chunk 20951/45455\n",
      "Processing chunk 21001/45455\n",
      "Processing chunk 21051/45455\n",
      "Processing chunk 21101/45455\n",
      "Processing chunk 21151/45455\n",
      "Processing chunk 21201/45455\n",
      "Processing chunk 21251/45455\n",
      "Processing chunk 21301/45455\n",
      "Processing chunk 21351/45455\n",
      "Processing chunk 21401/45455\n",
      "Processing chunk 21451/45455\n",
      "Processing chunk 21501/45455\n",
      "Processing chunk 21551/45455\n",
      "Processing chunk 21601/45455\n",
      "Processing chunk 21651/45455\n",
      "Processing chunk 21701/45455\n",
      "Processing chunk 21751/45455\n",
      "Processing chunk 21801/45455\n",
      "Processing chunk 21851/45455\n",
      "Processing chunk 21901/45455\n",
      "Processing chunk 21951/45455\n",
      "Processing chunk 22001/45455\n",
      "Processing chunk 22051/45455\n",
      "Processing chunk 22101/45455\n",
      "Processing chunk 22151/45455\n",
      "Processing chunk 22201/45455\n",
      "Processing chunk 22251/45455\n",
      "Processing chunk 22301/45455\n",
      "Processing chunk 22351/45455\n",
      "Processing chunk 22401/45455\n",
      "Processing chunk 22451/45455\n",
      "Processing chunk 22501/45455\n",
      "Processing chunk 22551/45455\n",
      "Processing chunk 22601/45455\n",
      "Processing chunk 22651/45455\n",
      "Processing chunk 22701/45455\n",
      "Processing chunk 22751/45455\n",
      "Processing chunk 22801/45455\n",
      "Processing chunk 22851/45455\n",
      "Processing chunk 22901/45455\n",
      "Processing chunk 22951/45455\n",
      "Processing chunk 23001/45455\n",
      "Processing chunk 23051/45455\n",
      "Processing chunk 23101/45455\n",
      "Processing chunk 23151/45455\n",
      "Processing chunk 23201/45455\n",
      "Processing chunk 23251/45455\n",
      "Processing chunk 23301/45455\n",
      "Processing chunk 23351/45455\n",
      "Processing chunk 23401/45455\n",
      "Processing chunk 23451/45455\n",
      "Processing chunk 23501/45455\n",
      "Processing chunk 23551/45455\n",
      "Processing chunk 23601/45455\n",
      "Processing chunk 23651/45455\n",
      "Processing chunk 23701/45455\n",
      "Processing chunk 23751/45455\n",
      "Processing chunk 23801/45455\n",
      "Processing chunk 23851/45455\n",
      "Processing chunk 23901/45455\n",
      "Processing chunk 23951/45455\n",
      "Processing chunk 24001/45455\n",
      "Processing chunk 24051/45455\n",
      "Processing chunk 24101/45455\n",
      "Processing chunk 24151/45455\n",
      "Processing chunk 24201/45455\n",
      "Processing chunk 24251/45455\n",
      "Processing chunk 24301/45455\n",
      "Processing chunk 24351/45455\n",
      "Processing chunk 24401/45455\n",
      "Processing chunk 24451/45455\n",
      "Processing chunk 24501/45455\n",
      "Processing chunk 24551/45455\n",
      "Processing chunk 24601/45455\n",
      "Processing chunk 24651/45455\n",
      "Processing chunk 24701/45455\n",
      "Processing chunk 24751/45455\n",
      "Processing chunk 24801/45455\n",
      "Processing chunk 24851/45455\n",
      "Processing chunk 24901/45455\n",
      "Processing chunk 24951/45455\n",
      "Processing chunk 25001/45455\n",
      "Processing chunk 25051/45455\n",
      "Processing chunk 25101/45455\n",
      "Processing chunk 25151/45455\n",
      "Processing chunk 25201/45455\n",
      "Processing chunk 25251/45455\n",
      "Processing chunk 25301/45455\n",
      "Processing chunk 25351/45455\n",
      "Processing chunk 25401/45455\n",
      "Processing chunk 25451/45455\n",
      "Processing chunk 25501/45455\n",
      "Processing chunk 25551/45455\n",
      "Processing chunk 25601/45455\n",
      "Processing chunk 25651/45455\n",
      "Processing chunk 25701/45455\n",
      "Processing chunk 25751/45455\n",
      "Processing chunk 25801/45455\n",
      "Processing chunk 25851/45455\n",
      "Processing chunk 25901/45455\n",
      "Processing chunk 25951/45455\n",
      "Processing chunk 26001/45455\n",
      "Processing chunk 26051/45455\n",
      "Processing chunk 26101/45455\n",
      "Processing chunk 26151/45455\n",
      "Processing chunk 26201/45455\n",
      "Processing chunk 26251/45455\n",
      "Processing chunk 26301/45455\n",
      "Processing chunk 26351/45455\n",
      "Processing chunk 26401/45455\n",
      "Processing chunk 26451/45455\n",
      "Processing chunk 26501/45455\n",
      "Processing chunk 26551/45455\n",
      "Processing chunk 26601/45455\n",
      "Processing chunk 26651/45455\n",
      "Processing chunk 26701/45455\n",
      "Processing chunk 26751/45455\n",
      "Processing chunk 26801/45455\n",
      "Processing chunk 26851/45455\n",
      "Processing chunk 26901/45455\n",
      "Processing chunk 26951/45455\n",
      "Processing chunk 27001/45455\n",
      "Processing chunk 27051/45455\n",
      "Processing chunk 27101/45455\n",
      "Processing chunk 27151/45455\n",
      "Processing chunk 27201/45455\n",
      "Processing chunk 27251/45455\n",
      "Processing chunk 27301/45455\n",
      "Processing chunk 27351/45455\n",
      "Processing chunk 27401/45455\n",
      "Processing chunk 27451/45455\n",
      "Processing chunk 27501/45455\n",
      "Processing chunk 27551/45455\n",
      "Processing chunk 27601/45455\n",
      "Processing chunk 27651/45455\n",
      "Processing chunk 27701/45455\n",
      "Processing chunk 27751/45455\n",
      "Processing chunk 27801/45455\n",
      "Processing chunk 27851/45455\n",
      "Processing chunk 27901/45455\n",
      "Processing chunk 27951/45455\n",
      "Processing chunk 28001/45455\n",
      "Processing chunk 28051/45455\n",
      "Processing chunk 28101/45455\n",
      "Processing chunk 28151/45455\n",
      "Processing chunk 28201/45455\n",
      "Processing chunk 28251/45455\n",
      "Processing chunk 28301/45455\n",
      "Processing chunk 28351/45455\n",
      "Processing chunk 28401/45455\n",
      "Processing chunk 28451/45455\n",
      "Processing chunk 28501/45455\n",
      "Processing chunk 28551/45455\n",
      "Processing chunk 28601/45455\n",
      "Processing chunk 28651/45455\n",
      "Processing chunk 28701/45455\n",
      "Processing chunk 28751/45455\n",
      "Processing chunk 28801/45455\n",
      "Processing chunk 28851/45455\n",
      "Processing chunk 28901/45455\n",
      "Processing chunk 28951/45455\n",
      "Processing chunk 29001/45455\n",
      "Processing chunk 29051/45455\n",
      "Processing chunk 29101/45455\n",
      "Processing chunk 29151/45455\n",
      "Processing chunk 29201/45455\n",
      "Processing chunk 29251/45455\n",
      "Processing chunk 29301/45455\n",
      "Processing chunk 29351/45455\n",
      "Processing chunk 29401/45455\n",
      "Processing chunk 29451/45455\n",
      "Processing chunk 29501/45455\n",
      "Processing chunk 29551/45455\n",
      "Processing chunk 29601/45455\n",
      "Processing chunk 29651/45455\n",
      "Processing chunk 29701/45455\n",
      "Processing chunk 29751/45455\n",
      "Processing chunk 29801/45455\n",
      "Processing chunk 29851/45455\n",
      "Processing chunk 29901/45455\n",
      "Processing chunk 29951/45455\n",
      "Processing chunk 30001/45455\n",
      "Processing chunk 30051/45455\n",
      "Processing chunk 30101/45455\n",
      "Processing chunk 30151/45455\n",
      "Processing chunk 30201/45455\n",
      "Processing chunk 30251/45455\n",
      "Processing chunk 30301/45455\n",
      "Processing chunk 30351/45455\n",
      "Processing chunk 30401/45455\n",
      "Processing chunk 30451/45455\n",
      "Processing chunk 30501/45455\n",
      "Processing chunk 30551/45455\n",
      "Processing chunk 30601/45455\n",
      "Processing chunk 30651/45455\n",
      "Processing chunk 30701/45455\n",
      "Processing chunk 30751/45455\n",
      "Processing chunk 30801/45455\n",
      "Processing chunk 30851/45455\n",
      "Processing chunk 30901/45455\n",
      "Processing chunk 30951/45455\n",
      "Processing chunk 31001/45455\n",
      "Processing chunk 31051/45455\n",
      "Processing chunk 31101/45455\n",
      "Processing chunk 31151/45455\n",
      "Processing chunk 31201/45455\n",
      "Processing chunk 31251/45455\n",
      "Processing chunk 31301/45455\n",
      "Processing chunk 31351/45455\n",
      "Processing chunk 31401/45455\n",
      "Processing chunk 31451/45455\n",
      "Processing chunk 31501/45455\n",
      "Processing chunk 31551/45455\n",
      "Processing chunk 31601/45455\n",
      "Processing chunk 31651/45455\n",
      "Processing chunk 31701/45455\n",
      "Processing chunk 31751/45455\n",
      "Processing chunk 31801/45455\n",
      "Processing chunk 31851/45455\n",
      "Processing chunk 31901/45455\n",
      "Processing chunk 31951/45455\n",
      "Processing chunk 32001/45455\n",
      "Processing chunk 32051/45455\n",
      "Processing chunk 32101/45455\n",
      "Processing chunk 32151/45455\n",
      "Processing chunk 32201/45455\n",
      "Processing chunk 32251/45455\n",
      "Processing chunk 32301/45455\n",
      "Processing chunk 32351/45455\n",
      "Processing chunk 32401/45455\n",
      "Processing chunk 32451/45455\n",
      "Processing chunk 32501/45455\n",
      "Processing chunk 32551/45455\n",
      "Processing chunk 32601/45455\n",
      "Processing chunk 32651/45455\n",
      "Processing chunk 32701/45455\n",
      "Processing chunk 32751/45455\n",
      "Processing chunk 32801/45455\n",
      "Processing chunk 32851/45455\n",
      "Processing chunk 32901/45455\n",
      "Processing chunk 32951/45455\n",
      "Processing chunk 33001/45455\n",
      "Processing chunk 33051/45455\n",
      "Processing chunk 33101/45455\n",
      "Processing chunk 33151/45455\n",
      "Processing chunk 33201/45455\n",
      "Processing chunk 33251/45455\n",
      "Processing chunk 33301/45455\n",
      "Processing chunk 33351/45455\n",
      "Processing chunk 33401/45455\n",
      "Processing chunk 33451/45455\n",
      "Processing chunk 33501/45455\n",
      "Processing chunk 33551/45455\n",
      "Processing chunk 33601/45455\n",
      "Processing chunk 33651/45455\n",
      "Processing chunk 33701/45455\n",
      "Processing chunk 33751/45455\n",
      "Processing chunk 33801/45455\n",
      "Processing chunk 33851/45455\n",
      "Processing chunk 33901/45455\n",
      "Processing chunk 33951/45455\n",
      "Processing chunk 34001/45455\n",
      "Processing chunk 34051/45455\n",
      "Processing chunk 34101/45455\n",
      "Processing chunk 34151/45455\n",
      "Processing chunk 34201/45455\n",
      "Processing chunk 34251/45455\n",
      "Processing chunk 34301/45455\n",
      "Processing chunk 34351/45455\n",
      "Processing chunk 34401/45455\n",
      "Processing chunk 34451/45455\n",
      "Processing chunk 34501/45455\n",
      "Processing chunk 34551/45455\n",
      "Processing chunk 34601/45455\n",
      "Processing chunk 34651/45455\n",
      "Processing chunk 34701/45455\n",
      "Processing chunk 34751/45455\n",
      "Processing chunk 34801/45455\n",
      "Processing chunk 34851/45455\n",
      "Processing chunk 34901/45455\n",
      "Processing chunk 34951/45455\n",
      "Processing chunk 35001/45455\n",
      "Processing chunk 35051/45455\n",
      "Processing chunk 35101/45455\n",
      "Processing chunk 35151/45455\n",
      "Processing chunk 35201/45455\n",
      "Processing chunk 35251/45455\n",
      "Processing chunk 35301/45455\n",
      "Processing chunk 35351/45455\n",
      "Processing chunk 35401/45455\n",
      "Processing chunk 35451/45455\n",
      "Processing chunk 35501/45455\n",
      "Processing chunk 35551/45455\n",
      "Processing chunk 35601/45455\n",
      "Processing chunk 35651/45455\n",
      "Processing chunk 35701/45455\n",
      "Processing chunk 35751/45455\n",
      "Processing chunk 35801/45455\n",
      "Processing chunk 35851/45455\n",
      "Processing chunk 35901/45455\n",
      "Processing chunk 35951/45455\n",
      "Processing chunk 36001/45455\n",
      "Processing chunk 36051/45455\n",
      "Processing chunk 36101/45455\n",
      "Processing chunk 36151/45455\n",
      "Processing chunk 36201/45455\n",
      "Processing chunk 36251/45455\n",
      "Processing chunk 36301/45455\n",
      "Processing chunk 36351/45455\n",
      "Processing chunk 36401/45455\n",
      "Processing chunk 36451/45455\n",
      "Processing chunk 36501/45455\n",
      "Processing chunk 36551/45455\n",
      "Processing chunk 36601/45455\n",
      "Processing chunk 36651/45455\n",
      "Processing chunk 36701/45455\n",
      "Processing chunk 36751/45455\n",
      "Processing chunk 36801/45455\n",
      "Processing chunk 36851/45455\n",
      "Processing chunk 36901/45455\n",
      "Processing chunk 36951/45455\n",
      "Processing chunk 37001/45455\n",
      "Processing chunk 37051/45455\n",
      "Processing chunk 37101/45455\n",
      "Processing chunk 37151/45455\n",
      "Processing chunk 37201/45455\n",
      "Processing chunk 37251/45455\n",
      "Processing chunk 37301/45455\n",
      "Processing chunk 37351/45455\n",
      "Processing chunk 37401/45455\n",
      "Processing chunk 37451/45455\n",
      "Processing chunk 37501/45455\n",
      "Processing chunk 37551/45455\n",
      "Processing chunk 37601/45455\n",
      "Processing chunk 37651/45455\n",
      "Processing chunk 37701/45455\n",
      "Processing chunk 37751/45455\n",
      "Processing chunk 37801/45455\n",
      "Processing chunk 37851/45455\n",
      "Processing chunk 37901/45455\n",
      "Processing chunk 37951/45455\n",
      "Processing chunk 38001/45455\n",
      "Processing chunk 38051/45455\n",
      "Processing chunk 38101/45455\n",
      "Processing chunk 38151/45455\n",
      "Processing chunk 38201/45455\n",
      "Processing chunk 38251/45455\n",
      "Processing chunk 38301/45455\n",
      "Processing chunk 38351/45455\n",
      "Processing chunk 38401/45455\n",
      "Processing chunk 38451/45455\n",
      "Processing chunk 38501/45455\n",
      "Processing chunk 38551/45455\n",
      "Processing chunk 38601/45455\n",
      "Processing chunk 38651/45455\n",
      "Processing chunk 38701/45455\n",
      "Processing chunk 38751/45455\n",
      "Processing chunk 38801/45455\n",
      "Processing chunk 38851/45455\n",
      "Processing chunk 38901/45455\n",
      "Processing chunk 38951/45455\n",
      "Processing chunk 39001/45455\n",
      "Processing chunk 39051/45455\n",
      "Processing chunk 39101/45455\n",
      "Processing chunk 39151/45455\n",
      "Processing chunk 39201/45455\n",
      "Processing chunk 39251/45455\n",
      "Processing chunk 39301/45455\n",
      "Processing chunk 39351/45455\n",
      "Processing chunk 39401/45455\n",
      "Processing chunk 39451/45455\n",
      "Processing chunk 39501/45455\n",
      "Processing chunk 39551/45455\n",
      "Processing chunk 39601/45455\n",
      "Processing chunk 39651/45455\n",
      "Processing chunk 39701/45455\n",
      "Processing chunk 39751/45455\n",
      "Processing chunk 39801/45455\n",
      "Processing chunk 39851/45455\n",
      "Processing chunk 39901/45455\n",
      "Processing chunk 39951/45455\n",
      "Processing chunk 40001/45455\n",
      "Processing chunk 40051/45455\n",
      "Processing chunk 40101/45455\n",
      "Processing chunk 40151/45455\n",
      "Processing chunk 40201/45455\n",
      "Processing chunk 40251/45455\n",
      "Processing chunk 40301/45455\n",
      "Processing chunk 40351/45455\n",
      "Processing chunk 40401/45455\n",
      "Processing chunk 40451/45455\n",
      "Processing chunk 40501/45455\n",
      "Processing chunk 40551/45455\n",
      "Processing chunk 40601/45455\n",
      "Processing chunk 40651/45455\n",
      "Processing chunk 40701/45455\n",
      "Processing chunk 40751/45455\n",
      "Processing chunk 40801/45455\n",
      "Processing chunk 40851/45455\n",
      "Processing chunk 40901/45455\n",
      "Processing chunk 40951/45455\n",
      "Processing chunk 41001/45455\n",
      "Processing chunk 41051/45455\n",
      "Processing chunk 41101/45455\n",
      "Processing chunk 41151/45455\n",
      "Processing chunk 41201/45455\n",
      "Processing chunk 41251/45455\n",
      "Processing chunk 41301/45455\n",
      "Processing chunk 41351/45455\n",
      "Processing chunk 41401/45455\n",
      "Processing chunk 41451/45455\n",
      "Processing chunk 41501/45455\n",
      "Processing chunk 41551/45455\n",
      "Processing chunk 41601/45455\n",
      "Processing chunk 41651/45455\n",
      "Processing chunk 41701/45455\n",
      "Processing chunk 41751/45455\n",
      "Processing chunk 41801/45455\n",
      "Processing chunk 41851/45455\n",
      "Processing chunk 41901/45455\n",
      "Processing chunk 41951/45455\n",
      "Processing chunk 42001/45455\n",
      "Processing chunk 42051/45455\n",
      "Processing chunk 42101/45455\n",
      "Processing chunk 42151/45455\n",
      "Processing chunk 42201/45455\n",
      "Processing chunk 42251/45455\n",
      "Processing chunk 42301/45455\n",
      "Processing chunk 42351/45455\n",
      "Processing chunk 42401/45455\n",
      "Processing chunk 42451/45455\n",
      "Processing chunk 42501/45455\n",
      "Processing chunk 42551/45455\n",
      "Processing chunk 42601/45455\n",
      "Processing chunk 42651/45455\n",
      "Processing chunk 42701/45455\n",
      "Processing chunk 42751/45455\n",
      "Processing chunk 42801/45455\n",
      "Processing chunk 42851/45455\n",
      "Processing chunk 42901/45455\n",
      "Processing chunk 42951/45455\n",
      "Processing chunk 43001/45455\n",
      "Processing chunk 43051/45455\n",
      "Processing chunk 43101/45455\n",
      "Processing chunk 43151/45455\n",
      "Processing chunk 43201/45455\n",
      "Processing chunk 43251/45455\n",
      "Processing chunk 43301/45455\n",
      "Processing chunk 43351/45455\n",
      "Processing chunk 43401/45455\n",
      "Processing chunk 43451/45455\n",
      "Processing chunk 43501/45455\n",
      "Processing chunk 43551/45455\n",
      "Processing chunk 43601/45455\n",
      "Processing chunk 43651/45455\n",
      "Processing chunk 43701/45455\n",
      "Processing chunk 43751/45455\n",
      "Processing chunk 43801/45455\n",
      "Processing chunk 43851/45455\n",
      "Processing chunk 43901/45455\n",
      "Processing chunk 43951/45455\n",
      "Processing chunk 44001/45455\n",
      "Processing chunk 44051/45455\n",
      "Processing chunk 44101/45455\n",
      "Processing chunk 44151/45455\n",
      "Processing chunk 44201/45455\n",
      "Processing chunk 44251/45455\n",
      "Processing chunk 44301/45455\n",
      "Processing chunk 44351/45455\n",
      "Processing chunk 44401/45455\n",
      "Processing chunk 44451/45455\n",
      "Processing chunk 44501/45455\n",
      "Processing chunk 44551/45455\n",
      "Processing chunk 44601/45455\n",
      "Processing chunk 44651/45455\n",
      "Processing chunk 44701/45455\n",
      "Processing chunk 44751/45455\n",
      "Processing chunk 44801/45455\n",
      "Processing chunk 44851/45455\n",
      "Processing chunk 44901/45455\n",
      "Processing chunk 44951/45455\n",
      "Processing chunk 45001/45455\n",
      "Processing chunk 45051/45455\n",
      "Processing chunk 45101/45455\n",
      "Processing chunk 45151/45455\n",
      "Processing chunk 45201/45455\n",
      "Processing chunk 45251/45455\n",
      "Processing chunk 45301/45455\n",
      "Processing chunk 45351/45455\n",
      "Processing chunk 45401/45455\n",
      "Processing chunk 45451/45455\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 10000\n",
      "Number of hits: 9928\n",
      "Average HR@20: 0.9928\n",
      "Average NDCG@20: 0.4736\n",
      "\n",
      "Training and evaluating ST-GCN...\n",
      "Epoch 1, Loss: 0.7072\n",
      "Epoch 2, Loss: 0.5500\n",
      "Epoch 3, Loss: 0.4634\n",
      "Epoch 4, Loss: 0.4055\n",
      "Epoch 5, Loss: 0.3561\n",
      "Epoch 6, Loss: 0.3109\n",
      "Epoch 7, Loss: 0.2708\n",
      "Epoch 8, Loss: 0.2361\n",
      "Epoch 9, Loss: 0.2058\n",
      "Epoch 10, Loss: 0.1785\n",
      "Training completed in 2.33s\n",
      "Preparing test instances...\n",
      "Generated 1000000 test instances\n",
      "Evaluating 1000000 instances in 45455 chunks...\n",
      "Processing chunk 1/45455\n",
      "Processing chunk 51/45455\n",
      "Processing chunk 101/45455\n",
      "Processing chunk 151/45455\n",
      "Processing chunk 201/45455\n",
      "Processing chunk 251/45455\n",
      "Processing chunk 301/45455\n",
      "Processing chunk 351/45455\n",
      "Processing chunk 401/45455\n",
      "Processing chunk 451/45455\n",
      "Processing chunk 501/45455\n",
      "Processing chunk 551/45455\n",
      "Processing chunk 601/45455\n",
      "Processing chunk 651/45455\n",
      "Processing chunk 701/45455\n",
      "Processing chunk 751/45455\n",
      "Processing chunk 801/45455\n",
      "Processing chunk 851/45455\n",
      "Processing chunk 901/45455\n",
      "Processing chunk 951/45455\n",
      "Processing chunk 1001/45455\n",
      "Processing chunk 1051/45455\n",
      "Processing chunk 1101/45455\n",
      "Processing chunk 1151/45455\n",
      "Processing chunk 1201/45455\n",
      "Processing chunk 1251/45455\n",
      "Processing chunk 1301/45455\n",
      "Processing chunk 1351/45455\n",
      "Processing chunk 1401/45455\n",
      "Processing chunk 1451/45455\n",
      "Processing chunk 1501/45455\n",
      "Processing chunk 1551/45455\n",
      "Processing chunk 1601/45455\n",
      "Processing chunk 1651/45455\n",
      "Processing chunk 1701/45455\n",
      "Processing chunk 1751/45455\n",
      "Processing chunk 1801/45455\n",
      "Processing chunk 1851/45455\n",
      "Processing chunk 1901/45455\n",
      "Processing chunk 1951/45455\n",
      "Processing chunk 2001/45455\n",
      "Processing chunk 2051/45455\n",
      "Processing chunk 2101/45455\n",
      "Processing chunk 2151/45455\n",
      "Processing chunk 2201/45455\n",
      "Processing chunk 2251/45455\n",
      "Processing chunk 2301/45455\n",
      "Processing chunk 2351/45455\n",
      "Processing chunk 2401/45455\n",
      "Processing chunk 2451/45455\n",
      "Processing chunk 2501/45455\n",
      "Processing chunk 2551/45455\n",
      "Processing chunk 2601/45455\n",
      "Processing chunk 2651/45455\n",
      "Processing chunk 2701/45455\n",
      "Processing chunk 2751/45455\n",
      "Processing chunk 2801/45455\n",
      "Processing chunk 2851/45455\n",
      "Processing chunk 2901/45455\n",
      "Processing chunk 2951/45455\n",
      "Processing chunk 3001/45455\n",
      "Processing chunk 3051/45455\n",
      "Processing chunk 3101/45455\n",
      "Processing chunk 3151/45455\n",
      "Processing chunk 3201/45455\n",
      "Processing chunk 3251/45455\n",
      "Processing chunk 3301/45455\n",
      "Processing chunk 3351/45455\n",
      "Processing chunk 3401/45455\n",
      "Processing chunk 3451/45455\n",
      "Processing chunk 3501/45455\n",
      "Processing chunk 3551/45455\n",
      "Processing chunk 3601/45455\n",
      "Processing chunk 3651/45455\n",
      "Processing chunk 3701/45455\n",
      "Processing chunk 3751/45455\n",
      "Processing chunk 3801/45455\n",
      "Processing chunk 3851/45455\n",
      "Processing chunk 3901/45455\n",
      "Processing chunk 3951/45455\n",
      "Processing chunk 4001/45455\n",
      "Processing chunk 4051/45455\n",
      "Processing chunk 4101/45455\n",
      "Processing chunk 4151/45455\n",
      "Processing chunk 4201/45455\n",
      "Processing chunk 4251/45455\n",
      "Processing chunk 4301/45455\n",
      "Processing chunk 4351/45455\n",
      "Processing chunk 4401/45455\n",
      "Processing chunk 4451/45455\n",
      "Processing chunk 4501/45455\n",
      "Processing chunk 4551/45455\n",
      "Processing chunk 4601/45455\n",
      "Processing chunk 4651/45455\n",
      "Processing chunk 4701/45455\n",
      "Processing chunk 4751/45455\n",
      "Processing chunk 4801/45455\n",
      "Processing chunk 4851/45455\n",
      "Processing chunk 4901/45455\n",
      "Processing chunk 4951/45455\n",
      "Processing chunk 5001/45455\n",
      "Processing chunk 5051/45455\n",
      "Processing chunk 5101/45455\n",
      "Processing chunk 5151/45455\n",
      "Processing chunk 5201/45455\n",
      "Processing chunk 5251/45455\n",
      "Processing chunk 5301/45455\n",
      "Processing chunk 5351/45455\n",
      "Processing chunk 5401/45455\n",
      "Processing chunk 5451/45455\n",
      "Processing chunk 5501/45455\n",
      "Processing chunk 5551/45455\n",
      "Processing chunk 5601/45455\n",
      "Processing chunk 5651/45455\n",
      "Processing chunk 5701/45455\n",
      "Processing chunk 5751/45455\n",
      "Processing chunk 5801/45455\n",
      "Processing chunk 5851/45455\n",
      "Processing chunk 5901/45455\n",
      "Processing chunk 5951/45455\n",
      "Processing chunk 6001/45455\n",
      "Processing chunk 6051/45455\n",
      "Processing chunk 6101/45455\n",
      "Processing chunk 6151/45455\n",
      "Processing chunk 6201/45455\n",
      "Processing chunk 6251/45455\n",
      "Processing chunk 6301/45455\n",
      "Processing chunk 6351/45455\n",
      "Processing chunk 6401/45455\n",
      "Processing chunk 6451/45455\n",
      "Processing chunk 6501/45455\n",
      "Processing chunk 6551/45455\n",
      "Processing chunk 6601/45455\n",
      "Processing chunk 6651/45455\n",
      "Processing chunk 6701/45455\n",
      "Processing chunk 6751/45455\n",
      "Processing chunk 6801/45455\n",
      "Processing chunk 6851/45455\n",
      "Processing chunk 6901/45455\n",
      "Processing chunk 6951/45455\n",
      "Processing chunk 7001/45455\n",
      "Processing chunk 7051/45455\n",
      "Processing chunk 7101/45455\n",
      "Processing chunk 7151/45455\n",
      "Processing chunk 7201/45455\n",
      "Processing chunk 7251/45455\n",
      "Processing chunk 7301/45455\n",
      "Processing chunk 7351/45455\n",
      "Processing chunk 7401/45455\n",
      "Processing chunk 7451/45455\n",
      "Processing chunk 7501/45455\n",
      "Processing chunk 7551/45455\n",
      "Processing chunk 7601/45455\n",
      "Processing chunk 7651/45455\n",
      "Processing chunk 7701/45455\n",
      "Processing chunk 7751/45455\n",
      "Processing chunk 7801/45455\n",
      "Processing chunk 7851/45455\n",
      "Processing chunk 7901/45455\n",
      "Processing chunk 7951/45455\n",
      "Processing chunk 8001/45455\n",
      "Processing chunk 8051/45455\n",
      "Processing chunk 8101/45455\n",
      "Processing chunk 8151/45455\n",
      "Processing chunk 8201/45455\n",
      "Processing chunk 8251/45455\n",
      "Processing chunk 8301/45455\n",
      "Processing chunk 8351/45455\n",
      "Processing chunk 8401/45455\n",
      "Processing chunk 8451/45455\n",
      "Processing chunk 8501/45455\n",
      "Processing chunk 8551/45455\n",
      "Processing chunk 8601/45455\n",
      "Processing chunk 8651/45455\n",
      "Processing chunk 8701/45455\n",
      "Processing chunk 8751/45455\n",
      "Processing chunk 8801/45455\n",
      "Processing chunk 8851/45455\n",
      "Processing chunk 8901/45455\n",
      "Processing chunk 8951/45455\n",
      "Processing chunk 9001/45455\n",
      "Processing chunk 9051/45455\n",
      "Processing chunk 9101/45455\n",
      "Processing chunk 9151/45455\n",
      "Processing chunk 9201/45455\n",
      "Processing chunk 9251/45455\n",
      "Processing chunk 9301/45455\n",
      "Processing chunk 9351/45455\n",
      "Processing chunk 9401/45455\n",
      "Processing chunk 9451/45455\n",
      "Processing chunk 9501/45455\n",
      "Processing chunk 9551/45455\n",
      "Processing chunk 9601/45455\n",
      "Processing chunk 9651/45455\n",
      "Processing chunk 9701/45455\n",
      "Processing chunk 9751/45455\n",
      "Processing chunk 9801/45455\n",
      "Processing chunk 9851/45455\n",
      "Processing chunk 9901/45455\n",
      "Processing chunk 9951/45455\n",
      "Processing chunk 10001/45455\n",
      "Processing chunk 10051/45455\n",
      "Processing chunk 10101/45455\n",
      "Processing chunk 10151/45455\n",
      "Processing chunk 10201/45455\n",
      "Processing chunk 10251/45455\n",
      "Processing chunk 10301/45455\n",
      "Processing chunk 10351/45455\n",
      "Processing chunk 10401/45455\n",
      "Processing chunk 10451/45455\n",
      "Processing chunk 10501/45455\n",
      "Processing chunk 10551/45455\n",
      "Processing chunk 10601/45455\n",
      "Processing chunk 10651/45455\n",
      "Processing chunk 10701/45455\n",
      "Processing chunk 10751/45455\n",
      "Processing chunk 10801/45455\n",
      "Processing chunk 10851/45455\n",
      "Processing chunk 10901/45455\n",
      "Processing chunk 10951/45455\n",
      "Processing chunk 11001/45455\n",
      "Processing chunk 11051/45455\n",
      "Processing chunk 11101/45455\n",
      "Processing chunk 11151/45455\n",
      "Processing chunk 11201/45455\n",
      "Processing chunk 11251/45455\n",
      "Processing chunk 11301/45455\n",
      "Processing chunk 11351/45455\n",
      "Processing chunk 11401/45455\n",
      "Processing chunk 11451/45455\n",
      "Processing chunk 11501/45455\n",
      "Processing chunk 11551/45455\n",
      "Processing chunk 11601/45455\n",
      "Processing chunk 11651/45455\n",
      "Processing chunk 11701/45455\n",
      "Processing chunk 11751/45455\n",
      "Processing chunk 11801/45455\n",
      "Processing chunk 11851/45455\n",
      "Processing chunk 11901/45455\n",
      "Processing chunk 11951/45455\n",
      "Processing chunk 12001/45455\n",
      "Processing chunk 12051/45455\n",
      "Processing chunk 12101/45455\n",
      "Processing chunk 12151/45455\n",
      "Processing chunk 12201/45455\n",
      "Processing chunk 12251/45455\n",
      "Processing chunk 12301/45455\n",
      "Processing chunk 12351/45455\n",
      "Processing chunk 12401/45455\n",
      "Processing chunk 12451/45455\n",
      "Processing chunk 12501/45455\n",
      "Processing chunk 12551/45455\n",
      "Processing chunk 12601/45455\n",
      "Processing chunk 12651/45455\n",
      "Processing chunk 12701/45455\n",
      "Processing chunk 12751/45455\n",
      "Processing chunk 12801/45455\n",
      "Processing chunk 12851/45455\n",
      "Processing chunk 12901/45455\n",
      "Processing chunk 12951/45455\n",
      "Processing chunk 13001/45455\n",
      "Processing chunk 13051/45455\n",
      "Processing chunk 13101/45455\n",
      "Processing chunk 13151/45455\n",
      "Processing chunk 13201/45455\n",
      "Processing chunk 13251/45455\n",
      "Processing chunk 13301/45455\n",
      "Processing chunk 13351/45455\n",
      "Processing chunk 13401/45455\n",
      "Processing chunk 13451/45455\n",
      "Processing chunk 13501/45455\n",
      "Processing chunk 13551/45455\n",
      "Processing chunk 13601/45455\n",
      "Processing chunk 13651/45455\n",
      "Processing chunk 13701/45455\n",
      "Processing chunk 13751/45455\n",
      "Processing chunk 13801/45455\n",
      "Processing chunk 13851/45455\n",
      "Processing chunk 13901/45455\n",
      "Processing chunk 13951/45455\n",
      "Processing chunk 14001/45455\n",
      "Processing chunk 14051/45455\n",
      "Processing chunk 14101/45455\n",
      "Processing chunk 14151/45455\n",
      "Processing chunk 14201/45455\n",
      "Processing chunk 14251/45455\n",
      "Processing chunk 14301/45455\n",
      "Processing chunk 14351/45455\n",
      "Processing chunk 14401/45455\n",
      "Processing chunk 14451/45455\n",
      "Processing chunk 14501/45455\n",
      "Processing chunk 14551/45455\n",
      "Processing chunk 14601/45455\n",
      "Processing chunk 14651/45455\n",
      "Processing chunk 14701/45455\n",
      "Processing chunk 14751/45455\n",
      "Processing chunk 14801/45455\n",
      "Processing chunk 14851/45455\n",
      "Processing chunk 14901/45455\n",
      "Processing chunk 14951/45455\n",
      "Processing chunk 15001/45455\n",
      "Processing chunk 15051/45455\n",
      "Processing chunk 15101/45455\n",
      "Processing chunk 15151/45455\n",
      "Processing chunk 15201/45455\n",
      "Processing chunk 15251/45455\n",
      "Processing chunk 15301/45455\n",
      "Processing chunk 15351/45455\n",
      "Processing chunk 15401/45455\n",
      "Processing chunk 15451/45455\n",
      "Processing chunk 15501/45455\n",
      "Processing chunk 15551/45455\n",
      "Processing chunk 15601/45455\n",
      "Processing chunk 15651/45455\n",
      "Processing chunk 15701/45455\n",
      "Processing chunk 15751/45455\n",
      "Processing chunk 15801/45455\n",
      "Processing chunk 15851/45455\n",
      "Processing chunk 15901/45455\n",
      "Processing chunk 15951/45455\n",
      "Processing chunk 16001/45455\n",
      "Processing chunk 16051/45455\n",
      "Processing chunk 16101/45455\n",
      "Processing chunk 16151/45455\n",
      "Processing chunk 16201/45455\n",
      "Processing chunk 16251/45455\n",
      "Processing chunk 16301/45455\n",
      "Processing chunk 16351/45455\n",
      "Processing chunk 16401/45455\n",
      "Processing chunk 16451/45455\n",
      "Processing chunk 16501/45455\n",
      "Processing chunk 16551/45455\n",
      "Processing chunk 16601/45455\n",
      "Processing chunk 16651/45455\n",
      "Processing chunk 16701/45455\n",
      "Processing chunk 16751/45455\n",
      "Processing chunk 16801/45455\n",
      "Processing chunk 16851/45455\n",
      "Processing chunk 16901/45455\n",
      "Processing chunk 16951/45455\n",
      "Processing chunk 17001/45455\n",
      "Processing chunk 17051/45455\n",
      "Processing chunk 17101/45455\n",
      "Processing chunk 17151/45455\n",
      "Processing chunk 17201/45455\n",
      "Processing chunk 17251/45455\n",
      "Processing chunk 17301/45455\n",
      "Processing chunk 17351/45455\n",
      "Processing chunk 17401/45455\n",
      "Processing chunk 17451/45455\n",
      "Processing chunk 17501/45455\n",
      "Processing chunk 17551/45455\n",
      "Processing chunk 17601/45455\n",
      "Processing chunk 17651/45455\n",
      "Processing chunk 17701/45455\n",
      "Processing chunk 17751/45455\n",
      "Processing chunk 17801/45455\n",
      "Processing chunk 17851/45455\n",
      "Processing chunk 17901/45455\n",
      "Processing chunk 17951/45455\n",
      "Processing chunk 18001/45455\n",
      "Processing chunk 18051/45455\n",
      "Processing chunk 18101/45455\n",
      "Processing chunk 18151/45455\n",
      "Processing chunk 18201/45455\n",
      "Processing chunk 18251/45455\n",
      "Processing chunk 18301/45455\n",
      "Processing chunk 18351/45455\n",
      "Processing chunk 18401/45455\n",
      "Processing chunk 18451/45455\n",
      "Processing chunk 18501/45455\n",
      "Processing chunk 18551/45455\n",
      "Processing chunk 18601/45455\n",
      "Processing chunk 18651/45455\n",
      "Processing chunk 18701/45455\n",
      "Processing chunk 18751/45455\n",
      "Processing chunk 18801/45455\n",
      "Processing chunk 18851/45455\n",
      "Processing chunk 18901/45455\n",
      "Processing chunk 18951/45455\n",
      "Processing chunk 19001/45455\n",
      "Processing chunk 19051/45455\n",
      "Processing chunk 19101/45455\n",
      "Processing chunk 19151/45455\n",
      "Processing chunk 19201/45455\n",
      "Processing chunk 19251/45455\n",
      "Processing chunk 19301/45455\n",
      "Processing chunk 19351/45455\n",
      "Processing chunk 19401/45455\n",
      "Processing chunk 19451/45455\n",
      "Processing chunk 19501/45455\n",
      "Processing chunk 19551/45455\n",
      "Processing chunk 19601/45455\n",
      "Processing chunk 19651/45455\n",
      "Processing chunk 19701/45455\n",
      "Processing chunk 19751/45455\n",
      "Processing chunk 19801/45455\n",
      "Processing chunk 19851/45455\n",
      "Processing chunk 19901/45455\n",
      "Processing chunk 19951/45455\n",
      "Processing chunk 20001/45455\n",
      "Processing chunk 20051/45455\n",
      "Processing chunk 20101/45455\n",
      "Processing chunk 20151/45455\n",
      "Processing chunk 20201/45455\n",
      "Processing chunk 20251/45455\n",
      "Processing chunk 20301/45455\n",
      "Processing chunk 20351/45455\n",
      "Processing chunk 20401/45455\n",
      "Processing chunk 20451/45455\n",
      "Processing chunk 20501/45455\n",
      "Processing chunk 20551/45455\n",
      "Processing chunk 20601/45455\n",
      "Processing chunk 20651/45455\n",
      "Processing chunk 20701/45455\n",
      "Processing chunk 20751/45455\n",
      "Processing chunk 20801/45455\n",
      "Processing chunk 20851/45455\n",
      "Processing chunk 20901/45455\n",
      "Processing chunk 20951/45455\n",
      "Processing chunk 21001/45455\n",
      "Processing chunk 21051/45455\n",
      "Processing chunk 21101/45455\n",
      "Processing chunk 21151/45455\n",
      "Processing chunk 21201/45455\n",
      "Processing chunk 21251/45455\n",
      "Processing chunk 21301/45455\n",
      "Processing chunk 21351/45455\n",
      "Processing chunk 21401/45455\n",
      "Processing chunk 21451/45455\n",
      "Processing chunk 21501/45455\n",
      "Processing chunk 21551/45455\n",
      "Processing chunk 21601/45455\n",
      "Processing chunk 21651/45455\n",
      "Processing chunk 21701/45455\n",
      "Processing chunk 21751/45455\n",
      "Processing chunk 21801/45455\n",
      "Processing chunk 21851/45455\n",
      "Processing chunk 21901/45455\n",
      "Processing chunk 21951/45455\n",
      "Processing chunk 22001/45455\n",
      "Processing chunk 22051/45455\n",
      "Processing chunk 22101/45455\n",
      "Processing chunk 22151/45455\n",
      "Processing chunk 22201/45455\n",
      "Processing chunk 22251/45455\n",
      "Processing chunk 22301/45455\n",
      "Processing chunk 22351/45455\n",
      "Processing chunk 22401/45455\n",
      "Processing chunk 22451/45455\n",
      "Processing chunk 22501/45455\n",
      "Processing chunk 22551/45455\n",
      "Processing chunk 22601/45455\n",
      "Processing chunk 22651/45455\n",
      "Processing chunk 22701/45455\n",
      "Processing chunk 22751/45455\n",
      "Processing chunk 22801/45455\n",
      "Processing chunk 22851/45455\n",
      "Processing chunk 22901/45455\n",
      "Processing chunk 22951/45455\n",
      "Processing chunk 23001/45455\n",
      "Processing chunk 23051/45455\n",
      "Processing chunk 23101/45455\n",
      "Processing chunk 23151/45455\n",
      "Processing chunk 23201/45455\n",
      "Processing chunk 23251/45455\n",
      "Processing chunk 23301/45455\n",
      "Processing chunk 23351/45455\n",
      "Processing chunk 23401/45455\n",
      "Processing chunk 23451/45455\n",
      "Processing chunk 23501/45455\n",
      "Processing chunk 23551/45455\n",
      "Processing chunk 23601/45455\n",
      "Processing chunk 23651/45455\n",
      "Processing chunk 23701/45455\n",
      "Processing chunk 23751/45455\n",
      "Processing chunk 23801/45455\n",
      "Processing chunk 23851/45455\n",
      "Processing chunk 23901/45455\n",
      "Processing chunk 23951/45455\n",
      "Processing chunk 24001/45455\n",
      "Processing chunk 24051/45455\n",
      "Processing chunk 24101/45455\n",
      "Processing chunk 24151/45455\n",
      "Processing chunk 24201/45455\n",
      "Processing chunk 24251/45455\n",
      "Processing chunk 24301/45455\n",
      "Processing chunk 24351/45455\n",
      "Processing chunk 24401/45455\n",
      "Processing chunk 24451/45455\n",
      "Processing chunk 24501/45455\n",
      "Processing chunk 24551/45455\n",
      "Processing chunk 24601/45455\n",
      "Processing chunk 24651/45455\n",
      "Processing chunk 24701/45455\n",
      "Processing chunk 24751/45455\n",
      "Processing chunk 24801/45455\n",
      "Processing chunk 24851/45455\n",
      "Processing chunk 24901/45455\n",
      "Processing chunk 24951/45455\n",
      "Processing chunk 25001/45455\n",
      "Processing chunk 25051/45455\n",
      "Processing chunk 25101/45455\n",
      "Processing chunk 25151/45455\n",
      "Processing chunk 25201/45455\n",
      "Processing chunk 25251/45455\n",
      "Processing chunk 25301/45455\n",
      "Processing chunk 25351/45455\n",
      "Processing chunk 25401/45455\n",
      "Processing chunk 25451/45455\n",
      "Processing chunk 25501/45455\n",
      "Processing chunk 25551/45455\n",
      "Processing chunk 25601/45455\n",
      "Processing chunk 25651/45455\n",
      "Processing chunk 25701/45455\n",
      "Processing chunk 25751/45455\n",
      "Processing chunk 25801/45455\n",
      "Processing chunk 25851/45455\n",
      "Processing chunk 25901/45455\n",
      "Processing chunk 25951/45455\n",
      "Processing chunk 26001/45455\n",
      "Processing chunk 26051/45455\n",
      "Processing chunk 26101/45455\n",
      "Processing chunk 26151/45455\n",
      "Processing chunk 26201/45455\n",
      "Processing chunk 26251/45455\n",
      "Processing chunk 26301/45455\n",
      "Processing chunk 26351/45455\n",
      "Processing chunk 26401/45455\n",
      "Processing chunk 26451/45455\n",
      "Processing chunk 26501/45455\n",
      "Processing chunk 26551/45455\n",
      "Processing chunk 26601/45455\n",
      "Processing chunk 26651/45455\n",
      "Processing chunk 26701/45455\n",
      "Processing chunk 26751/45455\n",
      "Processing chunk 26801/45455\n",
      "Processing chunk 26851/45455\n",
      "Processing chunk 26901/45455\n",
      "Processing chunk 26951/45455\n",
      "Processing chunk 27001/45455\n",
      "Processing chunk 27051/45455\n",
      "Processing chunk 27101/45455\n",
      "Processing chunk 27151/45455\n",
      "Processing chunk 27201/45455\n",
      "Processing chunk 27251/45455\n",
      "Processing chunk 27301/45455\n",
      "Processing chunk 27351/45455\n",
      "Processing chunk 27401/45455\n",
      "Processing chunk 27451/45455\n",
      "Processing chunk 27501/45455\n",
      "Processing chunk 27551/45455\n",
      "Processing chunk 27601/45455\n",
      "Processing chunk 27651/45455\n",
      "Processing chunk 27701/45455\n",
      "Processing chunk 27751/45455\n",
      "Processing chunk 27801/45455\n",
      "Processing chunk 27851/45455\n",
      "Processing chunk 27901/45455\n",
      "Processing chunk 27951/45455\n",
      "Processing chunk 28001/45455\n",
      "Processing chunk 28051/45455\n",
      "Processing chunk 28101/45455\n",
      "Processing chunk 28151/45455\n",
      "Processing chunk 28201/45455\n",
      "Processing chunk 28251/45455\n",
      "Processing chunk 28301/45455\n",
      "Processing chunk 28351/45455\n",
      "Processing chunk 28401/45455\n",
      "Processing chunk 28451/45455\n",
      "Processing chunk 28501/45455\n",
      "Processing chunk 28551/45455\n",
      "Processing chunk 28601/45455\n",
      "Processing chunk 28651/45455\n",
      "Processing chunk 28701/45455\n",
      "Processing chunk 28751/45455\n",
      "Processing chunk 28801/45455\n",
      "Processing chunk 28851/45455\n",
      "Processing chunk 28901/45455\n",
      "Processing chunk 28951/45455\n",
      "Processing chunk 29001/45455\n",
      "Processing chunk 29051/45455\n",
      "Processing chunk 29101/45455\n",
      "Processing chunk 29151/45455\n",
      "Processing chunk 29201/45455\n",
      "Processing chunk 29251/45455\n",
      "Processing chunk 29301/45455\n",
      "Processing chunk 29351/45455\n",
      "Processing chunk 29401/45455\n",
      "Processing chunk 29451/45455\n",
      "Processing chunk 29501/45455\n",
      "Processing chunk 29551/45455\n",
      "Processing chunk 29601/45455\n",
      "Processing chunk 29651/45455\n",
      "Processing chunk 29701/45455\n",
      "Processing chunk 29751/45455\n",
      "Processing chunk 29801/45455\n",
      "Processing chunk 29851/45455\n",
      "Processing chunk 29901/45455\n",
      "Processing chunk 29951/45455\n",
      "Processing chunk 30001/45455\n",
      "Processing chunk 30051/45455\n",
      "Processing chunk 30101/45455\n",
      "Processing chunk 30151/45455\n",
      "Processing chunk 30201/45455\n",
      "Processing chunk 30251/45455\n",
      "Processing chunk 30301/45455\n",
      "Processing chunk 30351/45455\n",
      "Processing chunk 30401/45455\n",
      "Processing chunk 30451/45455\n",
      "Processing chunk 30501/45455\n",
      "Processing chunk 30551/45455\n",
      "Processing chunk 30601/45455\n",
      "Processing chunk 30651/45455\n",
      "Processing chunk 30701/45455\n",
      "Processing chunk 30751/45455\n",
      "Processing chunk 30801/45455\n",
      "Processing chunk 30851/45455\n",
      "Processing chunk 30901/45455\n",
      "Processing chunk 30951/45455\n",
      "Processing chunk 31001/45455\n",
      "Processing chunk 31051/45455\n",
      "Processing chunk 31101/45455\n",
      "Processing chunk 31151/45455\n",
      "Processing chunk 31201/45455\n",
      "Processing chunk 31251/45455\n",
      "Processing chunk 31301/45455\n",
      "Processing chunk 31351/45455\n",
      "Processing chunk 31401/45455\n",
      "Processing chunk 31451/45455\n",
      "Processing chunk 31501/45455\n",
      "Processing chunk 31551/45455\n",
      "Processing chunk 31601/45455\n",
      "Processing chunk 31651/45455\n",
      "Processing chunk 31701/45455\n",
      "Processing chunk 31751/45455\n",
      "Processing chunk 31801/45455\n",
      "Processing chunk 31851/45455\n",
      "Processing chunk 31901/45455\n",
      "Processing chunk 31951/45455\n",
      "Processing chunk 32001/45455\n",
      "Processing chunk 32051/45455\n",
      "Processing chunk 32101/45455\n",
      "Processing chunk 32151/45455\n",
      "Processing chunk 32201/45455\n",
      "Processing chunk 32251/45455\n",
      "Processing chunk 32301/45455\n",
      "Processing chunk 32351/45455\n",
      "Processing chunk 32401/45455\n",
      "Processing chunk 32451/45455\n",
      "Processing chunk 32501/45455\n",
      "Processing chunk 32551/45455\n",
      "Processing chunk 32601/45455\n",
      "Processing chunk 32651/45455\n",
      "Processing chunk 32701/45455\n",
      "Processing chunk 32751/45455\n",
      "Processing chunk 32801/45455\n",
      "Processing chunk 32851/45455\n",
      "Processing chunk 32901/45455\n",
      "Processing chunk 32951/45455\n",
      "Processing chunk 33001/45455\n",
      "Processing chunk 33051/45455\n",
      "Processing chunk 33101/45455\n",
      "Processing chunk 33151/45455\n",
      "Processing chunk 33201/45455\n",
      "Processing chunk 33251/45455\n",
      "Processing chunk 33301/45455\n",
      "Processing chunk 33351/45455\n",
      "Processing chunk 33401/45455\n",
      "Processing chunk 33451/45455\n",
      "Processing chunk 33501/45455\n",
      "Processing chunk 33551/45455\n",
      "Processing chunk 33601/45455\n",
      "Processing chunk 33651/45455\n",
      "Processing chunk 33701/45455\n",
      "Processing chunk 33751/45455\n",
      "Processing chunk 33801/45455\n",
      "Processing chunk 33851/45455\n",
      "Processing chunk 33901/45455\n",
      "Processing chunk 33951/45455\n",
      "Processing chunk 34001/45455\n",
      "Processing chunk 34051/45455\n",
      "Processing chunk 34101/45455\n",
      "Processing chunk 34151/45455\n",
      "Processing chunk 34201/45455\n",
      "Processing chunk 34251/45455\n",
      "Processing chunk 34301/45455\n",
      "Processing chunk 34351/45455\n",
      "Processing chunk 34401/45455\n",
      "Processing chunk 34451/45455\n",
      "Processing chunk 34501/45455\n",
      "Processing chunk 34551/45455\n",
      "Processing chunk 34601/45455\n",
      "Processing chunk 34651/45455\n",
      "Processing chunk 34701/45455\n",
      "Processing chunk 34751/45455\n",
      "Processing chunk 34801/45455\n",
      "Processing chunk 34851/45455\n",
      "Processing chunk 34901/45455\n",
      "Processing chunk 34951/45455\n",
      "Processing chunk 35001/45455\n",
      "Processing chunk 35051/45455\n",
      "Processing chunk 35101/45455\n",
      "Processing chunk 35151/45455\n",
      "Processing chunk 35201/45455\n",
      "Processing chunk 35251/45455\n",
      "Processing chunk 35301/45455\n",
      "Processing chunk 35351/45455\n",
      "Processing chunk 35401/45455\n",
      "Processing chunk 35451/45455\n",
      "Processing chunk 35501/45455\n",
      "Processing chunk 35551/45455\n",
      "Processing chunk 35601/45455\n",
      "Processing chunk 35651/45455\n",
      "Processing chunk 35701/45455\n",
      "Processing chunk 35751/45455\n",
      "Processing chunk 35801/45455\n",
      "Processing chunk 35851/45455\n",
      "Processing chunk 35901/45455\n",
      "Processing chunk 35951/45455\n",
      "Processing chunk 36001/45455\n",
      "Processing chunk 36051/45455\n",
      "Processing chunk 36101/45455\n",
      "Processing chunk 36151/45455\n",
      "Processing chunk 36201/45455\n",
      "Processing chunk 36251/45455\n",
      "Processing chunk 36301/45455\n",
      "Processing chunk 36351/45455\n",
      "Processing chunk 36401/45455\n",
      "Processing chunk 36451/45455\n",
      "Processing chunk 36501/45455\n",
      "Processing chunk 36551/45455\n",
      "Processing chunk 36601/45455\n",
      "Processing chunk 36651/45455\n",
      "Processing chunk 36701/45455\n",
      "Processing chunk 36751/45455\n",
      "Processing chunk 36801/45455\n",
      "Processing chunk 36851/45455\n",
      "Processing chunk 36901/45455\n",
      "Processing chunk 36951/45455\n",
      "Processing chunk 37001/45455\n",
      "Processing chunk 37051/45455\n",
      "Processing chunk 37101/45455\n",
      "Processing chunk 37151/45455\n",
      "Processing chunk 37201/45455\n",
      "Processing chunk 37251/45455\n",
      "Processing chunk 37301/45455\n",
      "Processing chunk 37351/45455\n",
      "Processing chunk 37401/45455\n",
      "Processing chunk 37451/45455\n",
      "Processing chunk 37501/45455\n",
      "Processing chunk 37551/45455\n",
      "Processing chunk 37601/45455\n",
      "Processing chunk 37651/45455\n",
      "Processing chunk 37701/45455\n",
      "Processing chunk 37751/45455\n",
      "Processing chunk 37801/45455\n",
      "Processing chunk 37851/45455\n",
      "Processing chunk 37901/45455\n",
      "Processing chunk 37951/45455\n",
      "Processing chunk 38001/45455\n",
      "Processing chunk 38051/45455\n",
      "Processing chunk 38101/45455\n",
      "Processing chunk 38151/45455\n",
      "Processing chunk 38201/45455\n",
      "Processing chunk 38251/45455\n",
      "Processing chunk 38301/45455\n",
      "Processing chunk 38351/45455\n",
      "Processing chunk 38401/45455\n",
      "Processing chunk 38451/45455\n",
      "Processing chunk 38501/45455\n",
      "Processing chunk 38551/45455\n",
      "Processing chunk 38601/45455\n",
      "Processing chunk 38651/45455\n",
      "Processing chunk 38701/45455\n",
      "Processing chunk 38751/45455\n",
      "Processing chunk 38801/45455\n",
      "Processing chunk 38851/45455\n",
      "Processing chunk 38901/45455\n",
      "Processing chunk 38951/45455\n",
      "Processing chunk 39001/45455\n",
      "Processing chunk 39051/45455\n",
      "Processing chunk 39101/45455\n",
      "Processing chunk 39151/45455\n",
      "Processing chunk 39201/45455\n",
      "Processing chunk 39251/45455\n",
      "Processing chunk 39301/45455\n",
      "Processing chunk 39351/45455\n",
      "Processing chunk 39401/45455\n",
      "Processing chunk 39451/45455\n",
      "Processing chunk 39501/45455\n",
      "Processing chunk 39551/45455\n",
      "Processing chunk 39601/45455\n",
      "Processing chunk 39651/45455\n",
      "Processing chunk 39701/45455\n",
      "Processing chunk 39751/45455\n",
      "Processing chunk 39801/45455\n",
      "Processing chunk 39851/45455\n",
      "Processing chunk 39901/45455\n",
      "Processing chunk 39951/45455\n",
      "Processing chunk 40001/45455\n",
      "Processing chunk 40051/45455\n",
      "Processing chunk 40101/45455\n",
      "Processing chunk 40151/45455\n",
      "Processing chunk 40201/45455\n",
      "Processing chunk 40251/45455\n",
      "Processing chunk 40301/45455\n",
      "Processing chunk 40351/45455\n",
      "Processing chunk 40401/45455\n",
      "Processing chunk 40451/45455\n",
      "Processing chunk 40501/45455\n",
      "Processing chunk 40551/45455\n",
      "Processing chunk 40601/45455\n",
      "Processing chunk 40651/45455\n",
      "Processing chunk 40701/45455\n",
      "Processing chunk 40751/45455\n",
      "Processing chunk 40801/45455\n",
      "Processing chunk 40851/45455\n",
      "Processing chunk 40901/45455\n",
      "Processing chunk 40951/45455\n",
      "Processing chunk 41001/45455\n",
      "Processing chunk 41051/45455\n",
      "Processing chunk 41101/45455\n",
      "Processing chunk 41151/45455\n",
      "Processing chunk 41201/45455\n",
      "Processing chunk 41251/45455\n",
      "Processing chunk 41301/45455\n",
      "Processing chunk 41351/45455\n",
      "Processing chunk 41401/45455\n",
      "Processing chunk 41451/45455\n",
      "Processing chunk 41501/45455\n",
      "Processing chunk 41551/45455\n",
      "Processing chunk 41601/45455\n",
      "Processing chunk 41651/45455\n",
      "Processing chunk 41701/45455\n",
      "Processing chunk 41751/45455\n",
      "Processing chunk 41801/45455\n",
      "Processing chunk 41851/45455\n",
      "Processing chunk 41901/45455\n",
      "Processing chunk 41951/45455\n",
      "Processing chunk 42001/45455\n",
      "Processing chunk 42051/45455\n",
      "Processing chunk 42101/45455\n",
      "Processing chunk 42151/45455\n",
      "Processing chunk 42201/45455\n",
      "Processing chunk 42251/45455\n",
      "Processing chunk 42301/45455\n",
      "Processing chunk 42351/45455\n",
      "Processing chunk 42401/45455\n",
      "Processing chunk 42451/45455\n",
      "Processing chunk 42501/45455\n",
      "Processing chunk 42551/45455\n",
      "Processing chunk 42601/45455\n",
      "Processing chunk 42651/45455\n",
      "Processing chunk 42701/45455\n",
      "Processing chunk 42751/45455\n",
      "Processing chunk 42801/45455\n",
      "Processing chunk 42851/45455\n",
      "Processing chunk 42901/45455\n",
      "Processing chunk 42951/45455\n",
      "Processing chunk 43001/45455\n",
      "Processing chunk 43051/45455\n",
      "Processing chunk 43101/45455\n",
      "Processing chunk 43151/45455\n",
      "Processing chunk 43201/45455\n",
      "Processing chunk 43251/45455\n",
      "Processing chunk 43301/45455\n",
      "Processing chunk 43351/45455\n",
      "Processing chunk 43401/45455\n",
      "Processing chunk 43451/45455\n",
      "Processing chunk 43501/45455\n",
      "Processing chunk 43551/45455\n",
      "Processing chunk 43601/45455\n",
      "Processing chunk 43651/45455\n",
      "Processing chunk 43701/45455\n",
      "Processing chunk 43751/45455\n",
      "Processing chunk 43801/45455\n",
      "Processing chunk 43851/45455\n",
      "Processing chunk 43901/45455\n",
      "Processing chunk 43951/45455\n",
      "Processing chunk 44001/45455\n",
      "Processing chunk 44051/45455\n",
      "Processing chunk 44101/45455\n",
      "Processing chunk 44151/45455\n",
      "Processing chunk 44201/45455\n",
      "Processing chunk 44251/45455\n",
      "Processing chunk 44301/45455\n",
      "Processing chunk 44351/45455\n",
      "Processing chunk 44401/45455\n",
      "Processing chunk 44451/45455\n",
      "Processing chunk 44501/45455\n",
      "Processing chunk 44551/45455\n",
      "Processing chunk 44601/45455\n",
      "Processing chunk 44651/45455\n",
      "Processing chunk 44701/45455\n",
      "Processing chunk 44751/45455\n",
      "Processing chunk 44801/45455\n",
      "Processing chunk 44851/45455\n",
      "Processing chunk 44901/45455\n",
      "Processing chunk 44951/45455\n",
      "Processing chunk 45001/45455\n",
      "Processing chunk 45051/45455\n",
      "Processing chunk 45101/45455\n",
      "Processing chunk 45151/45455\n",
      "Processing chunk 45201/45455\n",
      "Processing chunk 45251/45455\n",
      "Processing chunk 45301/45455\n",
      "Processing chunk 45351/45455\n",
      "Processing chunk 45401/45455\n",
      "Processing chunk 45451/45455\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 10000\n",
      "Number of hits: 9906\n",
      "Average HR@20: 0.9906\n",
      "Average NDCG@20: 0.4537\n",
      "\n",
      "Training and evaluating NGCF...\n",
      "Epoch 1, Loss: 0.6922\n",
      "Epoch 2, Loss: 0.5383\n",
      "Epoch 3, Loss: 0.4545\n",
      "Epoch 4, Loss: 0.3962\n",
      "Epoch 5, Loss: 0.3462\n",
      "Epoch 6, Loss: 0.3011\n",
      "Epoch 7, Loss: 0.2616\n",
      "Epoch 8, Loss: 0.2275\n",
      "Epoch 9, Loss: 0.1975\n",
      "Epoch 10, Loss: 0.1704\n",
      "Training completed in 2.20s\n",
      "Preparing test instances...\n",
      "Generated 1000000 test instances\n",
      "Evaluating 1000000 instances in 45455 chunks...\n",
      "Processing chunk 1/45455\n",
      "Processing chunk 51/45455\n",
      "Processing chunk 101/45455\n",
      "Processing chunk 151/45455\n",
      "Processing chunk 201/45455\n",
      "Processing chunk 251/45455\n",
      "Processing chunk 301/45455\n",
      "Processing chunk 351/45455\n",
      "Processing chunk 401/45455\n",
      "Processing chunk 451/45455\n",
      "Processing chunk 501/45455\n",
      "Processing chunk 551/45455\n",
      "Processing chunk 601/45455\n",
      "Processing chunk 651/45455\n",
      "Processing chunk 701/45455\n",
      "Processing chunk 751/45455\n",
      "Processing chunk 801/45455\n",
      "Processing chunk 851/45455\n",
      "Processing chunk 901/45455\n",
      "Processing chunk 951/45455\n",
      "Processing chunk 1001/45455\n",
      "Processing chunk 1051/45455\n",
      "Processing chunk 1101/45455\n",
      "Processing chunk 1151/45455\n",
      "Processing chunk 1201/45455\n",
      "Processing chunk 1251/45455\n",
      "Processing chunk 1301/45455\n",
      "Processing chunk 1351/45455\n",
      "Processing chunk 1401/45455\n",
      "Processing chunk 1451/45455\n",
      "Processing chunk 1501/45455\n",
      "Processing chunk 1551/45455\n",
      "Processing chunk 1601/45455\n",
      "Processing chunk 1651/45455\n",
      "Processing chunk 1701/45455\n",
      "Processing chunk 1751/45455\n",
      "Processing chunk 1801/45455\n",
      "Processing chunk 1851/45455\n",
      "Processing chunk 1901/45455\n",
      "Processing chunk 1951/45455\n",
      "Processing chunk 2001/45455\n",
      "Processing chunk 2051/45455\n",
      "Processing chunk 2101/45455\n",
      "Processing chunk 2151/45455\n",
      "Processing chunk 2201/45455\n",
      "Processing chunk 2251/45455\n",
      "Processing chunk 2301/45455\n",
      "Processing chunk 2351/45455\n",
      "Processing chunk 2401/45455\n",
      "Processing chunk 2451/45455\n",
      "Processing chunk 2501/45455\n",
      "Processing chunk 2551/45455\n",
      "Processing chunk 2601/45455\n",
      "Processing chunk 2651/45455\n",
      "Processing chunk 2701/45455\n",
      "Processing chunk 2751/45455\n",
      "Processing chunk 2801/45455\n",
      "Processing chunk 2851/45455\n",
      "Processing chunk 2901/45455\n",
      "Processing chunk 2951/45455\n",
      "Processing chunk 3001/45455\n",
      "Processing chunk 3051/45455\n",
      "Processing chunk 3101/45455\n",
      "Processing chunk 3151/45455\n",
      "Processing chunk 3201/45455\n",
      "Processing chunk 3251/45455\n",
      "Processing chunk 3301/45455\n",
      "Processing chunk 3351/45455\n",
      "Processing chunk 3401/45455\n",
      "Processing chunk 3451/45455\n",
      "Processing chunk 3501/45455\n",
      "Processing chunk 3551/45455\n",
      "Processing chunk 3601/45455\n",
      "Processing chunk 3651/45455\n",
      "Processing chunk 3701/45455\n",
      "Processing chunk 3751/45455\n",
      "Processing chunk 3801/45455\n",
      "Processing chunk 3851/45455\n",
      "Processing chunk 3901/45455\n",
      "Processing chunk 3951/45455\n",
      "Processing chunk 4001/45455\n",
      "Processing chunk 4051/45455\n",
      "Processing chunk 4101/45455\n",
      "Processing chunk 4151/45455\n",
      "Processing chunk 4201/45455\n",
      "Processing chunk 4251/45455\n",
      "Processing chunk 4301/45455\n",
      "Processing chunk 4351/45455\n",
      "Processing chunk 4401/45455\n",
      "Processing chunk 4451/45455\n",
      "Processing chunk 4501/45455\n",
      "Processing chunk 4551/45455\n",
      "Processing chunk 4601/45455\n",
      "Processing chunk 4651/45455\n",
      "Processing chunk 4701/45455\n",
      "Processing chunk 4751/45455\n",
      "Processing chunk 4801/45455\n",
      "Processing chunk 4851/45455\n",
      "Processing chunk 4901/45455\n",
      "Processing chunk 4951/45455\n",
      "Processing chunk 5001/45455\n",
      "Processing chunk 5051/45455\n",
      "Processing chunk 5101/45455\n",
      "Processing chunk 5151/45455\n",
      "Processing chunk 5201/45455\n",
      "Processing chunk 5251/45455\n",
      "Processing chunk 5301/45455\n",
      "Processing chunk 5351/45455\n",
      "Processing chunk 5401/45455\n",
      "Processing chunk 5451/45455\n",
      "Processing chunk 5501/45455\n",
      "Processing chunk 5551/45455\n",
      "Processing chunk 5601/45455\n",
      "Processing chunk 5651/45455\n",
      "Processing chunk 5701/45455\n",
      "Processing chunk 5751/45455\n",
      "Processing chunk 5801/45455\n",
      "Processing chunk 5851/45455\n",
      "Processing chunk 5901/45455\n",
      "Processing chunk 5951/45455\n",
      "Processing chunk 6001/45455\n",
      "Processing chunk 6051/45455\n",
      "Processing chunk 6101/45455\n",
      "Processing chunk 6151/45455\n",
      "Processing chunk 6201/45455\n",
      "Processing chunk 6251/45455\n",
      "Processing chunk 6301/45455\n",
      "Processing chunk 6351/45455\n",
      "Processing chunk 6401/45455\n",
      "Processing chunk 6451/45455\n",
      "Processing chunk 6501/45455\n",
      "Processing chunk 6551/45455\n",
      "Processing chunk 6601/45455\n",
      "Processing chunk 6651/45455\n",
      "Processing chunk 6701/45455\n",
      "Processing chunk 6751/45455\n",
      "Processing chunk 6801/45455\n",
      "Processing chunk 6851/45455\n",
      "Processing chunk 6901/45455\n",
      "Processing chunk 6951/45455\n",
      "Processing chunk 7001/45455\n",
      "Processing chunk 7051/45455\n",
      "Processing chunk 7101/45455\n",
      "Processing chunk 7151/45455\n",
      "Processing chunk 7201/45455\n",
      "Processing chunk 7251/45455\n",
      "Processing chunk 7301/45455\n",
      "Processing chunk 7351/45455\n",
      "Processing chunk 7401/45455\n",
      "Processing chunk 7451/45455\n",
      "Processing chunk 7501/45455\n",
      "Processing chunk 7551/45455\n",
      "Processing chunk 7601/45455\n",
      "Processing chunk 7651/45455\n",
      "Processing chunk 7701/45455\n",
      "Processing chunk 7751/45455\n",
      "Processing chunk 7801/45455\n",
      "Processing chunk 7851/45455\n",
      "Processing chunk 7901/45455\n",
      "Processing chunk 7951/45455\n",
      "Processing chunk 8001/45455\n",
      "Processing chunk 8051/45455\n",
      "Processing chunk 8101/45455\n",
      "Processing chunk 8151/45455\n",
      "Processing chunk 8201/45455\n",
      "Processing chunk 8251/45455\n",
      "Processing chunk 8301/45455\n",
      "Processing chunk 8351/45455\n",
      "Processing chunk 8401/45455\n",
      "Processing chunk 8451/45455\n",
      "Processing chunk 8501/45455\n",
      "Processing chunk 8551/45455\n",
      "Processing chunk 8601/45455\n",
      "Processing chunk 8651/45455\n",
      "Processing chunk 8701/45455\n",
      "Processing chunk 8751/45455\n",
      "Processing chunk 8801/45455\n",
      "Processing chunk 8851/45455\n",
      "Processing chunk 8901/45455\n",
      "Processing chunk 8951/45455\n",
      "Processing chunk 9001/45455\n",
      "Processing chunk 9051/45455\n",
      "Processing chunk 9101/45455\n",
      "Processing chunk 9151/45455\n",
      "Processing chunk 9201/45455\n",
      "Processing chunk 9251/45455\n",
      "Processing chunk 9301/45455\n",
      "Processing chunk 9351/45455\n",
      "Processing chunk 9401/45455\n",
      "Processing chunk 9451/45455\n",
      "Processing chunk 9501/45455\n",
      "Processing chunk 9551/45455\n",
      "Processing chunk 9601/45455\n",
      "Processing chunk 9651/45455\n",
      "Processing chunk 9701/45455\n",
      "Processing chunk 9751/45455\n",
      "Processing chunk 9801/45455\n",
      "Processing chunk 9851/45455\n",
      "Processing chunk 9901/45455\n",
      "Processing chunk 9951/45455\n",
      "Processing chunk 10001/45455\n",
      "Processing chunk 10051/45455\n",
      "Processing chunk 10101/45455\n",
      "Processing chunk 10151/45455\n",
      "Processing chunk 10201/45455\n",
      "Processing chunk 10251/45455\n",
      "Processing chunk 10301/45455\n",
      "Processing chunk 10351/45455\n",
      "Processing chunk 10401/45455\n",
      "Processing chunk 10451/45455\n",
      "Processing chunk 10501/45455\n",
      "Processing chunk 10551/45455\n",
      "Processing chunk 10601/45455\n",
      "Processing chunk 10651/45455\n",
      "Processing chunk 10701/45455\n",
      "Processing chunk 10751/45455\n",
      "Processing chunk 10801/45455\n",
      "Processing chunk 10851/45455\n",
      "Processing chunk 10901/45455\n",
      "Processing chunk 10951/45455\n",
      "Processing chunk 11001/45455\n",
      "Processing chunk 11051/45455\n",
      "Processing chunk 11101/45455\n",
      "Processing chunk 11151/45455\n",
      "Processing chunk 11201/45455\n",
      "Processing chunk 11251/45455\n",
      "Processing chunk 11301/45455\n",
      "Processing chunk 11351/45455\n",
      "Processing chunk 11401/45455\n",
      "Processing chunk 11451/45455\n",
      "Processing chunk 11501/45455\n",
      "Processing chunk 11551/45455\n",
      "Processing chunk 11601/45455\n",
      "Processing chunk 11651/45455\n",
      "Processing chunk 11701/45455\n",
      "Processing chunk 11751/45455\n",
      "Processing chunk 11801/45455\n",
      "Processing chunk 11851/45455\n",
      "Processing chunk 11901/45455\n",
      "Processing chunk 11951/45455\n",
      "Processing chunk 12001/45455\n",
      "Processing chunk 12051/45455\n",
      "Processing chunk 12101/45455\n",
      "Processing chunk 12151/45455\n",
      "Processing chunk 12201/45455\n",
      "Processing chunk 12251/45455\n",
      "Processing chunk 12301/45455\n",
      "Processing chunk 12351/45455\n",
      "Processing chunk 12401/45455\n",
      "Processing chunk 12451/45455\n",
      "Processing chunk 12501/45455\n",
      "Processing chunk 12551/45455\n",
      "Processing chunk 12601/45455\n",
      "Processing chunk 12651/45455\n",
      "Processing chunk 12701/45455\n",
      "Processing chunk 12751/45455\n",
      "Processing chunk 12801/45455\n",
      "Processing chunk 12851/45455\n",
      "Processing chunk 12901/45455\n",
      "Processing chunk 12951/45455\n",
      "Processing chunk 13001/45455\n",
      "Processing chunk 13051/45455\n",
      "Processing chunk 13101/45455\n",
      "Processing chunk 13151/45455\n",
      "Processing chunk 13201/45455\n",
      "Processing chunk 13251/45455\n",
      "Processing chunk 13301/45455\n",
      "Processing chunk 13351/45455\n",
      "Processing chunk 13401/45455\n",
      "Processing chunk 13451/45455\n",
      "Processing chunk 13501/45455\n",
      "Processing chunk 13551/45455\n",
      "Processing chunk 13601/45455\n",
      "Processing chunk 13651/45455\n",
      "Processing chunk 13701/45455\n",
      "Processing chunk 13751/45455\n",
      "Processing chunk 13801/45455\n",
      "Processing chunk 13851/45455\n",
      "Processing chunk 13901/45455\n",
      "Processing chunk 13951/45455\n",
      "Processing chunk 14001/45455\n",
      "Processing chunk 14051/45455\n",
      "Processing chunk 14101/45455\n",
      "Processing chunk 14151/45455\n",
      "Processing chunk 14201/45455\n",
      "Processing chunk 14251/45455\n",
      "Processing chunk 14301/45455\n",
      "Processing chunk 14351/45455\n",
      "Processing chunk 14401/45455\n",
      "Processing chunk 14451/45455\n",
      "Processing chunk 14501/45455\n",
      "Processing chunk 14551/45455\n",
      "Processing chunk 14601/45455\n",
      "Processing chunk 14651/45455\n",
      "Processing chunk 14701/45455\n",
      "Processing chunk 14751/45455\n",
      "Processing chunk 14801/45455\n",
      "Processing chunk 14851/45455\n",
      "Processing chunk 14901/45455\n",
      "Processing chunk 14951/45455\n",
      "Processing chunk 15001/45455\n",
      "Processing chunk 15051/45455\n",
      "Processing chunk 15101/45455\n",
      "Processing chunk 15151/45455\n",
      "Processing chunk 15201/45455\n",
      "Processing chunk 15251/45455\n",
      "Processing chunk 15301/45455\n",
      "Processing chunk 15351/45455\n",
      "Processing chunk 15401/45455\n",
      "Processing chunk 15451/45455\n",
      "Processing chunk 15501/45455\n",
      "Processing chunk 15551/45455\n",
      "Processing chunk 15601/45455\n",
      "Processing chunk 15651/45455\n",
      "Processing chunk 15701/45455\n",
      "Processing chunk 15751/45455\n",
      "Processing chunk 15801/45455\n",
      "Processing chunk 15851/45455\n",
      "Processing chunk 15901/45455\n",
      "Processing chunk 15951/45455\n",
      "Processing chunk 16001/45455\n",
      "Processing chunk 16051/45455\n",
      "Processing chunk 16101/45455\n",
      "Processing chunk 16151/45455\n",
      "Processing chunk 16201/45455\n",
      "Processing chunk 16251/45455\n",
      "Processing chunk 16301/45455\n",
      "Processing chunk 16351/45455\n",
      "Processing chunk 16401/45455\n",
      "Processing chunk 16451/45455\n",
      "Processing chunk 16501/45455\n",
      "Processing chunk 16551/45455\n",
      "Processing chunk 16601/45455\n",
      "Processing chunk 16651/45455\n",
      "Processing chunk 16701/45455\n",
      "Processing chunk 16751/45455\n",
      "Processing chunk 16801/45455\n",
      "Processing chunk 16851/45455\n",
      "Processing chunk 16901/45455\n",
      "Processing chunk 16951/45455\n",
      "Processing chunk 17001/45455\n",
      "Processing chunk 17051/45455\n",
      "Processing chunk 17101/45455\n",
      "Processing chunk 17151/45455\n",
      "Processing chunk 17201/45455\n",
      "Processing chunk 17251/45455\n",
      "Processing chunk 17301/45455\n",
      "Processing chunk 17351/45455\n",
      "Processing chunk 17401/45455\n",
      "Processing chunk 17451/45455\n",
      "Processing chunk 17501/45455\n",
      "Processing chunk 17551/45455\n",
      "Processing chunk 17601/45455\n",
      "Processing chunk 17651/45455\n",
      "Processing chunk 17701/45455\n",
      "Processing chunk 17751/45455\n",
      "Processing chunk 17801/45455\n",
      "Processing chunk 17851/45455\n",
      "Processing chunk 17901/45455\n",
      "Processing chunk 17951/45455\n",
      "Processing chunk 18001/45455\n",
      "Processing chunk 18051/45455\n",
      "Processing chunk 18101/45455\n",
      "Processing chunk 18151/45455\n",
      "Processing chunk 18201/45455\n",
      "Processing chunk 18251/45455\n",
      "Processing chunk 18301/45455\n",
      "Processing chunk 18351/45455\n",
      "Processing chunk 18401/45455\n",
      "Processing chunk 18451/45455\n",
      "Processing chunk 18501/45455\n",
      "Processing chunk 18551/45455\n",
      "Processing chunk 18601/45455\n",
      "Processing chunk 18651/45455\n",
      "Processing chunk 18701/45455\n",
      "Processing chunk 18751/45455\n",
      "Processing chunk 18801/45455\n",
      "Processing chunk 18851/45455\n",
      "Processing chunk 18901/45455\n",
      "Processing chunk 18951/45455\n",
      "Processing chunk 19001/45455\n",
      "Processing chunk 19051/45455\n",
      "Processing chunk 19101/45455\n",
      "Processing chunk 19151/45455\n",
      "Processing chunk 19201/45455\n",
      "Processing chunk 19251/45455\n",
      "Processing chunk 19301/45455\n",
      "Processing chunk 19351/45455\n",
      "Processing chunk 19401/45455\n",
      "Processing chunk 19451/45455\n",
      "Processing chunk 19501/45455\n",
      "Processing chunk 19551/45455\n",
      "Processing chunk 19601/45455\n",
      "Processing chunk 19651/45455\n",
      "Processing chunk 19701/45455\n",
      "Processing chunk 19751/45455\n",
      "Processing chunk 19801/45455\n",
      "Processing chunk 19851/45455\n",
      "Processing chunk 19901/45455\n",
      "Processing chunk 19951/45455\n",
      "Processing chunk 20001/45455\n",
      "Processing chunk 20051/45455\n",
      "Processing chunk 20101/45455\n",
      "Processing chunk 20151/45455\n",
      "Processing chunk 20201/45455\n",
      "Processing chunk 20251/45455\n",
      "Processing chunk 20301/45455\n",
      "Processing chunk 20351/45455\n",
      "Processing chunk 20401/45455\n",
      "Processing chunk 20451/45455\n",
      "Processing chunk 20501/45455\n",
      "Processing chunk 20551/45455\n",
      "Processing chunk 20601/45455\n",
      "Processing chunk 20651/45455\n",
      "Processing chunk 20701/45455\n",
      "Processing chunk 20751/45455\n",
      "Processing chunk 20801/45455\n",
      "Processing chunk 20851/45455\n",
      "Processing chunk 20901/45455\n",
      "Processing chunk 20951/45455\n",
      "Processing chunk 21001/45455\n",
      "Processing chunk 21051/45455\n",
      "Processing chunk 21101/45455\n",
      "Processing chunk 21151/45455\n",
      "Processing chunk 21201/45455\n",
      "Processing chunk 21251/45455\n",
      "Processing chunk 21301/45455\n",
      "Processing chunk 21351/45455\n",
      "Processing chunk 21401/45455\n",
      "Processing chunk 21451/45455\n",
      "Processing chunk 21501/45455\n",
      "Processing chunk 21551/45455\n",
      "Processing chunk 21601/45455\n",
      "Processing chunk 21651/45455\n",
      "Processing chunk 21701/45455\n",
      "Processing chunk 21751/45455\n",
      "Processing chunk 21801/45455\n",
      "Processing chunk 21851/45455\n",
      "Processing chunk 21901/45455\n",
      "Processing chunk 21951/45455\n",
      "Processing chunk 22001/45455\n",
      "Processing chunk 22051/45455\n",
      "Processing chunk 22101/45455\n",
      "Processing chunk 22151/45455\n",
      "Processing chunk 22201/45455\n",
      "Processing chunk 22251/45455\n",
      "Processing chunk 22301/45455\n",
      "Processing chunk 22351/45455\n",
      "Processing chunk 22401/45455\n",
      "Processing chunk 22451/45455\n",
      "Processing chunk 22501/45455\n",
      "Processing chunk 22551/45455\n",
      "Processing chunk 22601/45455\n",
      "Processing chunk 22651/45455\n",
      "Processing chunk 22701/45455\n",
      "Processing chunk 22751/45455\n",
      "Processing chunk 22801/45455\n",
      "Processing chunk 22851/45455\n",
      "Processing chunk 22901/45455\n",
      "Processing chunk 22951/45455\n",
      "Processing chunk 23001/45455\n",
      "Processing chunk 23051/45455\n",
      "Processing chunk 23101/45455\n",
      "Processing chunk 23151/45455\n",
      "Processing chunk 23201/45455\n",
      "Processing chunk 23251/45455\n",
      "Processing chunk 23301/45455\n",
      "Processing chunk 23351/45455\n",
      "Processing chunk 23401/45455\n",
      "Processing chunk 23451/45455\n",
      "Processing chunk 23501/45455\n",
      "Processing chunk 23551/45455\n",
      "Processing chunk 23601/45455\n",
      "Processing chunk 23651/45455\n",
      "Processing chunk 23701/45455\n",
      "Processing chunk 23751/45455\n",
      "Processing chunk 23801/45455\n",
      "Processing chunk 23851/45455\n",
      "Processing chunk 23901/45455\n",
      "Processing chunk 23951/45455\n",
      "Processing chunk 24001/45455\n",
      "Processing chunk 24051/45455\n",
      "Processing chunk 24101/45455\n",
      "Processing chunk 24151/45455\n",
      "Processing chunk 24201/45455\n",
      "Processing chunk 24251/45455\n",
      "Processing chunk 24301/45455\n",
      "Processing chunk 24351/45455\n",
      "Processing chunk 24401/45455\n",
      "Processing chunk 24451/45455\n",
      "Processing chunk 24501/45455\n",
      "Processing chunk 24551/45455\n",
      "Processing chunk 24601/45455\n",
      "Processing chunk 24651/45455\n",
      "Processing chunk 24701/45455\n",
      "Processing chunk 24751/45455\n",
      "Processing chunk 24801/45455\n",
      "Processing chunk 24851/45455\n",
      "Processing chunk 24901/45455\n",
      "Processing chunk 24951/45455\n",
      "Processing chunk 25001/45455\n",
      "Processing chunk 25051/45455\n",
      "Processing chunk 25101/45455\n",
      "Processing chunk 25151/45455\n",
      "Processing chunk 25201/45455\n",
      "Processing chunk 25251/45455\n",
      "Processing chunk 25301/45455\n",
      "Processing chunk 25351/45455\n",
      "Processing chunk 25401/45455\n",
      "Processing chunk 25451/45455\n",
      "Processing chunk 25501/45455\n",
      "Processing chunk 25551/45455\n",
      "Processing chunk 25601/45455\n",
      "Processing chunk 25651/45455\n",
      "Processing chunk 25701/45455\n",
      "Processing chunk 25751/45455\n",
      "Processing chunk 25801/45455\n",
      "Processing chunk 25851/45455\n",
      "Processing chunk 25901/45455\n",
      "Processing chunk 25951/45455\n",
      "Processing chunk 26001/45455\n",
      "Processing chunk 26051/45455\n",
      "Processing chunk 26101/45455\n",
      "Processing chunk 26151/45455\n",
      "Processing chunk 26201/45455\n",
      "Processing chunk 26251/45455\n",
      "Processing chunk 26301/45455\n",
      "Processing chunk 26351/45455\n",
      "Processing chunk 26401/45455\n",
      "Processing chunk 26451/45455\n",
      "Processing chunk 26501/45455\n",
      "Processing chunk 26551/45455\n",
      "Processing chunk 26601/45455\n",
      "Processing chunk 26651/45455\n",
      "Processing chunk 26701/45455\n",
      "Processing chunk 26751/45455\n",
      "Processing chunk 26801/45455\n",
      "Processing chunk 26851/45455\n",
      "Processing chunk 26901/45455\n",
      "Processing chunk 26951/45455\n",
      "Processing chunk 27001/45455\n",
      "Processing chunk 27051/45455\n",
      "Processing chunk 27101/45455\n",
      "Processing chunk 27151/45455\n",
      "Processing chunk 27201/45455\n",
      "Processing chunk 27251/45455\n",
      "Processing chunk 27301/45455\n",
      "Processing chunk 27351/45455\n",
      "Processing chunk 27401/45455\n",
      "Processing chunk 27451/45455\n",
      "Processing chunk 27501/45455\n",
      "Processing chunk 27551/45455\n",
      "Processing chunk 27601/45455\n",
      "Processing chunk 27651/45455\n",
      "Processing chunk 27701/45455\n",
      "Processing chunk 27751/45455\n",
      "Processing chunk 27801/45455\n",
      "Processing chunk 27851/45455\n",
      "Processing chunk 27901/45455\n",
      "Processing chunk 27951/45455\n",
      "Processing chunk 28001/45455\n",
      "Processing chunk 28051/45455\n",
      "Processing chunk 28101/45455\n",
      "Processing chunk 28151/45455\n",
      "Processing chunk 28201/45455\n",
      "Processing chunk 28251/45455\n",
      "Processing chunk 28301/45455\n",
      "Processing chunk 28351/45455\n",
      "Processing chunk 28401/45455\n",
      "Processing chunk 28451/45455\n",
      "Processing chunk 28501/45455\n",
      "Processing chunk 28551/45455\n",
      "Processing chunk 28601/45455\n",
      "Processing chunk 28651/45455\n",
      "Processing chunk 28701/45455\n",
      "Processing chunk 28751/45455\n",
      "Processing chunk 28801/45455\n",
      "Processing chunk 28851/45455\n",
      "Processing chunk 28901/45455\n",
      "Processing chunk 28951/45455\n",
      "Processing chunk 29001/45455\n",
      "Processing chunk 29051/45455\n",
      "Processing chunk 29101/45455\n",
      "Processing chunk 29151/45455\n",
      "Processing chunk 29201/45455\n",
      "Processing chunk 29251/45455\n",
      "Processing chunk 29301/45455\n",
      "Processing chunk 29351/45455\n",
      "Processing chunk 29401/45455\n",
      "Processing chunk 29451/45455\n",
      "Processing chunk 29501/45455\n",
      "Processing chunk 29551/45455\n",
      "Processing chunk 29601/45455\n",
      "Processing chunk 29651/45455\n",
      "Processing chunk 29701/45455\n",
      "Processing chunk 29751/45455\n",
      "Processing chunk 29801/45455\n",
      "Processing chunk 29851/45455\n",
      "Processing chunk 29901/45455\n",
      "Processing chunk 29951/45455\n",
      "Processing chunk 30001/45455\n",
      "Processing chunk 30051/45455\n",
      "Processing chunk 30101/45455\n",
      "Processing chunk 30151/45455\n",
      "Processing chunk 30201/45455\n",
      "Processing chunk 30251/45455\n",
      "Processing chunk 30301/45455\n",
      "Processing chunk 30351/45455\n",
      "Processing chunk 30401/45455\n",
      "Processing chunk 30451/45455\n",
      "Processing chunk 30501/45455\n",
      "Processing chunk 30551/45455\n",
      "Processing chunk 30601/45455\n",
      "Processing chunk 30651/45455\n",
      "Processing chunk 30701/45455\n",
      "Processing chunk 30751/45455\n",
      "Processing chunk 30801/45455\n",
      "Processing chunk 30851/45455\n",
      "Processing chunk 30901/45455\n",
      "Processing chunk 30951/45455\n",
      "Processing chunk 31001/45455\n",
      "Processing chunk 31051/45455\n",
      "Processing chunk 31101/45455\n",
      "Processing chunk 31151/45455\n",
      "Processing chunk 31201/45455\n",
      "Processing chunk 31251/45455\n",
      "Processing chunk 31301/45455\n",
      "Processing chunk 31351/45455\n",
      "Processing chunk 31401/45455\n",
      "Processing chunk 31451/45455\n",
      "Processing chunk 31501/45455\n",
      "Processing chunk 31551/45455\n",
      "Processing chunk 31601/45455\n",
      "Processing chunk 31651/45455\n",
      "Processing chunk 31701/45455\n",
      "Processing chunk 31751/45455\n",
      "Processing chunk 31801/45455\n",
      "Processing chunk 31851/45455\n",
      "Processing chunk 31901/45455\n",
      "Processing chunk 31951/45455\n",
      "Processing chunk 32001/45455\n",
      "Processing chunk 32051/45455\n",
      "Processing chunk 32101/45455\n",
      "Processing chunk 32151/45455\n",
      "Processing chunk 32201/45455\n",
      "Processing chunk 32251/45455\n",
      "Processing chunk 32301/45455\n",
      "Processing chunk 32351/45455\n",
      "Processing chunk 32401/45455\n",
      "Processing chunk 32451/45455\n",
      "Processing chunk 32501/45455\n",
      "Processing chunk 32551/45455\n",
      "Processing chunk 32601/45455\n",
      "Processing chunk 32651/45455\n",
      "Processing chunk 32701/45455\n",
      "Processing chunk 32751/45455\n",
      "Processing chunk 32801/45455\n",
      "Processing chunk 32851/45455\n",
      "Processing chunk 32901/45455\n",
      "Processing chunk 32951/45455\n",
      "Processing chunk 33001/45455\n",
      "Processing chunk 33051/45455\n",
      "Processing chunk 33101/45455\n",
      "Processing chunk 33151/45455\n",
      "Processing chunk 33201/45455\n",
      "Processing chunk 33251/45455\n",
      "Processing chunk 33301/45455\n",
      "Processing chunk 33351/45455\n",
      "Processing chunk 33401/45455\n",
      "Processing chunk 33451/45455\n",
      "Processing chunk 33501/45455\n",
      "Processing chunk 33551/45455\n",
      "Processing chunk 33601/45455\n",
      "Processing chunk 33651/45455\n",
      "Processing chunk 33701/45455\n",
      "Processing chunk 33751/45455\n",
      "Processing chunk 33801/45455\n",
      "Processing chunk 33851/45455\n",
      "Processing chunk 33901/45455\n",
      "Processing chunk 33951/45455\n",
      "Processing chunk 34001/45455\n",
      "Processing chunk 34051/45455\n",
      "Processing chunk 34101/45455\n",
      "Processing chunk 34151/45455\n",
      "Processing chunk 34201/45455\n",
      "Processing chunk 34251/45455\n",
      "Processing chunk 34301/45455\n",
      "Processing chunk 34351/45455\n",
      "Processing chunk 34401/45455\n",
      "Processing chunk 34451/45455\n",
      "Processing chunk 34501/45455\n",
      "Processing chunk 34551/45455\n",
      "Processing chunk 34601/45455\n",
      "Processing chunk 34651/45455\n",
      "Processing chunk 34701/45455\n",
      "Processing chunk 34751/45455\n",
      "Processing chunk 34801/45455\n",
      "Processing chunk 34851/45455\n",
      "Processing chunk 34901/45455\n",
      "Processing chunk 34951/45455\n",
      "Processing chunk 35001/45455\n",
      "Processing chunk 35051/45455\n",
      "Processing chunk 35101/45455\n",
      "Processing chunk 35151/45455\n",
      "Processing chunk 35201/45455\n",
      "Processing chunk 35251/45455\n",
      "Processing chunk 35301/45455\n",
      "Processing chunk 35351/45455\n",
      "Processing chunk 35401/45455\n",
      "Processing chunk 35451/45455\n",
      "Processing chunk 35501/45455\n",
      "Processing chunk 35551/45455\n",
      "Processing chunk 35601/45455\n",
      "Processing chunk 35651/45455\n",
      "Processing chunk 35701/45455\n",
      "Processing chunk 35751/45455\n",
      "Processing chunk 35801/45455\n",
      "Processing chunk 35851/45455\n",
      "Processing chunk 35901/45455\n",
      "Processing chunk 35951/45455\n",
      "Processing chunk 36001/45455\n",
      "Processing chunk 36051/45455\n",
      "Processing chunk 36101/45455\n",
      "Processing chunk 36151/45455\n",
      "Processing chunk 36201/45455\n",
      "Processing chunk 36251/45455\n",
      "Processing chunk 36301/45455\n",
      "Processing chunk 36351/45455\n",
      "Processing chunk 36401/45455\n",
      "Processing chunk 36451/45455\n",
      "Processing chunk 36501/45455\n",
      "Processing chunk 36551/45455\n",
      "Processing chunk 36601/45455\n",
      "Processing chunk 36651/45455\n",
      "Processing chunk 36701/45455\n",
      "Processing chunk 36751/45455\n",
      "Processing chunk 36801/45455\n",
      "Processing chunk 36851/45455\n",
      "Processing chunk 36901/45455\n",
      "Processing chunk 36951/45455\n",
      "Processing chunk 37001/45455\n",
      "Processing chunk 37051/45455\n",
      "Processing chunk 37101/45455\n",
      "Processing chunk 37151/45455\n",
      "Processing chunk 37201/45455\n",
      "Processing chunk 37251/45455\n",
      "Processing chunk 37301/45455\n",
      "Processing chunk 37351/45455\n",
      "Processing chunk 37401/45455\n",
      "Processing chunk 37451/45455\n",
      "Processing chunk 37501/45455\n",
      "Processing chunk 37551/45455\n",
      "Processing chunk 37601/45455\n",
      "Processing chunk 37651/45455\n",
      "Processing chunk 37701/45455\n",
      "Processing chunk 37751/45455\n",
      "Processing chunk 37801/45455\n",
      "Processing chunk 37851/45455\n",
      "Processing chunk 37901/45455\n",
      "Processing chunk 37951/45455\n",
      "Processing chunk 38001/45455\n",
      "Processing chunk 38051/45455\n",
      "Processing chunk 38101/45455\n",
      "Processing chunk 38151/45455\n",
      "Processing chunk 38201/45455\n",
      "Processing chunk 38251/45455\n",
      "Processing chunk 38301/45455\n",
      "Processing chunk 38351/45455\n",
      "Processing chunk 38401/45455\n",
      "Processing chunk 38451/45455\n",
      "Processing chunk 38501/45455\n",
      "Processing chunk 38551/45455\n",
      "Processing chunk 38601/45455\n",
      "Processing chunk 38651/45455\n",
      "Processing chunk 38701/45455\n",
      "Processing chunk 38751/45455\n",
      "Processing chunk 38801/45455\n",
      "Processing chunk 38851/45455\n",
      "Processing chunk 38901/45455\n",
      "Processing chunk 38951/45455\n",
      "Processing chunk 39001/45455\n",
      "Processing chunk 39051/45455\n",
      "Processing chunk 39101/45455\n",
      "Processing chunk 39151/45455\n",
      "Processing chunk 39201/45455\n",
      "Processing chunk 39251/45455\n",
      "Processing chunk 39301/45455\n",
      "Processing chunk 39351/45455\n",
      "Processing chunk 39401/45455\n",
      "Processing chunk 39451/45455\n",
      "Processing chunk 39501/45455\n",
      "Processing chunk 39551/45455\n",
      "Processing chunk 39601/45455\n",
      "Processing chunk 39651/45455\n",
      "Processing chunk 39701/45455\n",
      "Processing chunk 39751/45455\n",
      "Processing chunk 39801/45455\n",
      "Processing chunk 39851/45455\n",
      "Processing chunk 39901/45455\n",
      "Processing chunk 39951/45455\n",
      "Processing chunk 40001/45455\n",
      "Processing chunk 40051/45455\n",
      "Processing chunk 40101/45455\n",
      "Processing chunk 40151/45455\n",
      "Processing chunk 40201/45455\n",
      "Processing chunk 40251/45455\n",
      "Processing chunk 40301/45455\n",
      "Processing chunk 40351/45455\n",
      "Processing chunk 40401/45455\n",
      "Processing chunk 40451/45455\n",
      "Processing chunk 40501/45455\n",
      "Processing chunk 40551/45455\n",
      "Processing chunk 40601/45455\n",
      "Processing chunk 40651/45455\n",
      "Processing chunk 40701/45455\n",
      "Processing chunk 40751/45455\n",
      "Processing chunk 40801/45455\n",
      "Processing chunk 40851/45455\n",
      "Processing chunk 40901/45455\n",
      "Processing chunk 40951/45455\n",
      "Processing chunk 41001/45455\n",
      "Processing chunk 41051/45455\n",
      "Processing chunk 41101/45455\n",
      "Processing chunk 41151/45455\n",
      "Processing chunk 41201/45455\n",
      "Processing chunk 41251/45455\n",
      "Processing chunk 41301/45455\n",
      "Processing chunk 41351/45455\n",
      "Processing chunk 41401/45455\n",
      "Processing chunk 41451/45455\n",
      "Processing chunk 41501/45455\n",
      "Processing chunk 41551/45455\n",
      "Processing chunk 41601/45455\n",
      "Processing chunk 41651/45455\n",
      "Processing chunk 41701/45455\n",
      "Processing chunk 41751/45455\n",
      "Processing chunk 41801/45455\n",
      "Processing chunk 41851/45455\n",
      "Processing chunk 41901/45455\n",
      "Processing chunk 41951/45455\n",
      "Processing chunk 42001/45455\n",
      "Processing chunk 42051/45455\n",
      "Processing chunk 42101/45455\n",
      "Processing chunk 42151/45455\n",
      "Processing chunk 42201/45455\n",
      "Processing chunk 42251/45455\n",
      "Processing chunk 42301/45455\n",
      "Processing chunk 42351/45455\n",
      "Processing chunk 42401/45455\n",
      "Processing chunk 42451/45455\n",
      "Processing chunk 42501/45455\n",
      "Processing chunk 42551/45455\n",
      "Processing chunk 42601/45455\n",
      "Processing chunk 42651/45455\n",
      "Processing chunk 42701/45455\n",
      "Processing chunk 42751/45455\n",
      "Processing chunk 42801/45455\n",
      "Processing chunk 42851/45455\n",
      "Processing chunk 42901/45455\n",
      "Processing chunk 42951/45455\n",
      "Processing chunk 43001/45455\n",
      "Processing chunk 43051/45455\n",
      "Processing chunk 43101/45455\n",
      "Processing chunk 43151/45455\n",
      "Processing chunk 43201/45455\n",
      "Processing chunk 43251/45455\n",
      "Processing chunk 43301/45455\n",
      "Processing chunk 43351/45455\n",
      "Processing chunk 43401/45455\n",
      "Processing chunk 43451/45455\n",
      "Processing chunk 43501/45455\n",
      "Processing chunk 43551/45455\n",
      "Processing chunk 43601/45455\n",
      "Processing chunk 43651/45455\n",
      "Processing chunk 43701/45455\n",
      "Processing chunk 43751/45455\n",
      "Processing chunk 43801/45455\n",
      "Processing chunk 43851/45455\n",
      "Processing chunk 43901/45455\n",
      "Processing chunk 43951/45455\n",
      "Processing chunk 44001/45455\n",
      "Processing chunk 44051/45455\n",
      "Processing chunk 44101/45455\n",
      "Processing chunk 44151/45455\n",
      "Processing chunk 44201/45455\n",
      "Processing chunk 44251/45455\n",
      "Processing chunk 44301/45455\n",
      "Processing chunk 44351/45455\n",
      "Processing chunk 44401/45455\n",
      "Processing chunk 44451/45455\n",
      "Processing chunk 44501/45455\n",
      "Processing chunk 44551/45455\n",
      "Processing chunk 44601/45455\n",
      "Processing chunk 44651/45455\n",
      "Processing chunk 44701/45455\n",
      "Processing chunk 44751/45455\n",
      "Processing chunk 44801/45455\n",
      "Processing chunk 44851/45455\n",
      "Processing chunk 44901/45455\n",
      "Processing chunk 44951/45455\n",
      "Processing chunk 45001/45455\n",
      "Processing chunk 45051/45455\n",
      "Processing chunk 45101/45455\n",
      "Processing chunk 45151/45455\n",
      "Processing chunk 45201/45455\n",
      "Processing chunk 45251/45455\n",
      "Processing chunk 45301/45455\n",
      "Processing chunk 45351/45455\n",
      "Processing chunk 45401/45455\n",
      "Processing chunk 45451/45455\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 10000\n",
      "Number of hits: 9913\n",
      "Average HR@20: 0.9913\n",
      "Average NDCG@20: 0.4729\n",
      "\n",
      "Training and evaluating NMTR...\n",
      "Epoch 1, Loss: 0.7272\n",
      "Epoch 2, Loss: 0.7046\n",
      "Epoch 3, Loss: 0.6837\n",
      "Epoch 4, Loss: 0.6643\n",
      "Epoch 5, Loss: 0.6463\n",
      "Epoch 6, Loss: 0.6295\n",
      "Epoch 7, Loss: 0.6137\n",
      "Epoch 8, Loss: 0.5987\n",
      "Epoch 9, Loss: 0.5845\n",
      "Epoch 10, Loss: 0.5709\n",
      "Training completed in 1.81s\n",
      "Preparing test instances...\n",
      "Generated 1000000 test instances\n",
      "Evaluating 1000000 instances in 45455 chunks...\n",
      "Processing chunk 1/45455\n",
      "Processing chunk 51/45455\n",
      "Processing chunk 101/45455\n",
      "Processing chunk 151/45455\n",
      "Processing chunk 201/45455\n",
      "Processing chunk 251/45455\n",
      "Processing chunk 301/45455\n",
      "Processing chunk 351/45455\n",
      "Processing chunk 401/45455\n",
      "Processing chunk 451/45455\n",
      "Processing chunk 501/45455\n",
      "Processing chunk 551/45455\n",
      "Processing chunk 601/45455\n",
      "Processing chunk 651/45455\n",
      "Processing chunk 701/45455\n",
      "Processing chunk 751/45455\n",
      "Processing chunk 801/45455\n",
      "Processing chunk 851/45455\n",
      "Processing chunk 901/45455\n",
      "Processing chunk 951/45455\n",
      "Processing chunk 1001/45455\n",
      "Processing chunk 1051/45455\n",
      "Processing chunk 1101/45455\n",
      "Processing chunk 1151/45455\n",
      "Processing chunk 1201/45455\n",
      "Processing chunk 1251/45455\n",
      "Processing chunk 1301/45455\n",
      "Processing chunk 1351/45455\n",
      "Processing chunk 1401/45455\n",
      "Processing chunk 1451/45455\n",
      "Processing chunk 1501/45455\n",
      "Processing chunk 1551/45455\n",
      "Processing chunk 1601/45455\n",
      "Processing chunk 1651/45455\n",
      "Processing chunk 1701/45455\n",
      "Processing chunk 1751/45455\n",
      "Processing chunk 1801/45455\n",
      "Processing chunk 1851/45455\n",
      "Processing chunk 1901/45455\n",
      "Processing chunk 1951/45455\n",
      "Processing chunk 2001/45455\n",
      "Processing chunk 2051/45455\n",
      "Processing chunk 2101/45455\n",
      "Processing chunk 2151/45455\n",
      "Processing chunk 2201/45455\n",
      "Processing chunk 2251/45455\n",
      "Processing chunk 2301/45455\n",
      "Processing chunk 2351/45455\n",
      "Processing chunk 2401/45455\n",
      "Processing chunk 2451/45455\n",
      "Processing chunk 2501/45455\n",
      "Processing chunk 2551/45455\n",
      "Processing chunk 2601/45455\n",
      "Processing chunk 2651/45455\n",
      "Processing chunk 2701/45455\n",
      "Processing chunk 2751/45455\n",
      "Processing chunk 2801/45455\n",
      "Processing chunk 2851/45455\n",
      "Processing chunk 2901/45455\n",
      "Processing chunk 2951/45455\n",
      "Processing chunk 3001/45455\n",
      "Processing chunk 3051/45455\n",
      "Processing chunk 3101/45455\n",
      "Processing chunk 3151/45455\n",
      "Processing chunk 3201/45455\n",
      "Processing chunk 3251/45455\n",
      "Processing chunk 3301/45455\n",
      "Processing chunk 3351/45455\n",
      "Processing chunk 3401/45455\n",
      "Processing chunk 3451/45455\n",
      "Processing chunk 3501/45455\n",
      "Processing chunk 3551/45455\n",
      "Processing chunk 3601/45455\n",
      "Processing chunk 3651/45455\n",
      "Processing chunk 3701/45455\n",
      "Processing chunk 3751/45455\n",
      "Processing chunk 3801/45455\n",
      "Processing chunk 3851/45455\n",
      "Processing chunk 3901/45455\n",
      "Processing chunk 3951/45455\n",
      "Processing chunk 4001/45455\n",
      "Processing chunk 4051/45455\n",
      "Processing chunk 4101/45455\n",
      "Processing chunk 4151/45455\n",
      "Processing chunk 4201/45455\n",
      "Processing chunk 4251/45455\n",
      "Processing chunk 4301/45455\n",
      "Processing chunk 4351/45455\n",
      "Processing chunk 4401/45455\n",
      "Processing chunk 4451/45455\n",
      "Processing chunk 4501/45455\n",
      "Processing chunk 4551/45455\n",
      "Processing chunk 4601/45455\n",
      "Processing chunk 4651/45455\n",
      "Processing chunk 4701/45455\n",
      "Processing chunk 4751/45455\n",
      "Processing chunk 4801/45455\n",
      "Processing chunk 4851/45455\n",
      "Processing chunk 4901/45455\n",
      "Processing chunk 4951/45455\n",
      "Processing chunk 5001/45455\n",
      "Processing chunk 5051/45455\n",
      "Processing chunk 5101/45455\n",
      "Processing chunk 5151/45455\n",
      "Processing chunk 5201/45455\n",
      "Processing chunk 5251/45455\n",
      "Processing chunk 5301/45455\n",
      "Processing chunk 5351/45455\n",
      "Processing chunk 5401/45455\n",
      "Processing chunk 5451/45455\n",
      "Processing chunk 5501/45455\n",
      "Processing chunk 5551/45455\n",
      "Processing chunk 5601/45455\n",
      "Processing chunk 5651/45455\n",
      "Processing chunk 5701/45455\n",
      "Processing chunk 5751/45455\n",
      "Processing chunk 5801/45455\n",
      "Processing chunk 5851/45455\n",
      "Processing chunk 5901/45455\n",
      "Processing chunk 5951/45455\n",
      "Processing chunk 6001/45455\n",
      "Processing chunk 6051/45455\n",
      "Processing chunk 6101/45455\n",
      "Processing chunk 6151/45455\n",
      "Processing chunk 6201/45455\n",
      "Processing chunk 6251/45455\n",
      "Processing chunk 6301/45455\n",
      "Processing chunk 6351/45455\n",
      "Processing chunk 6401/45455\n",
      "Processing chunk 6451/45455\n",
      "Processing chunk 6501/45455\n",
      "Processing chunk 6551/45455\n",
      "Processing chunk 6601/45455\n",
      "Processing chunk 6651/45455\n",
      "Processing chunk 6701/45455\n",
      "Processing chunk 6751/45455\n",
      "Processing chunk 6801/45455\n",
      "Processing chunk 6851/45455\n",
      "Processing chunk 6901/45455\n",
      "Processing chunk 6951/45455\n",
      "Processing chunk 7001/45455\n",
      "Processing chunk 7051/45455\n",
      "Processing chunk 7101/45455\n",
      "Processing chunk 7151/45455\n",
      "Processing chunk 7201/45455\n",
      "Processing chunk 7251/45455\n",
      "Processing chunk 7301/45455\n",
      "Processing chunk 7351/45455\n",
      "Processing chunk 7401/45455\n",
      "Processing chunk 7451/45455\n",
      "Processing chunk 7501/45455\n",
      "Processing chunk 7551/45455\n",
      "Processing chunk 7601/45455\n",
      "Processing chunk 7651/45455\n",
      "Processing chunk 7701/45455\n",
      "Processing chunk 7751/45455\n",
      "Processing chunk 7801/45455\n",
      "Processing chunk 7851/45455\n",
      "Processing chunk 7901/45455\n",
      "Processing chunk 7951/45455\n",
      "Processing chunk 8001/45455\n",
      "Processing chunk 8051/45455\n",
      "Processing chunk 8101/45455\n",
      "Processing chunk 8151/45455\n",
      "Processing chunk 8201/45455\n",
      "Processing chunk 8251/45455\n",
      "Processing chunk 8301/45455\n",
      "Processing chunk 8351/45455\n",
      "Processing chunk 8401/45455\n",
      "Processing chunk 8451/45455\n",
      "Processing chunk 8501/45455\n",
      "Processing chunk 8551/45455\n",
      "Processing chunk 8601/45455\n",
      "Processing chunk 8651/45455\n",
      "Processing chunk 8701/45455\n",
      "Processing chunk 8751/45455\n",
      "Processing chunk 8801/45455\n",
      "Processing chunk 8851/45455\n",
      "Processing chunk 8901/45455\n",
      "Processing chunk 8951/45455\n",
      "Processing chunk 9001/45455\n",
      "Processing chunk 9051/45455\n",
      "Processing chunk 9101/45455\n",
      "Processing chunk 9151/45455\n",
      "Processing chunk 9201/45455\n",
      "Processing chunk 9251/45455\n",
      "Processing chunk 9301/45455\n",
      "Processing chunk 9351/45455\n",
      "Processing chunk 9401/45455\n",
      "Processing chunk 9451/45455\n",
      "Processing chunk 9501/45455\n",
      "Processing chunk 9551/45455\n",
      "Processing chunk 9601/45455\n",
      "Processing chunk 9651/45455\n",
      "Processing chunk 9701/45455\n",
      "Processing chunk 9751/45455\n",
      "Processing chunk 9801/45455\n",
      "Processing chunk 9851/45455\n",
      "Processing chunk 9901/45455\n",
      "Processing chunk 9951/45455\n",
      "Processing chunk 10001/45455\n",
      "Processing chunk 10051/45455\n",
      "Processing chunk 10101/45455\n",
      "Processing chunk 10151/45455\n",
      "Processing chunk 10201/45455\n",
      "Processing chunk 10251/45455\n",
      "Processing chunk 10301/45455\n",
      "Processing chunk 10351/45455\n",
      "Processing chunk 10401/45455\n",
      "Processing chunk 10451/45455\n",
      "Processing chunk 10501/45455\n",
      "Processing chunk 10551/45455\n",
      "Processing chunk 10601/45455\n",
      "Processing chunk 10651/45455\n",
      "Processing chunk 10701/45455\n",
      "Processing chunk 10751/45455\n",
      "Processing chunk 10801/45455\n",
      "Processing chunk 10851/45455\n",
      "Processing chunk 10901/45455\n",
      "Processing chunk 10951/45455\n",
      "Processing chunk 11001/45455\n",
      "Processing chunk 11051/45455\n",
      "Processing chunk 11101/45455\n",
      "Processing chunk 11151/45455\n",
      "Processing chunk 11201/45455\n",
      "Processing chunk 11251/45455\n",
      "Processing chunk 11301/45455\n",
      "Processing chunk 11351/45455\n",
      "Processing chunk 11401/45455\n",
      "Processing chunk 11451/45455\n",
      "Processing chunk 11501/45455\n",
      "Processing chunk 11551/45455\n",
      "Processing chunk 11601/45455\n",
      "Processing chunk 11651/45455\n",
      "Processing chunk 11701/45455\n",
      "Processing chunk 11751/45455\n",
      "Processing chunk 11801/45455\n",
      "Processing chunk 11851/45455\n",
      "Processing chunk 11901/45455\n",
      "Processing chunk 11951/45455\n",
      "Processing chunk 12001/45455\n",
      "Processing chunk 12051/45455\n",
      "Processing chunk 12101/45455\n",
      "Processing chunk 12151/45455\n",
      "Processing chunk 12201/45455\n",
      "Processing chunk 12251/45455\n",
      "Processing chunk 12301/45455\n",
      "Processing chunk 12351/45455\n",
      "Processing chunk 12401/45455\n",
      "Processing chunk 12451/45455\n",
      "Processing chunk 12501/45455\n",
      "Processing chunk 12551/45455\n",
      "Processing chunk 12601/45455\n",
      "Processing chunk 12651/45455\n",
      "Processing chunk 12701/45455\n",
      "Processing chunk 12751/45455\n",
      "Processing chunk 12801/45455\n",
      "Processing chunk 12851/45455\n",
      "Processing chunk 12901/45455\n",
      "Processing chunk 12951/45455\n",
      "Processing chunk 13001/45455\n",
      "Processing chunk 13051/45455\n",
      "Processing chunk 13101/45455\n",
      "Processing chunk 13151/45455\n",
      "Processing chunk 13201/45455\n",
      "Processing chunk 13251/45455\n",
      "Processing chunk 13301/45455\n",
      "Processing chunk 13351/45455\n",
      "Processing chunk 13401/45455\n",
      "Processing chunk 13451/45455\n",
      "Processing chunk 13501/45455\n",
      "Processing chunk 13551/45455\n",
      "Processing chunk 13601/45455\n",
      "Processing chunk 13651/45455\n",
      "Processing chunk 13701/45455\n",
      "Processing chunk 13751/45455\n",
      "Processing chunk 13801/45455\n",
      "Processing chunk 13851/45455\n",
      "Processing chunk 13901/45455\n",
      "Processing chunk 13951/45455\n",
      "Processing chunk 14001/45455\n",
      "Processing chunk 14051/45455\n",
      "Processing chunk 14101/45455\n",
      "Processing chunk 14151/45455\n",
      "Processing chunk 14201/45455\n",
      "Processing chunk 14251/45455\n",
      "Processing chunk 14301/45455\n",
      "Processing chunk 14351/45455\n",
      "Processing chunk 14401/45455\n",
      "Processing chunk 14451/45455\n",
      "Processing chunk 14501/45455\n",
      "Processing chunk 14551/45455\n",
      "Processing chunk 14601/45455\n",
      "Processing chunk 14651/45455\n",
      "Processing chunk 14701/45455\n",
      "Processing chunk 14751/45455\n",
      "Processing chunk 14801/45455\n",
      "Processing chunk 14851/45455\n",
      "Processing chunk 14901/45455\n",
      "Processing chunk 14951/45455\n",
      "Processing chunk 15001/45455\n",
      "Processing chunk 15051/45455\n",
      "Processing chunk 15101/45455\n",
      "Processing chunk 15151/45455\n",
      "Processing chunk 15201/45455\n",
      "Processing chunk 15251/45455\n",
      "Processing chunk 15301/45455\n",
      "Processing chunk 15351/45455\n",
      "Processing chunk 15401/45455\n",
      "Processing chunk 15451/45455\n",
      "Processing chunk 15501/45455\n",
      "Processing chunk 15551/45455\n",
      "Processing chunk 15601/45455\n",
      "Processing chunk 15651/45455\n",
      "Processing chunk 15701/45455\n",
      "Processing chunk 15751/45455\n",
      "Processing chunk 15801/45455\n",
      "Processing chunk 15851/45455\n",
      "Processing chunk 15901/45455\n",
      "Processing chunk 15951/45455\n",
      "Processing chunk 16001/45455\n",
      "Processing chunk 16051/45455\n",
      "Processing chunk 16101/45455\n",
      "Processing chunk 16151/45455\n",
      "Processing chunk 16201/45455\n",
      "Processing chunk 16251/45455\n",
      "Processing chunk 16301/45455\n",
      "Processing chunk 16351/45455\n",
      "Processing chunk 16401/45455\n",
      "Processing chunk 16451/45455\n",
      "Processing chunk 16501/45455\n",
      "Processing chunk 16551/45455\n",
      "Processing chunk 16601/45455\n",
      "Processing chunk 16651/45455\n",
      "Processing chunk 16701/45455\n",
      "Processing chunk 16751/45455\n",
      "Processing chunk 16801/45455\n",
      "Processing chunk 16851/45455\n",
      "Processing chunk 16901/45455\n",
      "Processing chunk 16951/45455\n",
      "Processing chunk 17001/45455\n",
      "Processing chunk 17051/45455\n",
      "Processing chunk 17101/45455\n",
      "Processing chunk 17151/45455\n",
      "Processing chunk 17201/45455\n",
      "Processing chunk 17251/45455\n",
      "Processing chunk 17301/45455\n",
      "Processing chunk 17351/45455\n",
      "Processing chunk 17401/45455\n",
      "Processing chunk 17451/45455\n",
      "Processing chunk 17501/45455\n",
      "Processing chunk 17551/45455\n",
      "Processing chunk 17601/45455\n",
      "Processing chunk 17651/45455\n",
      "Processing chunk 17701/45455\n",
      "Processing chunk 17751/45455\n",
      "Processing chunk 17801/45455\n",
      "Processing chunk 17851/45455\n",
      "Processing chunk 17901/45455\n",
      "Processing chunk 17951/45455\n",
      "Processing chunk 18001/45455\n",
      "Processing chunk 18051/45455\n",
      "Processing chunk 18101/45455\n",
      "Processing chunk 18151/45455\n",
      "Processing chunk 18201/45455\n",
      "Processing chunk 18251/45455\n",
      "Processing chunk 18301/45455\n",
      "Processing chunk 18351/45455\n",
      "Processing chunk 18401/45455\n",
      "Processing chunk 18451/45455\n",
      "Processing chunk 18501/45455\n",
      "Processing chunk 18551/45455\n",
      "Processing chunk 18601/45455\n",
      "Processing chunk 18651/45455\n",
      "Processing chunk 18701/45455\n",
      "Processing chunk 18751/45455\n",
      "Processing chunk 18801/45455\n",
      "Processing chunk 18851/45455\n",
      "Processing chunk 18901/45455\n",
      "Processing chunk 18951/45455\n",
      "Processing chunk 19001/45455\n",
      "Processing chunk 19051/45455\n",
      "Processing chunk 19101/45455\n",
      "Processing chunk 19151/45455\n",
      "Processing chunk 19201/45455\n",
      "Processing chunk 19251/45455\n",
      "Processing chunk 19301/45455\n",
      "Processing chunk 19351/45455\n",
      "Processing chunk 19401/45455\n",
      "Processing chunk 19451/45455\n",
      "Processing chunk 19501/45455\n",
      "Processing chunk 19551/45455\n",
      "Processing chunk 19601/45455\n",
      "Processing chunk 19651/45455\n",
      "Processing chunk 19701/45455\n",
      "Processing chunk 19751/45455\n",
      "Processing chunk 19801/45455\n",
      "Processing chunk 19851/45455\n",
      "Processing chunk 19901/45455\n",
      "Processing chunk 19951/45455\n",
      "Processing chunk 20001/45455\n",
      "Processing chunk 20051/45455\n",
      "Processing chunk 20101/45455\n",
      "Processing chunk 20151/45455\n",
      "Processing chunk 20201/45455\n",
      "Processing chunk 20251/45455\n",
      "Processing chunk 20301/45455\n",
      "Processing chunk 20351/45455\n",
      "Processing chunk 20401/45455\n",
      "Processing chunk 20451/45455\n",
      "Processing chunk 20501/45455\n",
      "Processing chunk 20551/45455\n",
      "Processing chunk 20601/45455\n",
      "Processing chunk 20651/45455\n",
      "Processing chunk 20701/45455\n",
      "Processing chunk 20751/45455\n",
      "Processing chunk 20801/45455\n",
      "Processing chunk 20851/45455\n",
      "Processing chunk 20901/45455\n",
      "Processing chunk 20951/45455\n",
      "Processing chunk 21001/45455\n",
      "Processing chunk 21051/45455\n",
      "Processing chunk 21101/45455\n",
      "Processing chunk 21151/45455\n",
      "Processing chunk 21201/45455\n",
      "Processing chunk 21251/45455\n",
      "Processing chunk 21301/45455\n",
      "Processing chunk 21351/45455\n",
      "Processing chunk 21401/45455\n",
      "Processing chunk 21451/45455\n",
      "Processing chunk 21501/45455\n",
      "Processing chunk 21551/45455\n",
      "Processing chunk 21601/45455\n",
      "Processing chunk 21651/45455\n",
      "Processing chunk 21701/45455\n",
      "Processing chunk 21751/45455\n",
      "Processing chunk 21801/45455\n",
      "Processing chunk 21851/45455\n",
      "Processing chunk 21901/45455\n",
      "Processing chunk 21951/45455\n",
      "Processing chunk 22001/45455\n",
      "Processing chunk 22051/45455\n",
      "Processing chunk 22101/45455\n",
      "Processing chunk 22151/45455\n",
      "Processing chunk 22201/45455\n",
      "Processing chunk 22251/45455\n",
      "Processing chunk 22301/45455\n",
      "Processing chunk 22351/45455\n",
      "Processing chunk 22401/45455\n",
      "Processing chunk 22451/45455\n",
      "Processing chunk 22501/45455\n",
      "Processing chunk 22551/45455\n",
      "Processing chunk 22601/45455\n",
      "Processing chunk 22651/45455\n",
      "Processing chunk 22701/45455\n",
      "Processing chunk 22751/45455\n",
      "Processing chunk 22801/45455\n",
      "Processing chunk 22851/45455\n",
      "Processing chunk 22901/45455\n",
      "Processing chunk 22951/45455\n",
      "Processing chunk 23001/45455\n",
      "Processing chunk 23051/45455\n",
      "Processing chunk 23101/45455\n",
      "Processing chunk 23151/45455\n",
      "Processing chunk 23201/45455\n",
      "Processing chunk 23251/45455\n",
      "Processing chunk 23301/45455\n",
      "Processing chunk 23351/45455\n",
      "Processing chunk 23401/45455\n",
      "Processing chunk 23451/45455\n",
      "Processing chunk 23501/45455\n",
      "Processing chunk 23551/45455\n",
      "Processing chunk 23601/45455\n",
      "Processing chunk 23651/45455\n",
      "Processing chunk 23701/45455\n",
      "Processing chunk 23751/45455\n",
      "Processing chunk 23801/45455\n",
      "Processing chunk 23851/45455\n",
      "Processing chunk 23901/45455\n",
      "Processing chunk 23951/45455\n",
      "Processing chunk 24001/45455\n",
      "Processing chunk 24051/45455\n",
      "Processing chunk 24101/45455\n",
      "Processing chunk 24151/45455\n",
      "Processing chunk 24201/45455\n",
      "Processing chunk 24251/45455\n",
      "Processing chunk 24301/45455\n",
      "Processing chunk 24351/45455\n",
      "Processing chunk 24401/45455\n",
      "Processing chunk 24451/45455\n",
      "Processing chunk 24501/45455\n",
      "Processing chunk 24551/45455\n",
      "Processing chunk 24601/45455\n",
      "Processing chunk 24651/45455\n",
      "Processing chunk 24701/45455\n",
      "Processing chunk 24751/45455\n",
      "Processing chunk 24801/45455\n",
      "Processing chunk 24851/45455\n",
      "Processing chunk 24901/45455\n",
      "Processing chunk 24951/45455\n",
      "Processing chunk 25001/45455\n",
      "Processing chunk 25051/45455\n",
      "Processing chunk 25101/45455\n",
      "Processing chunk 25151/45455\n",
      "Processing chunk 25201/45455\n",
      "Processing chunk 25251/45455\n",
      "Processing chunk 25301/45455\n",
      "Processing chunk 25351/45455\n",
      "Processing chunk 25401/45455\n",
      "Processing chunk 25451/45455\n",
      "Processing chunk 25501/45455\n",
      "Processing chunk 25551/45455\n",
      "Processing chunk 25601/45455\n",
      "Processing chunk 25651/45455\n",
      "Processing chunk 25701/45455\n",
      "Processing chunk 25751/45455\n",
      "Processing chunk 25801/45455\n",
      "Processing chunk 25851/45455\n",
      "Processing chunk 25901/45455\n",
      "Processing chunk 25951/45455\n",
      "Processing chunk 26001/45455\n",
      "Processing chunk 26051/45455\n",
      "Processing chunk 26101/45455\n",
      "Processing chunk 26151/45455\n",
      "Processing chunk 26201/45455\n",
      "Processing chunk 26251/45455\n",
      "Processing chunk 26301/45455\n",
      "Processing chunk 26351/45455\n",
      "Processing chunk 26401/45455\n",
      "Processing chunk 26451/45455\n",
      "Processing chunk 26501/45455\n",
      "Processing chunk 26551/45455\n",
      "Processing chunk 26601/45455\n",
      "Processing chunk 26651/45455\n",
      "Processing chunk 26701/45455\n",
      "Processing chunk 26751/45455\n",
      "Processing chunk 26801/45455\n",
      "Processing chunk 26851/45455\n",
      "Processing chunk 26901/45455\n",
      "Processing chunk 26951/45455\n",
      "Processing chunk 27001/45455\n",
      "Processing chunk 27051/45455\n",
      "Processing chunk 27101/45455\n",
      "Processing chunk 27151/45455\n",
      "Processing chunk 27201/45455\n",
      "Processing chunk 27251/45455\n",
      "Processing chunk 27301/45455\n",
      "Processing chunk 27351/45455\n",
      "Processing chunk 27401/45455\n",
      "Processing chunk 27451/45455\n",
      "Processing chunk 27501/45455\n",
      "Processing chunk 27551/45455\n",
      "Processing chunk 27601/45455\n",
      "Processing chunk 27651/45455\n",
      "Processing chunk 27701/45455\n",
      "Processing chunk 27751/45455\n",
      "Processing chunk 27801/45455\n",
      "Processing chunk 27851/45455\n",
      "Processing chunk 27901/45455\n",
      "Processing chunk 27951/45455\n",
      "Processing chunk 28001/45455\n",
      "Processing chunk 28051/45455\n",
      "Processing chunk 28101/45455\n",
      "Processing chunk 28151/45455\n",
      "Processing chunk 28201/45455\n",
      "Processing chunk 28251/45455\n",
      "Processing chunk 28301/45455\n",
      "Processing chunk 28351/45455\n",
      "Processing chunk 28401/45455\n",
      "Processing chunk 28451/45455\n",
      "Processing chunk 28501/45455\n",
      "Processing chunk 28551/45455\n",
      "Processing chunk 28601/45455\n",
      "Processing chunk 28651/45455\n",
      "Processing chunk 28701/45455\n",
      "Processing chunk 28751/45455\n",
      "Processing chunk 28801/45455\n",
      "Processing chunk 28851/45455\n",
      "Processing chunk 28901/45455\n",
      "Processing chunk 28951/45455\n",
      "Processing chunk 29001/45455\n",
      "Processing chunk 29051/45455\n",
      "Processing chunk 29101/45455\n",
      "Processing chunk 29151/45455\n",
      "Processing chunk 29201/45455\n",
      "Processing chunk 29251/45455\n",
      "Processing chunk 29301/45455\n",
      "Processing chunk 29351/45455\n",
      "Processing chunk 29401/45455\n",
      "Processing chunk 29451/45455\n",
      "Processing chunk 29501/45455\n",
      "Processing chunk 29551/45455\n",
      "Processing chunk 29601/45455\n",
      "Processing chunk 29651/45455\n",
      "Processing chunk 29701/45455\n",
      "Processing chunk 29751/45455\n",
      "Processing chunk 29801/45455\n",
      "Processing chunk 29851/45455\n",
      "Processing chunk 29901/45455\n",
      "Processing chunk 29951/45455\n",
      "Processing chunk 30001/45455\n",
      "Processing chunk 30051/45455\n",
      "Processing chunk 30101/45455\n",
      "Processing chunk 30151/45455\n",
      "Processing chunk 30201/45455\n",
      "Processing chunk 30251/45455\n",
      "Processing chunk 30301/45455\n",
      "Processing chunk 30351/45455\n",
      "Processing chunk 30401/45455\n",
      "Processing chunk 30451/45455\n",
      "Processing chunk 30501/45455\n",
      "Processing chunk 30551/45455\n",
      "Processing chunk 30601/45455\n",
      "Processing chunk 30651/45455\n",
      "Processing chunk 30701/45455\n",
      "Processing chunk 30751/45455\n",
      "Processing chunk 30801/45455\n",
      "Processing chunk 30851/45455\n",
      "Processing chunk 30901/45455\n",
      "Processing chunk 30951/45455\n",
      "Processing chunk 31001/45455\n",
      "Processing chunk 31051/45455\n",
      "Processing chunk 31101/45455\n",
      "Processing chunk 31151/45455\n",
      "Processing chunk 31201/45455\n",
      "Processing chunk 31251/45455\n",
      "Processing chunk 31301/45455\n",
      "Processing chunk 31351/45455\n",
      "Processing chunk 31401/45455\n",
      "Processing chunk 31451/45455\n",
      "Processing chunk 31501/45455\n",
      "Processing chunk 31551/45455\n",
      "Processing chunk 31601/45455\n",
      "Processing chunk 31651/45455\n",
      "Processing chunk 31701/45455\n",
      "Processing chunk 31751/45455\n",
      "Processing chunk 31801/45455\n",
      "Processing chunk 31851/45455\n",
      "Processing chunk 31901/45455\n",
      "Processing chunk 31951/45455\n",
      "Processing chunk 32001/45455\n",
      "Processing chunk 32051/45455\n",
      "Processing chunk 32101/45455\n",
      "Processing chunk 32151/45455\n",
      "Processing chunk 32201/45455\n",
      "Processing chunk 32251/45455\n",
      "Processing chunk 32301/45455\n",
      "Processing chunk 32351/45455\n",
      "Processing chunk 32401/45455\n",
      "Processing chunk 32451/45455\n",
      "Processing chunk 32501/45455\n",
      "Processing chunk 32551/45455\n",
      "Processing chunk 32601/45455\n",
      "Processing chunk 32651/45455\n",
      "Processing chunk 32701/45455\n",
      "Processing chunk 32751/45455\n",
      "Processing chunk 32801/45455\n",
      "Processing chunk 32851/45455\n",
      "Processing chunk 32901/45455\n",
      "Processing chunk 32951/45455\n",
      "Processing chunk 33001/45455\n",
      "Processing chunk 33051/45455\n",
      "Processing chunk 33101/45455\n",
      "Processing chunk 33151/45455\n",
      "Processing chunk 33201/45455\n",
      "Processing chunk 33251/45455\n",
      "Processing chunk 33301/45455\n",
      "Processing chunk 33351/45455\n",
      "Processing chunk 33401/45455\n",
      "Processing chunk 33451/45455\n",
      "Processing chunk 33501/45455\n",
      "Processing chunk 33551/45455\n",
      "Processing chunk 33601/45455\n",
      "Processing chunk 33651/45455\n",
      "Processing chunk 33701/45455\n",
      "Processing chunk 33751/45455\n",
      "Processing chunk 33801/45455\n",
      "Processing chunk 33851/45455\n",
      "Processing chunk 33901/45455\n",
      "Processing chunk 33951/45455\n",
      "Processing chunk 34001/45455\n",
      "Processing chunk 34051/45455\n",
      "Processing chunk 34101/45455\n",
      "Processing chunk 34151/45455\n",
      "Processing chunk 34201/45455\n",
      "Processing chunk 34251/45455\n",
      "Processing chunk 34301/45455\n",
      "Processing chunk 34351/45455\n",
      "Processing chunk 34401/45455\n",
      "Processing chunk 34451/45455\n",
      "Processing chunk 34501/45455\n",
      "Processing chunk 34551/45455\n",
      "Processing chunk 34601/45455\n",
      "Processing chunk 34651/45455\n",
      "Processing chunk 34701/45455\n",
      "Processing chunk 34751/45455\n",
      "Processing chunk 34801/45455\n",
      "Processing chunk 34851/45455\n",
      "Processing chunk 34901/45455\n",
      "Processing chunk 34951/45455\n",
      "Processing chunk 35001/45455\n",
      "Processing chunk 35051/45455\n",
      "Processing chunk 35101/45455\n",
      "Processing chunk 35151/45455\n",
      "Processing chunk 35201/45455\n",
      "Processing chunk 35251/45455\n",
      "Processing chunk 35301/45455\n",
      "Processing chunk 35351/45455\n",
      "Processing chunk 35401/45455\n",
      "Processing chunk 35451/45455\n",
      "Processing chunk 35501/45455\n",
      "Processing chunk 35551/45455\n",
      "Processing chunk 35601/45455\n",
      "Processing chunk 35651/45455\n",
      "Processing chunk 35701/45455\n",
      "Processing chunk 35751/45455\n",
      "Processing chunk 35801/45455\n",
      "Processing chunk 35851/45455\n",
      "Processing chunk 35901/45455\n",
      "Processing chunk 35951/45455\n",
      "Processing chunk 36001/45455\n",
      "Processing chunk 36051/45455\n",
      "Processing chunk 36101/45455\n",
      "Processing chunk 36151/45455\n",
      "Processing chunk 36201/45455\n",
      "Processing chunk 36251/45455\n",
      "Processing chunk 36301/45455\n",
      "Processing chunk 36351/45455\n",
      "Processing chunk 36401/45455\n",
      "Processing chunk 36451/45455\n",
      "Processing chunk 36501/45455\n",
      "Processing chunk 36551/45455\n",
      "Processing chunk 36601/45455\n",
      "Processing chunk 36651/45455\n",
      "Processing chunk 36701/45455\n",
      "Processing chunk 36751/45455\n",
      "Processing chunk 36801/45455\n",
      "Processing chunk 36851/45455\n",
      "Processing chunk 36901/45455\n",
      "Processing chunk 36951/45455\n",
      "Processing chunk 37001/45455\n",
      "Processing chunk 37051/45455\n",
      "Processing chunk 37101/45455\n",
      "Processing chunk 37151/45455\n",
      "Processing chunk 37201/45455\n",
      "Processing chunk 37251/45455\n",
      "Processing chunk 37301/45455\n",
      "Processing chunk 37351/45455\n",
      "Processing chunk 37401/45455\n",
      "Processing chunk 37451/45455\n",
      "Processing chunk 37501/45455\n",
      "Processing chunk 37551/45455\n",
      "Processing chunk 37601/45455\n",
      "Processing chunk 37651/45455\n",
      "Processing chunk 37701/45455\n",
      "Processing chunk 37751/45455\n",
      "Processing chunk 37801/45455\n",
      "Processing chunk 37851/45455\n",
      "Processing chunk 37901/45455\n",
      "Processing chunk 37951/45455\n",
      "Processing chunk 38001/45455\n",
      "Processing chunk 38051/45455\n",
      "Processing chunk 38101/45455\n",
      "Processing chunk 38151/45455\n",
      "Processing chunk 38201/45455\n",
      "Processing chunk 38251/45455\n",
      "Processing chunk 38301/45455\n",
      "Processing chunk 38351/45455\n",
      "Processing chunk 38401/45455\n",
      "Processing chunk 38451/45455\n",
      "Processing chunk 38501/45455\n",
      "Processing chunk 38551/45455\n",
      "Processing chunk 38601/45455\n",
      "Processing chunk 38651/45455\n",
      "Processing chunk 38701/45455\n",
      "Processing chunk 38751/45455\n",
      "Processing chunk 38801/45455\n",
      "Processing chunk 38851/45455\n",
      "Processing chunk 38901/45455\n",
      "Processing chunk 38951/45455\n",
      "Processing chunk 39001/45455\n",
      "Processing chunk 39051/45455\n",
      "Processing chunk 39101/45455\n",
      "Processing chunk 39151/45455\n",
      "Processing chunk 39201/45455\n",
      "Processing chunk 39251/45455\n",
      "Processing chunk 39301/45455\n",
      "Processing chunk 39351/45455\n",
      "Processing chunk 39401/45455\n",
      "Processing chunk 39451/45455\n",
      "Processing chunk 39501/45455\n",
      "Processing chunk 39551/45455\n",
      "Processing chunk 39601/45455\n",
      "Processing chunk 39651/45455\n",
      "Processing chunk 39701/45455\n",
      "Processing chunk 39751/45455\n",
      "Processing chunk 39801/45455\n",
      "Processing chunk 39851/45455\n",
      "Processing chunk 39901/45455\n",
      "Processing chunk 39951/45455\n",
      "Processing chunk 40001/45455\n",
      "Processing chunk 40051/45455\n",
      "Processing chunk 40101/45455\n",
      "Processing chunk 40151/45455\n",
      "Processing chunk 40201/45455\n",
      "Processing chunk 40251/45455\n",
      "Processing chunk 40301/45455\n",
      "Processing chunk 40351/45455\n",
      "Processing chunk 40401/45455\n",
      "Processing chunk 40451/45455\n",
      "Processing chunk 40501/45455\n",
      "Processing chunk 40551/45455\n",
      "Processing chunk 40601/45455\n",
      "Processing chunk 40651/45455\n",
      "Processing chunk 40701/45455\n",
      "Processing chunk 40751/45455\n",
      "Processing chunk 40801/45455\n",
      "Processing chunk 40851/45455\n",
      "Processing chunk 40901/45455\n",
      "Processing chunk 40951/45455\n",
      "Processing chunk 41001/45455\n",
      "Processing chunk 41051/45455\n",
      "Processing chunk 41101/45455\n",
      "Processing chunk 41151/45455\n",
      "Processing chunk 41201/45455\n",
      "Processing chunk 41251/45455\n",
      "Processing chunk 41301/45455\n",
      "Processing chunk 41351/45455\n",
      "Processing chunk 41401/45455\n",
      "Processing chunk 41451/45455\n",
      "Processing chunk 41501/45455\n",
      "Processing chunk 41551/45455\n",
      "Processing chunk 41601/45455\n",
      "Processing chunk 41651/45455\n",
      "Processing chunk 41701/45455\n",
      "Processing chunk 41751/45455\n",
      "Processing chunk 41801/45455\n",
      "Processing chunk 41851/45455\n",
      "Processing chunk 41901/45455\n",
      "Processing chunk 41951/45455\n",
      "Processing chunk 42001/45455\n",
      "Processing chunk 42051/45455\n",
      "Processing chunk 42101/45455\n",
      "Processing chunk 42151/45455\n",
      "Processing chunk 42201/45455\n",
      "Processing chunk 42251/45455\n",
      "Processing chunk 42301/45455\n",
      "Processing chunk 42351/45455\n",
      "Processing chunk 42401/45455\n",
      "Processing chunk 42451/45455\n",
      "Processing chunk 42501/45455\n",
      "Processing chunk 42551/45455\n",
      "Processing chunk 42601/45455\n",
      "Processing chunk 42651/45455\n",
      "Processing chunk 42701/45455\n",
      "Processing chunk 42751/45455\n",
      "Processing chunk 42801/45455\n",
      "Processing chunk 42851/45455\n",
      "Processing chunk 42901/45455\n",
      "Processing chunk 42951/45455\n",
      "Processing chunk 43001/45455\n",
      "Processing chunk 43051/45455\n",
      "Processing chunk 43101/45455\n",
      "Processing chunk 43151/45455\n",
      "Processing chunk 43201/45455\n",
      "Processing chunk 43251/45455\n",
      "Processing chunk 43301/45455\n",
      "Processing chunk 43351/45455\n",
      "Processing chunk 43401/45455\n",
      "Processing chunk 43451/45455\n",
      "Processing chunk 43501/45455\n",
      "Processing chunk 43551/45455\n",
      "Processing chunk 43601/45455\n",
      "Processing chunk 43651/45455\n",
      "Processing chunk 43701/45455\n",
      "Processing chunk 43751/45455\n",
      "Processing chunk 43801/45455\n",
      "Processing chunk 43851/45455\n",
      "Processing chunk 43901/45455\n",
      "Processing chunk 43951/45455\n",
      "Processing chunk 44001/45455\n",
      "Processing chunk 44051/45455\n",
      "Processing chunk 44101/45455\n",
      "Processing chunk 44151/45455\n",
      "Processing chunk 44201/45455\n",
      "Processing chunk 44251/45455\n",
      "Processing chunk 44301/45455\n",
      "Processing chunk 44351/45455\n",
      "Processing chunk 44401/45455\n",
      "Processing chunk 44451/45455\n",
      "Processing chunk 44501/45455\n",
      "Processing chunk 44551/45455\n",
      "Processing chunk 44601/45455\n",
      "Processing chunk 44651/45455\n",
      "Processing chunk 44701/45455\n",
      "Processing chunk 44751/45455\n",
      "Processing chunk 44801/45455\n",
      "Processing chunk 44851/45455\n",
      "Processing chunk 44901/45455\n",
      "Processing chunk 44951/45455\n",
      "Processing chunk 45001/45455\n",
      "Processing chunk 45051/45455\n",
      "Processing chunk 45101/45455\n",
      "Processing chunk 45151/45455\n",
      "Processing chunk 45201/45455\n",
      "Processing chunk 45251/45455\n",
      "Processing chunk 45301/45455\n",
      "Processing chunk 45351/45455\n",
      "Processing chunk 45401/45455\n",
      "Processing chunk 45451/45455\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 10000\n",
      "Number of hits: 9906\n",
      "Average HR@20: 0.9906\n",
      "Average NDCG@20: 0.4510\n",
      "\n",
      "Training and evaluating DIPN...\n",
      "Epoch 1, Loss: 0.7397\n",
      "Epoch 2, Loss: 0.7164\n",
      "Epoch 3, Loss: 0.6949\n",
      "Epoch 4, Loss: 0.6750\n",
      "Epoch 5, Loss: 0.6566\n",
      "Epoch 6, Loss: 0.6395\n",
      "Epoch 7, Loss: 0.6235\n",
      "Epoch 8, Loss: 0.6085\n",
      "Epoch 9, Loss: 0.5944\n",
      "Epoch 10, Loss: 0.5809\n",
      "Training completed in 2.16s\n",
      "Preparing test instances...\n",
      "Generated 1000000 test instances\n",
      "Evaluating 1000000 instances in 45455 chunks...\n",
      "Processing chunk 1/45455\n",
      "Processing chunk 51/45455\n",
      "Processing chunk 101/45455\n",
      "Processing chunk 151/45455\n",
      "Processing chunk 201/45455\n",
      "Processing chunk 251/45455\n",
      "Processing chunk 301/45455\n",
      "Processing chunk 351/45455\n",
      "Processing chunk 401/45455\n",
      "Processing chunk 451/45455\n",
      "Processing chunk 501/45455\n",
      "Processing chunk 551/45455\n",
      "Processing chunk 601/45455\n",
      "Processing chunk 651/45455\n",
      "Processing chunk 701/45455\n",
      "Processing chunk 751/45455\n",
      "Processing chunk 801/45455\n",
      "Processing chunk 851/45455\n",
      "Processing chunk 901/45455\n",
      "Processing chunk 951/45455\n",
      "Processing chunk 1001/45455\n",
      "Processing chunk 1051/45455\n",
      "Processing chunk 1101/45455\n",
      "Processing chunk 1151/45455\n",
      "Processing chunk 1201/45455\n",
      "Processing chunk 1251/45455\n",
      "Processing chunk 1301/45455\n",
      "Processing chunk 1351/45455\n",
      "Processing chunk 1401/45455\n",
      "Processing chunk 1451/45455\n",
      "Processing chunk 1501/45455\n",
      "Processing chunk 1551/45455\n",
      "Processing chunk 1601/45455\n",
      "Processing chunk 1651/45455\n",
      "Processing chunk 1701/45455\n",
      "Processing chunk 1751/45455\n",
      "Processing chunk 1801/45455\n",
      "Processing chunk 1851/45455\n",
      "Processing chunk 1901/45455\n",
      "Processing chunk 1951/45455\n",
      "Processing chunk 2001/45455\n",
      "Processing chunk 2051/45455\n",
      "Processing chunk 2101/45455\n",
      "Processing chunk 2151/45455\n",
      "Processing chunk 2201/45455\n",
      "Processing chunk 2251/45455\n",
      "Processing chunk 2301/45455\n",
      "Processing chunk 2351/45455\n",
      "Processing chunk 2401/45455\n",
      "Processing chunk 2451/45455\n",
      "Processing chunk 2501/45455\n",
      "Processing chunk 2551/45455\n",
      "Processing chunk 2601/45455\n",
      "Processing chunk 2651/45455\n",
      "Processing chunk 2701/45455\n",
      "Processing chunk 2751/45455\n",
      "Processing chunk 2801/45455\n",
      "Processing chunk 2851/45455\n",
      "Processing chunk 2901/45455\n",
      "Processing chunk 2951/45455\n",
      "Processing chunk 3001/45455\n",
      "Processing chunk 3051/45455\n",
      "Processing chunk 3101/45455\n",
      "Processing chunk 3151/45455\n",
      "Processing chunk 3201/45455\n",
      "Processing chunk 3251/45455\n",
      "Processing chunk 3301/45455\n",
      "Processing chunk 3351/45455\n",
      "Processing chunk 3401/45455\n",
      "Processing chunk 3451/45455\n",
      "Processing chunk 3501/45455\n",
      "Processing chunk 3551/45455\n",
      "Processing chunk 3601/45455\n",
      "Processing chunk 3651/45455\n",
      "Processing chunk 3701/45455\n",
      "Processing chunk 3751/45455\n",
      "Processing chunk 3801/45455\n",
      "Processing chunk 3851/45455\n",
      "Processing chunk 3901/45455\n",
      "Processing chunk 3951/45455\n",
      "Processing chunk 4001/45455\n",
      "Processing chunk 4051/45455\n",
      "Processing chunk 4101/45455\n",
      "Processing chunk 4151/45455\n",
      "Processing chunk 4201/45455\n",
      "Processing chunk 4251/45455\n",
      "Processing chunk 4301/45455\n",
      "Processing chunk 4351/45455\n",
      "Processing chunk 4401/45455\n",
      "Processing chunk 4451/45455\n",
      "Processing chunk 4501/45455\n",
      "Processing chunk 4551/45455\n",
      "Processing chunk 4601/45455\n",
      "Processing chunk 4651/45455\n",
      "Processing chunk 4701/45455\n",
      "Processing chunk 4751/45455\n",
      "Processing chunk 4801/45455\n",
      "Processing chunk 4851/45455\n",
      "Processing chunk 4901/45455\n",
      "Processing chunk 4951/45455\n",
      "Processing chunk 5001/45455\n",
      "Processing chunk 5051/45455\n",
      "Processing chunk 5101/45455\n",
      "Processing chunk 5151/45455\n",
      "Processing chunk 5201/45455\n",
      "Processing chunk 5251/45455\n",
      "Processing chunk 5301/45455\n",
      "Processing chunk 5351/45455\n",
      "Processing chunk 5401/45455\n",
      "Processing chunk 5451/45455\n",
      "Processing chunk 5501/45455\n",
      "Processing chunk 5551/45455\n",
      "Processing chunk 5601/45455\n",
      "Processing chunk 5651/45455\n",
      "Processing chunk 5701/45455\n",
      "Processing chunk 5751/45455\n",
      "Processing chunk 5801/45455\n",
      "Processing chunk 5851/45455\n",
      "Processing chunk 5901/45455\n",
      "Processing chunk 5951/45455\n",
      "Processing chunk 6001/45455\n",
      "Processing chunk 6051/45455\n",
      "Processing chunk 6101/45455\n",
      "Processing chunk 6151/45455\n",
      "Processing chunk 6201/45455\n",
      "Processing chunk 6251/45455\n",
      "Processing chunk 6301/45455\n",
      "Processing chunk 6351/45455\n",
      "Processing chunk 6401/45455\n",
      "Processing chunk 6451/45455\n",
      "Processing chunk 6501/45455\n",
      "Processing chunk 6551/45455\n",
      "Processing chunk 6601/45455\n",
      "Processing chunk 6651/45455\n",
      "Processing chunk 6701/45455\n",
      "Processing chunk 6751/45455\n",
      "Processing chunk 6801/45455\n",
      "Processing chunk 6851/45455\n",
      "Processing chunk 6901/45455\n",
      "Processing chunk 6951/45455\n",
      "Processing chunk 7001/45455\n",
      "Processing chunk 7051/45455\n",
      "Processing chunk 7101/45455\n",
      "Processing chunk 7151/45455\n",
      "Processing chunk 7201/45455\n",
      "Processing chunk 7251/45455\n",
      "Processing chunk 7301/45455\n",
      "Processing chunk 7351/45455\n",
      "Processing chunk 7401/45455\n",
      "Processing chunk 7451/45455\n",
      "Processing chunk 7501/45455\n",
      "Processing chunk 7551/45455\n",
      "Processing chunk 7601/45455\n",
      "Processing chunk 7651/45455\n",
      "Processing chunk 7701/45455\n",
      "Processing chunk 7751/45455\n",
      "Processing chunk 7801/45455\n",
      "Processing chunk 7851/45455\n",
      "Processing chunk 7901/45455\n",
      "Processing chunk 7951/45455\n",
      "Processing chunk 8001/45455\n",
      "Processing chunk 8051/45455\n",
      "Processing chunk 8101/45455\n",
      "Processing chunk 8151/45455\n",
      "Processing chunk 8201/45455\n",
      "Processing chunk 8251/45455\n",
      "Processing chunk 8301/45455\n",
      "Processing chunk 8351/45455\n",
      "Processing chunk 8401/45455\n",
      "Processing chunk 8451/45455\n",
      "Processing chunk 8501/45455\n",
      "Processing chunk 8551/45455\n",
      "Processing chunk 8601/45455\n",
      "Processing chunk 8651/45455\n",
      "Processing chunk 8701/45455\n",
      "Processing chunk 8751/45455\n",
      "Processing chunk 8801/45455\n",
      "Processing chunk 8851/45455\n",
      "Processing chunk 8901/45455\n",
      "Processing chunk 8951/45455\n",
      "Processing chunk 9001/45455\n",
      "Processing chunk 9051/45455\n",
      "Processing chunk 9101/45455\n",
      "Processing chunk 9151/45455\n",
      "Processing chunk 9201/45455\n",
      "Processing chunk 9251/45455\n",
      "Processing chunk 9301/45455\n",
      "Processing chunk 9351/45455\n",
      "Processing chunk 9401/45455\n",
      "Processing chunk 9451/45455\n",
      "Processing chunk 9501/45455\n",
      "Processing chunk 9551/45455\n",
      "Processing chunk 9601/45455\n",
      "Processing chunk 9651/45455\n",
      "Processing chunk 9701/45455\n",
      "Processing chunk 9751/45455\n",
      "Processing chunk 9801/45455\n",
      "Processing chunk 9851/45455\n",
      "Processing chunk 9901/45455\n",
      "Processing chunk 9951/45455\n",
      "Processing chunk 10001/45455\n",
      "Processing chunk 10051/45455\n",
      "Processing chunk 10101/45455\n",
      "Processing chunk 10151/45455\n",
      "Processing chunk 10201/45455\n",
      "Processing chunk 10251/45455\n",
      "Processing chunk 10301/45455\n",
      "Processing chunk 10351/45455\n",
      "Processing chunk 10401/45455\n",
      "Processing chunk 10451/45455\n",
      "Processing chunk 10501/45455\n",
      "Processing chunk 10551/45455\n",
      "Processing chunk 10601/45455\n",
      "Processing chunk 10651/45455\n",
      "Processing chunk 10701/45455\n",
      "Processing chunk 10751/45455\n",
      "Processing chunk 10801/45455\n",
      "Processing chunk 10851/45455\n",
      "Processing chunk 10901/45455\n",
      "Processing chunk 10951/45455\n",
      "Processing chunk 11001/45455\n",
      "Processing chunk 11051/45455\n",
      "Processing chunk 11101/45455\n",
      "Processing chunk 11151/45455\n",
      "Processing chunk 11201/45455\n",
      "Processing chunk 11251/45455\n",
      "Processing chunk 11301/45455\n",
      "Processing chunk 11351/45455\n",
      "Processing chunk 11401/45455\n",
      "Processing chunk 11451/45455\n",
      "Processing chunk 11501/45455\n",
      "Processing chunk 11551/45455\n",
      "Processing chunk 11601/45455\n",
      "Processing chunk 11651/45455\n",
      "Processing chunk 11701/45455\n",
      "Processing chunk 11751/45455\n",
      "Processing chunk 11801/45455\n",
      "Processing chunk 11851/45455\n",
      "Processing chunk 11901/45455\n",
      "Processing chunk 11951/45455\n",
      "Processing chunk 12001/45455\n",
      "Processing chunk 12051/45455\n",
      "Processing chunk 12101/45455\n",
      "Processing chunk 12151/45455\n",
      "Processing chunk 12201/45455\n",
      "Processing chunk 12251/45455\n",
      "Processing chunk 12301/45455\n",
      "Processing chunk 12351/45455\n",
      "Processing chunk 12401/45455\n",
      "Processing chunk 12451/45455\n",
      "Processing chunk 12501/45455\n",
      "Processing chunk 12551/45455\n",
      "Processing chunk 12601/45455\n",
      "Processing chunk 12651/45455\n",
      "Processing chunk 12701/45455\n",
      "Processing chunk 12751/45455\n",
      "Processing chunk 12801/45455\n",
      "Processing chunk 12851/45455\n",
      "Processing chunk 12901/45455\n",
      "Processing chunk 12951/45455\n",
      "Processing chunk 13001/45455\n",
      "Processing chunk 13051/45455\n",
      "Processing chunk 13101/45455\n",
      "Processing chunk 13151/45455\n",
      "Processing chunk 13201/45455\n",
      "Processing chunk 13251/45455\n",
      "Processing chunk 13301/45455\n",
      "Processing chunk 13351/45455\n",
      "Processing chunk 13401/45455\n",
      "Processing chunk 13451/45455\n",
      "Processing chunk 13501/45455\n",
      "Processing chunk 13551/45455\n",
      "Processing chunk 13601/45455\n",
      "Processing chunk 13651/45455\n",
      "Processing chunk 13701/45455\n",
      "Processing chunk 13751/45455\n",
      "Processing chunk 13801/45455\n",
      "Processing chunk 13851/45455\n",
      "Processing chunk 13901/45455\n",
      "Processing chunk 13951/45455\n",
      "Processing chunk 14001/45455\n",
      "Processing chunk 14051/45455\n",
      "Processing chunk 14101/45455\n",
      "Processing chunk 14151/45455\n",
      "Processing chunk 14201/45455\n",
      "Processing chunk 14251/45455\n",
      "Processing chunk 14301/45455\n",
      "Processing chunk 14351/45455\n",
      "Processing chunk 14401/45455\n",
      "Processing chunk 14451/45455\n",
      "Processing chunk 14501/45455\n",
      "Processing chunk 14551/45455\n",
      "Processing chunk 14601/45455\n",
      "Processing chunk 14651/45455\n",
      "Processing chunk 14701/45455\n",
      "Processing chunk 14751/45455\n",
      "Processing chunk 14801/45455\n",
      "Processing chunk 14851/45455\n",
      "Processing chunk 14901/45455\n",
      "Processing chunk 14951/45455\n",
      "Processing chunk 15001/45455\n",
      "Processing chunk 15051/45455\n",
      "Processing chunk 15101/45455\n",
      "Processing chunk 15151/45455\n",
      "Processing chunk 15201/45455\n",
      "Processing chunk 15251/45455\n",
      "Processing chunk 15301/45455\n",
      "Processing chunk 15351/45455\n",
      "Processing chunk 15401/45455\n",
      "Processing chunk 15451/45455\n",
      "Processing chunk 15501/45455\n",
      "Processing chunk 15551/45455\n",
      "Processing chunk 15601/45455\n",
      "Processing chunk 15651/45455\n",
      "Processing chunk 15701/45455\n",
      "Processing chunk 15751/45455\n",
      "Processing chunk 15801/45455\n",
      "Processing chunk 15851/45455\n",
      "Processing chunk 15901/45455\n",
      "Processing chunk 15951/45455\n",
      "Processing chunk 16001/45455\n",
      "Processing chunk 16051/45455\n",
      "Processing chunk 16101/45455\n",
      "Processing chunk 16151/45455\n",
      "Processing chunk 16201/45455\n",
      "Processing chunk 16251/45455\n",
      "Processing chunk 16301/45455\n",
      "Processing chunk 16351/45455\n",
      "Processing chunk 16401/45455\n",
      "Processing chunk 16451/45455\n",
      "Processing chunk 16501/45455\n",
      "Processing chunk 16551/45455\n",
      "Processing chunk 16601/45455\n",
      "Processing chunk 16651/45455\n",
      "Processing chunk 16701/45455\n",
      "Processing chunk 16751/45455\n",
      "Processing chunk 16801/45455\n",
      "Processing chunk 16851/45455\n",
      "Processing chunk 16901/45455\n",
      "Processing chunk 16951/45455\n",
      "Processing chunk 17001/45455\n",
      "Processing chunk 17051/45455\n",
      "Processing chunk 17101/45455\n",
      "Processing chunk 17151/45455\n",
      "Processing chunk 17201/45455\n",
      "Processing chunk 17251/45455\n",
      "Processing chunk 17301/45455\n",
      "Processing chunk 17351/45455\n",
      "Processing chunk 17401/45455\n",
      "Processing chunk 17451/45455\n",
      "Processing chunk 17501/45455\n",
      "Processing chunk 17551/45455\n",
      "Processing chunk 17601/45455\n",
      "Processing chunk 17651/45455\n",
      "Processing chunk 17701/45455\n",
      "Processing chunk 17751/45455\n",
      "Processing chunk 17801/45455\n",
      "Processing chunk 17851/45455\n",
      "Processing chunk 17901/45455\n",
      "Processing chunk 17951/45455\n",
      "Processing chunk 18001/45455\n",
      "Processing chunk 18051/45455\n",
      "Processing chunk 18101/45455\n",
      "Processing chunk 18151/45455\n",
      "Processing chunk 18201/45455\n",
      "Processing chunk 18251/45455\n",
      "Processing chunk 18301/45455\n",
      "Processing chunk 18351/45455\n",
      "Processing chunk 18401/45455\n",
      "Processing chunk 18451/45455\n",
      "Processing chunk 18501/45455\n",
      "Processing chunk 18551/45455\n",
      "Processing chunk 18601/45455\n",
      "Processing chunk 18651/45455\n",
      "Processing chunk 18701/45455\n",
      "Processing chunk 18751/45455\n",
      "Processing chunk 18801/45455\n",
      "Processing chunk 18851/45455\n",
      "Processing chunk 18901/45455\n",
      "Processing chunk 18951/45455\n",
      "Processing chunk 19001/45455\n",
      "Processing chunk 19051/45455\n",
      "Processing chunk 19101/45455\n",
      "Processing chunk 19151/45455\n",
      "Processing chunk 19201/45455\n",
      "Processing chunk 19251/45455\n",
      "Processing chunk 19301/45455\n",
      "Processing chunk 19351/45455\n",
      "Processing chunk 19401/45455\n",
      "Processing chunk 19451/45455\n",
      "Processing chunk 19501/45455\n",
      "Processing chunk 19551/45455\n",
      "Processing chunk 19601/45455\n",
      "Processing chunk 19651/45455\n",
      "Processing chunk 19701/45455\n",
      "Processing chunk 19751/45455\n",
      "Processing chunk 19801/45455\n",
      "Processing chunk 19851/45455\n",
      "Processing chunk 19901/45455\n",
      "Processing chunk 19951/45455\n",
      "Processing chunk 20001/45455\n",
      "Processing chunk 20051/45455\n",
      "Processing chunk 20101/45455\n",
      "Processing chunk 20151/45455\n",
      "Processing chunk 20201/45455\n",
      "Processing chunk 20251/45455\n",
      "Processing chunk 20301/45455\n",
      "Processing chunk 20351/45455\n",
      "Processing chunk 20401/45455\n",
      "Processing chunk 20451/45455\n",
      "Processing chunk 20501/45455\n",
      "Processing chunk 20551/45455\n",
      "Processing chunk 20601/45455\n",
      "Processing chunk 20651/45455\n",
      "Processing chunk 20701/45455\n",
      "Processing chunk 20751/45455\n",
      "Processing chunk 20801/45455\n",
      "Processing chunk 20851/45455\n",
      "Processing chunk 20901/45455\n",
      "Processing chunk 20951/45455\n",
      "Processing chunk 21001/45455\n",
      "Processing chunk 21051/45455\n",
      "Processing chunk 21101/45455\n",
      "Processing chunk 21151/45455\n",
      "Processing chunk 21201/45455\n",
      "Processing chunk 21251/45455\n",
      "Processing chunk 21301/45455\n",
      "Processing chunk 21351/45455\n",
      "Processing chunk 21401/45455\n",
      "Processing chunk 21451/45455\n",
      "Processing chunk 21501/45455\n",
      "Processing chunk 21551/45455\n",
      "Processing chunk 21601/45455\n",
      "Processing chunk 21651/45455\n",
      "Processing chunk 21701/45455\n",
      "Processing chunk 21751/45455\n",
      "Processing chunk 21801/45455\n",
      "Processing chunk 21851/45455\n",
      "Processing chunk 21901/45455\n",
      "Processing chunk 21951/45455\n",
      "Processing chunk 22001/45455\n",
      "Processing chunk 22051/45455\n",
      "Processing chunk 22101/45455\n",
      "Processing chunk 22151/45455\n",
      "Processing chunk 22201/45455\n",
      "Processing chunk 22251/45455\n",
      "Processing chunk 22301/45455\n",
      "Processing chunk 22351/45455\n",
      "Processing chunk 22401/45455\n",
      "Processing chunk 22451/45455\n",
      "Processing chunk 22501/45455\n",
      "Processing chunk 22551/45455\n",
      "Processing chunk 22601/45455\n",
      "Processing chunk 22651/45455\n",
      "Processing chunk 22701/45455\n",
      "Processing chunk 22751/45455\n",
      "Processing chunk 22801/45455\n",
      "Processing chunk 22851/45455\n",
      "Processing chunk 22901/45455\n",
      "Processing chunk 22951/45455\n",
      "Processing chunk 23001/45455\n",
      "Processing chunk 23051/45455\n",
      "Processing chunk 23101/45455\n",
      "Processing chunk 23151/45455\n",
      "Processing chunk 23201/45455\n",
      "Processing chunk 23251/45455\n",
      "Processing chunk 23301/45455\n",
      "Processing chunk 23351/45455\n",
      "Processing chunk 23401/45455\n",
      "Processing chunk 23451/45455\n",
      "Processing chunk 23501/45455\n",
      "Processing chunk 23551/45455\n",
      "Processing chunk 23601/45455\n",
      "Processing chunk 23651/45455\n",
      "Processing chunk 23701/45455\n",
      "Processing chunk 23751/45455\n",
      "Processing chunk 23801/45455\n",
      "Processing chunk 23851/45455\n",
      "Processing chunk 23901/45455\n",
      "Processing chunk 23951/45455\n",
      "Processing chunk 24001/45455\n",
      "Processing chunk 24051/45455\n",
      "Processing chunk 24101/45455\n",
      "Processing chunk 24151/45455\n",
      "Processing chunk 24201/45455\n",
      "Processing chunk 24251/45455\n",
      "Processing chunk 24301/45455\n",
      "Processing chunk 24351/45455\n",
      "Processing chunk 24401/45455\n",
      "Processing chunk 24451/45455\n",
      "Processing chunk 24501/45455\n",
      "Processing chunk 24551/45455\n",
      "Processing chunk 24601/45455\n",
      "Processing chunk 24651/45455\n",
      "Processing chunk 24701/45455\n",
      "Processing chunk 24751/45455\n",
      "Processing chunk 24801/45455\n",
      "Processing chunk 24851/45455\n",
      "Processing chunk 24901/45455\n",
      "Processing chunk 24951/45455\n",
      "Processing chunk 25001/45455\n",
      "Processing chunk 25051/45455\n",
      "Processing chunk 25101/45455\n",
      "Processing chunk 25151/45455\n",
      "Processing chunk 25201/45455\n",
      "Processing chunk 25251/45455\n",
      "Processing chunk 25301/45455\n",
      "Processing chunk 25351/45455\n",
      "Processing chunk 25401/45455\n",
      "Processing chunk 25451/45455\n",
      "Processing chunk 25501/45455\n",
      "Processing chunk 25551/45455\n",
      "Processing chunk 25601/45455\n",
      "Processing chunk 25651/45455\n",
      "Processing chunk 25701/45455\n",
      "Processing chunk 25751/45455\n",
      "Processing chunk 25801/45455\n",
      "Processing chunk 25851/45455\n",
      "Processing chunk 25901/45455\n",
      "Processing chunk 25951/45455\n",
      "Processing chunk 26001/45455\n",
      "Processing chunk 26051/45455\n",
      "Processing chunk 26101/45455\n",
      "Processing chunk 26151/45455\n",
      "Processing chunk 26201/45455\n",
      "Processing chunk 26251/45455\n",
      "Processing chunk 26301/45455\n",
      "Processing chunk 26351/45455\n",
      "Processing chunk 26401/45455\n",
      "Processing chunk 26451/45455\n",
      "Processing chunk 26501/45455\n",
      "Processing chunk 26551/45455\n",
      "Processing chunk 26601/45455\n",
      "Processing chunk 26651/45455\n",
      "Processing chunk 26701/45455\n",
      "Processing chunk 26751/45455\n",
      "Processing chunk 26801/45455\n",
      "Processing chunk 26851/45455\n",
      "Processing chunk 26901/45455\n",
      "Processing chunk 26951/45455\n",
      "Processing chunk 27001/45455\n",
      "Processing chunk 27051/45455\n",
      "Processing chunk 27101/45455\n",
      "Processing chunk 27151/45455\n",
      "Processing chunk 27201/45455\n",
      "Processing chunk 27251/45455\n",
      "Processing chunk 27301/45455\n",
      "Processing chunk 27351/45455\n",
      "Processing chunk 27401/45455\n",
      "Processing chunk 27451/45455\n",
      "Processing chunk 27501/45455\n",
      "Processing chunk 27551/45455\n",
      "Processing chunk 27601/45455\n",
      "Processing chunk 27651/45455\n",
      "Processing chunk 27701/45455\n",
      "Processing chunk 27751/45455\n",
      "Processing chunk 27801/45455\n",
      "Processing chunk 27851/45455\n",
      "Processing chunk 27901/45455\n",
      "Processing chunk 27951/45455\n",
      "Processing chunk 28001/45455\n",
      "Processing chunk 28051/45455\n",
      "Processing chunk 28101/45455\n",
      "Processing chunk 28151/45455\n",
      "Processing chunk 28201/45455\n",
      "Processing chunk 28251/45455\n",
      "Processing chunk 28301/45455\n",
      "Processing chunk 28351/45455\n",
      "Processing chunk 28401/45455\n",
      "Processing chunk 28451/45455\n",
      "Processing chunk 28501/45455\n",
      "Processing chunk 28551/45455\n",
      "Processing chunk 28601/45455\n",
      "Processing chunk 28651/45455\n",
      "Processing chunk 28701/45455\n",
      "Processing chunk 28751/45455\n",
      "Processing chunk 28801/45455\n",
      "Processing chunk 28851/45455\n",
      "Processing chunk 28901/45455\n",
      "Processing chunk 28951/45455\n",
      "Processing chunk 29001/45455\n",
      "Processing chunk 29051/45455\n",
      "Processing chunk 29101/45455\n",
      "Processing chunk 29151/45455\n",
      "Processing chunk 29201/45455\n",
      "Processing chunk 29251/45455\n",
      "Processing chunk 29301/45455\n",
      "Processing chunk 29351/45455\n",
      "Processing chunk 29401/45455\n",
      "Processing chunk 29451/45455\n",
      "Processing chunk 29501/45455\n",
      "Processing chunk 29551/45455\n",
      "Processing chunk 29601/45455\n",
      "Processing chunk 29651/45455\n",
      "Processing chunk 29701/45455\n",
      "Processing chunk 29751/45455\n",
      "Processing chunk 29801/45455\n",
      "Processing chunk 29851/45455\n",
      "Processing chunk 29901/45455\n",
      "Processing chunk 29951/45455\n",
      "Processing chunk 30001/45455\n",
      "Processing chunk 30051/45455\n",
      "Processing chunk 30101/45455\n",
      "Processing chunk 30151/45455\n",
      "Processing chunk 30201/45455\n",
      "Processing chunk 30251/45455\n",
      "Processing chunk 30301/45455\n",
      "Processing chunk 30351/45455\n",
      "Processing chunk 30401/45455\n",
      "Processing chunk 30451/45455\n",
      "Processing chunk 30501/45455\n",
      "Processing chunk 30551/45455\n",
      "Processing chunk 30601/45455\n",
      "Processing chunk 30651/45455\n",
      "Processing chunk 30701/45455\n",
      "Processing chunk 30751/45455\n",
      "Processing chunk 30801/45455\n",
      "Processing chunk 30851/45455\n",
      "Processing chunk 30901/45455\n",
      "Processing chunk 30951/45455\n",
      "Processing chunk 31001/45455\n",
      "Processing chunk 31051/45455\n",
      "Processing chunk 31101/45455\n",
      "Processing chunk 31151/45455\n",
      "Processing chunk 31201/45455\n",
      "Processing chunk 31251/45455\n",
      "Processing chunk 31301/45455\n",
      "Processing chunk 31351/45455\n",
      "Processing chunk 31401/45455\n",
      "Processing chunk 31451/45455\n",
      "Processing chunk 31501/45455\n",
      "Processing chunk 31551/45455\n",
      "Processing chunk 31601/45455\n",
      "Processing chunk 31651/45455\n",
      "Processing chunk 31701/45455\n",
      "Processing chunk 31751/45455\n",
      "Processing chunk 31801/45455\n",
      "Processing chunk 31851/45455\n",
      "Processing chunk 31901/45455\n",
      "Processing chunk 31951/45455\n",
      "Processing chunk 32001/45455\n",
      "Processing chunk 32051/45455\n",
      "Processing chunk 32101/45455\n",
      "Processing chunk 32151/45455\n",
      "Processing chunk 32201/45455\n",
      "Processing chunk 32251/45455\n",
      "Processing chunk 32301/45455\n",
      "Processing chunk 32351/45455\n",
      "Processing chunk 32401/45455\n",
      "Processing chunk 32451/45455\n",
      "Processing chunk 32501/45455\n",
      "Processing chunk 32551/45455\n",
      "Processing chunk 32601/45455\n",
      "Processing chunk 32651/45455\n",
      "Processing chunk 32701/45455\n",
      "Processing chunk 32751/45455\n",
      "Processing chunk 32801/45455\n",
      "Processing chunk 32851/45455\n",
      "Processing chunk 32901/45455\n",
      "Processing chunk 32951/45455\n",
      "Processing chunk 33001/45455\n",
      "Processing chunk 33051/45455\n",
      "Processing chunk 33101/45455\n",
      "Processing chunk 33151/45455\n",
      "Processing chunk 33201/45455\n",
      "Processing chunk 33251/45455\n",
      "Processing chunk 33301/45455\n",
      "Processing chunk 33351/45455\n",
      "Processing chunk 33401/45455\n",
      "Processing chunk 33451/45455\n",
      "Processing chunk 33501/45455\n",
      "Processing chunk 33551/45455\n",
      "Processing chunk 33601/45455\n",
      "Processing chunk 33651/45455\n",
      "Processing chunk 33701/45455\n",
      "Processing chunk 33751/45455\n",
      "Processing chunk 33801/45455\n",
      "Processing chunk 33851/45455\n",
      "Processing chunk 33901/45455\n",
      "Processing chunk 33951/45455\n",
      "Processing chunk 34001/45455\n",
      "Processing chunk 34051/45455\n",
      "Processing chunk 34101/45455\n",
      "Processing chunk 34151/45455\n",
      "Processing chunk 34201/45455\n",
      "Processing chunk 34251/45455\n",
      "Processing chunk 34301/45455\n",
      "Processing chunk 34351/45455\n",
      "Processing chunk 34401/45455\n",
      "Processing chunk 34451/45455\n",
      "Processing chunk 34501/45455\n",
      "Processing chunk 34551/45455\n",
      "Processing chunk 34601/45455\n",
      "Processing chunk 34651/45455\n",
      "Processing chunk 34701/45455\n",
      "Processing chunk 34751/45455\n",
      "Processing chunk 34801/45455\n",
      "Processing chunk 34851/45455\n",
      "Processing chunk 34901/45455\n",
      "Processing chunk 34951/45455\n",
      "Processing chunk 35001/45455\n",
      "Processing chunk 35051/45455\n",
      "Processing chunk 35101/45455\n",
      "Processing chunk 35151/45455\n",
      "Processing chunk 35201/45455\n",
      "Processing chunk 35251/45455\n",
      "Processing chunk 35301/45455\n",
      "Processing chunk 35351/45455\n",
      "Processing chunk 35401/45455\n",
      "Processing chunk 35451/45455\n",
      "Processing chunk 35501/45455\n",
      "Processing chunk 35551/45455\n",
      "Processing chunk 35601/45455\n",
      "Processing chunk 35651/45455\n",
      "Processing chunk 35701/45455\n",
      "Processing chunk 35751/45455\n",
      "Processing chunk 35801/45455\n",
      "Processing chunk 35851/45455\n",
      "Processing chunk 35901/45455\n",
      "Processing chunk 35951/45455\n",
      "Processing chunk 36001/45455\n",
      "Processing chunk 36051/45455\n",
      "Processing chunk 36101/45455\n",
      "Processing chunk 36151/45455\n",
      "Processing chunk 36201/45455\n",
      "Processing chunk 36251/45455\n",
      "Processing chunk 36301/45455\n",
      "Processing chunk 36351/45455\n",
      "Processing chunk 36401/45455\n",
      "Processing chunk 36451/45455\n",
      "Processing chunk 36501/45455\n",
      "Processing chunk 36551/45455\n",
      "Processing chunk 36601/45455\n",
      "Processing chunk 36651/45455\n",
      "Processing chunk 36701/45455\n",
      "Processing chunk 36751/45455\n",
      "Processing chunk 36801/45455\n",
      "Processing chunk 36851/45455\n",
      "Processing chunk 36901/45455\n",
      "Processing chunk 36951/45455\n",
      "Processing chunk 37001/45455\n",
      "Processing chunk 37051/45455\n",
      "Processing chunk 37101/45455\n",
      "Processing chunk 37151/45455\n",
      "Processing chunk 37201/45455\n",
      "Processing chunk 37251/45455\n",
      "Processing chunk 37301/45455\n",
      "Processing chunk 37351/45455\n",
      "Processing chunk 37401/45455\n",
      "Processing chunk 37451/45455\n",
      "Processing chunk 37501/45455\n",
      "Processing chunk 37551/45455\n",
      "Processing chunk 37601/45455\n",
      "Processing chunk 37651/45455\n",
      "Processing chunk 37701/45455\n",
      "Processing chunk 37751/45455\n",
      "Processing chunk 37801/45455\n",
      "Processing chunk 37851/45455\n",
      "Processing chunk 37901/45455\n",
      "Processing chunk 37951/45455\n",
      "Processing chunk 38001/45455\n",
      "Processing chunk 38051/45455\n",
      "Processing chunk 38101/45455\n",
      "Processing chunk 38151/45455\n",
      "Processing chunk 38201/45455\n",
      "Processing chunk 38251/45455\n",
      "Processing chunk 38301/45455\n",
      "Processing chunk 38351/45455\n",
      "Processing chunk 38401/45455\n",
      "Processing chunk 38451/45455\n",
      "Processing chunk 38501/45455\n",
      "Processing chunk 38551/45455\n",
      "Processing chunk 38601/45455\n",
      "Processing chunk 38651/45455\n",
      "Processing chunk 38701/45455\n",
      "Processing chunk 38751/45455\n",
      "Processing chunk 38801/45455\n",
      "Processing chunk 38851/45455\n",
      "Processing chunk 38901/45455\n",
      "Processing chunk 38951/45455\n",
      "Processing chunk 39001/45455\n",
      "Processing chunk 39051/45455\n",
      "Processing chunk 39101/45455\n",
      "Processing chunk 39151/45455\n",
      "Processing chunk 39201/45455\n",
      "Processing chunk 39251/45455\n",
      "Processing chunk 39301/45455\n",
      "Processing chunk 39351/45455\n",
      "Processing chunk 39401/45455\n",
      "Processing chunk 39451/45455\n",
      "Processing chunk 39501/45455\n",
      "Processing chunk 39551/45455\n",
      "Processing chunk 39601/45455\n",
      "Processing chunk 39651/45455\n",
      "Processing chunk 39701/45455\n",
      "Processing chunk 39751/45455\n",
      "Processing chunk 39801/45455\n",
      "Processing chunk 39851/45455\n",
      "Processing chunk 39901/45455\n",
      "Processing chunk 39951/45455\n",
      "Processing chunk 40001/45455\n",
      "Processing chunk 40051/45455\n",
      "Processing chunk 40101/45455\n",
      "Processing chunk 40151/45455\n",
      "Processing chunk 40201/45455\n",
      "Processing chunk 40251/45455\n",
      "Processing chunk 40301/45455\n",
      "Processing chunk 40351/45455\n",
      "Processing chunk 40401/45455\n",
      "Processing chunk 40451/45455\n",
      "Processing chunk 40501/45455\n",
      "Processing chunk 40551/45455\n",
      "Processing chunk 40601/45455\n",
      "Processing chunk 40651/45455\n",
      "Processing chunk 40701/45455\n",
      "Processing chunk 40751/45455\n",
      "Processing chunk 40801/45455\n",
      "Processing chunk 40851/45455\n",
      "Processing chunk 40901/45455\n",
      "Processing chunk 40951/45455\n",
      "Processing chunk 41001/45455\n",
      "Processing chunk 41051/45455\n",
      "Processing chunk 41101/45455\n",
      "Processing chunk 41151/45455\n",
      "Processing chunk 41201/45455\n",
      "Processing chunk 41251/45455\n",
      "Processing chunk 41301/45455\n",
      "Processing chunk 41351/45455\n",
      "Processing chunk 41401/45455\n",
      "Processing chunk 41451/45455\n",
      "Processing chunk 41501/45455\n",
      "Processing chunk 41551/45455\n",
      "Processing chunk 41601/45455\n",
      "Processing chunk 41651/45455\n",
      "Processing chunk 41701/45455\n",
      "Processing chunk 41751/45455\n",
      "Processing chunk 41801/45455\n",
      "Processing chunk 41851/45455\n",
      "Processing chunk 41901/45455\n",
      "Processing chunk 41951/45455\n",
      "Processing chunk 42001/45455\n",
      "Processing chunk 42051/45455\n",
      "Processing chunk 42101/45455\n",
      "Processing chunk 42151/45455\n",
      "Processing chunk 42201/45455\n",
      "Processing chunk 42251/45455\n",
      "Processing chunk 42301/45455\n",
      "Processing chunk 42351/45455\n",
      "Processing chunk 42401/45455\n",
      "Processing chunk 42451/45455\n",
      "Processing chunk 42501/45455\n",
      "Processing chunk 42551/45455\n",
      "Processing chunk 42601/45455\n",
      "Processing chunk 42651/45455\n",
      "Processing chunk 42701/45455\n",
      "Processing chunk 42751/45455\n",
      "Processing chunk 42801/45455\n",
      "Processing chunk 42851/45455\n",
      "Processing chunk 42901/45455\n",
      "Processing chunk 42951/45455\n",
      "Processing chunk 43001/45455\n",
      "Processing chunk 43051/45455\n",
      "Processing chunk 43101/45455\n",
      "Processing chunk 43151/45455\n",
      "Processing chunk 43201/45455\n",
      "Processing chunk 43251/45455\n",
      "Processing chunk 43301/45455\n",
      "Processing chunk 43351/45455\n",
      "Processing chunk 43401/45455\n",
      "Processing chunk 43451/45455\n",
      "Processing chunk 43501/45455\n",
      "Processing chunk 43551/45455\n",
      "Processing chunk 43601/45455\n",
      "Processing chunk 43651/45455\n",
      "Processing chunk 43701/45455\n",
      "Processing chunk 43751/45455\n",
      "Processing chunk 43801/45455\n",
      "Processing chunk 43851/45455\n",
      "Processing chunk 43901/45455\n",
      "Processing chunk 43951/45455\n",
      "Processing chunk 44001/45455\n",
      "Processing chunk 44051/45455\n",
      "Processing chunk 44101/45455\n",
      "Processing chunk 44151/45455\n",
      "Processing chunk 44201/45455\n",
      "Processing chunk 44251/45455\n",
      "Processing chunk 44301/45455\n",
      "Processing chunk 44351/45455\n",
      "Processing chunk 44401/45455\n",
      "Processing chunk 44451/45455\n",
      "Processing chunk 44501/45455\n",
      "Processing chunk 44551/45455\n",
      "Processing chunk 44601/45455\n",
      "Processing chunk 44651/45455\n",
      "Processing chunk 44701/45455\n",
      "Processing chunk 44751/45455\n",
      "Processing chunk 44801/45455\n",
      "Processing chunk 44851/45455\n",
      "Processing chunk 44901/45455\n",
      "Processing chunk 44951/45455\n",
      "Processing chunk 45001/45455\n",
      "Processing chunk 45051/45455\n",
      "Processing chunk 45101/45455\n",
      "Processing chunk 45151/45455\n",
      "Processing chunk 45201/45455\n",
      "Processing chunk 45251/45455\n",
      "Processing chunk 45301/45455\n",
      "Processing chunk 45351/45455\n",
      "Processing chunk 45401/45455\n",
      "Processing chunk 45451/45455\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 10000\n",
      "Number of hits: 9918\n",
      "Average HR@20: 0.9918\n",
      "Average NDCG@20: 0.4926\n",
      "\n",
      "Training and evaluating NGCF+M...\n",
      "Epoch 1, Loss: 0.6802\n",
      "Epoch 2, Loss: 0.5359\n",
      "Epoch 3, Loss: 0.4551\n",
      "Epoch 4, Loss: 0.3974\n",
      "Epoch 5, Loss: 0.3477\n",
      "Epoch 6, Loss: 0.3031\n",
      "Epoch 7, Loss: 0.2640\n",
      "Epoch 8, Loss: 0.2300\n",
      "Epoch 9, Loss: 0.1999\n",
      "Epoch 10, Loss: 0.1727\n",
      "Training completed in 1.94s\n",
      "Preparing test instances...\n",
      "Generated 1000000 test instances\n",
      "Evaluating 1000000 instances in 45455 chunks...\n",
      "Processing chunk 1/45455\n",
      "Processing chunk 51/45455\n",
      "Processing chunk 101/45455\n",
      "Processing chunk 151/45455\n",
      "Processing chunk 201/45455\n",
      "Processing chunk 251/45455\n",
      "Processing chunk 301/45455\n",
      "Processing chunk 351/45455\n",
      "Processing chunk 401/45455\n",
      "Processing chunk 451/45455\n",
      "Processing chunk 501/45455\n",
      "Processing chunk 551/45455\n",
      "Processing chunk 601/45455\n",
      "Processing chunk 651/45455\n",
      "Processing chunk 701/45455\n",
      "Processing chunk 751/45455\n",
      "Processing chunk 801/45455\n",
      "Processing chunk 851/45455\n",
      "Processing chunk 901/45455\n",
      "Processing chunk 951/45455\n",
      "Processing chunk 1001/45455\n",
      "Processing chunk 1051/45455\n",
      "Processing chunk 1101/45455\n",
      "Processing chunk 1151/45455\n",
      "Processing chunk 1201/45455\n",
      "Processing chunk 1251/45455\n",
      "Processing chunk 1301/45455\n",
      "Processing chunk 1351/45455\n",
      "Processing chunk 1401/45455\n",
      "Processing chunk 1451/45455\n",
      "Processing chunk 1501/45455\n",
      "Processing chunk 1551/45455\n",
      "Processing chunk 1601/45455\n",
      "Processing chunk 1651/45455\n",
      "Processing chunk 1701/45455\n",
      "Processing chunk 1751/45455\n",
      "Processing chunk 1801/45455\n",
      "Processing chunk 1851/45455\n",
      "Processing chunk 1901/45455\n",
      "Processing chunk 1951/45455\n",
      "Processing chunk 2001/45455\n",
      "Processing chunk 2051/45455\n",
      "Processing chunk 2101/45455\n",
      "Processing chunk 2151/45455\n",
      "Processing chunk 2201/45455\n",
      "Processing chunk 2251/45455\n",
      "Processing chunk 2301/45455\n",
      "Processing chunk 2351/45455\n",
      "Processing chunk 2401/45455\n",
      "Processing chunk 2451/45455\n",
      "Processing chunk 2501/45455\n",
      "Processing chunk 2551/45455\n",
      "Processing chunk 2601/45455\n",
      "Processing chunk 2651/45455\n",
      "Processing chunk 2701/45455\n",
      "Processing chunk 2751/45455\n",
      "Processing chunk 2801/45455\n",
      "Processing chunk 2851/45455\n",
      "Processing chunk 2901/45455\n",
      "Processing chunk 2951/45455\n",
      "Processing chunk 3001/45455\n",
      "Processing chunk 3051/45455\n",
      "Processing chunk 3101/45455\n",
      "Processing chunk 3151/45455\n",
      "Processing chunk 3201/45455\n",
      "Processing chunk 3251/45455\n",
      "Processing chunk 3301/45455\n",
      "Processing chunk 3351/45455\n",
      "Processing chunk 3401/45455\n",
      "Processing chunk 3451/45455\n",
      "Processing chunk 3501/45455\n",
      "Processing chunk 3551/45455\n",
      "Processing chunk 3601/45455\n",
      "Processing chunk 3651/45455\n",
      "Processing chunk 3701/45455\n",
      "Processing chunk 3751/45455\n",
      "Processing chunk 3801/45455\n",
      "Processing chunk 3851/45455\n",
      "Processing chunk 3901/45455\n",
      "Processing chunk 3951/45455\n",
      "Processing chunk 4001/45455\n",
      "Processing chunk 4051/45455\n",
      "Processing chunk 4101/45455\n",
      "Processing chunk 4151/45455\n",
      "Processing chunk 4201/45455\n",
      "Processing chunk 4251/45455\n",
      "Processing chunk 4301/45455\n",
      "Processing chunk 4351/45455\n",
      "Processing chunk 4401/45455\n",
      "Processing chunk 4451/45455\n",
      "Processing chunk 4501/45455\n",
      "Processing chunk 4551/45455\n",
      "Processing chunk 4601/45455\n",
      "Processing chunk 4651/45455\n",
      "Processing chunk 4701/45455\n",
      "Processing chunk 4751/45455\n",
      "Processing chunk 4801/45455\n",
      "Processing chunk 4851/45455\n",
      "Processing chunk 4901/45455\n",
      "Processing chunk 4951/45455\n",
      "Processing chunk 5001/45455\n",
      "Processing chunk 5051/45455\n",
      "Processing chunk 5101/45455\n",
      "Processing chunk 5151/45455\n",
      "Processing chunk 5201/45455\n",
      "Processing chunk 5251/45455\n",
      "Processing chunk 5301/45455\n",
      "Processing chunk 5351/45455\n",
      "Processing chunk 5401/45455\n",
      "Processing chunk 5451/45455\n",
      "Processing chunk 5501/45455\n",
      "Processing chunk 5551/45455\n",
      "Processing chunk 5601/45455\n",
      "Processing chunk 5651/45455\n",
      "Processing chunk 5701/45455\n",
      "Processing chunk 5751/45455\n",
      "Processing chunk 5801/45455\n",
      "Processing chunk 5851/45455\n",
      "Processing chunk 5901/45455\n",
      "Processing chunk 5951/45455\n",
      "Processing chunk 6001/45455\n",
      "Processing chunk 6051/45455\n",
      "Processing chunk 6101/45455\n",
      "Processing chunk 6151/45455\n",
      "Processing chunk 6201/45455\n",
      "Processing chunk 6251/45455\n",
      "Processing chunk 6301/45455\n",
      "Processing chunk 6351/45455\n",
      "Processing chunk 6401/45455\n",
      "Processing chunk 6451/45455\n",
      "Processing chunk 6501/45455\n",
      "Processing chunk 6551/45455\n",
      "Processing chunk 6601/45455\n",
      "Processing chunk 6651/45455\n",
      "Processing chunk 6701/45455\n",
      "Processing chunk 6751/45455\n",
      "Processing chunk 6801/45455\n",
      "Processing chunk 6851/45455\n",
      "Processing chunk 6901/45455\n",
      "Processing chunk 6951/45455\n",
      "Processing chunk 7001/45455\n",
      "Processing chunk 7051/45455\n",
      "Processing chunk 7101/45455\n",
      "Processing chunk 7151/45455\n",
      "Processing chunk 7201/45455\n",
      "Processing chunk 7251/45455\n",
      "Processing chunk 7301/45455\n",
      "Processing chunk 7351/45455\n",
      "Processing chunk 7401/45455\n",
      "Processing chunk 7451/45455\n",
      "Processing chunk 7501/45455\n",
      "Processing chunk 7551/45455\n",
      "Processing chunk 7601/45455\n",
      "Processing chunk 7651/45455\n",
      "Processing chunk 7701/45455\n",
      "Processing chunk 7751/45455\n",
      "Processing chunk 7801/45455\n",
      "Processing chunk 7851/45455\n",
      "Processing chunk 7901/45455\n",
      "Processing chunk 7951/45455\n",
      "Processing chunk 8001/45455\n",
      "Processing chunk 8051/45455\n",
      "Processing chunk 8101/45455\n",
      "Processing chunk 8151/45455\n",
      "Processing chunk 8201/45455\n",
      "Processing chunk 8251/45455\n",
      "Processing chunk 8301/45455\n",
      "Processing chunk 8351/45455\n",
      "Processing chunk 8401/45455\n",
      "Processing chunk 8451/45455\n",
      "Processing chunk 8501/45455\n",
      "Processing chunk 8551/45455\n",
      "Processing chunk 8601/45455\n",
      "Processing chunk 8651/45455\n",
      "Processing chunk 8701/45455\n",
      "Processing chunk 8751/45455\n",
      "Processing chunk 8801/45455\n",
      "Processing chunk 8851/45455\n",
      "Processing chunk 8901/45455\n",
      "Processing chunk 8951/45455\n",
      "Processing chunk 9001/45455\n",
      "Processing chunk 9051/45455\n",
      "Processing chunk 9101/45455\n",
      "Processing chunk 9151/45455\n",
      "Processing chunk 9201/45455\n",
      "Processing chunk 9251/45455\n",
      "Processing chunk 9301/45455\n",
      "Processing chunk 9351/45455\n",
      "Processing chunk 9401/45455\n",
      "Processing chunk 9451/45455\n",
      "Processing chunk 9501/45455\n",
      "Processing chunk 9551/45455\n",
      "Processing chunk 9601/45455\n",
      "Processing chunk 9651/45455\n",
      "Processing chunk 9701/45455\n",
      "Processing chunk 9751/45455\n",
      "Processing chunk 9801/45455\n",
      "Processing chunk 9851/45455\n",
      "Processing chunk 9901/45455\n",
      "Processing chunk 9951/45455\n",
      "Processing chunk 10001/45455\n",
      "Processing chunk 10051/45455\n",
      "Processing chunk 10101/45455\n",
      "Processing chunk 10151/45455\n",
      "Processing chunk 10201/45455\n",
      "Processing chunk 10251/45455\n",
      "Processing chunk 10301/45455\n",
      "Processing chunk 10351/45455\n",
      "Processing chunk 10401/45455\n",
      "Processing chunk 10451/45455\n",
      "Processing chunk 10501/45455\n",
      "Processing chunk 10551/45455\n",
      "Processing chunk 10601/45455\n",
      "Processing chunk 10651/45455\n",
      "Processing chunk 10701/45455\n",
      "Processing chunk 10751/45455\n",
      "Processing chunk 10801/45455\n",
      "Processing chunk 10851/45455\n",
      "Processing chunk 10901/45455\n",
      "Processing chunk 10951/45455\n",
      "Processing chunk 11001/45455\n",
      "Processing chunk 11051/45455\n",
      "Processing chunk 11101/45455\n",
      "Processing chunk 11151/45455\n",
      "Processing chunk 11201/45455\n",
      "Processing chunk 11251/45455\n",
      "Processing chunk 11301/45455\n",
      "Processing chunk 11351/45455\n",
      "Processing chunk 11401/45455\n",
      "Processing chunk 11451/45455\n",
      "Processing chunk 11501/45455\n",
      "Processing chunk 11551/45455\n",
      "Processing chunk 11601/45455\n",
      "Processing chunk 11651/45455\n",
      "Processing chunk 11701/45455\n",
      "Processing chunk 11751/45455\n",
      "Processing chunk 11801/45455\n",
      "Processing chunk 11851/45455\n",
      "Processing chunk 11901/45455\n",
      "Processing chunk 11951/45455\n",
      "Processing chunk 12001/45455\n",
      "Processing chunk 12051/45455\n",
      "Processing chunk 12101/45455\n",
      "Processing chunk 12151/45455\n",
      "Processing chunk 12201/45455\n",
      "Processing chunk 12251/45455\n",
      "Processing chunk 12301/45455\n",
      "Processing chunk 12351/45455\n",
      "Processing chunk 12401/45455\n",
      "Processing chunk 12451/45455\n",
      "Processing chunk 12501/45455\n",
      "Processing chunk 12551/45455\n",
      "Processing chunk 12601/45455\n",
      "Processing chunk 12651/45455\n",
      "Processing chunk 12701/45455\n",
      "Processing chunk 12751/45455\n",
      "Processing chunk 12801/45455\n",
      "Processing chunk 12851/45455\n",
      "Processing chunk 12901/45455\n",
      "Processing chunk 12951/45455\n",
      "Processing chunk 13001/45455\n",
      "Processing chunk 13051/45455\n",
      "Processing chunk 13101/45455\n",
      "Processing chunk 13151/45455\n",
      "Processing chunk 13201/45455\n",
      "Processing chunk 13251/45455\n",
      "Processing chunk 13301/45455\n",
      "Processing chunk 13351/45455\n",
      "Processing chunk 13401/45455\n",
      "Processing chunk 13451/45455\n",
      "Processing chunk 13501/45455\n",
      "Processing chunk 13551/45455\n",
      "Processing chunk 13601/45455\n",
      "Processing chunk 13651/45455\n",
      "Processing chunk 13701/45455\n",
      "Processing chunk 13751/45455\n",
      "Processing chunk 13801/45455\n",
      "Processing chunk 13851/45455\n",
      "Processing chunk 13901/45455\n",
      "Processing chunk 13951/45455\n",
      "Processing chunk 14001/45455\n",
      "Processing chunk 14051/45455\n",
      "Processing chunk 14101/45455\n",
      "Processing chunk 14151/45455\n",
      "Processing chunk 14201/45455\n",
      "Processing chunk 14251/45455\n",
      "Processing chunk 14301/45455\n",
      "Processing chunk 14351/45455\n",
      "Processing chunk 14401/45455\n",
      "Processing chunk 14451/45455\n",
      "Processing chunk 14501/45455\n",
      "Processing chunk 14551/45455\n",
      "Processing chunk 14601/45455\n",
      "Processing chunk 14651/45455\n",
      "Processing chunk 14701/45455\n",
      "Processing chunk 14751/45455\n",
      "Processing chunk 14801/45455\n",
      "Processing chunk 14851/45455\n",
      "Processing chunk 14901/45455\n",
      "Processing chunk 14951/45455\n",
      "Processing chunk 15001/45455\n",
      "Processing chunk 15051/45455\n",
      "Processing chunk 15101/45455\n",
      "Processing chunk 15151/45455\n",
      "Processing chunk 15201/45455\n",
      "Processing chunk 15251/45455\n",
      "Processing chunk 15301/45455\n",
      "Processing chunk 15351/45455\n",
      "Processing chunk 15401/45455\n",
      "Processing chunk 15451/45455\n",
      "Processing chunk 15501/45455\n",
      "Processing chunk 15551/45455\n",
      "Processing chunk 15601/45455\n",
      "Processing chunk 15651/45455\n",
      "Processing chunk 15701/45455\n",
      "Processing chunk 15751/45455\n",
      "Processing chunk 15801/45455\n",
      "Processing chunk 15851/45455\n",
      "Processing chunk 15901/45455\n",
      "Processing chunk 15951/45455\n",
      "Processing chunk 16001/45455\n",
      "Processing chunk 16051/45455\n",
      "Processing chunk 16101/45455\n",
      "Processing chunk 16151/45455\n",
      "Processing chunk 16201/45455\n",
      "Processing chunk 16251/45455\n",
      "Processing chunk 16301/45455\n",
      "Processing chunk 16351/45455\n",
      "Processing chunk 16401/45455\n",
      "Processing chunk 16451/45455\n",
      "Processing chunk 16501/45455\n",
      "Processing chunk 16551/45455\n",
      "Processing chunk 16601/45455\n",
      "Processing chunk 16651/45455\n",
      "Processing chunk 16701/45455\n",
      "Processing chunk 16751/45455\n",
      "Processing chunk 16801/45455\n",
      "Processing chunk 16851/45455\n",
      "Processing chunk 16901/45455\n",
      "Processing chunk 16951/45455\n",
      "Processing chunk 17001/45455\n",
      "Processing chunk 17051/45455\n",
      "Processing chunk 17101/45455\n",
      "Processing chunk 17151/45455\n",
      "Processing chunk 17201/45455\n",
      "Processing chunk 17251/45455\n",
      "Processing chunk 17301/45455\n",
      "Processing chunk 17351/45455\n",
      "Processing chunk 17401/45455\n",
      "Processing chunk 17451/45455\n",
      "Processing chunk 17501/45455\n",
      "Processing chunk 17551/45455\n",
      "Processing chunk 17601/45455\n",
      "Processing chunk 17651/45455\n",
      "Processing chunk 17701/45455\n",
      "Processing chunk 17751/45455\n",
      "Processing chunk 17801/45455\n",
      "Processing chunk 17851/45455\n",
      "Processing chunk 17901/45455\n",
      "Processing chunk 17951/45455\n",
      "Processing chunk 18001/45455\n",
      "Processing chunk 18051/45455\n",
      "Processing chunk 18101/45455\n",
      "Processing chunk 18151/45455\n",
      "Processing chunk 18201/45455\n",
      "Processing chunk 18251/45455\n",
      "Processing chunk 18301/45455\n",
      "Processing chunk 18351/45455\n",
      "Processing chunk 18401/45455\n",
      "Processing chunk 18451/45455\n",
      "Processing chunk 18501/45455\n",
      "Processing chunk 18551/45455\n",
      "Processing chunk 18601/45455\n",
      "Processing chunk 18651/45455\n",
      "Processing chunk 18701/45455\n",
      "Processing chunk 18751/45455\n",
      "Processing chunk 18801/45455\n",
      "Processing chunk 18851/45455\n",
      "Processing chunk 18901/45455\n",
      "Processing chunk 18951/45455\n",
      "Processing chunk 19001/45455\n",
      "Processing chunk 19051/45455\n",
      "Processing chunk 19101/45455\n",
      "Processing chunk 19151/45455\n",
      "Processing chunk 19201/45455\n",
      "Processing chunk 19251/45455\n",
      "Processing chunk 19301/45455\n",
      "Processing chunk 19351/45455\n",
      "Processing chunk 19401/45455\n",
      "Processing chunk 19451/45455\n",
      "Processing chunk 19501/45455\n",
      "Processing chunk 19551/45455\n",
      "Processing chunk 19601/45455\n",
      "Processing chunk 19651/45455\n",
      "Processing chunk 19701/45455\n",
      "Processing chunk 19751/45455\n",
      "Processing chunk 19801/45455\n",
      "Processing chunk 19851/45455\n",
      "Processing chunk 19901/45455\n",
      "Processing chunk 19951/45455\n",
      "Processing chunk 20001/45455\n",
      "Processing chunk 20051/45455\n",
      "Processing chunk 20101/45455\n",
      "Processing chunk 20151/45455\n",
      "Processing chunk 20201/45455\n",
      "Processing chunk 20251/45455\n",
      "Processing chunk 20301/45455\n",
      "Processing chunk 20351/45455\n",
      "Processing chunk 20401/45455\n",
      "Processing chunk 20451/45455\n",
      "Processing chunk 20501/45455\n",
      "Processing chunk 20551/45455\n",
      "Processing chunk 20601/45455\n",
      "Processing chunk 20651/45455\n",
      "Processing chunk 20701/45455\n",
      "Processing chunk 20751/45455\n",
      "Processing chunk 20801/45455\n",
      "Processing chunk 20851/45455\n",
      "Processing chunk 20901/45455\n",
      "Processing chunk 20951/45455\n",
      "Processing chunk 21001/45455\n",
      "Processing chunk 21051/45455\n",
      "Processing chunk 21101/45455\n",
      "Processing chunk 21151/45455\n",
      "Processing chunk 21201/45455\n",
      "Processing chunk 21251/45455\n",
      "Processing chunk 21301/45455\n",
      "Processing chunk 21351/45455\n",
      "Processing chunk 21401/45455\n",
      "Processing chunk 21451/45455\n",
      "Processing chunk 21501/45455\n",
      "Processing chunk 21551/45455\n",
      "Processing chunk 21601/45455\n",
      "Processing chunk 21651/45455\n",
      "Processing chunk 21701/45455\n",
      "Processing chunk 21751/45455\n",
      "Processing chunk 21801/45455\n",
      "Processing chunk 21851/45455\n",
      "Processing chunk 21901/45455\n",
      "Processing chunk 21951/45455\n",
      "Processing chunk 22001/45455\n",
      "Processing chunk 22051/45455\n",
      "Processing chunk 22101/45455\n",
      "Processing chunk 22151/45455\n",
      "Processing chunk 22201/45455\n",
      "Processing chunk 22251/45455\n",
      "Processing chunk 22301/45455\n",
      "Processing chunk 22351/45455\n",
      "Processing chunk 22401/45455\n",
      "Processing chunk 22451/45455\n",
      "Processing chunk 22501/45455\n",
      "Processing chunk 22551/45455\n",
      "Processing chunk 22601/45455\n",
      "Processing chunk 22651/45455\n",
      "Processing chunk 22701/45455\n",
      "Processing chunk 22751/45455\n",
      "Processing chunk 22801/45455\n",
      "Processing chunk 22851/45455\n",
      "Processing chunk 22901/45455\n",
      "Processing chunk 22951/45455\n",
      "Processing chunk 23001/45455\n",
      "Processing chunk 23051/45455\n",
      "Processing chunk 23101/45455\n",
      "Processing chunk 23151/45455\n",
      "Processing chunk 23201/45455\n",
      "Processing chunk 23251/45455\n",
      "Processing chunk 23301/45455\n",
      "Processing chunk 23351/45455\n",
      "Processing chunk 23401/45455\n",
      "Processing chunk 23451/45455\n",
      "Processing chunk 23501/45455\n",
      "Processing chunk 23551/45455\n",
      "Processing chunk 23601/45455\n",
      "Processing chunk 23651/45455\n",
      "Processing chunk 23701/45455\n",
      "Processing chunk 23751/45455\n",
      "Processing chunk 23801/45455\n",
      "Processing chunk 23851/45455\n",
      "Processing chunk 23901/45455\n",
      "Processing chunk 23951/45455\n",
      "Processing chunk 24001/45455\n",
      "Processing chunk 24051/45455\n",
      "Processing chunk 24101/45455\n",
      "Processing chunk 24151/45455\n",
      "Processing chunk 24201/45455\n",
      "Processing chunk 24251/45455\n",
      "Processing chunk 24301/45455\n",
      "Processing chunk 24351/45455\n",
      "Processing chunk 24401/45455\n",
      "Processing chunk 24451/45455\n",
      "Processing chunk 24501/45455\n",
      "Processing chunk 24551/45455\n",
      "Processing chunk 24601/45455\n",
      "Processing chunk 24651/45455\n",
      "Processing chunk 24701/45455\n",
      "Processing chunk 24751/45455\n",
      "Processing chunk 24801/45455\n",
      "Processing chunk 24851/45455\n",
      "Processing chunk 24901/45455\n",
      "Processing chunk 24951/45455\n",
      "Processing chunk 25001/45455\n",
      "Processing chunk 25051/45455\n",
      "Processing chunk 25101/45455\n",
      "Processing chunk 25151/45455\n",
      "Processing chunk 25201/45455\n",
      "Processing chunk 25251/45455\n",
      "Processing chunk 25301/45455\n",
      "Processing chunk 25351/45455\n",
      "Processing chunk 25401/45455\n",
      "Processing chunk 25451/45455\n",
      "Processing chunk 25501/45455\n",
      "Processing chunk 25551/45455\n",
      "Processing chunk 25601/45455\n",
      "Processing chunk 25651/45455\n",
      "Processing chunk 25701/45455\n",
      "Processing chunk 25751/45455\n",
      "Processing chunk 25801/45455\n",
      "Processing chunk 25851/45455\n",
      "Processing chunk 25901/45455\n",
      "Processing chunk 25951/45455\n",
      "Processing chunk 26001/45455\n",
      "Processing chunk 26051/45455\n",
      "Processing chunk 26101/45455\n",
      "Processing chunk 26151/45455\n",
      "Processing chunk 26201/45455\n",
      "Processing chunk 26251/45455\n",
      "Processing chunk 26301/45455\n",
      "Processing chunk 26351/45455\n",
      "Processing chunk 26401/45455\n",
      "Processing chunk 26451/45455\n",
      "Processing chunk 26501/45455\n",
      "Processing chunk 26551/45455\n",
      "Processing chunk 26601/45455\n",
      "Processing chunk 26651/45455\n",
      "Processing chunk 26701/45455\n",
      "Processing chunk 26751/45455\n",
      "Processing chunk 26801/45455\n",
      "Processing chunk 26851/45455\n",
      "Processing chunk 26901/45455\n",
      "Processing chunk 26951/45455\n",
      "Processing chunk 27001/45455\n",
      "Processing chunk 27051/45455\n",
      "Processing chunk 27101/45455\n",
      "Processing chunk 27151/45455\n",
      "Processing chunk 27201/45455\n",
      "Processing chunk 27251/45455\n",
      "Processing chunk 27301/45455\n",
      "Processing chunk 27351/45455\n",
      "Processing chunk 27401/45455\n",
      "Processing chunk 27451/45455\n",
      "Processing chunk 27501/45455\n",
      "Processing chunk 27551/45455\n",
      "Processing chunk 27601/45455\n",
      "Processing chunk 27651/45455\n",
      "Processing chunk 27701/45455\n",
      "Processing chunk 27751/45455\n",
      "Processing chunk 27801/45455\n",
      "Processing chunk 27851/45455\n",
      "Processing chunk 27901/45455\n",
      "Processing chunk 27951/45455\n",
      "Processing chunk 28001/45455\n",
      "Processing chunk 28051/45455\n",
      "Processing chunk 28101/45455\n",
      "Processing chunk 28151/45455\n",
      "Processing chunk 28201/45455\n",
      "Processing chunk 28251/45455\n",
      "Processing chunk 28301/45455\n",
      "Processing chunk 28351/45455\n",
      "Processing chunk 28401/45455\n",
      "Processing chunk 28451/45455\n",
      "Processing chunk 28501/45455\n",
      "Processing chunk 28551/45455\n",
      "Processing chunk 28601/45455\n",
      "Processing chunk 28651/45455\n",
      "Processing chunk 28701/45455\n",
      "Processing chunk 28751/45455\n",
      "Processing chunk 28801/45455\n",
      "Processing chunk 28851/45455\n",
      "Processing chunk 28901/45455\n",
      "Processing chunk 28951/45455\n",
      "Processing chunk 29001/45455\n",
      "Processing chunk 29051/45455\n",
      "Processing chunk 29101/45455\n",
      "Processing chunk 29151/45455\n",
      "Processing chunk 29201/45455\n",
      "Processing chunk 29251/45455\n",
      "Processing chunk 29301/45455\n",
      "Processing chunk 29351/45455\n",
      "Processing chunk 29401/45455\n",
      "Processing chunk 29451/45455\n",
      "Processing chunk 29501/45455\n",
      "Processing chunk 29551/45455\n",
      "Processing chunk 29601/45455\n",
      "Processing chunk 29651/45455\n",
      "Processing chunk 29701/45455\n",
      "Processing chunk 29751/45455\n",
      "Processing chunk 29801/45455\n",
      "Processing chunk 29851/45455\n",
      "Processing chunk 29901/45455\n",
      "Processing chunk 29951/45455\n",
      "Processing chunk 30001/45455\n",
      "Processing chunk 30051/45455\n",
      "Processing chunk 30101/45455\n",
      "Processing chunk 30151/45455\n",
      "Processing chunk 30201/45455\n",
      "Processing chunk 30251/45455\n",
      "Processing chunk 30301/45455\n",
      "Processing chunk 30351/45455\n",
      "Processing chunk 30401/45455\n",
      "Processing chunk 30451/45455\n",
      "Processing chunk 30501/45455\n",
      "Processing chunk 30551/45455\n",
      "Processing chunk 30601/45455\n",
      "Processing chunk 30651/45455\n",
      "Processing chunk 30701/45455\n",
      "Processing chunk 30751/45455\n",
      "Processing chunk 30801/45455\n",
      "Processing chunk 30851/45455\n",
      "Processing chunk 30901/45455\n",
      "Processing chunk 30951/45455\n",
      "Processing chunk 31001/45455\n",
      "Processing chunk 31051/45455\n",
      "Processing chunk 31101/45455\n",
      "Processing chunk 31151/45455\n",
      "Processing chunk 31201/45455\n",
      "Processing chunk 31251/45455\n",
      "Processing chunk 31301/45455\n",
      "Processing chunk 31351/45455\n",
      "Processing chunk 31401/45455\n",
      "Processing chunk 31451/45455\n",
      "Processing chunk 31501/45455\n",
      "Processing chunk 31551/45455\n",
      "Processing chunk 31601/45455\n",
      "Processing chunk 31651/45455\n",
      "Processing chunk 31701/45455\n",
      "Processing chunk 31751/45455\n",
      "Processing chunk 31801/45455\n",
      "Processing chunk 31851/45455\n",
      "Processing chunk 31901/45455\n",
      "Processing chunk 31951/45455\n",
      "Processing chunk 32001/45455\n",
      "Processing chunk 32051/45455\n",
      "Processing chunk 32101/45455\n",
      "Processing chunk 32151/45455\n",
      "Processing chunk 32201/45455\n",
      "Processing chunk 32251/45455\n",
      "Processing chunk 32301/45455\n",
      "Processing chunk 32351/45455\n",
      "Processing chunk 32401/45455\n",
      "Processing chunk 32451/45455\n",
      "Processing chunk 32501/45455\n",
      "Processing chunk 32551/45455\n",
      "Processing chunk 32601/45455\n",
      "Processing chunk 32651/45455\n",
      "Processing chunk 32701/45455\n",
      "Processing chunk 32751/45455\n",
      "Processing chunk 32801/45455\n",
      "Processing chunk 32851/45455\n",
      "Processing chunk 32901/45455\n",
      "Processing chunk 32951/45455\n",
      "Processing chunk 33001/45455\n",
      "Processing chunk 33051/45455\n",
      "Processing chunk 33101/45455\n",
      "Processing chunk 33151/45455\n",
      "Processing chunk 33201/45455\n",
      "Processing chunk 33251/45455\n",
      "Processing chunk 33301/45455\n",
      "Processing chunk 33351/45455\n",
      "Processing chunk 33401/45455\n",
      "Processing chunk 33451/45455\n",
      "Processing chunk 33501/45455\n",
      "Processing chunk 33551/45455\n",
      "Processing chunk 33601/45455\n",
      "Processing chunk 33651/45455\n",
      "Processing chunk 33701/45455\n",
      "Processing chunk 33751/45455\n",
      "Processing chunk 33801/45455\n",
      "Processing chunk 33851/45455\n",
      "Processing chunk 33901/45455\n",
      "Processing chunk 33951/45455\n",
      "Processing chunk 34001/45455\n",
      "Processing chunk 34051/45455\n",
      "Processing chunk 34101/45455\n",
      "Processing chunk 34151/45455\n",
      "Processing chunk 34201/45455\n",
      "Processing chunk 34251/45455\n",
      "Processing chunk 34301/45455\n",
      "Processing chunk 34351/45455\n",
      "Processing chunk 34401/45455\n",
      "Processing chunk 34451/45455\n",
      "Processing chunk 34501/45455\n",
      "Processing chunk 34551/45455\n",
      "Processing chunk 34601/45455\n",
      "Processing chunk 34651/45455\n",
      "Processing chunk 34701/45455\n",
      "Processing chunk 34751/45455\n",
      "Processing chunk 34801/45455\n",
      "Processing chunk 34851/45455\n",
      "Processing chunk 34901/45455\n",
      "Processing chunk 34951/45455\n",
      "Processing chunk 35001/45455\n",
      "Processing chunk 35051/45455\n",
      "Processing chunk 35101/45455\n",
      "Processing chunk 35151/45455\n",
      "Processing chunk 35201/45455\n",
      "Processing chunk 35251/45455\n",
      "Processing chunk 35301/45455\n",
      "Processing chunk 35351/45455\n",
      "Processing chunk 35401/45455\n",
      "Processing chunk 35451/45455\n",
      "Processing chunk 35501/45455\n",
      "Processing chunk 35551/45455\n",
      "Processing chunk 35601/45455\n",
      "Processing chunk 35651/45455\n",
      "Processing chunk 35701/45455\n",
      "Processing chunk 35751/45455\n",
      "Processing chunk 35801/45455\n",
      "Processing chunk 35851/45455\n",
      "Processing chunk 35901/45455\n",
      "Processing chunk 35951/45455\n",
      "Processing chunk 36001/45455\n",
      "Processing chunk 36051/45455\n",
      "Processing chunk 36101/45455\n",
      "Processing chunk 36151/45455\n",
      "Processing chunk 36201/45455\n",
      "Processing chunk 36251/45455\n",
      "Processing chunk 36301/45455\n",
      "Processing chunk 36351/45455\n",
      "Processing chunk 36401/45455\n",
      "Processing chunk 36451/45455\n",
      "Processing chunk 36501/45455\n",
      "Processing chunk 36551/45455\n",
      "Processing chunk 36601/45455\n",
      "Processing chunk 36651/45455\n",
      "Processing chunk 36701/45455\n",
      "Processing chunk 36751/45455\n",
      "Processing chunk 36801/45455\n",
      "Processing chunk 36851/45455\n",
      "Processing chunk 36901/45455\n",
      "Processing chunk 36951/45455\n",
      "Processing chunk 37001/45455\n",
      "Processing chunk 37051/45455\n",
      "Processing chunk 37101/45455\n",
      "Processing chunk 37151/45455\n",
      "Processing chunk 37201/45455\n",
      "Processing chunk 37251/45455\n",
      "Processing chunk 37301/45455\n",
      "Processing chunk 37351/45455\n",
      "Processing chunk 37401/45455\n",
      "Processing chunk 37451/45455\n",
      "Processing chunk 37501/45455\n",
      "Processing chunk 37551/45455\n",
      "Processing chunk 37601/45455\n",
      "Processing chunk 37651/45455\n",
      "Processing chunk 37701/45455\n",
      "Processing chunk 37751/45455\n",
      "Processing chunk 37801/45455\n",
      "Processing chunk 37851/45455\n",
      "Processing chunk 37901/45455\n",
      "Processing chunk 37951/45455\n",
      "Processing chunk 38001/45455\n",
      "Processing chunk 38051/45455\n",
      "Processing chunk 38101/45455\n",
      "Processing chunk 38151/45455\n",
      "Processing chunk 38201/45455\n",
      "Processing chunk 38251/45455\n",
      "Processing chunk 38301/45455\n",
      "Processing chunk 38351/45455\n",
      "Processing chunk 38401/45455\n",
      "Processing chunk 38451/45455\n",
      "Processing chunk 38501/45455\n",
      "Processing chunk 38551/45455\n",
      "Processing chunk 38601/45455\n",
      "Processing chunk 38651/45455\n",
      "Processing chunk 38701/45455\n",
      "Processing chunk 38751/45455\n",
      "Processing chunk 38801/45455\n",
      "Processing chunk 38851/45455\n",
      "Processing chunk 38901/45455\n",
      "Processing chunk 38951/45455\n",
      "Processing chunk 39001/45455\n",
      "Processing chunk 39051/45455\n",
      "Processing chunk 39101/45455\n",
      "Processing chunk 39151/45455\n",
      "Processing chunk 39201/45455\n",
      "Processing chunk 39251/45455\n",
      "Processing chunk 39301/45455\n",
      "Processing chunk 39351/45455\n",
      "Processing chunk 39401/45455\n",
      "Processing chunk 39451/45455\n",
      "Processing chunk 39501/45455\n",
      "Processing chunk 39551/45455\n",
      "Processing chunk 39601/45455\n",
      "Processing chunk 39651/45455\n",
      "Processing chunk 39701/45455\n",
      "Processing chunk 39751/45455\n",
      "Processing chunk 39801/45455\n",
      "Processing chunk 39851/45455\n",
      "Processing chunk 39901/45455\n",
      "Processing chunk 39951/45455\n",
      "Processing chunk 40001/45455\n",
      "Processing chunk 40051/45455\n",
      "Processing chunk 40101/45455\n",
      "Processing chunk 40151/45455\n",
      "Processing chunk 40201/45455\n",
      "Processing chunk 40251/45455\n",
      "Processing chunk 40301/45455\n",
      "Processing chunk 40351/45455\n",
      "Processing chunk 40401/45455\n",
      "Processing chunk 40451/45455\n",
      "Processing chunk 40501/45455\n",
      "Processing chunk 40551/45455\n",
      "Processing chunk 40601/45455\n",
      "Processing chunk 40651/45455\n",
      "Processing chunk 40701/45455\n",
      "Processing chunk 40751/45455\n",
      "Processing chunk 40801/45455\n",
      "Processing chunk 40851/45455\n",
      "Processing chunk 40901/45455\n",
      "Processing chunk 40951/45455\n",
      "Processing chunk 41001/45455\n",
      "Processing chunk 41051/45455\n",
      "Processing chunk 41101/45455\n",
      "Processing chunk 41151/45455\n",
      "Processing chunk 41201/45455\n",
      "Processing chunk 41251/45455\n",
      "Processing chunk 41301/45455\n",
      "Processing chunk 41351/45455\n",
      "Processing chunk 41401/45455\n",
      "Processing chunk 41451/45455\n",
      "Processing chunk 41501/45455\n",
      "Processing chunk 41551/45455\n",
      "Processing chunk 41601/45455\n",
      "Processing chunk 41651/45455\n",
      "Processing chunk 41701/45455\n",
      "Processing chunk 41751/45455\n",
      "Processing chunk 41801/45455\n",
      "Processing chunk 41851/45455\n",
      "Processing chunk 41901/45455\n",
      "Processing chunk 41951/45455\n",
      "Processing chunk 42001/45455\n",
      "Processing chunk 42051/45455\n",
      "Processing chunk 42101/45455\n",
      "Processing chunk 42151/45455\n",
      "Processing chunk 42201/45455\n",
      "Processing chunk 42251/45455\n",
      "Processing chunk 42301/45455\n",
      "Processing chunk 42351/45455\n",
      "Processing chunk 42401/45455\n",
      "Processing chunk 42451/45455\n",
      "Processing chunk 42501/45455\n",
      "Processing chunk 42551/45455\n",
      "Processing chunk 42601/45455\n",
      "Processing chunk 42651/45455\n",
      "Processing chunk 42701/45455\n",
      "Processing chunk 42751/45455\n",
      "Processing chunk 42801/45455\n",
      "Processing chunk 42851/45455\n",
      "Processing chunk 42901/45455\n",
      "Processing chunk 42951/45455\n",
      "Processing chunk 43001/45455\n",
      "Processing chunk 43051/45455\n",
      "Processing chunk 43101/45455\n",
      "Processing chunk 43151/45455\n",
      "Processing chunk 43201/45455\n",
      "Processing chunk 43251/45455\n",
      "Processing chunk 43301/45455\n",
      "Processing chunk 43351/45455\n",
      "Processing chunk 43401/45455\n",
      "Processing chunk 43451/45455\n",
      "Processing chunk 43501/45455\n",
      "Processing chunk 43551/45455\n",
      "Processing chunk 43601/45455\n",
      "Processing chunk 43651/45455\n",
      "Processing chunk 43701/45455\n",
      "Processing chunk 43751/45455\n",
      "Processing chunk 43801/45455\n",
      "Processing chunk 43851/45455\n",
      "Processing chunk 43901/45455\n",
      "Processing chunk 43951/45455\n",
      "Processing chunk 44001/45455\n",
      "Processing chunk 44051/45455\n",
      "Processing chunk 44101/45455\n",
      "Processing chunk 44151/45455\n",
      "Processing chunk 44201/45455\n",
      "Processing chunk 44251/45455\n",
      "Processing chunk 44301/45455\n",
      "Processing chunk 44351/45455\n",
      "Processing chunk 44401/45455\n",
      "Processing chunk 44451/45455\n",
      "Processing chunk 44501/45455\n",
      "Processing chunk 44551/45455\n",
      "Processing chunk 44601/45455\n",
      "Processing chunk 44651/45455\n",
      "Processing chunk 44701/45455\n",
      "Processing chunk 44751/45455\n",
      "Processing chunk 44801/45455\n",
      "Processing chunk 44851/45455\n",
      "Processing chunk 44901/45455\n",
      "Processing chunk 44951/45455\n",
      "Processing chunk 45001/45455\n",
      "Processing chunk 45051/45455\n",
      "Processing chunk 45101/45455\n",
      "Processing chunk 45151/45455\n",
      "Processing chunk 45201/45455\n",
      "Processing chunk 45251/45455\n",
      "Processing chunk 45301/45455\n",
      "Processing chunk 45351/45455\n",
      "Processing chunk 45401/45455\n",
      "Processing chunk 45451/45455\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 10000\n",
      "Number of hits: 9918\n",
      "Average HR@20: 0.9918\n",
      "Average NDCG@20: 0.4645\n",
      "\n",
      "Training and evaluating MBGCN...\n",
      "Epoch 1, Loss: 0.7738\n",
      "Epoch 2, Loss: 0.5832\n",
      "Epoch 3, Loss: 0.4773\n",
      "Epoch 4, Loss: 0.4152\n",
      "Epoch 5, Loss: 0.3681\n",
      "Epoch 6, Loss: 0.3247\n",
      "Epoch 7, Loss: 0.2840\n",
      "Epoch 8, Loss: 0.2477\n",
      "Epoch 9, Loss: 0.2165\n",
      "Epoch 10, Loss: 0.1894\n",
      "Training completed in 1.87s\n",
      "Preparing test instances...\n",
      "Generated 1000000 test instances\n",
      "Evaluating 1000000 instances in 45455 chunks...\n",
      "Processing chunk 1/45455\n",
      "Processing chunk 51/45455\n",
      "Processing chunk 101/45455\n",
      "Processing chunk 151/45455\n",
      "Processing chunk 201/45455\n",
      "Processing chunk 251/45455\n",
      "Processing chunk 301/45455\n",
      "Processing chunk 351/45455\n",
      "Processing chunk 401/45455\n",
      "Processing chunk 451/45455\n",
      "Processing chunk 501/45455\n",
      "Processing chunk 551/45455\n",
      "Processing chunk 601/45455\n",
      "Processing chunk 651/45455\n",
      "Processing chunk 701/45455\n",
      "Processing chunk 751/45455\n",
      "Processing chunk 801/45455\n",
      "Processing chunk 851/45455\n",
      "Processing chunk 901/45455\n",
      "Processing chunk 951/45455\n",
      "Processing chunk 1001/45455\n",
      "Processing chunk 1051/45455\n",
      "Processing chunk 1101/45455\n",
      "Processing chunk 1151/45455\n",
      "Processing chunk 1201/45455\n",
      "Processing chunk 1251/45455\n",
      "Processing chunk 1301/45455\n",
      "Processing chunk 1351/45455\n",
      "Processing chunk 1401/45455\n",
      "Processing chunk 1451/45455\n",
      "Processing chunk 1501/45455\n",
      "Processing chunk 1551/45455\n",
      "Processing chunk 1601/45455\n",
      "Processing chunk 1651/45455\n",
      "Processing chunk 1701/45455\n",
      "Processing chunk 1751/45455\n",
      "Processing chunk 1801/45455\n",
      "Processing chunk 1851/45455\n",
      "Processing chunk 1901/45455\n",
      "Processing chunk 1951/45455\n",
      "Processing chunk 2001/45455\n",
      "Processing chunk 2051/45455\n",
      "Processing chunk 2101/45455\n",
      "Processing chunk 2151/45455\n",
      "Processing chunk 2201/45455\n",
      "Processing chunk 2251/45455\n",
      "Processing chunk 2301/45455\n",
      "Processing chunk 2351/45455\n",
      "Processing chunk 2401/45455\n",
      "Processing chunk 2451/45455\n",
      "Processing chunk 2501/45455\n",
      "Processing chunk 2551/45455\n",
      "Processing chunk 2601/45455\n",
      "Processing chunk 2651/45455\n",
      "Processing chunk 2701/45455\n",
      "Processing chunk 2751/45455\n",
      "Processing chunk 2801/45455\n",
      "Processing chunk 2851/45455\n",
      "Processing chunk 2901/45455\n",
      "Processing chunk 2951/45455\n",
      "Processing chunk 3001/45455\n",
      "Processing chunk 3051/45455\n",
      "Processing chunk 3101/45455\n",
      "Processing chunk 3151/45455\n",
      "Processing chunk 3201/45455\n",
      "Processing chunk 3251/45455\n",
      "Processing chunk 3301/45455\n",
      "Processing chunk 3351/45455\n",
      "Processing chunk 3401/45455\n",
      "Processing chunk 3451/45455\n",
      "Processing chunk 3501/45455\n",
      "Processing chunk 3551/45455\n",
      "Processing chunk 3601/45455\n",
      "Processing chunk 3651/45455\n",
      "Processing chunk 3701/45455\n",
      "Processing chunk 3751/45455\n",
      "Processing chunk 3801/45455\n",
      "Processing chunk 3851/45455\n",
      "Processing chunk 3901/45455\n",
      "Processing chunk 3951/45455\n",
      "Processing chunk 4001/45455\n",
      "Processing chunk 4051/45455\n",
      "Processing chunk 4101/45455\n",
      "Processing chunk 4151/45455\n",
      "Processing chunk 4201/45455\n",
      "Processing chunk 4251/45455\n",
      "Processing chunk 4301/45455\n",
      "Processing chunk 4351/45455\n",
      "Processing chunk 4401/45455\n",
      "Processing chunk 4451/45455\n",
      "Processing chunk 4501/45455\n",
      "Processing chunk 4551/45455\n",
      "Processing chunk 4601/45455\n",
      "Processing chunk 4651/45455\n",
      "Processing chunk 4701/45455\n",
      "Processing chunk 4751/45455\n",
      "Processing chunk 4801/45455\n",
      "Processing chunk 4851/45455\n",
      "Processing chunk 4901/45455\n",
      "Processing chunk 4951/45455\n",
      "Processing chunk 5001/45455\n",
      "Processing chunk 5051/45455\n",
      "Processing chunk 5101/45455\n",
      "Processing chunk 5151/45455\n",
      "Processing chunk 5201/45455\n",
      "Processing chunk 5251/45455\n",
      "Processing chunk 5301/45455\n",
      "Processing chunk 5351/45455\n",
      "Processing chunk 5401/45455\n",
      "Processing chunk 5451/45455\n",
      "Processing chunk 5501/45455\n",
      "Processing chunk 5551/45455\n",
      "Processing chunk 5601/45455\n",
      "Processing chunk 5651/45455\n",
      "Processing chunk 5701/45455\n",
      "Processing chunk 5751/45455\n",
      "Processing chunk 5801/45455\n",
      "Processing chunk 5851/45455\n",
      "Processing chunk 5901/45455\n",
      "Processing chunk 5951/45455\n",
      "Processing chunk 6001/45455\n",
      "Processing chunk 6051/45455\n",
      "Processing chunk 6101/45455\n",
      "Processing chunk 6151/45455\n",
      "Processing chunk 6201/45455\n",
      "Processing chunk 6251/45455\n",
      "Processing chunk 6301/45455\n",
      "Processing chunk 6351/45455\n",
      "Processing chunk 6401/45455\n",
      "Processing chunk 6451/45455\n",
      "Processing chunk 6501/45455\n",
      "Processing chunk 6551/45455\n",
      "Processing chunk 6601/45455\n",
      "Processing chunk 6651/45455\n",
      "Processing chunk 6701/45455\n",
      "Processing chunk 6751/45455\n",
      "Processing chunk 6801/45455\n",
      "Processing chunk 6851/45455\n",
      "Processing chunk 6901/45455\n",
      "Processing chunk 6951/45455\n",
      "Processing chunk 7001/45455\n",
      "Processing chunk 7051/45455\n",
      "Processing chunk 7101/45455\n",
      "Processing chunk 7151/45455\n",
      "Processing chunk 7201/45455\n",
      "Processing chunk 7251/45455\n",
      "Processing chunk 7301/45455\n",
      "Processing chunk 7351/45455\n",
      "Processing chunk 7401/45455\n",
      "Processing chunk 7451/45455\n",
      "Processing chunk 7501/45455\n",
      "Processing chunk 7551/45455\n",
      "Processing chunk 7601/45455\n",
      "Processing chunk 7651/45455\n",
      "Processing chunk 7701/45455\n",
      "Processing chunk 7751/45455\n",
      "Processing chunk 7801/45455\n",
      "Processing chunk 7851/45455\n",
      "Processing chunk 7901/45455\n",
      "Processing chunk 7951/45455\n",
      "Processing chunk 8001/45455\n",
      "Processing chunk 8051/45455\n",
      "Processing chunk 8101/45455\n",
      "Processing chunk 8151/45455\n",
      "Processing chunk 8201/45455\n",
      "Processing chunk 8251/45455\n",
      "Processing chunk 8301/45455\n",
      "Processing chunk 8351/45455\n",
      "Processing chunk 8401/45455\n",
      "Processing chunk 8451/45455\n",
      "Processing chunk 8501/45455\n",
      "Processing chunk 8551/45455\n",
      "Processing chunk 8601/45455\n",
      "Processing chunk 8651/45455\n",
      "Processing chunk 8701/45455\n",
      "Processing chunk 8751/45455\n",
      "Processing chunk 8801/45455\n",
      "Processing chunk 8851/45455\n",
      "Processing chunk 8901/45455\n",
      "Processing chunk 8951/45455\n",
      "Processing chunk 9001/45455\n",
      "Processing chunk 9051/45455\n",
      "Processing chunk 9101/45455\n",
      "Processing chunk 9151/45455\n",
      "Processing chunk 9201/45455\n",
      "Processing chunk 9251/45455\n",
      "Processing chunk 9301/45455\n",
      "Processing chunk 9351/45455\n",
      "Processing chunk 9401/45455\n",
      "Processing chunk 9451/45455\n",
      "Processing chunk 9501/45455\n",
      "Processing chunk 9551/45455\n",
      "Processing chunk 9601/45455\n",
      "Processing chunk 9651/45455\n",
      "Processing chunk 9701/45455\n",
      "Processing chunk 9751/45455\n",
      "Processing chunk 9801/45455\n",
      "Processing chunk 9851/45455\n",
      "Processing chunk 9901/45455\n",
      "Processing chunk 9951/45455\n",
      "Processing chunk 10001/45455\n",
      "Processing chunk 10051/45455\n",
      "Processing chunk 10101/45455\n",
      "Processing chunk 10151/45455\n",
      "Processing chunk 10201/45455\n",
      "Processing chunk 10251/45455\n",
      "Processing chunk 10301/45455\n",
      "Processing chunk 10351/45455\n",
      "Processing chunk 10401/45455\n",
      "Processing chunk 10451/45455\n",
      "Processing chunk 10501/45455\n",
      "Processing chunk 10551/45455\n",
      "Processing chunk 10601/45455\n",
      "Processing chunk 10651/45455\n",
      "Processing chunk 10701/45455\n",
      "Processing chunk 10751/45455\n",
      "Processing chunk 10801/45455\n",
      "Processing chunk 10851/45455\n",
      "Processing chunk 10901/45455\n",
      "Processing chunk 10951/45455\n",
      "Processing chunk 11001/45455\n",
      "Processing chunk 11051/45455\n",
      "Processing chunk 11101/45455\n",
      "Processing chunk 11151/45455\n",
      "Processing chunk 11201/45455\n",
      "Processing chunk 11251/45455\n",
      "Processing chunk 11301/45455\n",
      "Processing chunk 11351/45455\n",
      "Processing chunk 11401/45455\n",
      "Processing chunk 11451/45455\n",
      "Processing chunk 11501/45455\n",
      "Processing chunk 11551/45455\n",
      "Processing chunk 11601/45455\n",
      "Processing chunk 11651/45455\n",
      "Processing chunk 11701/45455\n",
      "Processing chunk 11751/45455\n",
      "Processing chunk 11801/45455\n",
      "Processing chunk 11851/45455\n",
      "Processing chunk 11901/45455\n",
      "Processing chunk 11951/45455\n",
      "Processing chunk 12001/45455\n",
      "Processing chunk 12051/45455\n",
      "Processing chunk 12101/45455\n",
      "Processing chunk 12151/45455\n",
      "Processing chunk 12201/45455\n",
      "Processing chunk 12251/45455\n",
      "Processing chunk 12301/45455\n",
      "Processing chunk 12351/45455\n",
      "Processing chunk 12401/45455\n",
      "Processing chunk 12451/45455\n",
      "Processing chunk 12501/45455\n",
      "Processing chunk 12551/45455\n",
      "Processing chunk 12601/45455\n",
      "Processing chunk 12651/45455\n",
      "Processing chunk 12701/45455\n",
      "Processing chunk 12751/45455\n",
      "Processing chunk 12801/45455\n",
      "Processing chunk 12851/45455\n",
      "Processing chunk 12901/45455\n",
      "Processing chunk 12951/45455\n",
      "Processing chunk 13001/45455\n",
      "Processing chunk 13051/45455\n",
      "Processing chunk 13101/45455\n",
      "Processing chunk 13151/45455\n",
      "Processing chunk 13201/45455\n",
      "Processing chunk 13251/45455\n",
      "Processing chunk 13301/45455\n",
      "Processing chunk 13351/45455\n",
      "Processing chunk 13401/45455\n",
      "Processing chunk 13451/45455\n",
      "Processing chunk 13501/45455\n",
      "Processing chunk 13551/45455\n",
      "Processing chunk 13601/45455\n",
      "Processing chunk 13651/45455\n",
      "Processing chunk 13701/45455\n",
      "Processing chunk 13751/45455\n",
      "Processing chunk 13801/45455\n",
      "Processing chunk 13851/45455\n",
      "Processing chunk 13901/45455\n",
      "Processing chunk 13951/45455\n",
      "Processing chunk 14001/45455\n",
      "Processing chunk 14051/45455\n",
      "Processing chunk 14101/45455\n",
      "Processing chunk 14151/45455\n",
      "Processing chunk 14201/45455\n",
      "Processing chunk 14251/45455\n",
      "Processing chunk 14301/45455\n",
      "Processing chunk 14351/45455\n",
      "Processing chunk 14401/45455\n",
      "Processing chunk 14451/45455\n",
      "Processing chunk 14501/45455\n",
      "Processing chunk 14551/45455\n",
      "Processing chunk 14601/45455\n",
      "Processing chunk 14651/45455\n",
      "Processing chunk 14701/45455\n",
      "Processing chunk 14751/45455\n",
      "Processing chunk 14801/45455\n",
      "Processing chunk 14851/45455\n",
      "Processing chunk 14901/45455\n",
      "Processing chunk 14951/45455\n",
      "Processing chunk 15001/45455\n",
      "Processing chunk 15051/45455\n",
      "Processing chunk 15101/45455\n",
      "Processing chunk 15151/45455\n",
      "Processing chunk 15201/45455\n",
      "Processing chunk 15251/45455\n",
      "Processing chunk 15301/45455\n",
      "Processing chunk 15351/45455\n",
      "Processing chunk 15401/45455\n",
      "Processing chunk 15451/45455\n",
      "Processing chunk 15501/45455\n",
      "Processing chunk 15551/45455\n",
      "Processing chunk 15601/45455\n",
      "Processing chunk 15651/45455\n",
      "Processing chunk 15701/45455\n",
      "Processing chunk 15751/45455\n",
      "Processing chunk 15801/45455\n",
      "Processing chunk 15851/45455\n",
      "Processing chunk 15901/45455\n",
      "Processing chunk 15951/45455\n",
      "Processing chunk 16001/45455\n",
      "Processing chunk 16051/45455\n",
      "Processing chunk 16101/45455\n",
      "Processing chunk 16151/45455\n",
      "Processing chunk 16201/45455\n",
      "Processing chunk 16251/45455\n",
      "Processing chunk 16301/45455\n",
      "Processing chunk 16351/45455\n",
      "Processing chunk 16401/45455\n",
      "Processing chunk 16451/45455\n",
      "Processing chunk 16501/45455\n",
      "Processing chunk 16551/45455\n",
      "Processing chunk 16601/45455\n",
      "Processing chunk 16651/45455\n",
      "Processing chunk 16701/45455\n",
      "Processing chunk 16751/45455\n",
      "Processing chunk 16801/45455\n",
      "Processing chunk 16851/45455\n",
      "Processing chunk 16901/45455\n",
      "Processing chunk 16951/45455\n",
      "Processing chunk 17001/45455\n",
      "Processing chunk 17051/45455\n",
      "Processing chunk 17101/45455\n",
      "Processing chunk 17151/45455\n",
      "Processing chunk 17201/45455\n",
      "Processing chunk 17251/45455\n",
      "Processing chunk 17301/45455\n",
      "Processing chunk 17351/45455\n",
      "Processing chunk 17401/45455\n",
      "Processing chunk 17451/45455\n",
      "Processing chunk 17501/45455\n",
      "Processing chunk 17551/45455\n",
      "Processing chunk 17601/45455\n",
      "Processing chunk 17651/45455\n",
      "Processing chunk 17701/45455\n",
      "Processing chunk 17751/45455\n",
      "Processing chunk 17801/45455\n",
      "Processing chunk 17851/45455\n",
      "Processing chunk 17901/45455\n",
      "Processing chunk 17951/45455\n",
      "Processing chunk 18001/45455\n",
      "Processing chunk 18051/45455\n",
      "Processing chunk 18101/45455\n",
      "Processing chunk 18151/45455\n",
      "Processing chunk 18201/45455\n",
      "Processing chunk 18251/45455\n",
      "Processing chunk 18301/45455\n",
      "Processing chunk 18351/45455\n",
      "Processing chunk 18401/45455\n",
      "Processing chunk 18451/45455\n",
      "Processing chunk 18501/45455\n",
      "Processing chunk 18551/45455\n",
      "Processing chunk 18601/45455\n",
      "Processing chunk 18651/45455\n",
      "Processing chunk 18701/45455\n",
      "Processing chunk 18751/45455\n",
      "Processing chunk 18801/45455\n",
      "Processing chunk 18851/45455\n",
      "Processing chunk 18901/45455\n",
      "Processing chunk 18951/45455\n",
      "Processing chunk 19001/45455\n",
      "Processing chunk 19051/45455\n",
      "Processing chunk 19101/45455\n",
      "Processing chunk 19151/45455\n",
      "Processing chunk 19201/45455\n",
      "Processing chunk 19251/45455\n",
      "Processing chunk 19301/45455\n",
      "Processing chunk 19351/45455\n",
      "Processing chunk 19401/45455\n",
      "Processing chunk 19451/45455\n",
      "Processing chunk 19501/45455\n",
      "Processing chunk 19551/45455\n",
      "Processing chunk 19601/45455\n",
      "Processing chunk 19651/45455\n",
      "Processing chunk 19701/45455\n",
      "Processing chunk 19751/45455\n",
      "Processing chunk 19801/45455\n",
      "Processing chunk 19851/45455\n",
      "Processing chunk 19901/45455\n",
      "Processing chunk 19951/45455\n",
      "Processing chunk 20001/45455\n",
      "Processing chunk 20051/45455\n",
      "Processing chunk 20101/45455\n",
      "Processing chunk 20151/45455\n",
      "Processing chunk 20201/45455\n",
      "Processing chunk 20251/45455\n",
      "Processing chunk 20301/45455\n",
      "Processing chunk 20351/45455\n",
      "Processing chunk 20401/45455\n",
      "Processing chunk 20451/45455\n",
      "Processing chunk 20501/45455\n",
      "Processing chunk 20551/45455\n",
      "Processing chunk 20601/45455\n",
      "Processing chunk 20651/45455\n",
      "Processing chunk 20701/45455\n",
      "Processing chunk 20751/45455\n",
      "Processing chunk 20801/45455\n",
      "Processing chunk 20851/45455\n",
      "Processing chunk 20901/45455\n",
      "Processing chunk 20951/45455\n",
      "Processing chunk 21001/45455\n",
      "Processing chunk 21051/45455\n",
      "Processing chunk 21101/45455\n",
      "Processing chunk 21151/45455\n",
      "Processing chunk 21201/45455\n",
      "Processing chunk 21251/45455\n",
      "Processing chunk 21301/45455\n",
      "Processing chunk 21351/45455\n",
      "Processing chunk 21401/45455\n",
      "Processing chunk 21451/45455\n",
      "Processing chunk 21501/45455\n",
      "Processing chunk 21551/45455\n",
      "Processing chunk 21601/45455\n",
      "Processing chunk 21651/45455\n",
      "Processing chunk 21701/45455\n",
      "Processing chunk 21751/45455\n",
      "Processing chunk 21801/45455\n",
      "Processing chunk 21851/45455\n",
      "Processing chunk 21901/45455\n",
      "Processing chunk 21951/45455\n",
      "Processing chunk 22001/45455\n",
      "Processing chunk 22051/45455\n",
      "Processing chunk 22101/45455\n",
      "Processing chunk 22151/45455\n",
      "Processing chunk 22201/45455\n",
      "Processing chunk 22251/45455\n",
      "Processing chunk 22301/45455\n",
      "Processing chunk 22351/45455\n",
      "Processing chunk 22401/45455\n",
      "Processing chunk 22451/45455\n",
      "Processing chunk 22501/45455\n",
      "Processing chunk 22551/45455\n",
      "Processing chunk 22601/45455\n",
      "Processing chunk 22651/45455\n",
      "Processing chunk 22701/45455\n",
      "Processing chunk 22751/45455\n",
      "Processing chunk 22801/45455\n",
      "Processing chunk 22851/45455\n",
      "Processing chunk 22901/45455\n",
      "Processing chunk 22951/45455\n",
      "Processing chunk 23001/45455\n",
      "Processing chunk 23051/45455\n",
      "Processing chunk 23101/45455\n",
      "Processing chunk 23151/45455\n",
      "Processing chunk 23201/45455\n",
      "Processing chunk 23251/45455\n",
      "Processing chunk 23301/45455\n",
      "Processing chunk 23351/45455\n",
      "Processing chunk 23401/45455\n",
      "Processing chunk 23451/45455\n",
      "Processing chunk 23501/45455\n",
      "Processing chunk 23551/45455\n",
      "Processing chunk 23601/45455\n",
      "Processing chunk 23651/45455\n",
      "Processing chunk 23701/45455\n",
      "Processing chunk 23751/45455\n",
      "Processing chunk 23801/45455\n",
      "Processing chunk 23851/45455\n",
      "Processing chunk 23901/45455\n",
      "Processing chunk 23951/45455\n",
      "Processing chunk 24001/45455\n",
      "Processing chunk 24051/45455\n",
      "Processing chunk 24101/45455\n",
      "Processing chunk 24151/45455\n",
      "Processing chunk 24201/45455\n",
      "Processing chunk 24251/45455\n",
      "Processing chunk 24301/45455\n",
      "Processing chunk 24351/45455\n",
      "Processing chunk 24401/45455\n",
      "Processing chunk 24451/45455\n",
      "Processing chunk 24501/45455\n",
      "Processing chunk 24551/45455\n",
      "Processing chunk 24601/45455\n",
      "Processing chunk 24651/45455\n",
      "Processing chunk 24701/45455\n",
      "Processing chunk 24751/45455\n",
      "Processing chunk 24801/45455\n",
      "Processing chunk 24851/45455\n",
      "Processing chunk 24901/45455\n",
      "Processing chunk 24951/45455\n",
      "Processing chunk 25001/45455\n",
      "Processing chunk 25051/45455\n",
      "Processing chunk 25101/45455\n",
      "Processing chunk 25151/45455\n",
      "Processing chunk 25201/45455\n",
      "Processing chunk 25251/45455\n",
      "Processing chunk 25301/45455\n",
      "Processing chunk 25351/45455\n",
      "Processing chunk 25401/45455\n",
      "Processing chunk 25451/45455\n",
      "Processing chunk 25501/45455\n",
      "Processing chunk 25551/45455\n",
      "Processing chunk 25601/45455\n",
      "Processing chunk 25651/45455\n",
      "Processing chunk 25701/45455\n",
      "Processing chunk 25751/45455\n",
      "Processing chunk 25801/45455\n",
      "Processing chunk 25851/45455\n",
      "Processing chunk 25901/45455\n",
      "Processing chunk 25951/45455\n",
      "Processing chunk 26001/45455\n",
      "Processing chunk 26051/45455\n",
      "Processing chunk 26101/45455\n",
      "Processing chunk 26151/45455\n",
      "Processing chunk 26201/45455\n",
      "Processing chunk 26251/45455\n",
      "Processing chunk 26301/45455\n",
      "Processing chunk 26351/45455\n",
      "Processing chunk 26401/45455\n",
      "Processing chunk 26451/45455\n",
      "Processing chunk 26501/45455\n",
      "Processing chunk 26551/45455\n",
      "Processing chunk 26601/45455\n",
      "Processing chunk 26651/45455\n",
      "Processing chunk 26701/45455\n",
      "Processing chunk 26751/45455\n",
      "Processing chunk 26801/45455\n",
      "Processing chunk 26851/45455\n",
      "Processing chunk 26901/45455\n",
      "Processing chunk 26951/45455\n",
      "Processing chunk 27001/45455\n",
      "Processing chunk 27051/45455\n",
      "Processing chunk 27101/45455\n",
      "Processing chunk 27151/45455\n",
      "Processing chunk 27201/45455\n",
      "Processing chunk 27251/45455\n",
      "Processing chunk 27301/45455\n",
      "Processing chunk 27351/45455\n",
      "Processing chunk 27401/45455\n",
      "Processing chunk 27451/45455\n",
      "Processing chunk 27501/45455\n",
      "Processing chunk 27551/45455\n",
      "Processing chunk 27601/45455\n",
      "Processing chunk 27651/45455\n",
      "Processing chunk 27701/45455\n",
      "Processing chunk 27751/45455\n",
      "Processing chunk 27801/45455\n",
      "Processing chunk 27851/45455\n",
      "Processing chunk 27901/45455\n",
      "Processing chunk 27951/45455\n",
      "Processing chunk 28001/45455\n",
      "Processing chunk 28051/45455\n",
      "Processing chunk 28101/45455\n",
      "Processing chunk 28151/45455\n",
      "Processing chunk 28201/45455\n",
      "Processing chunk 28251/45455\n",
      "Processing chunk 28301/45455\n",
      "Processing chunk 28351/45455\n",
      "Processing chunk 28401/45455\n",
      "Processing chunk 28451/45455\n",
      "Processing chunk 28501/45455\n",
      "Processing chunk 28551/45455\n",
      "Processing chunk 28601/45455\n",
      "Processing chunk 28651/45455\n",
      "Processing chunk 28701/45455\n",
      "Processing chunk 28751/45455\n",
      "Processing chunk 28801/45455\n",
      "Processing chunk 28851/45455\n",
      "Processing chunk 28901/45455\n",
      "Processing chunk 28951/45455\n",
      "Processing chunk 29001/45455\n",
      "Processing chunk 29051/45455\n",
      "Processing chunk 29101/45455\n",
      "Processing chunk 29151/45455\n",
      "Processing chunk 29201/45455\n",
      "Processing chunk 29251/45455\n",
      "Processing chunk 29301/45455\n",
      "Processing chunk 29351/45455\n",
      "Processing chunk 29401/45455\n",
      "Processing chunk 29451/45455\n",
      "Processing chunk 29501/45455\n",
      "Processing chunk 29551/45455\n",
      "Processing chunk 29601/45455\n",
      "Processing chunk 29651/45455\n",
      "Processing chunk 29701/45455\n",
      "Processing chunk 29751/45455\n",
      "Processing chunk 29801/45455\n",
      "Processing chunk 29851/45455\n",
      "Processing chunk 29901/45455\n",
      "Processing chunk 29951/45455\n",
      "Processing chunk 30001/45455\n",
      "Processing chunk 30051/45455\n",
      "Processing chunk 30101/45455\n",
      "Processing chunk 30151/45455\n",
      "Processing chunk 30201/45455\n",
      "Processing chunk 30251/45455\n",
      "Processing chunk 30301/45455\n",
      "Processing chunk 30351/45455\n",
      "Processing chunk 30401/45455\n",
      "Processing chunk 30451/45455\n",
      "Processing chunk 30501/45455\n",
      "Processing chunk 30551/45455\n",
      "Processing chunk 30601/45455\n",
      "Processing chunk 30651/45455\n",
      "Processing chunk 30701/45455\n",
      "Processing chunk 30751/45455\n",
      "Processing chunk 30801/45455\n",
      "Processing chunk 30851/45455\n",
      "Processing chunk 30901/45455\n",
      "Processing chunk 30951/45455\n",
      "Processing chunk 31001/45455\n",
      "Processing chunk 31051/45455\n",
      "Processing chunk 31101/45455\n",
      "Processing chunk 31151/45455\n",
      "Processing chunk 31201/45455\n",
      "Processing chunk 31251/45455\n",
      "Processing chunk 31301/45455\n",
      "Processing chunk 31351/45455\n",
      "Processing chunk 31401/45455\n",
      "Processing chunk 31451/45455\n",
      "Processing chunk 31501/45455\n",
      "Processing chunk 31551/45455\n",
      "Processing chunk 31601/45455\n",
      "Processing chunk 31651/45455\n",
      "Processing chunk 31701/45455\n",
      "Processing chunk 31751/45455\n",
      "Processing chunk 31801/45455\n",
      "Processing chunk 31851/45455\n",
      "Processing chunk 31901/45455\n",
      "Processing chunk 31951/45455\n",
      "Processing chunk 32001/45455\n",
      "Processing chunk 32051/45455\n",
      "Processing chunk 32101/45455\n",
      "Processing chunk 32151/45455\n",
      "Processing chunk 32201/45455\n",
      "Processing chunk 32251/45455\n",
      "Processing chunk 32301/45455\n",
      "Processing chunk 32351/45455\n",
      "Processing chunk 32401/45455\n",
      "Processing chunk 32451/45455\n",
      "Processing chunk 32501/45455\n",
      "Processing chunk 32551/45455\n",
      "Processing chunk 32601/45455\n",
      "Processing chunk 32651/45455\n",
      "Processing chunk 32701/45455\n",
      "Processing chunk 32751/45455\n",
      "Processing chunk 32801/45455\n",
      "Processing chunk 32851/45455\n",
      "Processing chunk 32901/45455\n",
      "Processing chunk 32951/45455\n",
      "Processing chunk 33001/45455\n",
      "Processing chunk 33051/45455\n",
      "Processing chunk 33101/45455\n",
      "Processing chunk 33151/45455\n",
      "Processing chunk 33201/45455\n",
      "Processing chunk 33251/45455\n",
      "Processing chunk 33301/45455\n",
      "Processing chunk 33351/45455\n",
      "Processing chunk 33401/45455\n",
      "Processing chunk 33451/45455\n",
      "Processing chunk 33501/45455\n",
      "Processing chunk 33551/45455\n",
      "Processing chunk 33601/45455\n",
      "Processing chunk 33651/45455\n",
      "Processing chunk 33701/45455\n",
      "Processing chunk 33751/45455\n",
      "Processing chunk 33801/45455\n",
      "Processing chunk 33851/45455\n",
      "Processing chunk 33901/45455\n",
      "Processing chunk 33951/45455\n",
      "Processing chunk 34001/45455\n",
      "Processing chunk 34051/45455\n",
      "Processing chunk 34101/45455\n",
      "Processing chunk 34151/45455\n",
      "Processing chunk 34201/45455\n",
      "Processing chunk 34251/45455\n",
      "Processing chunk 34301/45455\n",
      "Processing chunk 34351/45455\n",
      "Processing chunk 34401/45455\n",
      "Processing chunk 34451/45455\n",
      "Processing chunk 34501/45455\n",
      "Processing chunk 34551/45455\n",
      "Processing chunk 34601/45455\n",
      "Processing chunk 34651/45455\n",
      "Processing chunk 34701/45455\n",
      "Processing chunk 34751/45455\n",
      "Processing chunk 34801/45455\n",
      "Processing chunk 34851/45455\n",
      "Processing chunk 34901/45455\n",
      "Processing chunk 34951/45455\n",
      "Processing chunk 35001/45455\n",
      "Processing chunk 35051/45455\n",
      "Processing chunk 35101/45455\n",
      "Processing chunk 35151/45455\n",
      "Processing chunk 35201/45455\n",
      "Processing chunk 35251/45455\n",
      "Processing chunk 35301/45455\n",
      "Processing chunk 35351/45455\n",
      "Processing chunk 35401/45455\n",
      "Processing chunk 35451/45455\n",
      "Processing chunk 35501/45455\n",
      "Processing chunk 35551/45455\n",
      "Processing chunk 35601/45455\n",
      "Processing chunk 35651/45455\n",
      "Processing chunk 35701/45455\n",
      "Processing chunk 35751/45455\n",
      "Processing chunk 35801/45455\n",
      "Processing chunk 35851/45455\n",
      "Processing chunk 35901/45455\n",
      "Processing chunk 35951/45455\n",
      "Processing chunk 36001/45455\n",
      "Processing chunk 36051/45455\n",
      "Processing chunk 36101/45455\n",
      "Processing chunk 36151/45455\n",
      "Processing chunk 36201/45455\n",
      "Processing chunk 36251/45455\n",
      "Processing chunk 36301/45455\n",
      "Processing chunk 36351/45455\n",
      "Processing chunk 36401/45455\n",
      "Processing chunk 36451/45455\n",
      "Processing chunk 36501/45455\n",
      "Processing chunk 36551/45455\n",
      "Processing chunk 36601/45455\n",
      "Processing chunk 36651/45455\n",
      "Processing chunk 36701/45455\n",
      "Processing chunk 36751/45455\n",
      "Processing chunk 36801/45455\n",
      "Processing chunk 36851/45455\n",
      "Processing chunk 36901/45455\n",
      "Processing chunk 36951/45455\n",
      "Processing chunk 37001/45455\n",
      "Processing chunk 37051/45455\n",
      "Processing chunk 37101/45455\n",
      "Processing chunk 37151/45455\n",
      "Processing chunk 37201/45455\n",
      "Processing chunk 37251/45455\n",
      "Processing chunk 37301/45455\n",
      "Processing chunk 37351/45455\n",
      "Processing chunk 37401/45455\n",
      "Processing chunk 37451/45455\n",
      "Processing chunk 37501/45455\n",
      "Processing chunk 37551/45455\n",
      "Processing chunk 37601/45455\n",
      "Processing chunk 37651/45455\n",
      "Processing chunk 37701/45455\n",
      "Processing chunk 37751/45455\n",
      "Processing chunk 37801/45455\n",
      "Processing chunk 37851/45455\n",
      "Processing chunk 37901/45455\n",
      "Processing chunk 37951/45455\n",
      "Processing chunk 38001/45455\n",
      "Processing chunk 38051/45455\n",
      "Processing chunk 38101/45455\n",
      "Processing chunk 38151/45455\n",
      "Processing chunk 38201/45455\n",
      "Processing chunk 38251/45455\n",
      "Processing chunk 38301/45455\n",
      "Processing chunk 38351/45455\n",
      "Processing chunk 38401/45455\n",
      "Processing chunk 38451/45455\n",
      "Processing chunk 38501/45455\n",
      "Processing chunk 38551/45455\n",
      "Processing chunk 38601/45455\n",
      "Processing chunk 38651/45455\n",
      "Processing chunk 38701/45455\n",
      "Processing chunk 38751/45455\n",
      "Processing chunk 38801/45455\n",
      "Processing chunk 38851/45455\n",
      "Processing chunk 38901/45455\n",
      "Processing chunk 38951/45455\n",
      "Processing chunk 39001/45455\n",
      "Processing chunk 39051/45455\n",
      "Processing chunk 39101/45455\n",
      "Processing chunk 39151/45455\n",
      "Processing chunk 39201/45455\n",
      "Processing chunk 39251/45455\n",
      "Processing chunk 39301/45455\n",
      "Processing chunk 39351/45455\n",
      "Processing chunk 39401/45455\n",
      "Processing chunk 39451/45455\n",
      "Processing chunk 39501/45455\n",
      "Processing chunk 39551/45455\n",
      "Processing chunk 39601/45455\n",
      "Processing chunk 39651/45455\n",
      "Processing chunk 39701/45455\n",
      "Processing chunk 39751/45455\n",
      "Processing chunk 39801/45455\n",
      "Processing chunk 39851/45455\n",
      "Processing chunk 39901/45455\n",
      "Processing chunk 39951/45455\n",
      "Processing chunk 40001/45455\n",
      "Processing chunk 40051/45455\n",
      "Processing chunk 40101/45455\n",
      "Processing chunk 40151/45455\n",
      "Processing chunk 40201/45455\n",
      "Processing chunk 40251/45455\n",
      "Processing chunk 40301/45455\n",
      "Processing chunk 40351/45455\n",
      "Processing chunk 40401/45455\n",
      "Processing chunk 40451/45455\n",
      "Processing chunk 40501/45455\n",
      "Processing chunk 40551/45455\n",
      "Processing chunk 40601/45455\n",
      "Processing chunk 40651/45455\n",
      "Processing chunk 40701/45455\n",
      "Processing chunk 40751/45455\n",
      "Processing chunk 40801/45455\n",
      "Processing chunk 40851/45455\n",
      "Processing chunk 40901/45455\n",
      "Processing chunk 40951/45455\n",
      "Processing chunk 41001/45455\n",
      "Processing chunk 41051/45455\n",
      "Processing chunk 41101/45455\n",
      "Processing chunk 41151/45455\n",
      "Processing chunk 41201/45455\n",
      "Processing chunk 41251/45455\n",
      "Processing chunk 41301/45455\n",
      "Processing chunk 41351/45455\n",
      "Processing chunk 41401/45455\n",
      "Processing chunk 41451/45455\n",
      "Processing chunk 41501/45455\n",
      "Processing chunk 41551/45455\n",
      "Processing chunk 41601/45455\n",
      "Processing chunk 41651/45455\n",
      "Processing chunk 41701/45455\n",
      "Processing chunk 41751/45455\n",
      "Processing chunk 41801/45455\n",
      "Processing chunk 41851/45455\n",
      "Processing chunk 41901/45455\n",
      "Processing chunk 41951/45455\n",
      "Processing chunk 42001/45455\n",
      "Processing chunk 42051/45455\n",
      "Processing chunk 42101/45455\n",
      "Processing chunk 42151/45455\n",
      "Processing chunk 42201/45455\n",
      "Processing chunk 42251/45455\n",
      "Processing chunk 42301/45455\n",
      "Processing chunk 42351/45455\n",
      "Processing chunk 42401/45455\n",
      "Processing chunk 42451/45455\n",
      "Processing chunk 42501/45455\n",
      "Processing chunk 42551/45455\n",
      "Processing chunk 42601/45455\n",
      "Processing chunk 42651/45455\n",
      "Processing chunk 42701/45455\n",
      "Processing chunk 42751/45455\n",
      "Processing chunk 42801/45455\n",
      "Processing chunk 42851/45455\n",
      "Processing chunk 42901/45455\n",
      "Processing chunk 42951/45455\n",
      "Processing chunk 43001/45455\n",
      "Processing chunk 43051/45455\n",
      "Processing chunk 43101/45455\n",
      "Processing chunk 43151/45455\n",
      "Processing chunk 43201/45455\n",
      "Processing chunk 43251/45455\n",
      "Processing chunk 43301/45455\n",
      "Processing chunk 43351/45455\n",
      "Processing chunk 43401/45455\n",
      "Processing chunk 43451/45455\n",
      "Processing chunk 43501/45455\n",
      "Processing chunk 43551/45455\n",
      "Processing chunk 43601/45455\n",
      "Processing chunk 43651/45455\n",
      "Processing chunk 43701/45455\n",
      "Processing chunk 43751/45455\n",
      "Processing chunk 43801/45455\n",
      "Processing chunk 43851/45455\n",
      "Processing chunk 43901/45455\n",
      "Processing chunk 43951/45455\n",
      "Processing chunk 44001/45455\n",
      "Processing chunk 44051/45455\n",
      "Processing chunk 44101/45455\n",
      "Processing chunk 44151/45455\n",
      "Processing chunk 44201/45455\n",
      "Processing chunk 44251/45455\n",
      "Processing chunk 44301/45455\n",
      "Processing chunk 44351/45455\n",
      "Processing chunk 44401/45455\n",
      "Processing chunk 44451/45455\n",
      "Processing chunk 44501/45455\n",
      "Processing chunk 44551/45455\n",
      "Processing chunk 44601/45455\n",
      "Processing chunk 44651/45455\n",
      "Processing chunk 44701/45455\n",
      "Processing chunk 44751/45455\n",
      "Processing chunk 44801/45455\n",
      "Processing chunk 44851/45455\n",
      "Processing chunk 44901/45455\n",
      "Processing chunk 44951/45455\n",
      "Processing chunk 45001/45455\n",
      "Processing chunk 45051/45455\n",
      "Processing chunk 45101/45455\n",
      "Processing chunk 45151/45455\n",
      "Processing chunk 45201/45455\n",
      "Processing chunk 45251/45455\n",
      "Processing chunk 45301/45455\n",
      "Processing chunk 45351/45455\n",
      "Processing chunk 45401/45455\n",
      "Processing chunk 45451/45455\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 10000\n",
      "Number of hits: 9905\n",
      "Average HR@20: 0.9905\n",
      "Average NDCG@20: 0.4639\n",
      "\n",
      "Training and evaluating MATN...\n",
      "Epoch 1, Loss: 0.7386\n",
      "Epoch 2, Loss: 0.7152\n",
      "Epoch 3, Loss: 0.6935\n",
      "Epoch 4, Loss: 0.6734\n",
      "Epoch 5, Loss: 0.6548\n",
      "Epoch 6, Loss: 0.6375\n",
      "Epoch 7, Loss: 0.6212\n",
      "Epoch 8, Loss: 0.6060\n",
      "Epoch 9, Loss: 0.5916\n",
      "Epoch 10, Loss: 0.5779\n",
      "Training completed in 1.32s\n",
      "Preparing test instances...\n",
      "Generated 1000000 test instances\n",
      "Evaluating 1000000 instances in 45455 chunks...\n",
      "Processing chunk 1/45455\n",
      "Processing chunk 51/45455\n",
      "Processing chunk 101/45455\n",
      "Processing chunk 151/45455\n",
      "Processing chunk 201/45455\n",
      "Processing chunk 251/45455\n",
      "Processing chunk 301/45455\n",
      "Processing chunk 351/45455\n",
      "Processing chunk 401/45455\n",
      "Processing chunk 451/45455\n",
      "Processing chunk 501/45455\n",
      "Processing chunk 551/45455\n",
      "Processing chunk 601/45455\n",
      "Processing chunk 651/45455\n",
      "Processing chunk 701/45455\n",
      "Processing chunk 751/45455\n",
      "Processing chunk 801/45455\n",
      "Processing chunk 851/45455\n",
      "Processing chunk 901/45455\n",
      "Processing chunk 951/45455\n",
      "Processing chunk 1001/45455\n",
      "Processing chunk 1051/45455\n",
      "Processing chunk 1101/45455\n",
      "Processing chunk 1151/45455\n",
      "Processing chunk 1201/45455\n",
      "Processing chunk 1251/45455\n",
      "Processing chunk 1301/45455\n",
      "Processing chunk 1351/45455\n",
      "Processing chunk 1401/45455\n",
      "Processing chunk 1451/45455\n",
      "Processing chunk 1501/45455\n",
      "Processing chunk 1551/45455\n",
      "Processing chunk 1601/45455\n",
      "Processing chunk 1651/45455\n",
      "Processing chunk 1701/45455\n",
      "Processing chunk 1751/45455\n",
      "Processing chunk 1801/45455\n",
      "Processing chunk 1851/45455\n",
      "Processing chunk 1901/45455\n",
      "Processing chunk 1951/45455\n",
      "Processing chunk 2001/45455\n",
      "Processing chunk 2051/45455\n",
      "Processing chunk 2101/45455\n",
      "Processing chunk 2151/45455\n",
      "Processing chunk 2201/45455\n",
      "Processing chunk 2251/45455\n",
      "Processing chunk 2301/45455\n",
      "Processing chunk 2351/45455\n",
      "Processing chunk 2401/45455\n",
      "Processing chunk 2451/45455\n",
      "Processing chunk 2501/45455\n",
      "Processing chunk 2551/45455\n",
      "Processing chunk 2601/45455\n",
      "Processing chunk 2651/45455\n",
      "Processing chunk 2701/45455\n",
      "Processing chunk 2751/45455\n",
      "Processing chunk 2801/45455\n",
      "Processing chunk 2851/45455\n",
      "Processing chunk 2901/45455\n",
      "Processing chunk 2951/45455\n",
      "Processing chunk 3001/45455\n",
      "Processing chunk 3051/45455\n",
      "Processing chunk 3101/45455\n",
      "Processing chunk 3151/45455\n",
      "Processing chunk 3201/45455\n",
      "Processing chunk 3251/45455\n",
      "Processing chunk 3301/45455\n",
      "Processing chunk 3351/45455\n",
      "Processing chunk 3401/45455\n",
      "Processing chunk 3451/45455\n",
      "Processing chunk 3501/45455\n",
      "Processing chunk 3551/45455\n",
      "Processing chunk 3601/45455\n",
      "Processing chunk 3651/45455\n",
      "Processing chunk 3701/45455\n",
      "Processing chunk 3751/45455\n",
      "Processing chunk 3801/45455\n",
      "Processing chunk 3851/45455\n",
      "Processing chunk 3901/45455\n",
      "Processing chunk 3951/45455\n",
      "Processing chunk 4001/45455\n",
      "Processing chunk 4051/45455\n",
      "Processing chunk 4101/45455\n",
      "Processing chunk 4151/45455\n",
      "Processing chunk 4201/45455\n",
      "Processing chunk 4251/45455\n",
      "Processing chunk 4301/45455\n",
      "Processing chunk 4351/45455\n",
      "Processing chunk 4401/45455\n",
      "Processing chunk 4451/45455\n",
      "Processing chunk 4501/45455\n",
      "Processing chunk 4551/45455\n",
      "Processing chunk 4601/45455\n",
      "Processing chunk 4651/45455\n",
      "Processing chunk 4701/45455\n",
      "Processing chunk 4751/45455\n",
      "Processing chunk 4801/45455\n",
      "Processing chunk 4851/45455\n",
      "Processing chunk 4901/45455\n",
      "Processing chunk 4951/45455\n",
      "Processing chunk 5001/45455\n",
      "Processing chunk 5051/45455\n",
      "Processing chunk 5101/45455\n",
      "Processing chunk 5151/45455\n",
      "Processing chunk 5201/45455\n",
      "Processing chunk 5251/45455\n",
      "Processing chunk 5301/45455\n",
      "Processing chunk 5351/45455\n",
      "Processing chunk 5401/45455\n",
      "Processing chunk 5451/45455\n",
      "Processing chunk 5501/45455\n",
      "Processing chunk 5551/45455\n",
      "Processing chunk 5601/45455\n",
      "Processing chunk 5651/45455\n",
      "Processing chunk 5701/45455\n",
      "Processing chunk 5751/45455\n",
      "Processing chunk 5801/45455\n",
      "Processing chunk 5851/45455\n",
      "Processing chunk 5901/45455\n",
      "Processing chunk 5951/45455\n",
      "Processing chunk 6001/45455\n",
      "Processing chunk 6051/45455\n",
      "Processing chunk 6101/45455\n",
      "Processing chunk 6151/45455\n",
      "Processing chunk 6201/45455\n",
      "Processing chunk 6251/45455\n",
      "Processing chunk 6301/45455\n",
      "Processing chunk 6351/45455\n",
      "Processing chunk 6401/45455\n",
      "Processing chunk 6451/45455\n",
      "Processing chunk 6501/45455\n",
      "Processing chunk 6551/45455\n",
      "Processing chunk 6601/45455\n",
      "Processing chunk 6651/45455\n",
      "Processing chunk 6701/45455\n",
      "Processing chunk 6751/45455\n",
      "Processing chunk 6801/45455\n",
      "Processing chunk 6851/45455\n",
      "Processing chunk 6901/45455\n",
      "Processing chunk 6951/45455\n",
      "Processing chunk 7001/45455\n",
      "Processing chunk 7051/45455\n",
      "Processing chunk 7101/45455\n",
      "Processing chunk 7151/45455\n",
      "Processing chunk 7201/45455\n",
      "Processing chunk 7251/45455\n",
      "Processing chunk 7301/45455\n",
      "Processing chunk 7351/45455\n",
      "Processing chunk 7401/45455\n",
      "Processing chunk 7451/45455\n",
      "Processing chunk 7501/45455\n",
      "Processing chunk 7551/45455\n",
      "Processing chunk 7601/45455\n",
      "Processing chunk 7651/45455\n",
      "Processing chunk 7701/45455\n",
      "Processing chunk 7751/45455\n",
      "Processing chunk 7801/45455\n",
      "Processing chunk 7851/45455\n",
      "Processing chunk 7901/45455\n",
      "Processing chunk 7951/45455\n",
      "Processing chunk 8001/45455\n",
      "Processing chunk 8051/45455\n",
      "Processing chunk 8101/45455\n",
      "Processing chunk 8151/45455\n",
      "Processing chunk 8201/45455\n",
      "Processing chunk 8251/45455\n",
      "Processing chunk 8301/45455\n",
      "Processing chunk 8351/45455\n",
      "Processing chunk 8401/45455\n",
      "Processing chunk 8451/45455\n",
      "Processing chunk 8501/45455\n",
      "Processing chunk 8551/45455\n",
      "Processing chunk 8601/45455\n",
      "Processing chunk 8651/45455\n",
      "Processing chunk 8701/45455\n",
      "Processing chunk 8751/45455\n",
      "Processing chunk 8801/45455\n",
      "Processing chunk 8851/45455\n",
      "Processing chunk 8901/45455\n",
      "Processing chunk 8951/45455\n",
      "Processing chunk 9001/45455\n",
      "Processing chunk 9051/45455\n",
      "Processing chunk 9101/45455\n",
      "Processing chunk 9151/45455\n",
      "Processing chunk 9201/45455\n",
      "Processing chunk 9251/45455\n",
      "Processing chunk 9301/45455\n",
      "Processing chunk 9351/45455\n",
      "Processing chunk 9401/45455\n",
      "Processing chunk 9451/45455\n",
      "Processing chunk 9501/45455\n",
      "Processing chunk 9551/45455\n",
      "Processing chunk 9601/45455\n",
      "Processing chunk 9651/45455\n",
      "Processing chunk 9701/45455\n",
      "Processing chunk 9751/45455\n",
      "Processing chunk 9801/45455\n",
      "Processing chunk 9851/45455\n",
      "Processing chunk 9901/45455\n",
      "Processing chunk 9951/45455\n",
      "Processing chunk 10001/45455\n",
      "Processing chunk 10051/45455\n",
      "Processing chunk 10101/45455\n",
      "Processing chunk 10151/45455\n",
      "Processing chunk 10201/45455\n",
      "Processing chunk 10251/45455\n",
      "Processing chunk 10301/45455\n",
      "Processing chunk 10351/45455\n",
      "Processing chunk 10401/45455\n",
      "Processing chunk 10451/45455\n",
      "Processing chunk 10501/45455\n",
      "Processing chunk 10551/45455\n",
      "Processing chunk 10601/45455\n",
      "Processing chunk 10651/45455\n",
      "Processing chunk 10701/45455\n",
      "Processing chunk 10751/45455\n",
      "Processing chunk 10801/45455\n",
      "Processing chunk 10851/45455\n",
      "Processing chunk 10901/45455\n",
      "Processing chunk 10951/45455\n",
      "Processing chunk 11001/45455\n",
      "Processing chunk 11051/45455\n",
      "Processing chunk 11101/45455\n",
      "Processing chunk 11151/45455\n",
      "Processing chunk 11201/45455\n",
      "Processing chunk 11251/45455\n",
      "Processing chunk 11301/45455\n",
      "Processing chunk 11351/45455\n",
      "Processing chunk 11401/45455\n",
      "Processing chunk 11451/45455\n",
      "Processing chunk 11501/45455\n",
      "Processing chunk 11551/45455\n",
      "Processing chunk 11601/45455\n",
      "Processing chunk 11651/45455\n",
      "Processing chunk 11701/45455\n",
      "Processing chunk 11751/45455\n",
      "Processing chunk 11801/45455\n",
      "Processing chunk 11851/45455\n",
      "Processing chunk 11901/45455\n",
      "Processing chunk 11951/45455\n",
      "Processing chunk 12001/45455\n",
      "Processing chunk 12051/45455\n",
      "Processing chunk 12101/45455\n",
      "Processing chunk 12151/45455\n",
      "Processing chunk 12201/45455\n",
      "Processing chunk 12251/45455\n",
      "Processing chunk 12301/45455\n",
      "Processing chunk 12351/45455\n",
      "Processing chunk 12401/45455\n",
      "Processing chunk 12451/45455\n",
      "Processing chunk 12501/45455\n",
      "Processing chunk 12551/45455\n",
      "Processing chunk 12601/45455\n",
      "Processing chunk 12651/45455\n",
      "Processing chunk 12701/45455\n",
      "Processing chunk 12751/45455\n",
      "Processing chunk 12801/45455\n",
      "Processing chunk 12851/45455\n",
      "Processing chunk 12901/45455\n",
      "Processing chunk 12951/45455\n",
      "Processing chunk 13001/45455\n",
      "Processing chunk 13051/45455\n",
      "Processing chunk 13101/45455\n",
      "Processing chunk 13151/45455\n",
      "Processing chunk 13201/45455\n",
      "Processing chunk 13251/45455\n",
      "Processing chunk 13301/45455\n",
      "Processing chunk 13351/45455\n",
      "Processing chunk 13401/45455\n",
      "Processing chunk 13451/45455\n",
      "Processing chunk 13501/45455\n",
      "Processing chunk 13551/45455\n",
      "Processing chunk 13601/45455\n",
      "Processing chunk 13651/45455\n",
      "Processing chunk 13701/45455\n",
      "Processing chunk 13751/45455\n",
      "Processing chunk 13801/45455\n",
      "Processing chunk 13851/45455\n",
      "Processing chunk 13901/45455\n",
      "Processing chunk 13951/45455\n",
      "Processing chunk 14001/45455\n",
      "Processing chunk 14051/45455\n",
      "Processing chunk 14101/45455\n",
      "Processing chunk 14151/45455\n",
      "Processing chunk 14201/45455\n",
      "Processing chunk 14251/45455\n",
      "Processing chunk 14301/45455\n",
      "Processing chunk 14351/45455\n",
      "Processing chunk 14401/45455\n",
      "Processing chunk 14451/45455\n",
      "Processing chunk 14501/45455\n",
      "Processing chunk 14551/45455\n",
      "Processing chunk 14601/45455\n",
      "Processing chunk 14651/45455\n",
      "Processing chunk 14701/45455\n",
      "Processing chunk 14751/45455\n",
      "Processing chunk 14801/45455\n",
      "Processing chunk 14851/45455\n",
      "Processing chunk 14901/45455\n",
      "Processing chunk 14951/45455\n",
      "Processing chunk 15001/45455\n",
      "Processing chunk 15051/45455\n",
      "Processing chunk 15101/45455\n",
      "Processing chunk 15151/45455\n",
      "Processing chunk 15201/45455\n",
      "Processing chunk 15251/45455\n",
      "Processing chunk 15301/45455\n",
      "Processing chunk 15351/45455\n",
      "Processing chunk 15401/45455\n",
      "Processing chunk 15451/45455\n",
      "Processing chunk 15501/45455\n",
      "Processing chunk 15551/45455\n",
      "Processing chunk 15601/45455\n",
      "Processing chunk 15651/45455\n",
      "Processing chunk 15701/45455\n",
      "Processing chunk 15751/45455\n",
      "Processing chunk 15801/45455\n",
      "Processing chunk 15851/45455\n",
      "Processing chunk 15901/45455\n",
      "Processing chunk 15951/45455\n",
      "Processing chunk 16001/45455\n",
      "Processing chunk 16051/45455\n",
      "Processing chunk 16101/45455\n",
      "Processing chunk 16151/45455\n",
      "Processing chunk 16201/45455\n",
      "Processing chunk 16251/45455\n",
      "Processing chunk 16301/45455\n",
      "Processing chunk 16351/45455\n",
      "Processing chunk 16401/45455\n",
      "Processing chunk 16451/45455\n",
      "Processing chunk 16501/45455\n",
      "Processing chunk 16551/45455\n",
      "Processing chunk 16601/45455\n",
      "Processing chunk 16651/45455\n",
      "Processing chunk 16701/45455\n",
      "Processing chunk 16751/45455\n",
      "Processing chunk 16801/45455\n",
      "Processing chunk 16851/45455\n",
      "Processing chunk 16901/45455\n",
      "Processing chunk 16951/45455\n",
      "Processing chunk 17001/45455\n",
      "Processing chunk 17051/45455\n",
      "Processing chunk 17101/45455\n",
      "Processing chunk 17151/45455\n",
      "Processing chunk 17201/45455\n",
      "Processing chunk 17251/45455\n",
      "Processing chunk 17301/45455\n",
      "Processing chunk 17351/45455\n",
      "Processing chunk 17401/45455\n",
      "Processing chunk 17451/45455\n",
      "Processing chunk 17501/45455\n",
      "Processing chunk 17551/45455\n",
      "Processing chunk 17601/45455\n",
      "Processing chunk 17651/45455\n",
      "Processing chunk 17701/45455\n",
      "Processing chunk 17751/45455\n",
      "Processing chunk 17801/45455\n",
      "Processing chunk 17851/45455\n",
      "Processing chunk 17901/45455\n",
      "Processing chunk 17951/45455\n",
      "Processing chunk 18001/45455\n",
      "Processing chunk 18051/45455\n",
      "Processing chunk 18101/45455\n",
      "Processing chunk 18151/45455\n",
      "Processing chunk 18201/45455\n",
      "Processing chunk 18251/45455\n",
      "Processing chunk 18301/45455\n",
      "Processing chunk 18351/45455\n",
      "Processing chunk 18401/45455\n",
      "Processing chunk 18451/45455\n",
      "Processing chunk 18501/45455\n",
      "Processing chunk 18551/45455\n",
      "Processing chunk 18601/45455\n",
      "Processing chunk 18651/45455\n",
      "Processing chunk 18701/45455\n",
      "Processing chunk 18751/45455\n",
      "Processing chunk 18801/45455\n",
      "Processing chunk 18851/45455\n",
      "Processing chunk 18901/45455\n",
      "Processing chunk 18951/45455\n",
      "Processing chunk 19001/45455\n",
      "Processing chunk 19051/45455\n",
      "Processing chunk 19101/45455\n",
      "Processing chunk 19151/45455\n",
      "Processing chunk 19201/45455\n",
      "Processing chunk 19251/45455\n",
      "Processing chunk 19301/45455\n",
      "Processing chunk 19351/45455\n",
      "Processing chunk 19401/45455\n",
      "Processing chunk 19451/45455\n",
      "Processing chunk 19501/45455\n",
      "Processing chunk 19551/45455\n",
      "Processing chunk 19601/45455\n",
      "Processing chunk 19651/45455\n",
      "Processing chunk 19701/45455\n",
      "Processing chunk 19751/45455\n",
      "Processing chunk 19801/45455\n",
      "Processing chunk 19851/45455\n",
      "Processing chunk 19901/45455\n",
      "Processing chunk 19951/45455\n",
      "Processing chunk 20001/45455\n",
      "Processing chunk 20051/45455\n",
      "Processing chunk 20101/45455\n",
      "Processing chunk 20151/45455\n",
      "Processing chunk 20201/45455\n",
      "Processing chunk 20251/45455\n",
      "Processing chunk 20301/45455\n",
      "Processing chunk 20351/45455\n",
      "Processing chunk 20401/45455\n",
      "Processing chunk 20451/45455\n",
      "Processing chunk 20501/45455\n",
      "Processing chunk 20551/45455\n",
      "Processing chunk 20601/45455\n",
      "Processing chunk 20651/45455\n",
      "Processing chunk 20701/45455\n",
      "Processing chunk 20751/45455\n",
      "Processing chunk 20801/45455\n",
      "Processing chunk 20851/45455\n",
      "Processing chunk 20901/45455\n",
      "Processing chunk 20951/45455\n",
      "Processing chunk 21001/45455\n",
      "Processing chunk 21051/45455\n",
      "Processing chunk 21101/45455\n",
      "Processing chunk 21151/45455\n",
      "Processing chunk 21201/45455\n",
      "Processing chunk 21251/45455\n",
      "Processing chunk 21301/45455\n",
      "Processing chunk 21351/45455\n",
      "Processing chunk 21401/45455\n",
      "Processing chunk 21451/45455\n",
      "Processing chunk 21501/45455\n",
      "Processing chunk 21551/45455\n",
      "Processing chunk 21601/45455\n",
      "Processing chunk 21651/45455\n",
      "Processing chunk 21701/45455\n",
      "Processing chunk 21751/45455\n",
      "Processing chunk 21801/45455\n",
      "Processing chunk 21851/45455\n",
      "Processing chunk 21901/45455\n",
      "Processing chunk 21951/45455\n",
      "Processing chunk 22001/45455\n",
      "Processing chunk 22051/45455\n",
      "Processing chunk 22101/45455\n",
      "Processing chunk 22151/45455\n",
      "Processing chunk 22201/45455\n",
      "Processing chunk 22251/45455\n",
      "Processing chunk 22301/45455\n",
      "Processing chunk 22351/45455\n",
      "Processing chunk 22401/45455\n",
      "Processing chunk 22451/45455\n",
      "Processing chunk 22501/45455\n",
      "Processing chunk 22551/45455\n",
      "Processing chunk 22601/45455\n",
      "Processing chunk 22651/45455\n",
      "Processing chunk 22701/45455\n",
      "Processing chunk 22751/45455\n",
      "Processing chunk 22801/45455\n",
      "Processing chunk 22851/45455\n",
      "Processing chunk 22901/45455\n",
      "Processing chunk 22951/45455\n",
      "Processing chunk 23001/45455\n",
      "Processing chunk 23051/45455\n",
      "Processing chunk 23101/45455\n",
      "Processing chunk 23151/45455\n",
      "Processing chunk 23201/45455\n",
      "Processing chunk 23251/45455\n",
      "Processing chunk 23301/45455\n",
      "Processing chunk 23351/45455\n",
      "Processing chunk 23401/45455\n",
      "Processing chunk 23451/45455\n",
      "Processing chunk 23501/45455\n",
      "Processing chunk 23551/45455\n",
      "Processing chunk 23601/45455\n",
      "Processing chunk 23651/45455\n",
      "Processing chunk 23701/45455\n",
      "Processing chunk 23751/45455\n",
      "Processing chunk 23801/45455\n",
      "Processing chunk 23851/45455\n",
      "Processing chunk 23901/45455\n",
      "Processing chunk 23951/45455\n",
      "Processing chunk 24001/45455\n",
      "Processing chunk 24051/45455\n",
      "Processing chunk 24101/45455\n",
      "Processing chunk 24151/45455\n",
      "Processing chunk 24201/45455\n",
      "Processing chunk 24251/45455\n",
      "Processing chunk 24301/45455\n",
      "Processing chunk 24351/45455\n",
      "Processing chunk 24401/45455\n",
      "Processing chunk 24451/45455\n",
      "Processing chunk 24501/45455\n",
      "Processing chunk 24551/45455\n",
      "Processing chunk 24601/45455\n",
      "Processing chunk 24651/45455\n",
      "Processing chunk 24701/45455\n",
      "Processing chunk 24751/45455\n",
      "Processing chunk 24801/45455\n",
      "Processing chunk 24851/45455\n",
      "Processing chunk 24901/45455\n",
      "Processing chunk 24951/45455\n",
      "Processing chunk 25001/45455\n",
      "Processing chunk 25051/45455\n",
      "Processing chunk 25101/45455\n",
      "Processing chunk 25151/45455\n",
      "Processing chunk 25201/45455\n",
      "Processing chunk 25251/45455\n",
      "Processing chunk 25301/45455\n",
      "Processing chunk 25351/45455\n",
      "Processing chunk 25401/45455\n",
      "Processing chunk 25451/45455\n",
      "Processing chunk 25501/45455\n",
      "Processing chunk 25551/45455\n",
      "Processing chunk 25601/45455\n",
      "Processing chunk 25651/45455\n",
      "Processing chunk 25701/45455\n",
      "Processing chunk 25751/45455\n",
      "Processing chunk 25801/45455\n",
      "Processing chunk 25851/45455\n",
      "Processing chunk 25901/45455\n",
      "Processing chunk 25951/45455\n",
      "Processing chunk 26001/45455\n",
      "Processing chunk 26051/45455\n",
      "Processing chunk 26101/45455\n",
      "Processing chunk 26151/45455\n",
      "Processing chunk 26201/45455\n",
      "Processing chunk 26251/45455\n",
      "Processing chunk 26301/45455\n",
      "Processing chunk 26351/45455\n",
      "Processing chunk 26401/45455\n",
      "Processing chunk 26451/45455\n",
      "Processing chunk 26501/45455\n",
      "Processing chunk 26551/45455\n",
      "Processing chunk 26601/45455\n",
      "Processing chunk 26651/45455\n",
      "Processing chunk 26701/45455\n",
      "Processing chunk 26751/45455\n",
      "Processing chunk 26801/45455\n",
      "Processing chunk 26851/45455\n",
      "Processing chunk 26901/45455\n",
      "Processing chunk 26951/45455\n",
      "Processing chunk 27001/45455\n",
      "Processing chunk 27051/45455\n",
      "Processing chunk 27101/45455\n",
      "Processing chunk 27151/45455\n",
      "Processing chunk 27201/45455\n",
      "Processing chunk 27251/45455\n",
      "Processing chunk 27301/45455\n",
      "Processing chunk 27351/45455\n",
      "Processing chunk 27401/45455\n",
      "Processing chunk 27451/45455\n",
      "Processing chunk 27501/45455\n",
      "Processing chunk 27551/45455\n",
      "Processing chunk 27601/45455\n",
      "Processing chunk 27651/45455\n",
      "Processing chunk 27701/45455\n",
      "Processing chunk 27751/45455\n",
      "Processing chunk 27801/45455\n",
      "Processing chunk 27851/45455\n",
      "Processing chunk 27901/45455\n",
      "Processing chunk 27951/45455\n",
      "Processing chunk 28001/45455\n",
      "Processing chunk 28051/45455\n",
      "Processing chunk 28101/45455\n",
      "Processing chunk 28151/45455\n",
      "Processing chunk 28201/45455\n",
      "Processing chunk 28251/45455\n",
      "Processing chunk 28301/45455\n",
      "Processing chunk 28351/45455\n",
      "Processing chunk 28401/45455\n",
      "Processing chunk 28451/45455\n",
      "Processing chunk 28501/45455\n",
      "Processing chunk 28551/45455\n",
      "Processing chunk 28601/45455\n",
      "Processing chunk 28651/45455\n",
      "Processing chunk 28701/45455\n",
      "Processing chunk 28751/45455\n",
      "Processing chunk 28801/45455\n",
      "Processing chunk 28851/45455\n",
      "Processing chunk 28901/45455\n",
      "Processing chunk 28951/45455\n",
      "Processing chunk 29001/45455\n",
      "Processing chunk 29051/45455\n",
      "Processing chunk 29101/45455\n",
      "Processing chunk 29151/45455\n",
      "Processing chunk 29201/45455\n",
      "Processing chunk 29251/45455\n",
      "Processing chunk 29301/45455\n",
      "Processing chunk 29351/45455\n",
      "Processing chunk 29401/45455\n",
      "Processing chunk 29451/45455\n",
      "Processing chunk 29501/45455\n",
      "Processing chunk 29551/45455\n",
      "Processing chunk 29601/45455\n",
      "Processing chunk 29651/45455\n",
      "Processing chunk 29701/45455\n",
      "Processing chunk 29751/45455\n",
      "Processing chunk 29801/45455\n",
      "Processing chunk 29851/45455\n",
      "Processing chunk 29901/45455\n",
      "Processing chunk 29951/45455\n",
      "Processing chunk 30001/45455\n",
      "Processing chunk 30051/45455\n",
      "Processing chunk 30101/45455\n",
      "Processing chunk 30151/45455\n",
      "Processing chunk 30201/45455\n",
      "Processing chunk 30251/45455\n",
      "Processing chunk 30301/45455\n",
      "Processing chunk 30351/45455\n",
      "Processing chunk 30401/45455\n",
      "Processing chunk 30451/45455\n",
      "Processing chunk 30501/45455\n",
      "Processing chunk 30551/45455\n",
      "Processing chunk 30601/45455\n",
      "Processing chunk 30651/45455\n",
      "Processing chunk 30701/45455\n",
      "Processing chunk 30751/45455\n",
      "Processing chunk 30801/45455\n",
      "Processing chunk 30851/45455\n",
      "Processing chunk 30901/45455\n",
      "Processing chunk 30951/45455\n",
      "Processing chunk 31001/45455\n",
      "Processing chunk 31051/45455\n",
      "Processing chunk 31101/45455\n",
      "Processing chunk 31151/45455\n",
      "Processing chunk 31201/45455\n",
      "Processing chunk 31251/45455\n",
      "Processing chunk 31301/45455\n",
      "Processing chunk 31351/45455\n",
      "Processing chunk 31401/45455\n",
      "Processing chunk 31451/45455\n",
      "Processing chunk 31501/45455\n",
      "Processing chunk 31551/45455\n",
      "Processing chunk 31601/45455\n",
      "Processing chunk 31651/45455\n",
      "Processing chunk 31701/45455\n",
      "Processing chunk 31751/45455\n",
      "Processing chunk 31801/45455\n",
      "Processing chunk 31851/45455\n",
      "Processing chunk 31901/45455\n",
      "Processing chunk 31951/45455\n",
      "Processing chunk 32001/45455\n",
      "Processing chunk 32051/45455\n",
      "Processing chunk 32101/45455\n",
      "Processing chunk 32151/45455\n",
      "Processing chunk 32201/45455\n",
      "Processing chunk 32251/45455\n",
      "Processing chunk 32301/45455\n",
      "Processing chunk 32351/45455\n",
      "Processing chunk 32401/45455\n",
      "Processing chunk 32451/45455\n",
      "Processing chunk 32501/45455\n",
      "Processing chunk 32551/45455\n",
      "Processing chunk 32601/45455\n",
      "Processing chunk 32651/45455\n",
      "Processing chunk 32701/45455\n",
      "Processing chunk 32751/45455\n",
      "Processing chunk 32801/45455\n",
      "Processing chunk 32851/45455\n",
      "Processing chunk 32901/45455\n",
      "Processing chunk 32951/45455\n",
      "Processing chunk 33001/45455\n",
      "Processing chunk 33051/45455\n",
      "Processing chunk 33101/45455\n",
      "Processing chunk 33151/45455\n",
      "Processing chunk 33201/45455\n",
      "Processing chunk 33251/45455\n",
      "Processing chunk 33301/45455\n",
      "Processing chunk 33351/45455\n",
      "Processing chunk 33401/45455\n",
      "Processing chunk 33451/45455\n",
      "Processing chunk 33501/45455\n",
      "Processing chunk 33551/45455\n",
      "Processing chunk 33601/45455\n",
      "Processing chunk 33651/45455\n",
      "Processing chunk 33701/45455\n",
      "Processing chunk 33751/45455\n",
      "Processing chunk 33801/45455\n",
      "Processing chunk 33851/45455\n",
      "Processing chunk 33901/45455\n",
      "Processing chunk 33951/45455\n",
      "Processing chunk 34001/45455\n",
      "Processing chunk 34051/45455\n",
      "Processing chunk 34101/45455\n",
      "Processing chunk 34151/45455\n",
      "Processing chunk 34201/45455\n",
      "Processing chunk 34251/45455\n",
      "Processing chunk 34301/45455\n",
      "Processing chunk 34351/45455\n",
      "Processing chunk 34401/45455\n",
      "Processing chunk 34451/45455\n",
      "Processing chunk 34501/45455\n",
      "Processing chunk 34551/45455\n",
      "Processing chunk 34601/45455\n",
      "Processing chunk 34651/45455\n",
      "Processing chunk 34701/45455\n",
      "Processing chunk 34751/45455\n",
      "Processing chunk 34801/45455\n",
      "Processing chunk 34851/45455\n",
      "Processing chunk 34901/45455\n",
      "Processing chunk 34951/45455\n",
      "Processing chunk 35001/45455\n",
      "Processing chunk 35051/45455\n",
      "Processing chunk 35101/45455\n",
      "Processing chunk 35151/45455\n",
      "Processing chunk 35201/45455\n",
      "Processing chunk 35251/45455\n",
      "Processing chunk 35301/45455\n",
      "Processing chunk 35351/45455\n",
      "Processing chunk 35401/45455\n",
      "Processing chunk 35451/45455\n",
      "Processing chunk 35501/45455\n",
      "Processing chunk 35551/45455\n",
      "Processing chunk 35601/45455\n",
      "Processing chunk 35651/45455\n",
      "Processing chunk 35701/45455\n",
      "Processing chunk 35751/45455\n",
      "Processing chunk 35801/45455\n",
      "Processing chunk 35851/45455\n",
      "Processing chunk 35901/45455\n",
      "Processing chunk 35951/45455\n",
      "Processing chunk 36001/45455\n",
      "Processing chunk 36051/45455\n",
      "Processing chunk 36101/45455\n",
      "Processing chunk 36151/45455\n",
      "Processing chunk 36201/45455\n",
      "Processing chunk 36251/45455\n",
      "Processing chunk 36301/45455\n",
      "Processing chunk 36351/45455\n",
      "Processing chunk 36401/45455\n",
      "Processing chunk 36451/45455\n",
      "Processing chunk 36501/45455\n",
      "Processing chunk 36551/45455\n",
      "Processing chunk 36601/45455\n",
      "Processing chunk 36651/45455\n",
      "Processing chunk 36701/45455\n",
      "Processing chunk 36751/45455\n",
      "Processing chunk 36801/45455\n",
      "Processing chunk 36851/45455\n",
      "Processing chunk 36901/45455\n",
      "Processing chunk 36951/45455\n",
      "Processing chunk 37001/45455\n",
      "Processing chunk 37051/45455\n",
      "Processing chunk 37101/45455\n",
      "Processing chunk 37151/45455\n",
      "Processing chunk 37201/45455\n",
      "Processing chunk 37251/45455\n",
      "Processing chunk 37301/45455\n",
      "Processing chunk 37351/45455\n",
      "Processing chunk 37401/45455\n",
      "Processing chunk 37451/45455\n",
      "Processing chunk 37501/45455\n",
      "Processing chunk 37551/45455\n",
      "Processing chunk 37601/45455\n",
      "Processing chunk 37651/45455\n",
      "Processing chunk 37701/45455\n",
      "Processing chunk 37751/45455\n",
      "Processing chunk 37801/45455\n",
      "Processing chunk 37851/45455\n",
      "Processing chunk 37901/45455\n",
      "Processing chunk 37951/45455\n",
      "Processing chunk 38001/45455\n",
      "Processing chunk 38051/45455\n",
      "Processing chunk 38101/45455\n",
      "Processing chunk 38151/45455\n",
      "Processing chunk 38201/45455\n",
      "Processing chunk 38251/45455\n",
      "Processing chunk 38301/45455\n",
      "Processing chunk 38351/45455\n",
      "Processing chunk 38401/45455\n",
      "Processing chunk 38451/45455\n",
      "Processing chunk 38501/45455\n",
      "Processing chunk 38551/45455\n",
      "Processing chunk 38601/45455\n",
      "Processing chunk 38651/45455\n",
      "Processing chunk 38701/45455\n",
      "Processing chunk 38751/45455\n",
      "Processing chunk 38801/45455\n",
      "Processing chunk 38851/45455\n",
      "Processing chunk 38901/45455\n",
      "Processing chunk 38951/45455\n",
      "Processing chunk 39001/45455\n",
      "Processing chunk 39051/45455\n",
      "Processing chunk 39101/45455\n",
      "Processing chunk 39151/45455\n",
      "Processing chunk 39201/45455\n",
      "Processing chunk 39251/45455\n",
      "Processing chunk 39301/45455\n",
      "Processing chunk 39351/45455\n",
      "Processing chunk 39401/45455\n",
      "Processing chunk 39451/45455\n",
      "Processing chunk 39501/45455\n",
      "Processing chunk 39551/45455\n",
      "Processing chunk 39601/45455\n",
      "Processing chunk 39651/45455\n",
      "Processing chunk 39701/45455\n",
      "Processing chunk 39751/45455\n",
      "Processing chunk 39801/45455\n",
      "Processing chunk 39851/45455\n",
      "Processing chunk 39901/45455\n",
      "Processing chunk 39951/45455\n",
      "Processing chunk 40001/45455\n",
      "Processing chunk 40051/45455\n",
      "Processing chunk 40101/45455\n",
      "Processing chunk 40151/45455\n",
      "Processing chunk 40201/45455\n",
      "Processing chunk 40251/45455\n",
      "Processing chunk 40301/45455\n",
      "Processing chunk 40351/45455\n",
      "Processing chunk 40401/45455\n",
      "Processing chunk 40451/45455\n",
      "Processing chunk 40501/45455\n",
      "Processing chunk 40551/45455\n",
      "Processing chunk 40601/45455\n",
      "Processing chunk 40651/45455\n",
      "Processing chunk 40701/45455\n",
      "Processing chunk 40751/45455\n",
      "Processing chunk 40801/45455\n",
      "Processing chunk 40851/45455\n",
      "Processing chunk 40901/45455\n",
      "Processing chunk 40951/45455\n",
      "Processing chunk 41001/45455\n",
      "Processing chunk 41051/45455\n",
      "Processing chunk 41101/45455\n",
      "Processing chunk 41151/45455\n",
      "Processing chunk 41201/45455\n",
      "Processing chunk 41251/45455\n",
      "Processing chunk 41301/45455\n",
      "Processing chunk 41351/45455\n",
      "Processing chunk 41401/45455\n",
      "Processing chunk 41451/45455\n",
      "Processing chunk 41501/45455\n",
      "Processing chunk 41551/45455\n",
      "Processing chunk 41601/45455\n",
      "Processing chunk 41651/45455\n",
      "Processing chunk 41701/45455\n",
      "Processing chunk 41751/45455\n",
      "Processing chunk 41801/45455\n",
      "Processing chunk 41851/45455\n",
      "Processing chunk 41901/45455\n",
      "Processing chunk 41951/45455\n",
      "Processing chunk 42001/45455\n",
      "Processing chunk 42051/45455\n",
      "Processing chunk 42101/45455\n",
      "Processing chunk 42151/45455\n",
      "Processing chunk 42201/45455\n",
      "Processing chunk 42251/45455\n",
      "Processing chunk 42301/45455\n",
      "Processing chunk 42351/45455\n",
      "Processing chunk 42401/45455\n",
      "Processing chunk 42451/45455\n",
      "Processing chunk 42501/45455\n",
      "Processing chunk 42551/45455\n",
      "Processing chunk 42601/45455\n",
      "Processing chunk 42651/45455\n",
      "Processing chunk 42701/45455\n",
      "Processing chunk 42751/45455\n",
      "Processing chunk 42801/45455\n",
      "Processing chunk 42851/45455\n",
      "Processing chunk 42901/45455\n",
      "Processing chunk 42951/45455\n",
      "Processing chunk 43001/45455\n",
      "Processing chunk 43051/45455\n",
      "Processing chunk 43101/45455\n",
      "Processing chunk 43151/45455\n",
      "Processing chunk 43201/45455\n",
      "Processing chunk 43251/45455\n",
      "Processing chunk 43301/45455\n",
      "Processing chunk 43351/45455\n",
      "Processing chunk 43401/45455\n",
      "Processing chunk 43451/45455\n",
      "Processing chunk 43501/45455\n",
      "Processing chunk 43551/45455\n",
      "Processing chunk 43601/45455\n",
      "Processing chunk 43651/45455\n",
      "Processing chunk 43701/45455\n",
      "Processing chunk 43751/45455\n",
      "Processing chunk 43801/45455\n",
      "Processing chunk 43851/45455\n",
      "Processing chunk 43901/45455\n",
      "Processing chunk 43951/45455\n",
      "Processing chunk 44001/45455\n",
      "Processing chunk 44051/45455\n",
      "Processing chunk 44101/45455\n",
      "Processing chunk 44151/45455\n",
      "Processing chunk 44201/45455\n",
      "Processing chunk 44251/45455\n",
      "Processing chunk 44301/45455\n",
      "Processing chunk 44351/45455\n",
      "Processing chunk 44401/45455\n",
      "Processing chunk 44451/45455\n",
      "Processing chunk 44501/45455\n",
      "Processing chunk 44551/45455\n",
      "Processing chunk 44601/45455\n",
      "Processing chunk 44651/45455\n",
      "Processing chunk 44701/45455\n",
      "Processing chunk 44751/45455\n",
      "Processing chunk 44801/45455\n",
      "Processing chunk 44851/45455\n",
      "Processing chunk 44901/45455\n",
      "Processing chunk 44951/45455\n",
      "Processing chunk 45001/45455\n",
      "Processing chunk 45051/45455\n",
      "Processing chunk 45101/45455\n",
      "Processing chunk 45151/45455\n",
      "Processing chunk 45201/45455\n",
      "Processing chunk 45251/45455\n",
      "Processing chunk 45301/45455\n",
      "Processing chunk 45351/45455\n",
      "Processing chunk 45401/45455\n",
      "Processing chunk 45451/45455\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 10000\n",
      "Number of hits: 9932\n",
      "Average HR@20: 0.9932\n",
      "Average NDCG@20: 0.4920\n",
      "\n",
      "Training and evaluating GNMR...\n",
      "Epoch 1, Loss: 0.7312\n",
      "Epoch 2, Loss: 0.7082\n",
      "Epoch 3, Loss: 0.6870\n",
      "Epoch 4, Loss: 0.6674\n",
      "Epoch 5, Loss: 0.6493\n",
      "Epoch 6, Loss: 0.6323\n",
      "Epoch 7, Loss: 0.6164\n",
      "Epoch 8, Loss: 0.6014\n",
      "Epoch 9, Loss: 0.5871\n",
      "Epoch 10, Loss: 0.5735\n",
      "Training completed in 1.29s\n",
      "Preparing test instances...\n",
      "Generated 1000000 test instances\n",
      "Evaluating 1000000 instances in 45455 chunks...\n",
      "Processing chunk 1/45455\n",
      "Processing chunk 51/45455\n",
      "Processing chunk 101/45455\n",
      "Processing chunk 151/45455\n",
      "Processing chunk 201/45455\n",
      "Processing chunk 251/45455\n",
      "Processing chunk 301/45455\n",
      "Processing chunk 351/45455\n",
      "Processing chunk 401/45455\n",
      "Processing chunk 451/45455\n",
      "Processing chunk 501/45455\n",
      "Processing chunk 551/45455\n",
      "Processing chunk 601/45455\n",
      "Processing chunk 651/45455\n",
      "Processing chunk 701/45455\n",
      "Processing chunk 751/45455\n",
      "Processing chunk 801/45455\n",
      "Processing chunk 851/45455\n",
      "Processing chunk 901/45455\n",
      "Processing chunk 951/45455\n",
      "Processing chunk 1001/45455\n",
      "Processing chunk 1051/45455\n",
      "Processing chunk 1101/45455\n",
      "Processing chunk 1151/45455\n",
      "Processing chunk 1201/45455\n",
      "Processing chunk 1251/45455\n",
      "Processing chunk 1301/45455\n",
      "Processing chunk 1351/45455\n",
      "Processing chunk 1401/45455\n",
      "Processing chunk 1451/45455\n",
      "Processing chunk 1501/45455\n",
      "Processing chunk 1551/45455\n",
      "Processing chunk 1601/45455\n",
      "Processing chunk 1651/45455\n",
      "Processing chunk 1701/45455\n",
      "Processing chunk 1751/45455\n",
      "Processing chunk 1801/45455\n",
      "Processing chunk 1851/45455\n",
      "Processing chunk 1901/45455\n",
      "Processing chunk 1951/45455\n",
      "Processing chunk 2001/45455\n",
      "Processing chunk 2051/45455\n",
      "Processing chunk 2101/45455\n",
      "Processing chunk 2151/45455\n",
      "Processing chunk 2201/45455\n",
      "Processing chunk 2251/45455\n",
      "Processing chunk 2301/45455\n",
      "Processing chunk 2351/45455\n",
      "Processing chunk 2401/45455\n",
      "Processing chunk 2451/45455\n",
      "Processing chunk 2501/45455\n",
      "Processing chunk 2551/45455\n",
      "Processing chunk 2601/45455\n",
      "Processing chunk 2651/45455\n",
      "Processing chunk 2701/45455\n",
      "Processing chunk 2751/45455\n",
      "Processing chunk 2801/45455\n",
      "Processing chunk 2851/45455\n",
      "Processing chunk 2901/45455\n",
      "Processing chunk 2951/45455\n",
      "Processing chunk 3001/45455\n",
      "Processing chunk 3051/45455\n",
      "Processing chunk 3101/45455\n",
      "Processing chunk 3151/45455\n",
      "Processing chunk 3201/45455\n",
      "Processing chunk 3251/45455\n",
      "Processing chunk 3301/45455\n",
      "Processing chunk 3351/45455\n",
      "Processing chunk 3401/45455\n",
      "Processing chunk 3451/45455\n",
      "Processing chunk 3501/45455\n",
      "Processing chunk 3551/45455\n",
      "Processing chunk 3601/45455\n",
      "Processing chunk 3651/45455\n",
      "Processing chunk 3701/45455\n",
      "Processing chunk 3751/45455\n",
      "Processing chunk 3801/45455\n",
      "Processing chunk 3851/45455\n",
      "Processing chunk 3901/45455\n",
      "Processing chunk 3951/45455\n",
      "Processing chunk 4001/45455\n",
      "Processing chunk 4051/45455\n",
      "Processing chunk 4101/45455\n",
      "Processing chunk 4151/45455\n",
      "Processing chunk 4201/45455\n",
      "Processing chunk 4251/45455\n",
      "Processing chunk 4301/45455\n",
      "Processing chunk 4351/45455\n",
      "Processing chunk 4401/45455\n",
      "Processing chunk 4451/45455\n",
      "Processing chunk 4501/45455\n",
      "Processing chunk 4551/45455\n",
      "Processing chunk 4601/45455\n",
      "Processing chunk 4651/45455\n",
      "Processing chunk 4701/45455\n",
      "Processing chunk 4751/45455\n",
      "Processing chunk 4801/45455\n",
      "Processing chunk 4851/45455\n",
      "Processing chunk 4901/45455\n",
      "Processing chunk 4951/45455\n",
      "Processing chunk 5001/45455\n",
      "Processing chunk 5051/45455\n",
      "Processing chunk 5101/45455\n",
      "Processing chunk 5151/45455\n",
      "Processing chunk 5201/45455\n",
      "Processing chunk 5251/45455\n",
      "Processing chunk 5301/45455\n",
      "Processing chunk 5351/45455\n",
      "Processing chunk 5401/45455\n",
      "Processing chunk 5451/45455\n",
      "Processing chunk 5501/45455\n",
      "Processing chunk 5551/45455\n",
      "Processing chunk 5601/45455\n",
      "Processing chunk 5651/45455\n",
      "Processing chunk 5701/45455\n",
      "Processing chunk 5751/45455\n",
      "Processing chunk 5801/45455\n",
      "Processing chunk 5851/45455\n",
      "Processing chunk 5901/45455\n",
      "Processing chunk 5951/45455\n",
      "Processing chunk 6001/45455\n",
      "Processing chunk 6051/45455\n",
      "Processing chunk 6101/45455\n",
      "Processing chunk 6151/45455\n",
      "Processing chunk 6201/45455\n",
      "Processing chunk 6251/45455\n",
      "Processing chunk 6301/45455\n",
      "Processing chunk 6351/45455\n",
      "Processing chunk 6401/45455\n",
      "Processing chunk 6451/45455\n",
      "Processing chunk 6501/45455\n",
      "Processing chunk 6551/45455\n",
      "Processing chunk 6601/45455\n",
      "Processing chunk 6651/45455\n",
      "Processing chunk 6701/45455\n",
      "Processing chunk 6751/45455\n",
      "Processing chunk 6801/45455\n",
      "Processing chunk 6851/45455\n",
      "Processing chunk 6901/45455\n",
      "Processing chunk 6951/45455\n",
      "Processing chunk 7001/45455\n",
      "Processing chunk 7051/45455\n",
      "Processing chunk 7101/45455\n",
      "Processing chunk 7151/45455\n",
      "Processing chunk 7201/45455\n",
      "Processing chunk 7251/45455\n",
      "Processing chunk 7301/45455\n",
      "Processing chunk 7351/45455\n",
      "Processing chunk 7401/45455\n",
      "Processing chunk 7451/45455\n",
      "Processing chunk 7501/45455\n",
      "Processing chunk 7551/45455\n",
      "Processing chunk 7601/45455\n",
      "Processing chunk 7651/45455\n",
      "Processing chunk 7701/45455\n",
      "Processing chunk 7751/45455\n",
      "Processing chunk 7801/45455\n",
      "Processing chunk 7851/45455\n",
      "Processing chunk 7901/45455\n",
      "Processing chunk 7951/45455\n",
      "Processing chunk 8001/45455\n",
      "Processing chunk 8051/45455\n",
      "Processing chunk 8101/45455\n",
      "Processing chunk 8151/45455\n",
      "Processing chunk 8201/45455\n",
      "Processing chunk 8251/45455\n",
      "Processing chunk 8301/45455\n",
      "Processing chunk 8351/45455\n",
      "Processing chunk 8401/45455\n",
      "Processing chunk 8451/45455\n",
      "Processing chunk 8501/45455\n",
      "Processing chunk 8551/45455\n",
      "Processing chunk 8601/45455\n",
      "Processing chunk 8651/45455\n",
      "Processing chunk 8701/45455\n",
      "Processing chunk 8751/45455\n",
      "Processing chunk 8801/45455\n",
      "Processing chunk 8851/45455\n",
      "Processing chunk 8901/45455\n",
      "Processing chunk 8951/45455\n",
      "Processing chunk 9001/45455\n",
      "Processing chunk 9051/45455\n",
      "Processing chunk 9101/45455\n",
      "Processing chunk 9151/45455\n",
      "Processing chunk 9201/45455\n",
      "Processing chunk 9251/45455\n",
      "Processing chunk 9301/45455\n",
      "Processing chunk 9351/45455\n",
      "Processing chunk 9401/45455\n",
      "Processing chunk 9451/45455\n",
      "Processing chunk 9501/45455\n",
      "Processing chunk 9551/45455\n",
      "Processing chunk 9601/45455\n",
      "Processing chunk 9651/45455\n",
      "Processing chunk 9701/45455\n",
      "Processing chunk 9751/45455\n",
      "Processing chunk 9801/45455\n",
      "Processing chunk 9851/45455\n",
      "Processing chunk 9901/45455\n",
      "Processing chunk 9951/45455\n",
      "Processing chunk 10001/45455\n",
      "Processing chunk 10051/45455\n",
      "Processing chunk 10101/45455\n",
      "Processing chunk 10151/45455\n",
      "Processing chunk 10201/45455\n",
      "Processing chunk 10251/45455\n",
      "Processing chunk 10301/45455\n",
      "Processing chunk 10351/45455\n",
      "Processing chunk 10401/45455\n",
      "Processing chunk 10451/45455\n",
      "Processing chunk 10501/45455\n",
      "Processing chunk 10551/45455\n",
      "Processing chunk 10601/45455\n",
      "Processing chunk 10651/45455\n",
      "Processing chunk 10701/45455\n",
      "Processing chunk 10751/45455\n",
      "Processing chunk 10801/45455\n",
      "Processing chunk 10851/45455\n",
      "Processing chunk 10901/45455\n",
      "Processing chunk 10951/45455\n",
      "Processing chunk 11001/45455\n",
      "Processing chunk 11051/45455\n",
      "Processing chunk 11101/45455\n",
      "Processing chunk 11151/45455\n",
      "Processing chunk 11201/45455\n",
      "Processing chunk 11251/45455\n",
      "Processing chunk 11301/45455\n",
      "Processing chunk 11351/45455\n",
      "Processing chunk 11401/45455\n",
      "Processing chunk 11451/45455\n",
      "Processing chunk 11501/45455\n",
      "Processing chunk 11551/45455\n",
      "Processing chunk 11601/45455\n",
      "Processing chunk 11651/45455\n",
      "Processing chunk 11701/45455\n",
      "Processing chunk 11751/45455\n",
      "Processing chunk 11801/45455\n",
      "Processing chunk 11851/45455\n",
      "Processing chunk 11901/45455\n",
      "Processing chunk 11951/45455\n",
      "Processing chunk 12001/45455\n",
      "Processing chunk 12051/45455\n",
      "Processing chunk 12101/45455\n",
      "Processing chunk 12151/45455\n",
      "Processing chunk 12201/45455\n",
      "Processing chunk 12251/45455\n",
      "Processing chunk 12301/45455\n",
      "Processing chunk 12351/45455\n",
      "Processing chunk 12401/45455\n",
      "Processing chunk 12451/45455\n",
      "Processing chunk 12501/45455\n",
      "Processing chunk 12551/45455\n",
      "Processing chunk 12601/45455\n",
      "Processing chunk 12651/45455\n",
      "Processing chunk 12701/45455\n",
      "Processing chunk 12751/45455\n",
      "Processing chunk 12801/45455\n",
      "Processing chunk 12851/45455\n",
      "Processing chunk 12901/45455\n",
      "Processing chunk 12951/45455\n",
      "Processing chunk 13001/45455\n",
      "Processing chunk 13051/45455\n",
      "Processing chunk 13101/45455\n",
      "Processing chunk 13151/45455\n",
      "Processing chunk 13201/45455\n",
      "Processing chunk 13251/45455\n",
      "Processing chunk 13301/45455\n",
      "Processing chunk 13351/45455\n",
      "Processing chunk 13401/45455\n",
      "Processing chunk 13451/45455\n",
      "Processing chunk 13501/45455\n",
      "Processing chunk 13551/45455\n",
      "Processing chunk 13601/45455\n",
      "Processing chunk 13651/45455\n",
      "Processing chunk 13701/45455\n",
      "Processing chunk 13751/45455\n",
      "Processing chunk 13801/45455\n",
      "Processing chunk 13851/45455\n",
      "Processing chunk 13901/45455\n",
      "Processing chunk 13951/45455\n",
      "Processing chunk 14001/45455\n",
      "Processing chunk 14051/45455\n",
      "Processing chunk 14101/45455\n",
      "Processing chunk 14151/45455\n",
      "Processing chunk 14201/45455\n",
      "Processing chunk 14251/45455\n",
      "Processing chunk 14301/45455\n",
      "Processing chunk 14351/45455\n",
      "Processing chunk 14401/45455\n",
      "Processing chunk 14451/45455\n",
      "Processing chunk 14501/45455\n",
      "Processing chunk 14551/45455\n",
      "Processing chunk 14601/45455\n",
      "Processing chunk 14651/45455\n",
      "Processing chunk 14701/45455\n",
      "Processing chunk 14751/45455\n",
      "Processing chunk 14801/45455\n",
      "Processing chunk 14851/45455\n",
      "Processing chunk 14901/45455\n",
      "Processing chunk 14951/45455\n",
      "Processing chunk 15001/45455\n",
      "Processing chunk 15051/45455\n",
      "Processing chunk 15101/45455\n",
      "Processing chunk 15151/45455\n",
      "Processing chunk 15201/45455\n",
      "Processing chunk 15251/45455\n",
      "Processing chunk 15301/45455\n",
      "Processing chunk 15351/45455\n",
      "Processing chunk 15401/45455\n",
      "Processing chunk 15451/45455\n",
      "Processing chunk 15501/45455\n",
      "Processing chunk 15551/45455\n",
      "Processing chunk 15601/45455\n",
      "Processing chunk 15651/45455\n",
      "Processing chunk 15701/45455\n",
      "Processing chunk 15751/45455\n",
      "Processing chunk 15801/45455\n",
      "Processing chunk 15851/45455\n",
      "Processing chunk 15901/45455\n",
      "Processing chunk 15951/45455\n",
      "Processing chunk 16001/45455\n",
      "Processing chunk 16051/45455\n",
      "Processing chunk 16101/45455\n",
      "Processing chunk 16151/45455\n",
      "Processing chunk 16201/45455\n",
      "Processing chunk 16251/45455\n",
      "Processing chunk 16301/45455\n",
      "Processing chunk 16351/45455\n",
      "Processing chunk 16401/45455\n",
      "Processing chunk 16451/45455\n",
      "Processing chunk 16501/45455\n",
      "Processing chunk 16551/45455\n",
      "Processing chunk 16601/45455\n",
      "Processing chunk 16651/45455\n",
      "Processing chunk 16701/45455\n",
      "Processing chunk 16751/45455\n",
      "Processing chunk 16801/45455\n",
      "Processing chunk 16851/45455\n",
      "Processing chunk 16901/45455\n",
      "Processing chunk 16951/45455\n",
      "Processing chunk 17001/45455\n",
      "Processing chunk 17051/45455\n",
      "Processing chunk 17101/45455\n",
      "Processing chunk 17151/45455\n",
      "Processing chunk 17201/45455\n",
      "Processing chunk 17251/45455\n",
      "Processing chunk 17301/45455\n",
      "Processing chunk 17351/45455\n",
      "Processing chunk 17401/45455\n",
      "Processing chunk 17451/45455\n",
      "Processing chunk 17501/45455\n",
      "Processing chunk 17551/45455\n",
      "Processing chunk 17601/45455\n",
      "Processing chunk 17651/45455\n",
      "Processing chunk 17701/45455\n",
      "Processing chunk 17751/45455\n",
      "Processing chunk 17801/45455\n",
      "Processing chunk 17851/45455\n",
      "Processing chunk 17901/45455\n",
      "Processing chunk 17951/45455\n",
      "Processing chunk 18001/45455\n",
      "Processing chunk 18051/45455\n",
      "Processing chunk 18101/45455\n",
      "Processing chunk 18151/45455\n",
      "Processing chunk 18201/45455\n",
      "Processing chunk 18251/45455\n",
      "Processing chunk 18301/45455\n",
      "Processing chunk 18351/45455\n",
      "Processing chunk 18401/45455\n",
      "Processing chunk 18451/45455\n",
      "Processing chunk 18501/45455\n",
      "Processing chunk 18551/45455\n",
      "Processing chunk 18601/45455\n",
      "Processing chunk 18651/45455\n",
      "Processing chunk 18701/45455\n",
      "Processing chunk 18751/45455\n",
      "Processing chunk 18801/45455\n",
      "Processing chunk 18851/45455\n",
      "Processing chunk 18901/45455\n",
      "Processing chunk 18951/45455\n",
      "Processing chunk 19001/45455\n",
      "Processing chunk 19051/45455\n",
      "Processing chunk 19101/45455\n",
      "Processing chunk 19151/45455\n",
      "Processing chunk 19201/45455\n",
      "Processing chunk 19251/45455\n",
      "Processing chunk 19301/45455\n",
      "Processing chunk 19351/45455\n",
      "Processing chunk 19401/45455\n",
      "Processing chunk 19451/45455\n",
      "Processing chunk 19501/45455\n",
      "Processing chunk 19551/45455\n",
      "Processing chunk 19601/45455\n",
      "Processing chunk 19651/45455\n",
      "Processing chunk 19701/45455\n",
      "Processing chunk 19751/45455\n",
      "Processing chunk 19801/45455\n",
      "Processing chunk 19851/45455\n",
      "Processing chunk 19901/45455\n",
      "Processing chunk 19951/45455\n",
      "Processing chunk 20001/45455\n",
      "Processing chunk 20051/45455\n",
      "Processing chunk 20101/45455\n",
      "Processing chunk 20151/45455\n",
      "Processing chunk 20201/45455\n",
      "Processing chunk 20251/45455\n",
      "Processing chunk 20301/45455\n",
      "Processing chunk 20351/45455\n",
      "Processing chunk 20401/45455\n",
      "Processing chunk 20451/45455\n",
      "Processing chunk 20501/45455\n",
      "Processing chunk 20551/45455\n",
      "Processing chunk 20601/45455\n",
      "Processing chunk 20651/45455\n",
      "Processing chunk 20701/45455\n",
      "Processing chunk 20751/45455\n",
      "Processing chunk 20801/45455\n",
      "Processing chunk 20851/45455\n",
      "Processing chunk 20901/45455\n",
      "Processing chunk 20951/45455\n",
      "Processing chunk 21001/45455\n",
      "Processing chunk 21051/45455\n",
      "Processing chunk 21101/45455\n",
      "Processing chunk 21151/45455\n",
      "Processing chunk 21201/45455\n",
      "Processing chunk 21251/45455\n",
      "Processing chunk 21301/45455\n",
      "Processing chunk 21351/45455\n",
      "Processing chunk 21401/45455\n",
      "Processing chunk 21451/45455\n",
      "Processing chunk 21501/45455\n",
      "Processing chunk 21551/45455\n",
      "Processing chunk 21601/45455\n",
      "Processing chunk 21651/45455\n",
      "Processing chunk 21701/45455\n",
      "Processing chunk 21751/45455\n",
      "Processing chunk 21801/45455\n",
      "Processing chunk 21851/45455\n",
      "Processing chunk 21901/45455\n",
      "Processing chunk 21951/45455\n",
      "Processing chunk 22001/45455\n",
      "Processing chunk 22051/45455\n",
      "Processing chunk 22101/45455\n",
      "Processing chunk 22151/45455\n",
      "Processing chunk 22201/45455\n",
      "Processing chunk 22251/45455\n",
      "Processing chunk 22301/45455\n",
      "Processing chunk 22351/45455\n",
      "Processing chunk 22401/45455\n",
      "Processing chunk 22451/45455\n",
      "Processing chunk 22501/45455\n",
      "Processing chunk 22551/45455\n",
      "Processing chunk 22601/45455\n",
      "Processing chunk 22651/45455\n",
      "Processing chunk 22701/45455\n",
      "Processing chunk 22751/45455\n",
      "Processing chunk 22801/45455\n",
      "Processing chunk 22851/45455\n",
      "Processing chunk 22901/45455\n",
      "Processing chunk 22951/45455\n",
      "Processing chunk 23001/45455\n",
      "Processing chunk 23051/45455\n",
      "Processing chunk 23101/45455\n",
      "Processing chunk 23151/45455\n",
      "Processing chunk 23201/45455\n",
      "Processing chunk 23251/45455\n",
      "Processing chunk 23301/45455\n",
      "Processing chunk 23351/45455\n",
      "Processing chunk 23401/45455\n",
      "Processing chunk 23451/45455\n",
      "Processing chunk 23501/45455\n",
      "Processing chunk 23551/45455\n",
      "Processing chunk 23601/45455\n",
      "Processing chunk 23651/45455\n",
      "Processing chunk 23701/45455\n",
      "Processing chunk 23751/45455\n",
      "Processing chunk 23801/45455\n",
      "Processing chunk 23851/45455\n",
      "Processing chunk 23901/45455\n",
      "Processing chunk 23951/45455\n",
      "Processing chunk 24001/45455\n",
      "Processing chunk 24051/45455\n",
      "Processing chunk 24101/45455\n",
      "Processing chunk 24151/45455\n",
      "Processing chunk 24201/45455\n",
      "Processing chunk 24251/45455\n",
      "Processing chunk 24301/45455\n",
      "Processing chunk 24351/45455\n",
      "Processing chunk 24401/45455\n",
      "Processing chunk 24451/45455\n",
      "Processing chunk 24501/45455\n",
      "Processing chunk 24551/45455\n",
      "Processing chunk 24601/45455\n",
      "Processing chunk 24651/45455\n",
      "Processing chunk 24701/45455\n",
      "Processing chunk 24751/45455\n",
      "Processing chunk 24801/45455\n",
      "Processing chunk 24851/45455\n",
      "Processing chunk 24901/45455\n",
      "Processing chunk 24951/45455\n",
      "Processing chunk 25001/45455\n",
      "Processing chunk 25051/45455\n",
      "Processing chunk 25101/45455\n",
      "Processing chunk 25151/45455\n",
      "Processing chunk 25201/45455\n",
      "Processing chunk 25251/45455\n",
      "Processing chunk 25301/45455\n",
      "Processing chunk 25351/45455\n",
      "Processing chunk 25401/45455\n",
      "Processing chunk 25451/45455\n",
      "Processing chunk 25501/45455\n",
      "Processing chunk 25551/45455\n",
      "Processing chunk 25601/45455\n",
      "Processing chunk 25651/45455\n",
      "Processing chunk 25701/45455\n",
      "Processing chunk 25751/45455\n",
      "Processing chunk 25801/45455\n",
      "Processing chunk 25851/45455\n",
      "Processing chunk 25901/45455\n",
      "Processing chunk 25951/45455\n",
      "Processing chunk 26001/45455\n",
      "Processing chunk 26051/45455\n",
      "Processing chunk 26101/45455\n",
      "Processing chunk 26151/45455\n",
      "Processing chunk 26201/45455\n",
      "Processing chunk 26251/45455\n",
      "Processing chunk 26301/45455\n",
      "Processing chunk 26351/45455\n",
      "Processing chunk 26401/45455\n",
      "Processing chunk 26451/45455\n",
      "Processing chunk 26501/45455\n",
      "Processing chunk 26551/45455\n",
      "Processing chunk 26601/45455\n",
      "Processing chunk 26651/45455\n",
      "Processing chunk 26701/45455\n",
      "Processing chunk 26751/45455\n",
      "Processing chunk 26801/45455\n",
      "Processing chunk 26851/45455\n",
      "Processing chunk 26901/45455\n",
      "Processing chunk 26951/45455\n",
      "Processing chunk 27001/45455\n",
      "Processing chunk 27051/45455\n",
      "Processing chunk 27101/45455\n",
      "Processing chunk 27151/45455\n",
      "Processing chunk 27201/45455\n",
      "Processing chunk 27251/45455\n",
      "Processing chunk 27301/45455\n",
      "Processing chunk 27351/45455\n",
      "Processing chunk 27401/45455\n",
      "Processing chunk 27451/45455\n",
      "Processing chunk 27501/45455\n",
      "Processing chunk 27551/45455\n",
      "Processing chunk 27601/45455\n",
      "Processing chunk 27651/45455\n",
      "Processing chunk 27701/45455\n",
      "Processing chunk 27751/45455\n",
      "Processing chunk 27801/45455\n",
      "Processing chunk 27851/45455\n",
      "Processing chunk 27901/45455\n",
      "Processing chunk 27951/45455\n",
      "Processing chunk 28001/45455\n",
      "Processing chunk 28051/45455\n",
      "Processing chunk 28101/45455\n",
      "Processing chunk 28151/45455\n",
      "Processing chunk 28201/45455\n",
      "Processing chunk 28251/45455\n",
      "Processing chunk 28301/45455\n",
      "Processing chunk 28351/45455\n",
      "Processing chunk 28401/45455\n",
      "Processing chunk 28451/45455\n",
      "Processing chunk 28501/45455\n",
      "Processing chunk 28551/45455\n",
      "Processing chunk 28601/45455\n",
      "Processing chunk 28651/45455\n",
      "Processing chunk 28701/45455\n",
      "Processing chunk 28751/45455\n",
      "Processing chunk 28801/45455\n",
      "Processing chunk 28851/45455\n",
      "Processing chunk 28901/45455\n",
      "Processing chunk 28951/45455\n",
      "Processing chunk 29001/45455\n",
      "Processing chunk 29051/45455\n",
      "Processing chunk 29101/45455\n",
      "Processing chunk 29151/45455\n",
      "Processing chunk 29201/45455\n",
      "Processing chunk 29251/45455\n",
      "Processing chunk 29301/45455\n",
      "Processing chunk 29351/45455\n",
      "Processing chunk 29401/45455\n",
      "Processing chunk 29451/45455\n",
      "Processing chunk 29501/45455\n",
      "Processing chunk 29551/45455\n",
      "Processing chunk 29601/45455\n",
      "Processing chunk 29651/45455\n",
      "Processing chunk 29701/45455\n",
      "Processing chunk 29751/45455\n",
      "Processing chunk 29801/45455\n",
      "Processing chunk 29851/45455\n",
      "Processing chunk 29901/45455\n",
      "Processing chunk 29951/45455\n",
      "Processing chunk 30001/45455\n",
      "Processing chunk 30051/45455\n",
      "Processing chunk 30101/45455\n",
      "Processing chunk 30151/45455\n",
      "Processing chunk 30201/45455\n",
      "Processing chunk 30251/45455\n",
      "Processing chunk 30301/45455\n",
      "Processing chunk 30351/45455\n",
      "Processing chunk 30401/45455\n",
      "Processing chunk 30451/45455\n",
      "Processing chunk 30501/45455\n",
      "Processing chunk 30551/45455\n",
      "Processing chunk 30601/45455\n",
      "Processing chunk 30651/45455\n",
      "Processing chunk 30701/45455\n",
      "Processing chunk 30751/45455\n",
      "Processing chunk 30801/45455\n",
      "Processing chunk 30851/45455\n",
      "Processing chunk 30901/45455\n",
      "Processing chunk 30951/45455\n",
      "Processing chunk 31001/45455\n",
      "Processing chunk 31051/45455\n",
      "Processing chunk 31101/45455\n",
      "Processing chunk 31151/45455\n",
      "Processing chunk 31201/45455\n",
      "Processing chunk 31251/45455\n",
      "Processing chunk 31301/45455\n",
      "Processing chunk 31351/45455\n",
      "Processing chunk 31401/45455\n",
      "Processing chunk 31451/45455\n",
      "Processing chunk 31501/45455\n",
      "Processing chunk 31551/45455\n",
      "Processing chunk 31601/45455\n",
      "Processing chunk 31651/45455\n",
      "Processing chunk 31701/45455\n",
      "Processing chunk 31751/45455\n",
      "Processing chunk 31801/45455\n",
      "Processing chunk 31851/45455\n",
      "Processing chunk 31901/45455\n",
      "Processing chunk 31951/45455\n",
      "Processing chunk 32001/45455\n",
      "Processing chunk 32051/45455\n",
      "Processing chunk 32101/45455\n",
      "Processing chunk 32151/45455\n",
      "Processing chunk 32201/45455\n",
      "Processing chunk 32251/45455\n",
      "Processing chunk 32301/45455\n",
      "Processing chunk 32351/45455\n",
      "Processing chunk 32401/45455\n",
      "Processing chunk 32451/45455\n",
      "Processing chunk 32501/45455\n",
      "Processing chunk 32551/45455\n",
      "Processing chunk 32601/45455\n",
      "Processing chunk 32651/45455\n",
      "Processing chunk 32701/45455\n",
      "Processing chunk 32751/45455\n",
      "Processing chunk 32801/45455\n",
      "Processing chunk 32851/45455\n",
      "Processing chunk 32901/45455\n",
      "Processing chunk 32951/45455\n",
      "Processing chunk 33001/45455\n",
      "Processing chunk 33051/45455\n",
      "Processing chunk 33101/45455\n",
      "Processing chunk 33151/45455\n",
      "Processing chunk 33201/45455\n",
      "Processing chunk 33251/45455\n",
      "Processing chunk 33301/45455\n",
      "Processing chunk 33351/45455\n",
      "Processing chunk 33401/45455\n",
      "Processing chunk 33451/45455\n",
      "Processing chunk 33501/45455\n",
      "Processing chunk 33551/45455\n",
      "Processing chunk 33601/45455\n",
      "Processing chunk 33651/45455\n",
      "Processing chunk 33701/45455\n",
      "Processing chunk 33751/45455\n",
      "Processing chunk 33801/45455\n",
      "Processing chunk 33851/45455\n",
      "Processing chunk 33901/45455\n",
      "Processing chunk 33951/45455\n",
      "Processing chunk 34001/45455\n",
      "Processing chunk 34051/45455\n",
      "Processing chunk 34101/45455\n",
      "Processing chunk 34151/45455\n",
      "Processing chunk 34201/45455\n",
      "Processing chunk 34251/45455\n",
      "Processing chunk 34301/45455\n",
      "Processing chunk 34351/45455\n",
      "Processing chunk 34401/45455\n",
      "Processing chunk 34451/45455\n",
      "Processing chunk 34501/45455\n",
      "Processing chunk 34551/45455\n",
      "Processing chunk 34601/45455\n",
      "Processing chunk 34651/45455\n",
      "Processing chunk 34701/45455\n",
      "Processing chunk 34751/45455\n",
      "Processing chunk 34801/45455\n",
      "Processing chunk 34851/45455\n",
      "Processing chunk 34901/45455\n",
      "Processing chunk 34951/45455\n",
      "Processing chunk 35001/45455\n",
      "Processing chunk 35051/45455\n",
      "Processing chunk 35101/45455\n",
      "Processing chunk 35151/45455\n",
      "Processing chunk 35201/45455\n",
      "Processing chunk 35251/45455\n",
      "Processing chunk 35301/45455\n",
      "Processing chunk 35351/45455\n",
      "Processing chunk 35401/45455\n",
      "Processing chunk 35451/45455\n",
      "Processing chunk 35501/45455\n",
      "Processing chunk 35551/45455\n",
      "Processing chunk 35601/45455\n",
      "Processing chunk 35651/45455\n",
      "Processing chunk 35701/45455\n",
      "Processing chunk 35751/45455\n",
      "Processing chunk 35801/45455\n",
      "Processing chunk 35851/45455\n",
      "Processing chunk 35901/45455\n",
      "Processing chunk 35951/45455\n",
      "Processing chunk 36001/45455\n",
      "Processing chunk 36051/45455\n",
      "Processing chunk 36101/45455\n",
      "Processing chunk 36151/45455\n",
      "Processing chunk 36201/45455\n",
      "Processing chunk 36251/45455\n",
      "Processing chunk 36301/45455\n",
      "Processing chunk 36351/45455\n",
      "Processing chunk 36401/45455\n",
      "Processing chunk 36451/45455\n",
      "Processing chunk 36501/45455\n",
      "Processing chunk 36551/45455\n",
      "Processing chunk 36601/45455\n",
      "Processing chunk 36651/45455\n",
      "Processing chunk 36701/45455\n",
      "Processing chunk 36751/45455\n",
      "Processing chunk 36801/45455\n",
      "Processing chunk 36851/45455\n",
      "Processing chunk 36901/45455\n",
      "Processing chunk 36951/45455\n",
      "Processing chunk 37001/45455\n",
      "Processing chunk 37051/45455\n",
      "Processing chunk 37101/45455\n",
      "Processing chunk 37151/45455\n",
      "Processing chunk 37201/45455\n",
      "Processing chunk 37251/45455\n",
      "Processing chunk 37301/45455\n",
      "Processing chunk 37351/45455\n",
      "Processing chunk 37401/45455\n",
      "Processing chunk 37451/45455\n",
      "Processing chunk 37501/45455\n",
      "Processing chunk 37551/45455\n",
      "Processing chunk 37601/45455\n",
      "Processing chunk 37651/45455\n",
      "Processing chunk 37701/45455\n",
      "Processing chunk 37751/45455\n",
      "Processing chunk 37801/45455\n",
      "Processing chunk 37851/45455\n",
      "Processing chunk 37901/45455\n",
      "Processing chunk 37951/45455\n",
      "Processing chunk 38001/45455\n",
      "Processing chunk 38051/45455\n",
      "Processing chunk 38101/45455\n",
      "Processing chunk 38151/45455\n",
      "Processing chunk 38201/45455\n",
      "Processing chunk 38251/45455\n",
      "Processing chunk 38301/45455\n",
      "Processing chunk 38351/45455\n",
      "Processing chunk 38401/45455\n",
      "Processing chunk 38451/45455\n",
      "Processing chunk 38501/45455\n",
      "Processing chunk 38551/45455\n",
      "Processing chunk 38601/45455\n",
      "Processing chunk 38651/45455\n",
      "Processing chunk 38701/45455\n",
      "Processing chunk 38751/45455\n",
      "Processing chunk 38801/45455\n",
      "Processing chunk 38851/45455\n",
      "Processing chunk 38901/45455\n",
      "Processing chunk 38951/45455\n",
      "Processing chunk 39001/45455\n",
      "Processing chunk 39051/45455\n",
      "Processing chunk 39101/45455\n",
      "Processing chunk 39151/45455\n",
      "Processing chunk 39201/45455\n",
      "Processing chunk 39251/45455\n",
      "Processing chunk 39301/45455\n",
      "Processing chunk 39351/45455\n",
      "Processing chunk 39401/45455\n",
      "Processing chunk 39451/45455\n",
      "Processing chunk 39501/45455\n",
      "Processing chunk 39551/45455\n",
      "Processing chunk 39601/45455\n",
      "Processing chunk 39651/45455\n",
      "Processing chunk 39701/45455\n",
      "Processing chunk 39751/45455\n",
      "Processing chunk 39801/45455\n",
      "Processing chunk 39851/45455\n",
      "Processing chunk 39901/45455\n",
      "Processing chunk 39951/45455\n",
      "Processing chunk 40001/45455\n",
      "Processing chunk 40051/45455\n",
      "Processing chunk 40101/45455\n",
      "Processing chunk 40151/45455\n",
      "Processing chunk 40201/45455\n",
      "Processing chunk 40251/45455\n",
      "Processing chunk 40301/45455\n",
      "Processing chunk 40351/45455\n",
      "Processing chunk 40401/45455\n",
      "Processing chunk 40451/45455\n",
      "Processing chunk 40501/45455\n",
      "Processing chunk 40551/45455\n",
      "Processing chunk 40601/45455\n",
      "Processing chunk 40651/45455\n",
      "Processing chunk 40701/45455\n",
      "Processing chunk 40751/45455\n",
      "Processing chunk 40801/45455\n",
      "Processing chunk 40851/45455\n",
      "Processing chunk 40901/45455\n",
      "Processing chunk 40951/45455\n",
      "Processing chunk 41001/45455\n",
      "Processing chunk 41051/45455\n",
      "Processing chunk 41101/45455\n",
      "Processing chunk 41151/45455\n",
      "Processing chunk 41201/45455\n",
      "Processing chunk 41251/45455\n",
      "Processing chunk 41301/45455\n",
      "Processing chunk 41351/45455\n",
      "Processing chunk 41401/45455\n",
      "Processing chunk 41451/45455\n",
      "Processing chunk 41501/45455\n",
      "Processing chunk 41551/45455\n",
      "Processing chunk 41601/45455\n",
      "Processing chunk 41651/45455\n",
      "Processing chunk 41701/45455\n",
      "Processing chunk 41751/45455\n",
      "Processing chunk 41801/45455\n",
      "Processing chunk 41851/45455\n",
      "Processing chunk 41901/45455\n",
      "Processing chunk 41951/45455\n",
      "Processing chunk 42001/45455\n",
      "Processing chunk 42051/45455\n",
      "Processing chunk 42101/45455\n",
      "Processing chunk 42151/45455\n",
      "Processing chunk 42201/45455\n",
      "Processing chunk 42251/45455\n",
      "Processing chunk 42301/45455\n",
      "Processing chunk 42351/45455\n",
      "Processing chunk 42401/45455\n",
      "Processing chunk 42451/45455\n",
      "Processing chunk 42501/45455\n",
      "Processing chunk 42551/45455\n",
      "Processing chunk 42601/45455\n",
      "Processing chunk 42651/45455\n",
      "Processing chunk 42701/45455\n",
      "Processing chunk 42751/45455\n",
      "Processing chunk 42801/45455\n",
      "Processing chunk 42851/45455\n",
      "Processing chunk 42901/45455\n",
      "Processing chunk 42951/45455\n",
      "Processing chunk 43001/45455\n",
      "Processing chunk 43051/45455\n",
      "Processing chunk 43101/45455\n",
      "Processing chunk 43151/45455\n",
      "Processing chunk 43201/45455\n",
      "Processing chunk 43251/45455\n",
      "Processing chunk 43301/45455\n",
      "Processing chunk 43351/45455\n",
      "Processing chunk 43401/45455\n",
      "Processing chunk 43451/45455\n",
      "Processing chunk 43501/45455\n",
      "Processing chunk 43551/45455\n",
      "Processing chunk 43601/45455\n",
      "Processing chunk 43651/45455\n",
      "Processing chunk 43701/45455\n",
      "Processing chunk 43751/45455\n",
      "Processing chunk 43801/45455\n",
      "Processing chunk 43851/45455\n",
      "Processing chunk 43901/45455\n",
      "Processing chunk 43951/45455\n",
      "Processing chunk 44001/45455\n",
      "Processing chunk 44051/45455\n",
      "Processing chunk 44101/45455\n",
      "Processing chunk 44151/45455\n",
      "Processing chunk 44201/45455\n",
      "Processing chunk 44251/45455\n",
      "Processing chunk 44301/45455\n",
      "Processing chunk 44351/45455\n",
      "Processing chunk 44401/45455\n",
      "Processing chunk 44451/45455\n",
      "Processing chunk 44501/45455\n",
      "Processing chunk 44551/45455\n",
      "Processing chunk 44601/45455\n",
      "Processing chunk 44651/45455\n",
      "Processing chunk 44701/45455\n",
      "Processing chunk 44751/45455\n",
      "Processing chunk 44801/45455\n",
      "Processing chunk 44851/45455\n",
      "Processing chunk 44901/45455\n",
      "Processing chunk 44951/45455\n",
      "Processing chunk 45001/45455\n",
      "Processing chunk 45051/45455\n",
      "Processing chunk 45101/45455\n",
      "Processing chunk 45151/45455\n",
      "Processing chunk 45201/45455\n",
      "Processing chunk 45251/45455\n",
      "Processing chunk 45301/45455\n",
      "Processing chunk 45351/45455\n",
      "Processing chunk 45401/45455\n",
      "Processing chunk 45451/45455\n",
      "\n",
      "Evaluation Statistics:\n",
      "Total users evaluated: 10000\n",
      "Number of hits: 9922\n",
      "Average HR@20: 0.9922\n",
      "Average NDCG@20: 0.4639\n",
      "\n",
      "Final Results:\n",
      "CF-UIcA: HR@20 = 0.9928, NDCG@20 = 0.4736, Training Time = 1.35s\n",
      "ST-GCN: HR@20 = 0.9906, NDCG@20 = 0.4537, Training Time = 2.33s\n",
      "NGCF: HR@20 = 0.9913, NDCG@20 = 0.4729, Training Time = 2.20s\n",
      "NMTR: HR@20 = 0.9906, NDCG@20 = 0.4510, Training Time = 1.81s\n",
      "DIPN: HR@20 = 0.9918, NDCG@20 = 0.4926, Training Time = 2.16s\n",
      "NGCF+M: HR@20 = 0.9918, NDCG@20 = 0.4645, Training Time = 1.94s\n",
      "MBGCN: HR@20 = 0.9905, NDCG@20 = 0.4639, Training Time = 1.87s\n",
      "MATN: HR@20 = 0.9932, NDCG@20 = 0.4920, Training Time = 1.32s\n",
      "GNMR: HR@20 = 0.9922, NDCG@20 = 0.4639, Training Time = 1.29s\n"
     ]
    }
   ],
   "source": [
    "MAX_U = 50000\n",
    "TOP_N = 20\n",
    "# --\n",
    "TRAIN_SAMP=5000\n",
    "EPOCH=10\n",
    "CHUNK_S=22\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import Linear, Dropout, LayerNorm\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import ModuleList\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from datetime import datetime\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class MultiBehaviorDataset:\n",
    "    def __init__(self, data_path='/Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/beibei01/', max_users=10000):\n",
    "        self.data_path = data_path\n",
    "        self.behaviors = ['pv', 'cart', 'buy']\n",
    "        self.trn_file = data_path + 'trn_'\n",
    "        self.tst_file = data_path + 'tst_'\n",
    "        self.max_users = max_users  # Limit number of users\n",
    "        \n",
    "        self.load_training_data()\n",
    "        self.load_test_data()\n",
    "    \n",
    "    def load_training_data(self):\n",
    "        print(\"Loading training data from:\", self.data_path)\n",
    "        self.trn_mats = []\n",
    "        for beh in self.behaviors:\n",
    "            path = self.trn_file + beh\n",
    "            print(f\"Loading behavior: {beh} from {path}\")\n",
    "            if not os.path.exists(path):\n",
    "                raise FileNotFoundError(f\"File not found: {path}\")\n",
    "            with open(path, 'rb') as fs:\n",
    "                mat = pickle.load(fs)\n",
    "                if not isinstance(mat, csr_matrix):\n",
    "                    mat = csr_matrix(mat)\n",
    "                mat = (mat != 0).astype(np.float32)\n",
    "                self.trn_mats.append(mat)\n",
    "        \n",
    "        self.trn_label = 1 * (self.trn_mats[-1] != 0)\n",
    "        self.n_users, self.n_items = self.trn_mats[0].shape\n",
    "        self.n_behaviors = len(self.behaviors)\n",
    "        print(f\"Dataset dimensions: {self.n_users} users, {self.n_items} items\")\n",
    "\n",
    "    def create_adjacency_matrix(self, users):\n",
    "        \"\"\"Optimized adjacency matrix creation\"\"\"\n",
    "        batch_size = len(users)\n",
    "        adj_matrix = torch.zeros(batch_size, batch_size, device=device)\n",
    "        \n",
    "        # Pre-compute user item sets\n",
    "        user_item_sets = []\n",
    "        for user in users:\n",
    "            user_items = set()\n",
    "            for mat in self.trn_mats:\n",
    "                user_items.update(mat[user].indices)\n",
    "            user_item_sets.append(user_items)\n",
    "        \n",
    "        # Compute similarities in parallel\n",
    "        for i in range(batch_size):\n",
    "            if not user_item_sets[i]:\n",
    "                continue\n",
    "            for j in range(i+1, batch_size):\n",
    "                if user_item_sets[j]:\n",
    "                    jaccard = len(user_item_sets[i] & user_item_sets[j]) / len(user_item_sets[i] | user_item_sets[j])\n",
    "                    adj_matrix[i,j] = adj_matrix[j,i] = jaccard\n",
    "        \n",
    "        return adj_matrix\n",
    "\n",
    "    def create_graph_metrics(self, users):\n",
    "        \"\"\"Optimized graph metrics creation\"\"\"\n",
    "        metrics = torch.zeros(len(users), 3, device=device)\n",
    "        \n",
    "        # Vectorized computation\n",
    "        for i, user in enumerate(users):\n",
    "            interactions = np.array([mat[user].nnz for mat in self.trn_mats])\n",
    "            metrics[i,0] = sum(interactions) / 100\n",
    "            metrics[i,1] = (interactions > 0).sum() / len(self.behaviors)\n",
    "            metrics[i,2] = interactions[-1] / max(interactions[0], 1)\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "    def prepare_train_instances(self, max_samples=TRAIN_SAMP):\n",
    "        \"\"\"Optimized training instance preparation\"\"\"\n",
    "        print(\"Preparing training instances...\")\n",
    "        train_data = []\n",
    "        \n",
    "        # Randomly select users\n",
    "        selected_users = np.random.choice(min(self.n_users, self.max_users), size=min(1000, self.max_users), replace=False)\n",
    "        \n",
    "        for user in selected_users:\n",
    "            pos_items = self.trn_label[user].indices[:2]  # Limit positive items\n",
    "            \n",
    "            if len(pos_items) > 0:\n",
    "                for item in pos_items:\n",
    "                    behaviors = [float(mat[user, item]) for mat in self.trn_mats]\n",
    "                    train_data.append([user, item, 1.0] + behaviors)\n",
    "                    \n",
    "                    # Limited negative sampling\n",
    "                    neg_items = np.random.choice(self.n_items, size=2, replace=False)\n",
    "                    for neg_item in neg_items:\n",
    "                        behaviors = [float(mat[user, neg_item]) for mat in self.trn_mats]\n",
    "                        train_data.append([user, neg_item, 0.0] + behaviors)\n",
    "                        \n",
    "                    if len(train_data) >= max_samples:\n",
    "                        break\n",
    "            \n",
    "            if len(train_data) >= max_samples:\n",
    "                break\n",
    "        \n",
    "        print(f\"Generated {len(train_data)} training instances\")\n",
    "        return np.array(train_data)\n",
    "    \n",
    "    def load_test_data(self):\n",
    "        \"\"\"Load test data\"\"\"\n",
    "        test_path = self.tst_file + 'int'\n",
    "        print(f\"Loading test data from: {test_path}\")\n",
    "        if not os.path.exists(test_path):\n",
    "            raise FileNotFoundError(f\"File not found: {test_path}\")\n",
    "        with open(test_path, 'rb') as fs:\n",
    "            self.tst_int = np.array(pickle.load(fs))\n",
    "        \n",
    "        self.tst_users = np.reshape(np.argwhere(self.tst_int != None), [-1])\n",
    "        # Limit test users for faster processing\n",
    "        self.tst_users = self.tst_users[:min(len(self.tst_users), self.max_users)]\n",
    "        print(f\"Using {len(self.tst_users)} test users\")\n",
    "\n",
    "    def get_test_instances(self, num_neg_samples=99):\n",
    "        \"\"\"Generate test instances with negative sampling\"\"\"\n",
    "        print(\"Preparing test instances...\")\n",
    "        test_instances = []\n",
    "        \n",
    "        for user in self.tst_users:\n",
    "            pos_item = self.tst_int[user]\n",
    "            if pos_item is not None:\n",
    "                # Add positive instance\n",
    "                test_instances.append([user, pos_item, 1.0])\n",
    "                \n",
    "                # Add negative instances\n",
    "                try:\n",
    "                    # Get all items and remove positive items\n",
    "                    all_items = set(range(self.n_items))\n",
    "                    pos_items_train = set(self.trn_label[user].indices)\n",
    "                    pos_items_train.add(pos_item)\n",
    "                    neg_items_pool = list(all_items - pos_items_train)\n",
    "                    \n",
    "                    # Sample negative items\n",
    "                    n_neg = min(num_neg_samples, len(neg_items_pool))\n",
    "                    if n_neg > 0:\n",
    "                        neg_items = np.random.choice(neg_items_pool, size=n_neg, replace=False)\n",
    "                        for neg_item in neg_items:\n",
    "                            test_instances.append([user, neg_item, 0.0])\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing test user {user}: {str(e)}\")\n",
    "                    continue\n",
    "                \n",
    "                # Limit the number of test instances for faster processing\n",
    "                if len(test_instances) >= self.max_users * 100:\n",
    "                    break\n",
    "        \n",
    "        if not test_instances:\n",
    "            raise ValueError(\"No test instances were generated!\")\n",
    "            \n",
    "        test_instances = np.array(test_instances)\n",
    "        print(f\"Generated {len(test_instances)} test instances\")\n",
    "        return test_instances\n",
    "\n",
    "def evaluate_model(model, dataset, test_instances, k=10):\n",
    "    \"\"\"Improved evaluation function with better metrics calculation\"\"\"\n",
    "    model.eval()\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    \n",
    "    # Process test instances in smaller chunks\n",
    "    chunk_size = CHUNK_S\n",
    "    test_chunks = [test_instances[i:i + chunk_size] for i in range(0, len(test_instances), chunk_size)]\n",
    "    \n",
    "    print(f\"Evaluating {len(test_instances)} instances in {len(test_chunks)} chunks...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for chunk_idx, chunk in enumerate(test_chunks):\n",
    "            if chunk_idx % 50 == 0:  # Reduced frequency of progress updates\n",
    "                print(f\"Processing chunk {chunk_idx + 1}/{len(test_chunks)}\")\n",
    "            \n",
    "            # Group by user and ensure we have both positive and negative items\n",
    "            user_items = {}\n",
    "            for inst in chunk:\n",
    "                user = int(inst[0])\n",
    "                item = int(inst[1])\n",
    "                label = float(inst[2])\n",
    "                \n",
    "                if user not in user_items:\n",
    "                    user_items[user] = {'pos': [], 'neg': [], 'all_items': [], 'all_scores': []}\n",
    "                \n",
    "                user_items[user]['all_items'].append(item)\n",
    "                if label > 0.5:\n",
    "                    user_items[user]['pos'].append(item)\n",
    "                else:\n",
    "                    user_items[user]['neg'].append(item)\n",
    "            \n",
    "            # Process each user that has both positive and negative items\n",
    "            for user, data in user_items.items():\n",
    "                if not data['pos'] or not data['neg']:\n",
    "                    continue\n",
    "                \n",
    "                items = data['all_items']\n",
    "                batch_size = len(items)\n",
    "                \n",
    "                # Create input features\n",
    "                user_tensor = torch.LongTensor([user] * batch_size).to(device)\n",
    "                item_tensor = torch.LongTensor(items).to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                predictions = model(user_tensor, item_tensor)  # Pass both user and item\n",
    "                predictions = predictions.cpu().numpy().flatten()\n",
    "                \n",
    "                # Store all scores\n",
    "                for item, score in zip(items, predictions):\n",
    "                    data['all_scores'].append((item, score))\n",
    "                \n",
    "                # Sort items by score\n",
    "                sorted_items = [x[0] for x in sorted(data['all_scores'], key=lambda x: x[1], reverse=True)]\n",
    "                recommended_items = sorted_items[:k]\n",
    "                \n",
    "                # Calculate HR\n",
    "                hit = any(pos_item in recommended_items for pos_item in data['pos'])\n",
    "                hits.append(hit)\n",
    "                \n",
    "                # Calculate NDCG\n",
    "                dcg = 0\n",
    "                for i, item in enumerate(recommended_items):\n",
    "                    if item in data['pos']:\n",
    "                        dcg += 1 / np.log2(i + 2)\n",
    "                idcg = sum(1 / np.log2(i + 2) for i in range(len(data['pos'])))  # Ideal DCG\n",
    "                ndcg = dcg / (idcg if idcg > 0 else 1)  # Avoid division by zero\n",
    "                ndcgs.append(ndcg)\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    hr = np.mean(hits) if hits else 0\n",
    "    ndcg = np.mean(ndcgs) if ndcgs else 0\n",
    "    \n",
    "    # Print detailed statistics\n",
    "    print(f\"\\nEvaluation Statistics:\")\n",
    "    print(f\"Total users evaluated: {len(hits)}\")\n",
    "    print(f\"Number of hits: {sum(hits)}\")\n",
    "    print(f\"Average HR@{k}: {hr:.4f}\")\n",
    "    print(f\"Average NDCG@{k}: {ndcg:.4f}\")\n",
    "    \n",
    "    return hr, ndcg\n",
    "\n",
    "# Define and Implement Each Algorithm\n",
    "class CF_UIcA(nn.Module):\n",
    "    def __init__(self, n_users, n_items, embedding_dim=128):\n",
    "        super(CF_UIcA, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(n_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(n_items, embedding_dim)\n",
    "        self.fc = nn.Linear(embedding_dim * 2, 1)\n",
    "        self.input_dim = embedding_dim * 2\n",
    "\n",
    "    def forward(self, users, items):\n",
    "        user_emb = self.user_embedding(users)\n",
    "        item_emb = self.item_embedding(items)\n",
    "        combined = torch.cat([user_emb, item_emb], dim=1)\n",
    "        return self.fc(combined).squeeze()\n",
    "\n",
    "class ST_GCN(nn.Module):\n",
    "    def __init__(self, n_users, n_items, embedding_dim=128):\n",
    "        super(ST_GCN, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(n_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(n_items, embedding_dim)\n",
    "        self.gcn_layer = nn.Linear(embedding_dim * 2, embedding_dim)\n",
    "        self.fc = nn.Linear(embedding_dim, 1)\n",
    "        self.input_dim = embedding_dim * 2\n",
    "\n",
    "    \n",
    "    def forward(self, users, items):\n",
    "        user_emb = self.user_embedding(users)\n",
    "        item_emb = self.item_embedding(items)\n",
    "        combined = torch.cat([user_emb, item_emb], dim=1)\n",
    "        gcn_output = F.relu(self.gcn_layer(combined))\n",
    "        return self.fc(gcn_output).squeeze()\n",
    "    \n",
    "class NGCF(nn.Module):\n",
    "    def __init__(self, n_users, n_items, embedding_dim=128):\n",
    "        super(NGCF, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(n_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(n_items, embedding_dim)\n",
    "        self.gcn_layer = nn.Linear(embedding_dim * 2, embedding_dim)\n",
    "        self.fc = nn.Linear(embedding_dim, 1)\n",
    "        self.input_dim = embedding_dim * 2\n",
    "\n",
    "    \n",
    "    def forward(self, users, items):\n",
    "        user_emb = self.user_embedding(users)\n",
    "        item_emb = self.item_embedding(items)\n",
    "        combined = torch.cat([user_emb, item_emb], dim=1)\n",
    "        gcn_output = F.relu(self.gcn_layer(combined))\n",
    "        return self.fc(gcn_output).squeeze()\n",
    "\n",
    "class NMTR(nn.Module):\n",
    "    def __init__(self, n_users, n_items, embedding_dim=128):\n",
    "        super(NMTR, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(n_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(n_items, embedding_dim)\n",
    "        self.fc = nn.Linear(embedding_dim * 2, 1)\n",
    "        self.input_dim = embedding_dim * 2\n",
    "\n",
    "    \n",
    "    def forward(self, users, items):\n",
    "        user_emb = self.user_embedding(users)\n",
    "        item_emb = self.item_embedding(items)\n",
    "        combined = torch.cat([user_emb, item_emb], dim=1)\n",
    "        return self.fc(combined).squeeze()\n",
    "\n",
    "class DIPN(nn.Module):\n",
    "    def __init__(self, n_users, n_items, embedding_dim=128):\n",
    "        super(DIPN, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(n_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(n_items, embedding_dim)\n",
    "        self.fc = nn.Linear(embedding_dim * 2, 1)\n",
    "        self.input_dim = embedding_dim * 2\n",
    "\n",
    "    \n",
    "    def forward(self, users, items):\n",
    "        user_emb = self.user_embedding(users)\n",
    "        item_emb = self.item_embedding(items)\n",
    "        combined = torch.cat([user_emb, item_emb], dim=1)\n",
    "        return self.fc(combined).squeeze()\n",
    "\n",
    "class NGCF_M(nn.Module):\n",
    "    def __init__(self, n_users, n_items, embedding_dim=128):\n",
    "        super(NGCF_M, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(n_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(n_items, embedding_dim)\n",
    "        self.gcn_layer = nn.Linear(embedding_dim * 2, embedding_dim)\n",
    "        self.fc = nn.Linear(embedding_dim, 1)\n",
    "        self.input_dim = embedding_dim * 2\n",
    "\n",
    "    \n",
    "    def forward(self, users, items):\n",
    "        user_emb = self.user_embedding(users)\n",
    "        item_emb = self.item_embedding(items)\n",
    "        combined = torch.cat([user_emb, item_emb], dim=1)\n",
    "        gcn_output = F.relu(self.gcn_layer(combined))\n",
    "        return self.fc(gcn_output).squeeze()\n",
    "\n",
    "class MBGCN(nn.Module):\n",
    "    def __init__(self, n_users, n_items, embedding_dim=128):\n",
    "        super(MBGCN, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(n_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(n_items, embedding_dim)\n",
    "        self.gcn_layer = nn.Linear(embedding_dim * 2, embedding_dim)\n",
    "        self.fc = nn.Linear(embedding_dim, 1)\n",
    "        self.input_dim = embedding_dim * 2\n",
    "\n",
    "    \n",
    "    def forward(self, users, items):\n",
    "        user_emb = self.user_embedding(users)\n",
    "        item_emb = self.item_embedding(items)\n",
    "        combined = torch.cat([user_emb, item_emb], dim=1)\n",
    "        gcn_output = F.relu(self.gcn_layer(combined))\n",
    "        return self.fc(gcn_output).squeeze()\n",
    "\n",
    "class MATN(nn.Module):\n",
    "    def __init__(self, n_users, n_items, embedding_dim=128):\n",
    "        super(MATN, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(n_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(n_items, embedding_dim)\n",
    "        self.fc = nn.Linear(embedding_dim * 2, 1)\n",
    "        self.input_dim = embedding_dim * 2\n",
    "\n",
    "    \n",
    "    def forward(self, users, items):\n",
    "        user_emb = self.user_embedding(users)\n",
    "        item_emb = self.item_embedding(items)\n",
    "        combined = torch.cat([user_emb, item_emb], dim=1)\n",
    "        return self.fc(combined).squeeze()\n",
    "\n",
    "class GNMR(nn.Module):\n",
    "    def __init__(self, n_users, n_items, embedding_dim=128):\n",
    "        super(GNMR, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(n_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(n_items, embedding_dim)\n",
    "        self.fc = nn.Linear(embedding_dim * 2, 1)\n",
    "        self.input_dim = embedding_dim * 2\n",
    "\n",
    "    \n",
    "    def forward(self, users, items):\n",
    "        user_emb = self.user_embedding(users)\n",
    "        item_emb = self.item_embedding(items)\n",
    "        combined = torch.cat([user_emb, item_emb], dim=1)\n",
    "        return self.fc(combined).squeeze()\n",
    "\n",
    "class CDAE(nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_behaviors, embedding_dim=128):\n",
    "        super(CDAE, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(n_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(n_items, embedding_dim)\n",
    "        self.fc1 = nn.Linear(embedding_dim, 64)  # Hidden layer\n",
    "        self.fc2 = nn.Linear(64, 1)  # Output layer\n",
    "        self.input_dim = n_behaviors  # Set input_dim based on the number of behaviors\n",
    "\n",
    "    def forward(self, user, item, adj_matrix=None, graph_metrics=None):\n",
    "        user_emb = self.user_embedding(user)\n",
    "        item_emb = self.item_embedding(item)\n",
    "        combined = user_emb * item_emb  # Element-wise multiplication\n",
    "        hidden = F.relu(self.fc1(combined))  # Activation function\n",
    "        output = self.fc2(hidden)  # A scalar value per pair\n",
    "        return output.squeeze()\n",
    "\n",
    "class NADE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(NADE, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        # Define layers\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through the network\n",
    "        hidden = F.relu(self.fc1(x))\n",
    "        output = self.fc2(hidden)\n",
    "        return output\n",
    "\n",
    "class AutoRec(nn.Module):\n",
    "    def __init__(self, num_items, hidden_dim=256):\n",
    "        super(AutoRec, self).__init__()\n",
    "        self.input_dim = num_items\n",
    "        \n",
    "        # Simplified architecture\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(num_items, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, num_items),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, adjacency_matrix=None, graph_metrics=None):\n",
    "        if x.dim() > 2:\n",
    "            x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Normalize input\n",
    "        x = torch.clamp(x, 0, 1)  # Ensure input is between 0 and 1\n",
    "        \n",
    "        h = self.encoder(x)\n",
    "        out = self.decoder(h)\n",
    "        return out\n",
    "\n",
    "class DMFModel(nn.Module):\n",
    "    def __init__(self, n_users, n_items, embedding_dim=128, behavior_dim=3):\n",
    "        super(DMFModel, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(n_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(n_items, embedding_dim)\n",
    "        self.behavior_fc = nn.Linear(behavior_dim, embedding_dim)\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(embedding_dim * 3, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, users, items, behaviors):\n",
    "        user_embed = self.user_embedding(users)\n",
    "        item_embed = self.item_embedding(items)\n",
    "        behavior_embed = self.behavior_fc(behaviors)\n",
    "        combined = torch.cat([user_embed, item_embed, behavior_embed], dim=1)\n",
    "        return self.fc_layers(combined).squeeze()\n",
    "\n",
    "\n",
    "# Main Function to Train and Evaluate All Models\n",
    "def main():\n",
    "    # Configuration\n",
    "    config = {\n",
    "        'embedding_dim': 1024,\n",
    "        'learning_rate': 0.001,\n",
    "        'weight_decay': 1e-6,\n",
    "        'dropout': 0.001,\n",
    "        'gradient_clip': 1.0,\n",
    "        'max_samples': 10000,\n",
    "        'eval_k': TOP_N,\n",
    "    }\n",
    "    \n",
    "    print(\"Initializing dataset...\")\n",
    "    dataset = MultiBehaviorDataset(max_users=MAX_U)\n",
    "    train_data = dataset.prepare_train_instances(max_samples=config['max_samples'])\n",
    "    \n",
    "    print(f\"Using {len(train_data)} training instances\")\n",
    "\n",
    "    # Define all models\n",
    "    models = {\n",
    "        \"CF-UIcA\": CF_UIcA(dataset.n_users, dataset.n_items, config['embedding_dim']).to(device),\n",
    "        \"ST-GCN\": ST_GCN(dataset.n_users, dataset.n_items, config['embedding_dim']).to(device),\n",
    "        \"NGCF\": NGCF(dataset.n_users, dataset.n_items, config['embedding_dim']).to(device),\n",
    "        \"NMTR\": NMTR(dataset.n_users, dataset.n_items, config['embedding_dim']).to(device),\n",
    "        \"DIPN\": DIPN(dataset.n_users, dataset.n_items, config['embedding_dim']).to(device),\n",
    "        \"NGCF+M\": NGCF_M(dataset.n_users, dataset.n_items, config['embedding_dim']).to(device),\n",
    "        \"MBGCN\": MBGCN(dataset.n_users, dataset.n_items, config['embedding_dim']).to(device),\n",
    "        \"MATN\": MATN(dataset.n_users, dataset.n_items, config['embedding_dim']).to(device),\n",
    "        \"GNMR\": GNMR(dataset.n_users, dataset.n_items, config['embedding_dim']).to(device),\n",
    "        # \"CDAE\": CDAE(dataset.n_users, dataset.n_items, config['embedding_dim']).to(device),\n",
    "\n",
    "    }\n",
    "\n",
    "\n",
    "    # Train and evaluate each model\n",
    "    results = {}\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nTraining and evaluating {model_name}...\")\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
    "\n",
    "        # Prepare training tensors\n",
    "        users = torch.LongTensor(train_data[:, 0]).to(device)\n",
    "        items = torch.LongTensor(train_data[:, 1]).to(device)\n",
    "        labels = torch.FloatTensor(train_data[:, 2]).to(device)\n",
    "        behaviors = torch.FloatTensor(train_data[:, 3:]).to(device)\n",
    "\n",
    "        # Training\n",
    "        model.train()\n",
    "        start_time = datetime.now()\n",
    "        for epoch in range(EPOCH):  # Adjust the number of epochs\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(users, items)\n",
    "            loss = criterion(predictions, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), config['gradient_clip'])\n",
    "            optimizer.step()\n",
    "            print(f\"Epoch {epoch + 1}, Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        training_time = (datetime.now() - start_time).total_seconds()\n",
    "        print(f\"Training completed in {training_time:.2f}s\")\n",
    "\n",
    "        # Evaluation\n",
    "        test_instances = dataset.get_test_instances()\n",
    "        hr, ndcg = evaluate_model(model, dataset, test_instances, k=config['eval_k'])\n",
    "        \n",
    "        # Save results\n",
    "        results[model_name] = {\n",
    "            'training_time': training_time,\n",
    "            'hr': hr,\n",
    "            'ndcg': ndcg\n",
    "        }\n",
    "    \n",
    "    # Print final results\n",
    "    print(\"\\nFinal Results:\")\n",
    "    for model_name, metrics in results.items():\n",
    "        print(f\"{model_name}: HR@{config['eval_k']} = {metrics['hr']:.4f}, NDCG@{config['eval_k']} = {metrics['ndcg']:.4f}, Training Time = {metrics['training_time']:.2f}s\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "colorscale": [
          [
           0,
           "#440154"
          ],
          [
           0.1111111111111111,
           "#482878"
          ],
          [
           0.2222222222222222,
           "#3e4989"
          ],
          [
           0.3333333333333333,
           "#31688e"
          ],
          [
           0.4444444444444444,
           "#26828e"
          ],
          [
           0.5555555555555556,
           "#1f9e89"
          ],
          [
           0.6666666666666666,
           "#35b779"
          ],
          [
           0.7777777777777778,
           "#6ece58"
          ],
          [
           0.8888888888888888,
           "#b5de2b"
          ],
          [
           1,
           "#fde725"
          ]
         ],
         "type": "heatmap",
         "x": [
          "hr@10",
          "ndcg@10",
          "hr@20",
          "ndcg@20",
          "hr@50",
          "ndcg@50",
          "hr@60",
          "ndcg@60"
         ],
         "y": [
          "GraphTransformer",
          "CF-UIcA",
          "ST-GCN",
          "NGCF",
          "NMTR",
          "DIPN",
          "NGCF+M",
          "MBGCN",
          "MATN",
          "GNMR",
          "GraphSAGE",
          "MFBias",
          "AutoRec",
          "NCF",
          "DMF",
          "CDAE",
          "NADE"
         ],
         "z": [
          [
           0.9631,
           0.9406,
           0.9981,
           0.8972,
           0.9991,
           0.499,
           0.998,
           0.8974
          ],
          [
           0.6041,
           0.2765,
           0.9928,
           0.3429,
           0.9266,
           0.2885,
           0.9765,
           0.2902
          ],
          [
           0.5933,
           0.267,
           0.9906,
           0.4537,
           0.927,
           0.2838,
           0.9739,
           0.2902
          ],
          [
           0.6084,
           0.2851,
           0.9913,
           0.4729,
           0.9196,
           0.2784,
           0.9793,
           0.3024
          ],
          [
           0.6047,
           0.6047,
           0.9906,
           0.451,
           0.9327,
           0.291,
           0.9811,
           0.3013
          ],
          [
           0.5934,
           0.2616,
           0.9918,
           0.4645,
           0.9331,
           0.2932,
           0.9769,
           0.2966
          ],
          [
           0.5972,
           0.2738,
           0.9218,
           0.4643,
           0.9351,
           0.2946,
           0.9833,
           0.3067
          ],
          [
           0.6035,
           0.2687,
           0.9905,
           0.4639,
           0.9216,
           0.2835,
           0.978,
           0.2989
          ],
          [
           0.636,
           0.2987,
           0.9932,
           0.4639,
           0.9375,
           0.2876,
           0.9811,
           0.3169
          ],
          [
           0.61,
           0.283,
           0.9922,
           0.4632,
           0.9349,
           0.2849,
           0.9761,
           0.2899
          ],
          [
           0.6039,
           0.3827,
           0.77,
           0.22,
           0.91,
           0.43,
           0.89,
           0.56
          ],
          [
           0.6953,
           0.6459,
           0.7259,
           0.6508,
           0.8303,
           0.667,
           0.8758,
           0.5234
          ],
          [
           0.932,
           0.4,
           0.98,
           0.56,
           0.933,
           0.43,
           0.89,
           0.32
          ],
          [
           0.6012,
           0.2821,
           0.8991,
           0.3479,
           1,
           0.3693,
           1,
           0.379
          ],
          [
           0.697,
           0.6434,
           0.7426,
           0.6454,
           0.8349,
           0.6659,
           0.8734,
           0.6871
          ],
          [
           0.7908,
           0.4212,
           0.9916,
           0.4722,
           0.87,
           0.4734,
           1,
           0.475
          ],
          [
           0.78,
           0.9734,
           1,
           0.9352,
           1,
           0.499,
           1,
           0.9673
          ]
         ]
        }
       ],
       "layout": {
        "height": 800,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Performance Heatmap (n=50000)"
        },
        "xaxis": {
         "title": {
          "text": "Metrics"
         }
        },
        "yaxis": {
         "title": {
          "text": "Models"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines+markers",
         "name": "n=500",
         "type": "scatter",
         "x": [
          10,
          20,
          50,
          60
         ],
         "y": [
          0.966,
          0.993,
          0.996,
          1
         ]
        },
        {
         "mode": "lines+markers",
         "name": "n=5000",
         "type": "scatter",
         "x": [
          10,
          20,
          50,
          60
         ],
         "y": [
          0.997,
          0.962,
          0.9412,
          0.992
         ]
        },
        {
         "mode": "lines+markers",
         "name": "n=50000",
         "type": "scatter",
         "x": [
          10,
          20,
          50,
          60
         ],
         "y": [
          0.9631,
          0.9981,
          0.9991,
          0.998
         ]
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "Sample Size"
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "HR@K for GraphTransformer"
        },
        "xaxis": {
         "title": {
          "text": "K"
         }
        },
        "yaxis": {
         "title": {
          "text": "HR"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines+markers",
         "name": "n=500",
         "type": "scatter",
         "x": [
          10,
          20,
          50,
          60
         ],
         "y": [
          0.9303,
          0.4311,
          0.963,
          0.7552
         ]
        },
        {
         "mode": "lines+markers",
         "name": "n=5000",
         "type": "scatter",
         "x": [
          10,
          20,
          50,
          60
         ],
         "y": [
          0.9627,
          0.9394,
          0.3933,
          0.8957
         ]
        },
        {
         "mode": "lines+markers",
         "name": "n=50000",
         "type": "scatter",
         "x": [
          10,
          20,
          50,
          60
         ],
         "y": [
          0.9406,
          0.8972,
          0.499,
          0.8974
         ]
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "Sample Size"
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "NDCG@K for GraphTransformer"
        },
        "xaxis": {
         "title": {
          "text": "K"
         }
        },
        "yaxis": {
         "title": {
          "text": "NDCG"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yf/20z1hn994jd04q4kl0gpgh740000gn/T/ipykernel_51372/1875773093.py:57: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "Model=%{x}<br>hr@10=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "GraphTransformer",
          "AutoRec",
          "CDAE",
          "NADE",
          "DMF",
          "MFBias",
          "MATN",
          "GNMR",
          "NGCF",
          "NMTR",
          "CF-UIcA",
          "GraphSAGE",
          "MBGCN",
          "NCF",
          "NGCF+M",
          "DIPN",
          "ST-GCN"
         ],
         "xaxis": "x",
         "y": [
          0.9631,
          0.932,
          0.7908,
          0.78,
          0.697,
          0.6953,
          0.636,
          0.61,
          0.6084,
          0.6047,
          0.6041,
          0.6039,
          0.6035,
          0.6012,
          0.5972,
          0.5934,
          0.5933
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "height": 600,
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Model Comparison - hr@10 (n=50000)"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "tickangle": 45,
         "title": {
          "text": "Model"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "hr@10"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Read the data\n",
    "data = pd.read_csv('b.csv')\n",
    "\n",
    "# 1. Create a heatmap of all metrics for all models at 50000\n",
    "def create_heatmap(data, n_samples=50000):\n",
    "    df_filtered = data[data['MODELS'].str.contains(str(n_samples))]\n",
    "    metrics = ['hr@10', 'ndcg@10', 'hr@20', 'ndcg@20', 'hr@50', 'ndcg@50', 'hr@60', 'ndcg@60']\n",
    "    model_names = [name.replace(f' {n_samples}', '') for name in df_filtered['MODELS']]\n",
    "    \n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=df_filtered[metrics].values,\n",
    "        x=metrics,\n",
    "        y=model_names,\n",
    "        colorscale='Viridis'\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f'Performance Heatmap (n={n_samples})',\n",
    "        xaxis_title='Metrics',\n",
    "        yaxis_title='Models',\n",
    "        height=800\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "# 2. Create line plots comparing HR@K and NDCG@K across different K values\n",
    "def create_metric_comparison(data, model_name='GraphTransformer', metric_prefix='hr'):\n",
    "    df_filtered = data[data['MODELS'].str.contains(model_name)]\n",
    "    metrics = [col for col in data.columns if metric_prefix in col]\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    for _, row in df_filtered.iterrows():\n",
    "        sample_size = row['MODELS'].split()[-1]\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[int(m.split('@')[1]) for m in metrics],\n",
    "            y=[row[m] for m in metrics],\n",
    "            name=f'n={sample_size}',\n",
    "            mode='lines+markers'\n",
    "        ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f'{metric_prefix.upper()}@K for {model_name}',\n",
    "        xaxis_title='K',\n",
    "        yaxis_title=metric_prefix.upper(),\n",
    "        legend_title='Sample Size'\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "# 3. Create bar plot comparing top models for specific metrics\n",
    "def create_model_comparison(data, metric='hr@10', n_samples=50000):\n",
    "    df_filtered = data[data['MODELS'].str.contains(str(n_samples))]\n",
    "    df_filtered['Model'] = df_filtered['MODELS'].apply(lambda x: x.replace(f' {n_samples}', ''))\n",
    "    \n",
    "    fig = px.bar(\n",
    "        df_filtered.sort_values(metric, ascending=False),\n",
    "        x='Model',\n",
    "        y=metric,\n",
    "        title=f'Model Comparison - {metric} (n={n_samples})'\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        xaxis_tickangle=45,\n",
    "        height=600\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "# Create visualizations\n",
    "create_heatmap(data)\n",
    "create_metric_comparison(data, 'GraphTransformer', 'hr')\n",
    "create_metric_comparison(data, 'GraphTransformer', 'ndcg')\n",
    "create_model_comparison(data, 'hr@10')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
