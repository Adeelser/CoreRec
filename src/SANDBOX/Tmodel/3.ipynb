{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import (\n",
    "    Module, \n",
    "    Linear, \n",
    "    Dropout, \n",
    "    LayerNorm, \n",
    "    ModuleList, \n",
    "    TransformerEncoder, \n",
    "    TransformerEncoderLayer\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class UserItemDataset:\n",
    "    def __init__(self, user_file, item_file, interaction_file):\n",
    "        self.users = pd.read_csv(user_file)\n",
    "        self.items = pd.read_csv(item_file)\n",
    "        self.interactions = pd.read_csv(interaction_file)\n",
    "\n",
    "        # Strip whitespace from column names\n",
    "        self.users.columns = self.users.columns.str.strip()\n",
    "        self.items.columns = self.items.columns.str.strip()\n",
    "        self.interactions.columns = self.interactions.columns.str.strip()\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the number of interactions (or samples) in the dataset\n",
    "        return len(self.interactions)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get the interaction data\n",
    "        interaction = self.interactions.iloc[index]\n",
    "        \n",
    "        user_id = interaction['user_id']  # Adjust based on your actual column names\n",
    "        item_id = interaction['item_id']  # This should be present in interactions\n",
    "        \n",
    "        # Find the corresponding label from the items DataFrame\n",
    "        item_row = self.items[self.items['merchant_id'] == item_id]\n",
    "        \n",
    "        if not item_row.empty:\n",
    "            label = item_row['label'].values[0]  # Get the label if it exists\n",
    "        else:\n",
    "            label = 0  # Default value if no label is found (or handle as needed)\n",
    "\n",
    "        return user_id, item_id, label\n",
    "\n",
    "class GraphTransformerV2(nn.Module):\n",
    "    def __init__(self, num_layers, d_model, num_heads, d_feedforward, input_dim, num_weights=10, use_weights=True, dropout=0.1):\n",
    "        super(GraphTransformerV2, self).__init__()\n",
    "        self.num_weights = num_weights\n",
    "        self.use_weights = use_weights\n",
    "        \n",
    "        # Adjust input_linear to handle the concatenated user-item embedding\n",
    "        self.input_linear = Linear(input_dim, d_model)\n",
    "        \n",
    "        self.encoder_layer = TransformerEncoderLayer(\n",
    "            d_model=d_model, \n",
    "            nhead=num_heads, \n",
    "            dim_feedforward=d_feedforward, \n",
    "            dropout=dropout, \n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        self.output_linear = Linear(d_model, input_dim)\n",
    "        self.dropout = Dropout(dropout)\n",
    "        self.layer_norm = LayerNorm(d_model)\n",
    "        \n",
    "        if self.use_weights:\n",
    "            self.weight_linears = ModuleList([Linear(input_dim, d_model) for _ in range(num_weights)])\n",
    "\n",
    "    def forward(self, x, adjacency_matrix, graph_metrics, weights=None):\n",
    "        # Ensure adjacency_matrix is a FloatTensor\n",
    "        adjacency_matrix = adjacency_matrix.float()\n",
    "        \n",
    "        # Ensure graph_metrics is a FloatTensor\n",
    "        graph_metrics = graph_metrics.float()\n",
    "\n",
    "        # Validate and potentially adjust dimensions\n",
    "        batch_size, input_dim = x.shape\n",
    "        \n",
    "        # Ensure adjacency matrix is square and matches batch size\n",
    "        if adjacency_matrix.size(0) != batch_size or adjacency_matrix.size(1) != batch_size:\n",
    "            # Create an identity-like matrix if dimensions don't match\n",
    "            adjacency_matrix = torch.eye(batch_size, device=x.device)\n",
    "\n",
    "        try:\n",
    "            # Direct Connections\n",
    "            direct_scores = adjacency_matrix @ x  # Matrix multiplication to get direct connection scores\n",
    "\n",
    "            # Neighborhood Similarity (modified to handle potential dimension issues)\n",
    "            try:\n",
    "                neighborhood_similarity = self.compute_neighborhood_similarity(adjacency_matrix, x)\n",
    "            except RuntimeError:\n",
    "                # Fallback: use a simplified similarity if computation fails\n",
    "                neighborhood_similarity = torch.zeros_like(x)\n",
    "\n",
    "            # Graph Structure Scores - modify to handle 2D graph metrics\n",
    "            if graph_metrics.dim() == 2:\n",
    "                # Project graph metrics to match input dimensions\n",
    "                graph_metrics_projected = self.project_graph_metrics(graph_metrics, input_dim)\n",
    "                graph_structure_scores = graph_metrics_projected * x  # Element-wise multiplication instead of matrix multiplication\n",
    "            else:\n",
    "                graph_structure_scores = torch.zeros_like(x)\n",
    "\n",
    "            # Combine DNG scores\n",
    "            dng_scores = direct_scores + neighborhood_similarity + graph_structure_scores\n",
    "\n",
    "            # Optional weighted processing\n",
    "            if self.use_weights and weights is not None:\n",
    "                weighted_x = torch.zeros_like(x)\n",
    "                for i, weight in enumerate(weights.T):\n",
    "                    weighted_x += self.weight_linears[i](x) * weight.unsqueeze(1)\n",
    "                x = weighted_x\n",
    "            else:\n",
    "                x = self.input_linear(x)\n",
    "\n",
    "            x = self.layer_norm(x)\n",
    "            x = self.transformer_encoder(x.unsqueeze(1)).squeeze(1)  # Adjust for transformer input\n",
    "            x = self.output_linear(x)\n",
    "            x = self.dropout(x)\n",
    "\n",
    "            # Combine with DNG scores\n",
    "            final_scores = F.relu(x + dng_scores)\n",
    "            return final_scores\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            print(f\"RuntimeError during forward pass: {e}\")\n",
    "            print(f\"x shape: {x.shape}, adjacency_matrix shape: {adjacency_matrix.shape}, graph_metrics shape: {graph_metrics.shape}\")\n",
    "            raise\n",
    "\n",
    "    def project_graph_metrics(self, graph_metrics, target_dim):\n",
    "        \"\"\"\n",
    "        Project graph metrics to match target dimension\n",
    "        \n",
    "        Args:\n",
    "        - graph_metrics: Tensor of shape [batch_size, num_metrics]\n",
    "        - target_dim: Desired output dimension\n",
    "        \n",
    "        Returns:\n",
    "        - Projected tensor of shape [batch_size, target_dim]\n",
    "        \"\"\"\n",
    "        # If graph_metrics has fewer dimensions than target, repeat or expand\n",
    "        if graph_metrics.size(1) < target_dim:\n",
    "            # Repeat the metrics to fill the target dimension\n",
    "            repeats = (target_dim + graph_metrics.size(1) - 1) // graph_metrics.size(1)\n",
    "            graph_metrics = graph_metrics.repeat(1, repeats)[:, :target_dim]\n",
    "        elif graph_metrics.size(1) > target_dim:\n",
    "            # Truncate if too many metrics\n",
    "            graph_metrics = graph_metrics[:, :target_dim]\n",
    "        \n",
    "        return graph_metrics\n",
    "\n",
    "    def compute_neighborhood_similarity(self, adjacency_matrix, x):\n",
    "        # Robust Jaccard similarity computation\n",
    "        try:\n",
    "            # Ensure adjacency matrix is binary\n",
    "            binary_adj = (adjacency_matrix > 0).float()\n",
    "            \n",
    "            # Compute intersection\n",
    "            intersection = binary_adj @ binary_adj.T\n",
    "            \n",
    "            # Compute row and column sums\n",
    "            row_sums = binary_adj.sum(dim=1, keepdim=True)\n",
    "            col_sums = binary_adj.sum(dim=0, keepdim=True)\n",
    "            \n",
    "            # Compute union\n",
    "            union = row_sums + col_sums.T - intersection\n",
    "            \n",
    "            # Compute similarity with small epsilon to avoid division by zero\n",
    "            similarity = intersection / (union + 1e-8)\n",
    "            \n",
    "            # Matrix multiplication with input\n",
    "            return similarity @ x\n",
    "        \n",
    "        except RuntimeError:\n",
    "            # Fallback to a simple similarity if computation fails\n",
    "            return torch.zeros_like(x)\n",
    "\n",
    "            \n",
    "\n",
    "    def forward(self, x, adjacency_matrix, graph_metrics, weights=None):\n",
    "        # Ensure adjacency_matrix is a FloatTensor\n",
    "        adjacency_matrix = adjacency_matrix.float()\n",
    "        \n",
    "        # Ensure graph_metrics is a FloatTensor\n",
    "        graph_metrics = graph_metrics.float()\n",
    "\n",
    "        # Validate and potentially adjust dimensions\n",
    "        batch_size, input_dim = x.shape\n",
    "        \n",
    "        # Ensure adjacency matrix is square and matches batch size\n",
    "        if adjacency_matrix.size(0) != batch_size or adjacency_matrix.size(1) != batch_size:\n",
    "            # Create an identity-like matrix if dimensions don't match\n",
    "            adjacency_matrix = torch.eye(batch_size, device=x.device)\n",
    "\n",
    "        try:\n",
    "            # Direct Connections\n",
    "            direct_scores = adjacency_matrix @ x  # Matrix multiplication to get direct connection scores\n",
    "\n",
    "            # Neighborhood Similarity (modified to handle potential dimension issues)\n",
    "            try:\n",
    "                neighborhood_similarity = self.compute_neighborhood_similarity(adjacency_matrix, x)\n",
    "            except RuntimeError:\n",
    "                # Fallback: use a simplified similarity if computation fails\n",
    "                neighborhood_similarity = torch.zeros_like(x)\n",
    "\n",
    "            # Graph Structure Scores - modify to handle 2D graph metrics\n",
    "            if graph_metrics.dim() == 2:\n",
    "                # Project graph metrics to match input dimensions\n",
    "                graph_metrics_projected = self.project_graph_metrics(graph_metrics, input_dim)\n",
    "                graph_structure_scores = graph_metrics_projected * x  # Element-wise multiplication instead of matrix multiplication\n",
    "            else:\n",
    "                graph_structure_scores = torch.zeros_like(x)\n",
    "\n",
    "            # Combine DNG scores\n",
    "            dng_scores = direct_scores + neighborhood_similarity + graph_structure_scores\n",
    "\n",
    "            # Optional weighted processing\n",
    "            if self.use_weights and weights is not None:\n",
    "                weighted_x = torch.zeros_like(x)\n",
    "                for i, weight in enumerate(weights.T):\n",
    "                    weighted_x += self.weight_linears[i](x) * weight.unsqueeze(1)\n",
    "                x = weighted_x\n",
    "            else:\n",
    "                x = self.input_linear(x)\n",
    "\n",
    "            x = self.layer_norm(x)\n",
    "            x = self.transformer_encoder(x.unsqueeze(1)).squeeze(1)  # Adjust for transformer input\n",
    "            x = self.output_linear(x)\n",
    "            x = self.dropout(x)\n",
    "\n",
    "            # Combine with DNG scores\n",
    "            final_scores = F.relu(x + dng_scores)\n",
    "            return final_scores\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            print(f\"RuntimeError during forward pass: {e}\")\n",
    "            print(f\"x shape: {x.shape}, adjacency_matrix shape: {adjacency_matrix.shape}, graph_metrics shape: {graph_metrics.shape}\")\n",
    "            raise\n",
    "\n",
    "    def project_graph_metrics(self, graph_metrics, target_dim):\n",
    "        \"\"\"\n",
    "        Project graph metrics to match target dimension\n",
    "        \n",
    "        Args:\n",
    "        - graph_metrics: Tensor of shape [batch_size, num_metrics]\n",
    "        - target_dim: Desired output dimension\n",
    "        \n",
    "        Returns:\n",
    "        - Projected tensor of shape [batch_size, target_dim]\n",
    "        \"\"\"\n",
    "        # If graph_metrics has fewer dimensions than target, repeat or expand\n",
    "        if graph_metrics.size(1) < target_dim:\n",
    "            # Repeat the metrics to fill the target dimension\n",
    "            repeats = (target_dim + graph_metrics.size(1) - 1) // graph_metrics.size(1)\n",
    "            graph_metrics = graph_metrics.repeat(1, repeats)[:, :target_dim]\n",
    "        elif graph_metrics.size(1) > target_dim:\n",
    "            # Truncate if too many metrics\n",
    "            graph_metrics = graph_metrics[:, :target_dim]\n",
    "        \n",
    "        return graph_metrics\n",
    "\n",
    "    def compute_neighborhood_similarity(self, adjacency_matrix, x):\n",
    "        # Robust Jaccard similarity computation\n",
    "        try:\n",
    "            # Ensure adjacency matrix is binary\n",
    "            binary_adj = (adjacency_matrix > 0).float()\n",
    "            \n",
    "            # Compute intersection\n",
    "            intersection = binary_adj @ binary_adj.T\n",
    "            \n",
    "            # Compute row and column sums\n",
    "            row_sums = binary_adj.sum(dim=1, keepdim=True)\n",
    "            col_sums = binary_adj.sum(dim=0, keepdim=True)\n",
    "            \n",
    "            # Compute union\n",
    "            union = row_sums + col_sums.T - intersection\n",
    "            \n",
    "            # Compute similarity with small epsilon to avoid division by zero\n",
    "            similarity = intersection / (union + 1e-8)\n",
    "            \n",
    "            # Matrix multiplication with input\n",
    "            return similarity @ x\n",
    "        \n",
    "        except RuntimeError:\n",
    "            # Fallback to a simple similarity if computation fails\n",
    "            return torch.zeros_like(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/Tmodel'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 424171\n",
      "Number of items: 1113167\n"
     ]
    }
   ],
   "source": [
    "# Paths to the IJCAI-15 dataset CSV files\n",
    "user_file = '/Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/IJCAI-15/user_info_format1.csv'\n",
    "item_file = '/Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/IJCAI-15/train_format1.csv'\n",
    "interaction_file = '/Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/IJCAI-15/user_log_format1.csv'\n",
    "\n",
    "# Load dataset\n",
    "dataset = UserItemDataset(user_file, item_file, interaction_file)\n",
    "data_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Get maximum user and item IDs\n",
    "max_user_id = dataset.users['user_id'].max()\n",
    "max_item_id = dataset.interactions['item_id'].max()  # Access item_id from interactions\n",
    "num_users = max_user_id + 1  # +1 because IDs are zero-indexed\n",
    "num_items = max_item_id + 1  # +1 for the same reason\n",
    "\n",
    "print(f\"Number of users: {num_users}\")\n",
    "print(f\"Number of items: {num_items}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerRecommender(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=64, num_layers=2, num_heads=4, dropout=0.1):\n",
    "        super(TransformerRecommender, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        # Initialize the transformer model\n",
    "        self.model = GraphTransformerV2(\n",
    "            num_layers=num_layers,\n",
    "            d_model=embedding_dim,\n",
    "            num_heads=num_heads,\n",
    "            d_feedforward=embedding_dim * 4,\n",
    "            input_dim=2 * embedding_dim,  \n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        # User and Item embeddings\n",
    "        self.user_embeddings = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embeddings = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "        # Loss function\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        # Optimizer\n",
    "        self.optimizer = torch.optim.Adam(self.parameters())\n",
    "\n",
    "    def create_batch_graph_structure(self, batch_size):\n",
    "        # Create adjacency matrix for the batch (batch_size x batch_size)\n",
    "        adj_matrix = torch.zeros((batch_size, batch_size))\n",
    "\n",
    "        # Create basic graph metrics\n",
    "        graph_metrics = {\n",
    "            'degree': torch.zeros(batch_size),\n",
    "            'clustering': torch.zeros(batch_size),\n",
    "            'centrality': torch.zeros(batch_size)\n",
    "        }\n",
    "\n",
    "        return adj_matrix, graph_metrics\n",
    "\n",
    "    def update_batch_graph_structure(self, user_ids, item_ids, batch_size):\n",
    "        # Create new batch-specific adjacency matrix\n",
    "        adj_matrix = torch.zeros((batch_size, batch_size))\n",
    "\n",
    "        # Create connections between users and items within the batch\n",
    "        for i in range(batch_size):\n",
    "            for j in range(batch_size):\n",
    "                if user_ids[i] == user_ids[j] or item_ids[i] == item_ids[j]:\n",
    "                    adj_matrix[i, j] = 1.0\n",
    "\n",
    "        # Calculate basic graph metrics for the batch\n",
    "        graph_metrics = {\n",
    "            'degree': adj_matrix.sum(dim=1),\n",
    "            'clustering': torch.zeros(batch_size),  # Simplified clustering coefficient\n",
    "            'centrality': adj_matrix.sum(dim=0) / batch_size  # Simplified centrality measure\n",
    "        }\n",
    "\n",
    "        return adj_matrix, graph_metrics\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        user_emb = self.user_embeddings(user_ids)\n",
    "        item_emb = self.item_embeddings(item_ids)\n",
    "\n",
    "        # Concatenate user and item embeddings\n",
    "        input_emb = torch.cat([user_emb, item_emb], dim=1)  # Shape: [batch_size, 2*embedding_dim]\n",
    "\n",
    "        # Update batch-specific graph structure\n",
    "        batch_size = user_ids.size(0)\n",
    "        adj_matrix, graph_metrics = self.update_batch_graph_structure(user_ids, item_ids, batch_size)\n",
    "\n",
    "        # Convert graph_metrics to a tensor\n",
    "        graph_metrics_tensor = torch.stack([\n",
    "            graph_metrics['degree'],\n",
    "            graph_metrics['clustering'],\n",
    "            graph_metrics['centrality']\n",
    "        ]).T  # Shape: [batch_size, 3]\n",
    "\n",
    "        # Forward pass through the transformer model\n",
    "        output = self.model(input_emb, adj_matrix, graph_metrics_tensor)\n",
    "\n",
    "        return output.mean(dim=1)  # Return mean predictions\n",
    "\n",
    "    def train_step(self, user_ids, item_ids, labels):\n",
    "        self.train()  # Set the model to training mode\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        pred = self.forward(user_ids, item_ids)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = self.criterion(pred, labels.float())\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.item()\n",
    "\n",
    "    def predict(self, user_ids, item_ids):\n",
    "        self.eval()  # Set the model to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            return self.forward(user_ids, item_ids)\n",
    "\n",
    "    def eval(self):\n",
    "        self.model.eval()  # Set the transformer model to evaluation mode     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define BiasMF\n",
    "class BiasMF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim):\n",
    "        super(BiasMF, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "        self.user_bias = nn.Embedding(num_users, 1)\n",
    "        self.item_bias = nn.Embedding(num_items, 1)\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        user_embeds = self.user_embedding(user_ids)\n",
    "        item_embeds = self.item_embedding(item_ids)\n",
    "        user_bias = self.user_bias(user_ids)\n",
    "        item_bias = self.item_bias(item_ids)\n",
    "        return (user_embeds * item_embeds).sum(1, keepdim=True) + user_bias + item_bias \n",
    "\n",
    "# Define DMF (Deep Matrix Factorization)\n",
    "class DMF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim):\n",
    "        super(DMF, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "        self.fc = nn.Linear(embedding_dim * 2, 1)\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "       user_embeds = self.user_embedding(user_ids)\n",
    "       item_embeds = self.item_embedding(item_ids)\n",
    "       x = torch.cat([user_embeds, item_embeds], dim=1)\n",
    "       return self.fc(x)  # Ensure this outputs [batch_size, 1]\n",
    "\n",
    "# Define AutoRec\n",
    "class AutoRec(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim):\n",
    "        super(AutoRec, self).__init__()\n",
    "        self.encoder = nn.Linear(num_items, embedding_dim)\n",
    "        self.decoder = nn.Linear(embedding_dim, num_items)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.encoder(x))\n",
    "        return self.decoder(x)\n",
    "\n",
    "# Define CDAE (Collaborative Denoising Autoencoder)\n",
    "class CDAE(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim):\n",
    "        super(CDAE, self).__init__()\n",
    "        self.encoder = nn.Linear(num_items, embedding_dim)\n",
    "        self.decoder = nn.Linear(embedding_dim, num_items)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.encoder(x))\n",
    "        return self.decoder(x)\n",
    "\n",
    "# Define NADE (Neural Autoregressive Distribution Estimator)\n",
    "# class NADE(nn.Module):\n",
    "#     def __init__(self, num_items, embedding_dim):\n",
    "#         super(NADE, self).__init__()\n",
    "#         self.fc = nn.Linear(num_items, embedding_dim)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.fc(x)\n",
    "\n",
    "# Define CF-UIcA (Collaborative Filtering with User-Item Contextual Attention)\n",
    "class CF_UIcA(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim):\n",
    "        super(CF_UIcA, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        user_embeds = self.user_embedding(user_ids)\n",
    "        item_embeds = self.item_embedding(item_ids)\n",
    "        return (user_embeds * item_embeds).sum(1)\n",
    "\n",
    "# Define ST-GCN (Spatial Temporal Graph Convolutional Network)\n",
    "class STGCN(nn.Module):\n",
    "    def __init__(self, num_nodes, in_channels, out_channels):\n",
    "        super(STGCN, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=(1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "# Define NGCF (Next Generation Collaborative Filtering)\n",
    "class NGCF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim):\n",
    "        super(NGCF, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        user_embeds = self.user_embedding(user_ids)\n",
    "        item_embeds = self.item_embedding(item_ids)\n",
    "        return (user_embeds * item_embeds).sum(1)\n",
    "\n",
    "# Define NMTR (Neural Matrix Factorization with Temporal Regularization)\n",
    "class NMTR(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim):\n",
    "        super(NMTR, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        user_embeds = self.user_embedding(user_ids)\n",
    "        item_embeds = self.item_embedding(item_ids)\n",
    "        return (user_embeds * item_embeds).sum(1)\n",
    "\n",
    "# Define DIPN (Deep Item-based Personalized Network)\n",
    "class DIPN(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim):\n",
    "        super(DIPN, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        user_embeds = self.user_embedding(user_ids)\n",
    "        item_embeds = self.item_embedding(item_ids)\n",
    "        return (user_embeds * item_embeds).sum(1)\n",
    "\n",
    "# Define NGCF+M (NGCF with Memory)\n",
    "class NGCF_M(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim):\n",
    "        super(NGCF_M, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        user_embeds = self.user_embedding(user_ids)\n",
    "        item_embeds = self.item_embedding(item_ids)\n",
    "        return (user_embeds * item_embeds).sum(1)\n",
    "\n",
    "# Define MBGCN (Multi-Branch Graph Convolutional Network)\n",
    "class MBGCN(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim):\n",
    "        super(MBGCN, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        user_embeds = self.user_embedding(user_ids)\n",
    "        item_embeds = self.item_embedding(item_ids)\n",
    "        return (user_embeds * item_embeds).sum(1)\n",
    "\n",
    "# Define MATN (Multi-Attention Temporal Network)\n",
    "class MATN(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim):\n",
    "        super(MATN, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        user_embeds = self.user_embedding(user_ids)\n",
    "        item_embeds = self.item_embedding(item_ids)\n",
    "        return (user_embeds * item_embeds).sum(1)\n",
    "\n",
    "# Define GNMR (Graph Neural Matrix Recommendation)\n",
    "class GNMR(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim):\n",
    "        super(GNMR, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        user_embeds = self.user_embedding(user_ids)\n",
    "        item_embeds = self.item_embedding(item_ids)\n",
    "        return (user_embeds * item_embeds).sum(1)\n",
    "\n",
    "# Define MBRec (Multi-Branch Recommendation)\n",
    "class MBRec(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim):\n",
    "        super(MBRec, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        user_embeds = self.user_embedding(user_ids)\n",
    "        item_embeds = self.item_embedding(item_ids)\n",
    "        return (user_embeds * item_embeds).sum(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 1\n",
      "User IDs shape: torch.Size([64]), Item IDs shape: torch.Size([64]), Labels shape: torch.Size([64])\n",
      "Output shape: torch.Size([64, 2]), Labels shape: torch.Size([64, 1])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([64, 1])) must be the same as input size (torch.Size([64, 2]))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Labels shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, labels)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Check for NaN loss\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(loss):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/loss.py:720\u001b[0m, in \u001b[0;36mBCEWithLogitsLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 720\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mbinary_cross_entropy_with_logits(\u001b[38;5;28minput\u001b[39m, target,\n\u001b[1;32m    721\u001b[0m                                               \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[1;32m    722\u001b[0m                                               pos_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_weight,\n\u001b[1;32m    723\u001b[0m                                               reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py:3163\u001b[0m, in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   3160\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   3162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()):\n\u001b[0;32m-> 3163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) must be the same as input size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(target\u001b[38;5;241m.\u001b[39msize(), \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m   3165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbinary_cross_entropy_with_logits(\u001b[38;5;28minput\u001b[39m, target, weight, pos_weight, reduction_enum)\n",
      "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([64, 1])) must be the same as input size (torch.Size([64, 2]))"
     ]
    }
   ],
   "source": [
    "embedding_dim = 64\n",
    "# Initialize models\n",
    "models = {\n",
    "    \"GraphTransformerV2\": GraphTransformerV2(num_layers=3, d_model=128, num_heads=8, d_feedforward=256, input_dim=2),\n",
    "    \"BiasMF\": BiasMF(num_users, num_items, embedding_dim),\n",
    "    \"DMF\": DMF(num_users, num_items, embedding_dim),\n",
    "    # \"NCF\": NCF(num_users, num_items, embedding_dim),\n",
    "    \"AutoRec\": AutoRec(num_users, num_items, embedding_dim),\n",
    "    \"CDAE\": CDAE(num_users, num_items, embedding_dim),\n",
    "    # \"NADE\": NADE(num_items, embedding_dim),\n",
    "    \"CF_UIcA\": CF_UIcA(num_users, num_items, embedding_dim),\n",
    "    \"STGCN\": STGCN(num_items, 1, embedding_dim),\n",
    "    \"NGCF\": NGCF(num_users, num_items, embedding_dim),\n",
    "    \"NMTR\": NMTR(num_users, num_items, embedding_dim),\n",
    "    \"DIPN\": DIPN(num_users, num_items, embedding_dim),\n",
    "    \"NGCF_M\": NGCF_M(num_users, num_items, embedding_dim),\n",
    "    \"MBGCN\": MBGCN(num_users, num_items, embedding_dim),\n",
    "    \"MATN\": MATN(num_users, num_items, embedding_dim),\n",
    "    \"GNMR\": GNMR(num_users, num_items, embedding_dim),\n",
    "    \"MBRec\": MBRec(num_users, num_items, embedding_dim),\n",
    "}\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Assume models are already defined and initialized in a dictionary 'models'\n",
    "# Assume data_loader is properly set up\n",
    "\n",
    "embedding_dim = 64\n",
    "num_epochs = 10\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.BCEWithLogitsLoss()  # Binary classification\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch_idx, (user_ids, item_ids, labels) in enumerate(data_loader):\n",
    "            print(f'Epoch {epoch + 1}, Batch {batch_idx + 1}')\n",
    "            print(f'User IDs shape: {user_ids.shape}, Item IDs shape: {item_ids.shape}, Labels shape: {labels.shape}')\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if model_name == \"GraphTransformerV2\":\n",
    "                # GraphTransformerV2 needs custom input preparation\n",
    "                x = torch.cat((user_ids.unsqueeze(1), item_ids.unsqueeze(1)), dim=1).float()  # Shape: [batch_size, 2]\n",
    "                adjacency_matrix = torch.eye(user_ids.size(0)).float()  # Identity matrix as adjacency matrix\n",
    "                graph_metrics = torch.zeros(user_ids.size(0), 2).float()  # Placeholder for graph metrics\n",
    "                output = model(x, adjacency_matrix, graph_metrics)\n",
    "            else:\n",
    "                # For other models, ensure they output [batch_size, 1]\n",
    "                output = model(user_ids, item_ids)\n",
    "                output = output.view(-1, 1)  # Ensure output is [batch_size, 1]\n",
    "\n",
    "            # Adjust labels for binary classification\n",
    "            labels = labels.view(-1, 1).float()  # Ensure labels are of shape [batch_size, 1]\n",
    "\n",
    "            # Debugging output shapes\n",
    "            print(f'Output shape: {output.shape}, Labels shape: {labels.shape}')\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(output, labels)\n",
    "            \n",
    "            # Check for NaN loss\n",
    "            if torch.isnan(loss):\n",
    "                print(f\"Loss is NaN for {model_name} in Epoch {epoch + 1}, Batch {batch_idx + 1}. Stopping training.\")\n",
    "                break\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Print loss for the current batch\n",
    "            print(f'Batch {batch_idx + 1}, Loss: {loss.item()}')\n",
    "\n",
    "        # Print average loss for the epoch\n",
    "        print(f'{model_name} - Epoch {epoch + 1}, Average Loss: {total_loss / len(data_loader)}')\n",
    "\n",
    "        # Optional: Early stopping if loss becomes NaN\n",
    "        if torch.isnan(torch.tensor(total_loss)):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
