{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import (\n",
    "    Module, \n",
    "    Linear, \n",
    "    Dropout, \n",
    "    LayerNorm, \n",
    "    ModuleList, \n",
    "    TransformerEncoder, \n",
    "    TransformerEncoderLayer\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "class GraphTransformerV2(nn.Module):\n",
    "    def __init__(self, num_layers, d_model, num_heads, d_feedforward, input_dim, num_weights=10, use_weights=True, dropout=0.1):\n",
    "        super(GraphTransformerV2, self).__init__()\n",
    "        self.num_weights = num_weights\n",
    "        self.use_weights = use_weights\n",
    "        \n",
    "        # Adjust input_linear to handle the concatenated user-item embedding\n",
    "        self.input_linear = Linear(input_dim, d_model)\n",
    "        \n",
    "        self.encoder_layer = TransformerEncoderLayer(\n",
    "            d_model=d_model, \n",
    "            nhead=num_heads, \n",
    "            dim_feedforward=d_feedforward, \n",
    "            dropout=dropout, \n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        self.output_linear = Linear(d_model, input_dim)\n",
    "        self.dropout = Dropout(dropout)\n",
    "        self.layer_norm = LayerNorm(d_model)\n",
    "        \n",
    "        if self.use_weights:\n",
    "            self.weight_linears = ModuleList([Linear(input_dim, d_model) for _ in range(num_weights)])\n",
    "\n",
    "    def forward(self, x, adjacency_matrix, graph_metrics, weights=None):\n",
    "        # Ensure adjacency_matrix is a FloatTensor\n",
    "        adjacency_matrix = adjacency_matrix.float()\n",
    "        \n",
    "        # Ensure graph_metrics is a FloatTensor\n",
    "        graph_metrics = graph_metrics.float()\n",
    "\n",
    "        # Validate and potentially adjust dimensions\n",
    "        batch_size, input_dim = x.shape\n",
    "        \n",
    "        # Ensure adjacency matrix is square and matches batch size\n",
    "        if adjacency_matrix.size(0) != batch_size or adjacency_matrix.size(1) != batch_size:\n",
    "            # Create an identity-like matrix if dimensions don't match\n",
    "            adjacency_matrix = torch.eye(batch_size, device=x.device)\n",
    "\n",
    "        try:\n",
    "            # Direct Connections\n",
    "            direct_scores = adjacency_matrix @ x  # Matrix multiplication to get direct connection scores\n",
    "\n",
    "            # Neighborhood Similarity (modified to handle potential dimension issues)\n",
    "            try:\n",
    "                neighborhood_similarity = self.compute_neighborhood_similarity(adjacency_matrix, x)\n",
    "            except RuntimeError:\n",
    "                # Fallback: use a simplified similarity if computation fails\n",
    "                neighborhood_similarity = torch.zeros_like(x)\n",
    "\n",
    "            # Graph Structure Scores - modify to handle 2D graph metrics\n",
    "            if graph_metrics.dim() == 2:\n",
    "                # Project graph metrics to match input dimensions\n",
    "                graph_metrics_projected = self.project_graph_metrics(graph_metrics, input_dim)\n",
    "                graph_structure_scores = graph_metrics_projected * x  # Element-wise multiplication instead of matrix multiplication\n",
    "            else:\n",
    "                graph_structure_scores = torch.zeros_like(x)\n",
    "\n",
    "            # Combine DNG scores\n",
    "            dng_scores = direct_scores + neighborhood_similarity + graph_structure_scores\n",
    "\n",
    "            # Optional weighted processing\n",
    "            if self.use_weights and weights is not None:\n",
    "                weighted_x = torch.zeros_like(x)\n",
    "                for i, weight in enumerate(weights.T):\n",
    "                    weighted_x += self.weight_linears[i](x) * weight.unsqueeze(1)\n",
    "                x = weighted_x\n",
    "            else:\n",
    "                x = self.input_linear(x)\n",
    "\n",
    "            x = self.layer_norm(x)\n",
    "            x = self.transformer_encoder(x.unsqueeze(1)).squeeze(1)  # Adjust for transformer input\n",
    "            x = self.output_linear(x)\n",
    "            x = self.dropout(x)\n",
    "\n",
    "            # Combine with DNG scores\n",
    "            final_scores = F.relu(x + dng_scores)\n",
    "            return final_scores\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            print(f\"RuntimeError during forward pass: {e}\")\n",
    "            print(f\"x shape: {x.shape}, adjacency_matrix shape: {adjacency_matrix.shape}, graph_metrics shape: {graph_metrics.shape}\")\n",
    "            raise\n",
    "\n",
    "    def project_graph_metrics(self, graph_metrics, target_dim):\n",
    "        \"\"\"\n",
    "        Project graph metrics to match target dimension\n",
    "        \n",
    "        Args:\n",
    "        - graph_metrics: Tensor of shape [batch_size, num_metrics]\n",
    "        - target_dim: Desired output dimension\n",
    "        \n",
    "        Returns:\n",
    "        - Projected tensor of shape [batch_size, target_dim]\n",
    "        \"\"\"\n",
    "        # If graph_metrics has fewer dimensions than target, repeat or expand\n",
    "        if graph_metrics.size(1) < target_dim:\n",
    "            # Repeat the metrics to fill the target dimension\n",
    "            repeats = (target_dim + graph_metrics.size(1) - 1) // graph_metrics.size(1)\n",
    "            graph_metrics = graph_metrics.repeat(1, repeats)[:, :target_dim]\n",
    "        elif graph_metrics.size(1) > target_dim:\n",
    "            # Truncate if too many metrics\n",
    "            graph_metrics = graph_metrics[:, :target_dim]\n",
    "        \n",
    "        return graph_metrics\n",
    "\n",
    "    def compute_neighborhood_similarity(self, adjacency_matrix, x):\n",
    "        # Robust Jaccard similarity computation\n",
    "        try:\n",
    "            # Ensure adjacency matrix is binary\n",
    "            binary_adj = (adjacency_matrix > 0).float()\n",
    "            \n",
    "            # Compute intersection\n",
    "            intersection = binary_adj @ binary_adj.T\n",
    "            \n",
    "            # Compute row and column sums\n",
    "            row_sums = binary_adj.sum(dim=1, keepdim=True)\n",
    "            col_sums = binary_adj.sum(dim=0, keepdim=True)\n",
    "            \n",
    "            # Compute union\n",
    "            union = row_sums + col_sums.T - intersection\n",
    "            \n",
    "            # Compute similarity with small epsilon to avoid division by zero\n",
    "            similarity = intersection / (union + 1e-8)\n",
    "            \n",
    "            # Matrix multiplication with input\n",
    "            return similarity @ x\n",
    "        \n",
    "        except RuntimeError:\n",
    "            # Fallback to a simple similarity if computation fails\n",
    "            return torch.zeros_like(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerRecommender:\n",
    "    def __init__(self, num_users, num_items, embedding_dim=64, num_layers=2, num_heads=4, dropout=0.1):\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        # Initialize the transformer model\n",
    "        self.model = GraphTransformerV2(\n",
    "            num_layers=num_layers,\n",
    "            d_model=embedding_dim,\n",
    "            num_heads=num_heads,\n",
    "            d_feedforward=embedding_dim * 4,\n",
    "            input_dim= 2 * embedding_dim,  \n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        # User and Item embeddings\n",
    "        self.user_embeddings = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embeddings = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "        # Initialize adjacency matrix for batch size\n",
    "        self.batch_adjacency_matrix = None\n",
    "        self.batch_graph_metrics = None\n",
    "\n",
    "        # Loss function\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        # Optimizer\n",
    "        self.optimizer = torch.optim.Adam(self.parameters())\n",
    "\n",
    "    def create_batch_graph_structure(self, batch_size):\n",
    "        \"\"\"\n",
    "        Creates batch-specific adjacency matrix and graph metrics\n",
    "        \"\"\"\n",
    "        # Create adjacency matrix for the batch (batch_size x batch_size)\n",
    "        adj_matrix = torch.zeros((batch_size, batch_size))\n",
    "\n",
    "        # Create basic graph metrics\n",
    "        graph_metrics = {\n",
    "            'degree': torch.zeros(batch_size),\n",
    "            'clustering': torch.zeros(batch_size),\n",
    "            'centrality': torch.zeros(batch_size)\n",
    "        }\n",
    "\n",
    "        return adj_matrix, graph_metrics\n",
    "\n",
    "    def update_batch_graph_structure(self, user_ids, item_ids, batch_size):\n",
    "        \"\"\"\n",
    "        Updates the batch-specific adjacency matrix and graph metrics\n",
    "        \"\"\"\n",
    "        # Create new batch-specific adjacency matrix\n",
    "        adj_matrix = torch.zeros((batch_size, batch_size))\n",
    "\n",
    "        # Create connections between users and items within the batch\n",
    "        for i in range(batch_size):\n",
    "            for j in range(batch_size):\n",
    "                if user_ids[i] == user_ids[j] or item_ids[i] == item_ids[j]:\n",
    "                    adj_matrix[i, j] = 1.0\n",
    "\n",
    "        # Calculate basic graph metrics for the batch\n",
    "        graph_metrics = {\n",
    "            'degree': adj_matrix.sum(dim=1),\n",
    "            'clustering': torch.zeros(batch_size),  # Simplified clustering coefficient\n",
    "            'centrality': adj_matrix.sum(dim=0) / batch_size  # Simplified centrality measure\n",
    "        }\n",
    "\n",
    "        return adj_matrix, graph_metrics\n",
    "\n",
    "    def parameters(self):\n",
    "        \"\"\"\n",
    "        Returns all trainable parameters\n",
    "        \"\"\"\n",
    "        return list(self.model.parameters()) + \\\n",
    "               list(self.user_embeddings.parameters()) + \\\n",
    "               list(self.item_embeddings.parameters())\n",
    "\n",
    "    def train_step(self, user_ids, item_ids, labels):\n",
    "        self.model.train()\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        batch_size = user_ids.size(0)\n",
    "\n",
    "        # Get embeddings\n",
    "        user_emb = self.user_embeddings(user_ids)\n",
    "        item_emb = self.item_embeddings(item_ids)\n",
    "\n",
    "        # Concatenate user and item embeddings\n",
    "        input_emb = torch.cat([user_emb, item_emb], dim=1)  # Shape: [batch_size, 2*embedding_dim]\n",
    "\n",
    "        # Update batch-specific graph structure\n",
    "        adj_matrix, graph_metrics = self.update_batch_graph_structure(user_ids, item_ids, batch_size)\n",
    "\n",
    "        # Convert graph_metrics to a tensor\n",
    "        graph_metrics_tensor = torch.stack([\n",
    "            graph_metrics['degree'],\n",
    "            graph_metrics['clustering'],\n",
    "            graph_metrics['centrality']\n",
    "        ]).T  # Shape: [batch_size, 3]\n",
    "\n",
    "        # Forward pass\n",
    "        output = self.model(input_emb, adj_matrix, graph_metrics_tensor)\n",
    "\n",
    "        # Calculate prediction (take mean of output)\n",
    "        pred = output.mean(dim=1)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = self.criterion(pred, labels.float())\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.item()\n",
    "\n",
    "    def predict(self, user_ids, item_ids):\n",
    "        self.model.eval()\n",
    "        batch_size = user_ids.size(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            user_emb = self.user_embeddings(user_ids)\n",
    "            item_emb = self.item_embeddings(item_ids)\n",
    "            input_emb = torch.cat([user_emb, item_emb], dim=1)\n",
    "\n",
    "            # Create batch-specific graph structure for prediction\n",
    "            adj_matrix, graph_metrics = self.update_batch_graph_structure(user_ids, item_ids, batch_size)\n",
    "\n",
    "            # Convert graph_metrics to a tensor\n",
    "            graph_metrics_tensor = torch.stack([\n",
    "                graph_metrics['degree'],\n",
    "                graph_metrics['clustering'],\n",
    "                graph_metrics['centrality']\n",
    "            ]).T  # Shape: [batch_size, 3]\n",
    "\n",
    "            output = self.model(input_emb, adj_matrix, graph_metrics_tensor)\n",
    "            pred = torch.sigmoid(output.mean(dim=1))\n",
    "        return pred\n",
    "\n",
    "    def eval(self):\n",
    "        self.model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yf/20z1hn994jd04q4kl0gpgh740000gn/T/ipykernel_38486/3273251167.py:24: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:277.)\n",
      "  edge_index = torch.tensor(\n",
      "/Users/visheshyadav/anaconda3/envs/tf/lib/python3.12/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n",
      "/Users/visheshyadav/anaconda3/envs/tf/lib/python3.12/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'edge_index'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency Matrix Shape: torch.Size([10320, 10320])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from torch_geometric.utils import negative_sampling\n",
    "# Load the dataset using Pandas\n",
    "data = pd.read_csv('/Users/visheshyadav/Documents/GitHub/CoreRec/src/SANDBOX/dataset/REES46/events.csv')\n",
    "\n",
    "# Reduce the dataset to 10,000 rows\n",
    "data = data.head(10000)\n",
    "\n",
    "# Extract user-item interactions\n",
    "user_item_interactions = data[['user_id', 'product_id']].drop_duplicates()\n",
    "\n",
    "# Map user and item IDs to consecutive integers\n",
    "user_mapping = {uid: idx for idx, uid in enumerate(user_item_interactions['user_id'].unique())}\n",
    "item_mapping = {iid: idx for idx, iid in enumerate(user_item_interactions['product_id'].unique())}\n",
    "\n",
    "# Map user_id and product_id to their respective indices\n",
    "user_item_interactions['user_id'] = user_item_interactions['user_id'].map(user_mapping)\n",
    "user_item_interactions['product_id'] = user_item_interactions['product_id'].map(item_mapping)\n",
    "\n",
    "# Create edge index for the graph\n",
    "edge_index = torch.tensor(\n",
    "    [user_item_interactions['user_id'].values, user_item_interactions['product_id'].values],\n",
    "    dtype=torch.long\n",
    ")\n",
    "\n",
    "# Split the data into training and test sets\n",
    "data = train_test_split_edges(Data(edge_index=edge_index))\n",
    "\n",
    "# Extract training and test edges\n",
    "train_edge_index = data.train_pos_edge_index\n",
    "test_edge_index = data.test_pos_edge_index\n",
    "\n",
    "# Create adjacency matrix for the graph\n",
    "num_users = len(user_mapping)\n",
    "num_items = len(item_mapping)\n",
    "adj_matrix = torch.zeros((num_users + num_items, num_users + num_items))\n",
    "adj_matrix[train_edge_index[0], train_edge_index[1]] = 1\n",
    "\n",
    "# Verify the adjacency matrix shape and some basic properties\n",
    "print(\"Adjacency Matrix Shape:\", adj_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseData.size of Data(val_pos_edge_index=[2, 90], test_pos_edge_index=[2, 181], train_pos_edge_index=[2, 3090], train_neg_adj_mask=[5664, 5664], val_neg_edge_index=[2, 90], test_neg_edge_index=[2, 181])>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, SAGEConv\n",
    "import torch.nn as nn \n",
    "\n",
    "class GraphGCN(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim):\n",
    "        super(GraphGCN, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.user_embeddings = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embeddings = nn.Embedding(num_items, embedding_dim)\n",
    "        self.conv1 = GCNConv(embedding_dim, embedding_dim)\n",
    "        self.conv2 = GCNConv(embedding_dim, embedding_dim)\n",
    "\n",
    "    def forward(self, edge_index):\n",
    "        x = torch.cat([self.user_embeddings.weight, self.item_embeddings.weight], dim=0)\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.user_embeddings = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embeddings = nn.Embedding(num_items, embedding_dim)\n",
    "        self.conv1 = SAGEConv(embedding_dim, embedding_dim)\n",
    "        self.conv2 = SAGEConv(embedding_dim, embedding_dim)\n",
    "\n",
    "    def forward(self, edge_index):\n",
    "        x = torch.cat([self.user_embeddings.weight, self.item_embeddings.weight], dim=0)\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gcn(model, data, optimizer, criterion, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.train_pos_edge_index)\n",
    "        pos_out = torch.sigmoid((out[data.train_pos_edge_index[0]] * out[data.train_pos_edge_index[1]]).sum(dim=1))\n",
    "        neg_edge_index = negative_sampling(data.train_pos_edge_index, num_neg_samples=data.train_pos_edge_index.size(1))\n",
    "        neg_out = torch.sigmoid((out[neg_edge_index[0]] * out[neg_edge_index[1]]).sum(dim=1))\n",
    "        loss = criterion(pos_out, torch.ones_like(pos_out)) + criterion(neg_out, torch.zeros_like(neg_out))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "def train_sage(model, data, optimizer, criterion, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.train_pos_edge_index)\n",
    "        pos_out = torch.sigmoid((out[data.train_pos_edge_index[0]] * out[data.train_pos_edge_index[1]]).sum(dim=1))\n",
    "        neg_edge_index = negative_sampling(data.train_pos_edge_index, num_neg_samples=data.train_pos_edge_index.size(1))\n",
    "        neg_out = torch.sigmoid((out[neg_edge_index[0]] * out[neg_edge_index[1]]).sum(dim=1))\n",
    "        loss = criterion(pos_out, torch.ones_like(pos_out)) + criterion(neg_out, torch.zeros_like(neg_out))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_gcn(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.train_pos_edge_index)\n",
    "        pos_out = torch.sigmoid((out[data.test_pos_edge_index[0]] * out[data.test_pos_edge_index[1]]).sum(dim=1))\n",
    "        neg_edge_index = negative_sampling(data.test_pos_edge_index, num_neg_samples=data.test_pos_edge_index.size(1))\n",
    "        neg_out = torch.sigmoid((out[neg_edge_index[0]] * out[neg_edge_index[1]]).sum(dim=1))\n",
    "        auc = (pos_out > neg_out).float().mean().item()\n",
    "        return auc\n",
    "\n",
    "def evaluate_sage(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.train_pos_edge_index)\n",
    "        pos_out = torch.sigmoid((out[data.test_pos_edge_index[0]] * out[data.test_pos_edge_index[1]]).sum(dim=1))\n",
    "        neg_edge_index = negative_sampling(data.test_pos_edge_index, num_neg_samples=data.test_pos_edge_index.size(1))\n",
    "        neg_out = torch.sigmoid((out[neg_edge_index[0]] * out[neg_edge_index[1]]).sum(dim=1))\n",
    "        auc = (pos_out > neg_out).float().mean().item()\n",
    "        return auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.11593830585479736\n",
      "Epoch 1, Loss: 1.6055958271026611\n",
      "Epoch 1, Loss: 1.4900624752044678\n",
      "Predictions: tensor([0.6813, 0.6732, 0.6728, 0.6698, 0.6762, 0.7045, 0.6729, 0.7018, 0.6638,\n",
      "        0.6759, 0.6699, 0.6885, 0.6695, 0.6850, 0.6834, 0.6766, 0.6677, 0.6695,\n",
      "        0.6726, 0.6801, 0.6660, 0.6702, 0.6725, 0.6680, 0.7054, 0.6625, 0.6761,\n",
      "        0.6750, 0.6820, 0.6687, 0.6849, 0.6704, 0.6716, 0.6784, 0.6782, 0.6996,\n",
      "        0.6790, 0.6846, 0.6798, 0.6924, 0.6794, 0.6644, 0.6728, 0.6740, 0.6830,\n",
      "        0.6754, 0.6714, 0.6793, 0.6703, 0.6805, 0.6770, 0.6641, 0.6774, 0.6851,\n",
      "        0.6714, 0.6747, 0.6785, 0.6861, 0.6686, 0.6804, 0.6817, 0.6671, 0.6714,\n",
      "        0.6805, 0.6824, 0.6778, 0.6771, 0.6932, 0.6784, 0.6683, 0.6745, 0.6793,\n",
      "        0.6667, 0.6795, 0.6771, 0.6769, 0.6764, 0.6756, 0.6717, 0.6858, 0.6752,\n",
      "        0.6805, 0.6727, 0.6824, 0.6742, 0.6770, 0.6707, 0.6740, 0.6933, 0.6727,\n",
      "        0.6834, 0.6747, 0.6673, 0.6829, 0.6660, 0.7071, 0.6889, 0.6747, 0.6785,\n",
      "        0.6687, 0.6771, 0.6858, 0.6761, 0.6793, 0.7078, 0.6822, 0.6755, 0.6862,\n",
      "        0.6698, 0.6774, 0.6752, 0.6740, 0.6707, 0.6728, 0.6670, 0.6776, 0.6776,\n",
      "        0.6627, 0.6837, 0.6817, 0.6747, 0.6702, 0.6769, 0.6774, 0.6811, 0.6765,\n",
      "        0.6681, 0.6881, 0.6761, 0.6676, 0.6708, 0.6840, 0.6727, 0.6731, 0.6746,\n",
      "        0.6744, 0.6863, 0.6621, 0.6775, 0.6769, 0.6746, 0.6770, 0.6743, 0.6726,\n",
      "        0.6845, 0.6813, 0.6725, 0.6805, 0.6813, 0.6664, 0.6799, 0.6778, 0.6855,\n",
      "        0.6939, 0.6756, 0.6686, 0.6774, 0.6831, 0.6727, 0.6834, 0.6734, 0.6731,\n",
      "        0.6800, 0.6848, 0.6750, 0.6721, 0.6712, 0.6697, 0.6751, 0.6731, 0.6781,\n",
      "        0.6828, 0.6769, 0.6702, 0.6739, 0.6693, 0.6702, 0.6800, 0.6690, 0.6717,\n",
      "        0.6811])\n",
      "Labels: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1.])\n",
      "TransformerRecommender AUC: 1.0\n",
      "GraphGCN AUC: 0.3867403268814087\n",
      "GraphSAGE AUC: 0.6464088559150696\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "def train(model, data, optimizer, criterion, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        # Extract user_ids, item_ids, and labels from the training data\n",
    "        user_ids = data.train_pos_edge_index[0]\n",
    "        item_ids = data.train_pos_edge_index[1]\n",
    "        labels = torch.ones(user_ids.size(0))  # Positive samples\n",
    "\n",
    "        # Call the train_step method with the required arguments\n",
    "        loss = model.train_step(user_ids, item_ids, labels)\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss}')\n",
    "\n",
    "def evaluate(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        user_ids = data.test_pos_edge_index[0]\n",
    "        item_ids = data.test_pos_edge_index[1]\n",
    "        labels = torch.ones(user_ids.size(0))  # Positive samples\n",
    "        global pred\n",
    "        # Get predictions\n",
    "        # pred = model.predict(user_ids, item_ids)\n",
    "        pred = torch.sigmoid(model.predict(user_ids, item_ids))\n",
    "        # Debugging statements\n",
    "        print(f'Predictions: {pred}')\n",
    "        print(f'Labels: {labels}')\n",
    "\n",
    "        # Calculate AUC\n",
    "        auc = (pred > 0.5).float().mean().item()\n",
    "        # auc = pred\n",
    "\n",
    "        return auc\n",
    "\n",
    "# Initialize models\n",
    "num_users = len(user_mapping)\n",
    "num_items = len(item_mapping)\n",
    "embedding_dim = 64\n",
    "\n",
    "transformer_recommender = TransformerRecommender(num_users, num_items, embedding_dim)\n",
    "graph_gcn = GraphGCN(num_users, num_items, embedding_dim)\n",
    "graph_sage = GraphSAGE(num_users, num_items, embedding_dim)\n",
    "\n",
    "# Define optimizers and loss functions\n",
    "optimizer_transformer = torch.optim.Adam(transformer_recommender.parameters(), lr=0.001)\n",
    "optimizer_gcn = torch.optim.Adam(graph_gcn.parameters(), lr=0.001)\n",
    "optimizer_sage = torch.optim.Adam(graph_sage.parameters(), lr=0.001)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Train models\n",
    "num_epochs = 1\n",
    "train(transformer_recommender, data, optimizer_transformer, criterion, num_epochs)\n",
    "train_gcn(graph_gcn, data, optimizer_gcn, criterion, num_epochs)\n",
    "train_sage(graph_sage, data, optimizer_sage, criterion, num_epochs)\n",
    "\n",
    "# Evaluate models\n",
    "auc_transformer = evaluate(transformer_recommender, data)\n",
    "auc_gcn = evaluate_gcn(graph_gcn, data)\n",
    "auc_sage = evaluate_sage(graph_sage, data)\n",
    "\n",
    "print(f'TransformerRecommender AUC: {auc_transformer}')\n",
    "print(f'GraphGCN AUC: {auc_gcn}')\n",
    "print(f'GraphSAGE AUC: {auc_sage}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: 0.6620938181877136, 0.7078345417976379\n"
     ]
    }
   ],
   "source": [
    "print(f'Predictions: {pred.min().item()}, {pred.max().item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
