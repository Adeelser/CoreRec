{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import networkx as nx\n",
    "import os,sys\n",
    "\n",
    "\n",
    "notebook_path = os.path.abspath(\"\")\n",
    "sys.path.append(os.path.abspath(os.path.join(notebook_path, '..')))\n",
    "from engine.core_rec import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import custom modules\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Workaround for __file__ not being defined in Jupyter notebooks\n",
    "notebook_path = os.path.abspath(\"\")\n",
    "sys.path.append(os.path.abspath(os.path.join(notebook_path, '..')))\n",
    "\n",
    "\n",
    "# Load the Cora dataset\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "data = dataset[0]\n",
    "\n",
    "# Convert data to torch tensors\n",
    "x = data.x\n",
    "edge_index = data.edge_index\n",
    "\n",
    "# Create a PyTorch Geometric Data object\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "# Add train_mask and test_mask\n",
    "num_nodes = x.size(0)\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "train_mask[:int(0.8 * num_nodes)] = True\n",
    "test_mask = ~train_mask\n",
    "\n",
    "data.train_mask = train_mask\n",
    "data.test_mask = test_mask\n",
    "\n",
    "# Add labels (y) if not already present\n",
    "num_classes = dataset.num_classes\n",
    "data.y = data.y if data.y is not None else torch.randint(0, num_classes, (num_nodes,), dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_matrix = nx.to_numpy_array(nx.from_edgelist(edge_index.t().tolist()))\n",
    "train_dataset = GraphDataset(adj_matrix[train_mask])\n",
    "test_dataset = GraphDataset(adj_matrix[test_mask])\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GraphTransformerV2.__init__() missing 1 required positional argument: 'output_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m d_feedforward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m\n\u001b[1;32m      6\u001b[0m input_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2708\u001b[39m \u001b[38;5;66;03m# Ensure this matches the number of features in the dataset\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m GraphTransformerV2(num_layers, d_model, num_heads, d_feedforward, input_dim)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Define the loss function and optimizer\u001b[39;00m\n\u001b[1;32m     10\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n",
      "\u001b[0;31mTypeError\u001b[0m: GraphTransformerV2.__init__() missing 1 required positional argument: 'output_dim'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the model\n",
    "num_layers = 1\n",
    "d_model = 128\n",
    "num_heads = 8\n",
    "d_feedforward = 512\n",
    "input_dim = 2708 # Ensure this matches the number of features in the dataset\n",
    "model = GraphTransformerV2(num_layers, d_model, num_heads, d_feedforward, input_dim)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs=100)\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        # print(f\"Input shape: {inputs.shape}\")  # Add this line to check the input shape\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        # print(f\"Preds shape: {preds.shape}, Targets shape: {targets.shape}\")  # Debugging shapes\n",
    "        targets = torch.argmax(targets, dim=1)  # Convert one-hot encoded targets to class indices\n",
    "        all_preds.extend(preds.cpu().numpy().flatten())  # Ensure preds are flattened\n",
    "        all_labels.extend(targets.cpu().numpy().flatten())  # Ensure targets are flattened\n",
    "        # print(f\"Current length of all_preds: {len(all_preds)}, all_labels: {len(all_labels)}\")  # Debugging lengths\n",
    "\n",
    "# Convert to numpy arrays\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Debugging: Print final lengths of all_preds and all_labels\n",
    "# print(f\"Final length of all_preds: {len(all_preds)}\")\n",
    "# print(f\"Final length of all_labels: {len(all_labels)}\")\n",
    "\n",
    "# Ensure both arrays are 1-dimensional\n",
    "all_preds = all_preds.flatten()\n",
    "all_labels = all_labels.flatten()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
